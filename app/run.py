# !/usr/bin/env python3
# -*- coding: utf-8 -*-
from flask import (
    json,
    Flask,
    url_for,
    session,
    jsonify,
    request,
    redirect,
    Response,
    render_template,
    send_from_directory,
    stream_with_context,
)
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from sdk.cloudsaver import CloudSaver
from datetime import timedelta, datetime
import subprocess
import requests
import hashlib
import logging
import base64
import sys
import os
import re
import random
import time
import treelib

parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
sys.path.insert(0, parent_dir)
from quark_auto_save import Quark
from quark_auto_save import Config, format_bytes

# æ·»åŠ å¯¼å…¥å…¨å±€extract_episode_numberå’Œsort_file_by_nameå‡½æ•°
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from quark_auto_save import extract_episode_number, sort_file_by_name, chinese_to_arabic, is_date_format

# å¯¼å…¥æ•°æ®åº“æ¨¡å—
try:
    # å…ˆå°è¯•ç›¸å¯¹å¯¼å…¥
    from sdk.db import RecordDB
except ImportError:
    try:
        # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ä»appåŒ…å¯¼å…¥
        from app.sdk.db import RecordDB
    except ImportError:
        # å¦‚æœæ²¡æœ‰æ•°æ®åº“æ¨¡å—ï¼Œå®šä¹‰ä¸€ä¸ªç©ºç±»
        class RecordDB:
            def __init__(self, *args, **kwargs):
                pass
            
            def get_records(self, *args, **kwargs):
                return {"records": [], "pagination": {"total_records": 0, "total_pages": 0, "current_page": 1, "page_size": 20}}

# å¯¼å…¥å·¥å…·å‡½æ•°
try:
    # å…ˆå°è¯•ç›¸å¯¹å¯¼å…¥
    from sdk.utils import format_bytes, get_file_icon, format_file_display
except ImportError:
    try:
        # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ä»appåŒ…å¯¼å…¥
        from app.sdk.utils import format_bytes, get_file_icon, format_file_display
    except ImportError:
        # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å®ç°æˆ–ä»quark_auto_saveå¯¼å…¥
        # format_byteså·²ä»quark_auto_saveå¯¼å…¥
        def get_file_icon(file_name, is_dir=False):
            return "ğŸ“„" if not is_dir else "ğŸ“"
            
        def format_file_display(prefix, icon, name):
            return f"{prefix}{icon} {name}"


def get_app_ver():
    BUILD_SHA = os.environ.get("BUILD_SHA", "")
    BUILD_TAG = os.environ.get("BUILD_TAG", "")
    if BUILD_TAG[:1] == "v":
        return BUILD_TAG
    elif BUILD_SHA:
        return f"{BUILD_TAG}({BUILD_SHA[:7]})"
    else:
        return "dev"


# æ–‡ä»¶è·¯å¾„
PYTHON_PATH = "python3" if os.path.exists("/usr/bin/python3") else "python"
SCRIPT_PATH = os.environ.get("SCRIPT_PATH", "./quark_auto_save.py")
CONFIG_PATH = os.environ.get("CONFIG_PATH", "./config/quark_config.json")
PLUGIN_FLAGS = os.environ.get("PLUGIN_FLAGS", "")
DEBUG = os.environ.get("DEBUG", "false").lower() == "true"
# ä»ç¯å¢ƒå˜é‡è·å–ç«¯å£ï¼Œé»˜è®¤ä¸º5005
PORT = int(os.environ.get("PORT", "5005"))

config_data = {}
task_plugins_config_default = {}

app = Flask(__name__)
app.config["APP_VERSION"] = get_app_ver()
app.secret_key = "ca943f6db6dd34823d36ab08d8d6f65d"
app.config["SESSION_COOKIE_NAME"] = "QUARK_AUTO_SAVE_SESSION"
app.config["PERMANENT_SESSION_LIFETIME"] = timedelta(days=31)
app.json.ensure_ascii = False
app.json.sort_keys = False
app.jinja_env.variable_start_string = "[["
app.jinja_env.variable_end_string = "]]"

scheduler = BackgroundScheduler()
logging.basicConfig(
    level=logging.DEBUG if DEBUG else logging.INFO,
    format="[%(asctime)s][%(levelname)s] %(message)s",
    datefmt="%m-%d %H:%M:%S",
)
# è¿‡æ»¤werkzeugæ—¥å¿—è¾“å‡º
if not DEBUG:
    logging.getLogger("werkzeug").setLevel(logging.ERROR)


def gen_md5(string):
    md5 = hashlib.md5()
    md5.update(string.encode("utf-8"))
    return md5.hexdigest()


def get_login_token():
    username = config_data["webui"]["username"]
    password = config_data["webui"]["password"]
    return gen_md5(f"token{username}{password}+-*/")[8:24]


def is_login():
    login_token = get_login_token()
    if session.get("token") == login_token or request.args.get("token") == login_token:
        return True
    else:
        return False


# è®¾ç½®icon
@app.route("/favicon.ico")
def favicon():
    return send_from_directory(
        os.path.join(app.root_path, "static"),
        "favicon.ico",
        mimetype="image/vnd.microsoft.icon",
    )


# ç™»å½•é¡µé¢
@app.route("/login", methods=["GET", "POST"])
def login():
    if request.method == "POST":
        username = config_data["webui"]["username"]
        password = config_data["webui"]["password"]
        input_username = request.form.get("username")
        input_password = request.form.get("password")
        
        # éªŒè¯ç”¨æˆ·åå’Œå¯†ç 
        if not input_username or not input_password:
            logging.info(">>> ç™»å½•å¤±è´¥ï¼šç”¨æˆ·åæˆ–å¯†ç ä¸ºç©º")
            return render_template("login.html", message="ç”¨æˆ·åå’Œå¯†ç ä¸èƒ½ä¸ºç©º")
        elif username != input_username:
            logging.info(f">>> ç™»å½•å¤±è´¥ï¼šç”¨æˆ·åé”™è¯¯ {input_username}")
            return render_template("login.html", message="ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")
        elif password != input_password:
            logging.info(f">>> ç”¨æˆ· {input_username} ç™»å½•å¤±è´¥ï¼šå¯†ç é”™è¯¯")
            return render_template("login.html", message="ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")
        else:
            logging.info(f">>> ç”¨æˆ· {username} ç™»å½•æˆåŠŸ")
            session.permanent = True
            session["token"] = get_login_token()
            return redirect(url_for("index"))

    if is_login():
        return redirect(url_for("index"))
    return render_template("login.html", error=None)


# é€€å‡ºç™»å½•
@app.route("/logout")
def logout():
    session.pop("token", None)
    return redirect(url_for("login"))


# ç®¡ç†é¡µé¢
@app.route("/")
def index():
    if not is_login():
        return redirect(url_for("login"))
    return render_template(
        "index.html", version=app.config["APP_VERSION"], plugin_flags=PLUGIN_FLAGS
    )


# è·å–é…ç½®æ•°æ®
@app.route("/data")
def get_data():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    data = Config.read_json(CONFIG_PATH)
    # å‘é€webuiä¿¡æ¯ï¼Œä½†ä¸å‘é€å¯†ç åŸæ–‡
    data["webui"] = {
        "username": config_data["webui"]["username"],
        "password": config_data["webui"]["password"]
    }
    data["api_token"] = get_login_token()
    data["task_plugins_config_default"] = task_plugins_config_default
    return jsonify({"success": True, "data": data})


def sync_task_plugins_config():
    """åŒæ­¥æ›´æ–°æ‰€æœ‰ä»»åŠ¡çš„æ’ä»¶é…ç½®
    
    1. æ£€æŸ¥æ¯ä¸ªä»»åŠ¡çš„æ’ä»¶é…ç½®
    2. å¦‚æœæ’ä»¶é…ç½®ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
    3. å¦‚æœæ’ä»¶é…ç½®å­˜åœ¨ä½†ç¼ºå°‘æ–°çš„é…ç½®é¡¹ï¼Œæ·»åŠ é»˜è®¤å€¼
    4. ä¿ç•™åŸæœ‰çš„è‡ªå®šä¹‰é…ç½®
    5. åªå¤„ç†å·²å¯ç”¨çš„æ’ä»¶ï¼ˆé€šè¿‡PLUGIN_FLAGSæ£€æŸ¥ï¼‰
    6. æ¸…ç†è¢«ç¦ç”¨æ’ä»¶çš„é…ç½®
    """
    global config_data, task_plugins_config_default
    
    # å¦‚æœæ²¡æœ‰ä»»åŠ¡åˆ—è¡¨ï¼Œç›´æ¥è¿”å›
    if not config_data.get("tasklist"):
        return
        
    # è·å–ç¦ç”¨çš„æ’ä»¶åˆ—è¡¨
    disabled_plugins = set()
    if PLUGIN_FLAGS:
        disabled_plugins = {name.lstrip('-') for name in PLUGIN_FLAGS.split(',')}
        
    # éå†æ‰€æœ‰ä»»åŠ¡
    for task in config_data["tasklist"]:
        # ç¡®ä¿ä»»åŠ¡æœ‰additionå­—æ®µ
        if "addition" not in task:
            task["addition"] = {}
            
        # æ¸…ç†è¢«ç¦ç”¨æ’ä»¶çš„é…ç½®
        for plugin_name in list(task["addition"].keys()):
            if plugin_name in disabled_plugins:
                del task["addition"][plugin_name]
            
        # éå†æ‰€æœ‰æ’ä»¶çš„é»˜è®¤é…ç½®
        for plugin_name, default_config in task_plugins_config_default.items():
            # è·³è¿‡è¢«ç¦ç”¨çš„æ’ä»¶
            if plugin_name in disabled_plugins:
                continue
                
            # å¦‚æœä»»åŠ¡ä¸­æ²¡æœ‰è¯¥æ’ä»¶çš„é…ç½®ï¼Œæ·»åŠ é»˜è®¤é…ç½®
            if plugin_name not in task["addition"]:
                task["addition"][plugin_name] = default_config.copy()
            else:
                # å¦‚æœä»»åŠ¡ä¸­æœ‰è¯¥æ’ä»¶çš„é…ç½®ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„é…ç½®é¡¹
                current_config = task["addition"][plugin_name]
                # ç¡®ä¿current_configæ˜¯å­—å…¸ç±»å‹
                if not isinstance(current_config, dict):
                    # å¦‚æœä¸æ˜¯å­—å…¸ç±»å‹ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
                    task["addition"][plugin_name] = default_config.copy()
                    continue
                    
                # éå†é»˜è®¤é…ç½®çš„æ¯ä¸ªé”®å€¼å¯¹
                for key, default_value in default_config.items():
                    if key not in current_config:
                        current_config[key] = default_value


# æ›´æ–°æ•°æ®
@app.route("/update", methods=["POST"])
def update():
    global config_data
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    dont_save_keys = ["task_plugins_config_default", "api_token"]
    for key, value in request.json.items():
        if key not in dont_save_keys:
            if key == "webui":
                # æ›´æ–°webuiå‡­æ®
                config_data["webui"]["username"] = value.get("username", config_data["webui"]["username"])
                config_data["webui"]["password"] = value.get("password", config_data["webui"]["password"])
            else:
                config_data.update({key: value})
    
    # åŒæ­¥æ›´æ–°ä»»åŠ¡çš„æ’ä»¶é…ç½®
    sync_task_plugins_config()
    
    Config.write_json(CONFIG_PATH, config_data)
    # æ›´æ–°session tokenï¼Œç¡®ä¿å½“å‰ä¼šè¯åœ¨ç”¨æˆ·åå¯†ç æ›´æ”¹åä»ç„¶æœ‰æ•ˆ
    session["token"] = get_login_token()
    # é‡æ–°åŠ è½½ä»»åŠ¡
    if reload_tasks():
        logging.info(f">>> é…ç½®æ›´æ–°æˆåŠŸ")
        return jsonify({"success": True, "message": "é…ç½®æ›´æ–°æˆåŠŸ"})
    else:
        logging.info(f">>> é…ç½®æ›´æ–°å¤±è´¥")
        return jsonify({"success": False, "message": "é…ç½®æ›´æ–°å¤±è´¥"})


# å¤„ç†è¿è¡Œè„šæœ¬è¯·æ±‚
@app.route("/run_script_now", methods=["POST"])
def run_script_now():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    tasklist = request.json.get("tasklist", [])
    command = [PYTHON_PATH, "-u", SCRIPT_PATH, CONFIG_PATH]
    logging.info(
        f">>> æ‰‹åŠ¨è¿è¡Œä»»åŠ¡ [{tasklist[0].get('taskname') if len(tasklist)>0 else 'ALL'}] å¼€å§‹æ‰§è¡Œ..."
    )

    def generate_output():
        # è®¾ç½®ç¯å¢ƒå˜é‡
        process_env = os.environ.copy()
        process_env["PYTHONIOENCODING"] = "utf-8"
        if tasklist:
            process_env["TASKLIST"] = json.dumps(tasklist, ensure_ascii=False)
            # æ·»åŠ åŸå§‹ä»»åŠ¡ç´¢å¼•çš„ç¯å¢ƒå˜é‡
            if len(tasklist) == 1 and 'original_index' in request.json:
                process_env["ORIGINAL_TASK_INDEX"] = str(request.json['original_index'])
        process = subprocess.Popen(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            encoding="utf-8",
            errors="replace",
            bufsize=1,
            env=process_env,
        )
        try:
            for line in iter(process.stdout.readline, ""):
                logging.info(line.strip())
                yield f"data: {line}\n\n"
            yield "data: [DONE]\n\n"
        finally:
            process.stdout.close()
            process.wait()

    return Response(
        stream_with_context(generate_output()),
        content_type="text/event-stream;charset=utf-8",
    )


# åˆ·æ–°Plexåª’ä½“åº“
@app.route("/refresh_plex_library", methods=["POST"])
def refresh_plex_library():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    task_index = request.json.get("task_index")
    if task_index is None:
        return jsonify({"success": False, "message": "ç¼ºå°‘ä»»åŠ¡ç´¢å¼•"})
        
    # è·å–ä»»åŠ¡ä¿¡æ¯
    task = config_data["tasklist"][task_index]
    if not task.get("savepath"):
        return jsonify({"success": False, "message": "ä»»åŠ¡æ²¡æœ‰ä¿å­˜è·¯å¾„"})
        
    # å¯¼å…¥Plexæ’ä»¶
    from plugins.plex import Plex
    
    # åˆå§‹åŒ–Plexæ’ä»¶
    plex = Plex(**config_data["plugins"]["plex"])
    if not plex.is_active:
        return jsonify({"success": False, "message": "Plex æ’ä»¶æœªæ­£ç¡®é…ç½®"})
        
    # æ‰§è¡Œåˆ·æ–°
    plex.run(task)
    
    return jsonify({"success": True, "message": "æˆåŠŸåˆ·æ–° Plex åª’ä½“åº“"})


# åˆ·æ–°AListç›®å½•
@app.route("/refresh_alist_directory", methods=["POST"])
def refresh_alist_directory():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    task_index = request.json.get("task_index")
    if task_index is None:
        return jsonify({"success": False, "message": "ç¼ºå°‘ä»»åŠ¡ç´¢å¼•"})
        
    # è·å–ä»»åŠ¡ä¿¡æ¯
    task = config_data["tasklist"][task_index]
    if not task.get("savepath"):
        return jsonify({"success": False, "message": "ä»»åŠ¡æ²¡æœ‰ä¿å­˜è·¯å¾„"})
        
    # å¯¼å…¥AListæ’ä»¶
    from plugins.alist import Alist
    
    # åˆå§‹åŒ–AListæ’ä»¶
    alist = Alist(**config_data["plugins"]["alist"])
    if not alist.is_active:
        return jsonify({"success": False, "message": "AList æ’ä»¶æœªæ­£ç¡®é…ç½®"})
        
    # æ‰§è¡Œåˆ·æ–°
    alist.run(task)
    
    return jsonify({"success": True, "message": "æˆåŠŸåˆ·æ–° AList ç›®å½•"})


@app.route("/task_suggestions")
def get_task_suggestions():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    query = request.args.get("q", "").lower()
    deep = request.args.get("d", "").lower()
    
    # æå–å‰§åï¼Œå»é™¤å­£æ•°ä¿¡æ¯
    def extract_show_name(task_name):
        # æ¸…ç†ä»»åŠ¡åç§°ä¸­çš„è¿ç»­ç©ºæ ¼å’Œç‰¹æ®Šç¬¦å·
        clean_name = task_name.replace('\u3000', ' ').replace('\t', ' ')
        clean_name = re.sub(r'\s+', ' ', clean_name).strip()
        
        # åŒ¹é…å¸¸è§çš„å­£æ•°æ ¼å¼
        # ä¾‹å¦‚ï¼šé»‘é•œ - S07ã€äººç”Ÿè‹¥å¦‚åˆè§ - S01ã€æŠ˜è…°.S01ã€éŸ³ä½ è€Œæ¥-S02ã€å¿«ä¹çš„å¤§äºº S02
        season_patterns = [
            r'^(.*?)[\s\.\-_]+S\d+$',  # é»‘é•œ - S07ã€æŠ˜è…°.S01ã€éŸ³ä½ è€Œæ¥-S02
            r'^(.*?)[\s\.\-_]+Season\s*\d+$',  # é»‘é•œ - Season 1
            r'^(.*?)\s+S\d+$',  # å¿«ä¹çš„å¤§äºº S02
            r'^(.*?)[\s\.\-_]+S\d+E\d+$',  # å¤„ç† S01E01 æ ¼å¼
            r'^(.*?)\s+ç¬¬\s*\d+\s*å­£$',  # å¤„ç† ç¬¬Nå­£ æ ¼å¼
            r'^(.*?)[\s\.\-_]+ç¬¬\s*\d+\s*å­£$',  # å¤„ç† - ç¬¬Nå­£ æ ¼å¼
            r'^(.*?)\s+ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åé›¶]+å­£$',  # å¤„ç† ç¬¬ä¸€å­£ã€ç¬¬äºŒå­£ æ ¼å¼
            r'^(.*?)[\s\.\-_]+ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åé›¶]+å­£$',  # å¤„ç† - ç¬¬ä¸€å­£ã€- ç¬¬äºŒå­£ æ ¼å¼
        ]
        
        for pattern in season_patterns:
            match = re.match(pattern, clean_name, re.IGNORECASE)
            if match:
                show_name = match.group(1).strip()
                # å»é™¤æœ«å°¾å¯èƒ½æ®‹ç•™çš„åˆ†éš”ç¬¦
                show_name = re.sub(r'[\s\.\-_]+$', '', show_name)
                return show_name
                
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°å­£æ•°æ ¼å¼ï¼Œè¿”å›åŸåç§°
        return clean_name
    
    # å¤„ç†æœç´¢å…³é”®è¯ï¼Œæå–å‰§å
    search_query = extract_show_name(query)
    
    try:
        cs_data = config_data.get("source", {}).get("cloudsaver", {})
        if (
            cs_data.get("server")
            and cs_data.get("username")
            and cs_data.get("password")
        ):
            cs = CloudSaver(cs_data.get("server"))
            cs.set_auth(
                cs_data.get("username", ""),
                cs_data.get("password", ""),
                cs_data.get("token", ""),
            )
            # ä½¿ç”¨å¤„ç†åçš„æœç´¢å…³é”®è¯
            search = cs.auto_login_search(search_query)
            if search.get("success"):
                if search.get("new_token"):
                    cs_data["token"] = search.get("new_token")
                    Config.write_json(CONFIG_PATH, config_data)
                search_results = cs.clean_search_results(search.get("data"))
                # åœ¨è¿”å›ç»“æœä¸­æ·»åŠ å®é™…ä½¿ç”¨çš„æœç´¢å…³é”®è¯
                return jsonify(
                    {
                        "success": True, 
                        "source": "CloudSaver", 
                        "data": search_results
                    }
                )
            else:
                return jsonify({"success": True, "message": search.get("message")})
        else:
            base_url = base64.b64decode("aHR0cHM6Ly9zLjkxNzc4OC54eXo=").decode()
            # ä½¿ç”¨å¤„ç†åçš„æœç´¢å…³é”®è¯
            url = f"{base_url}/task_suggestions?q={search_query}&d={deep}"
            response = requests.get(url)
            return jsonify(
                {
                    "success": True, 
                    "source": "ç½‘ç»œå…¬å¼€", 
                    "data": response.json()
                }
            )
    except Exception as e:
        return jsonify({"success": True, "message": f"error: {str(e)}"})


# è·å–åˆ†äº«è¯¦æƒ…æ¥å£
@app.route("/get_share_detail", methods=["GET", "POST"])
def get_share_detail():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    # æ”¯æŒGETå’ŒPOSTè¯·æ±‚
    if request.method == "GET":
        shareurl = request.args.get("shareurl", "")
        stoken = request.args.get("stoken", "")
    else:
        shareurl = request.json.get("shareurl", "")
        stoken = request.json.get("stoken", "")
        
    account = Quark("", 0)
    # è®¾ç½®accountçš„å¿…è¦å±æ€§
    account.episode_patterns = request.json.get("regex", {}).get("episode_patterns", []) if request.method == "POST" else []
    
    pwd_id, passcode, pdir_fid, paths = account.extract_url(shareurl)
    if not stoken:
        is_sharing, stoken = account.get_stoken(pwd_id, passcode)
        if not is_sharing:
            return jsonify({"success": False, "data": {"error": stoken}})
    share_detail = account.get_detail(pwd_id, stoken, pdir_fid, _fetch_share=1)
    share_detail["paths"] = paths
    share_detail["stoken"] = stoken

    # å¦‚æœæ˜¯GETè¯·æ±‚æˆ–è€…ä¸éœ€è¦é¢„è§ˆæ­£åˆ™ï¼Œç›´æ¥è¿”å›åˆ†äº«è¯¦æƒ…
    if request.method == "GET" or not request.json.get("regex"):
        return jsonify({"success": True, "data": share_detail})
        
    # æ­£åˆ™å‘½åé¢„è§ˆ
    def preview_regex(share_detail):
        regex = request.json.get("regex")
        # æ£€æŸ¥æ˜¯å¦ä¸ºé¡ºåºå‘½åæ¨¡å¼
        if regex.get("use_sequence_naming") and regex.get("sequence_naming"):
            # é¡ºåºå‘½åæ¨¡å¼é¢„è§ˆ
            sequence_pattern = regex.get("sequence_naming")
            current_sequence = 1
            
            # æ„å»ºé¡ºåºå‘½åçš„æ­£åˆ™è¡¨è¾¾å¼
            if sequence_pattern == "{}":
                # å¯¹äºå•ç‹¬çš„{}ï¼Œä½¿ç”¨ç‰¹æ®ŠåŒ¹é…
                regex_pattern = "(\\d+)"
            else:
                regex_pattern = re.escape(sequence_pattern).replace('\\{\\}', '(\\d+)')
            
            # å®ç°ä¸å®é™…é‡å‘½åç›¸åŒçš„æ’åºç®—æ³•
            def extract_sort_value(file):
                return sort_file_by_name(file)
            
            # è¿‡æ»¤å‡ºéç›®å½•æ–‡ä»¶ï¼Œå¹¶ä¸”æ’é™¤å·²ç»ç¬¦åˆå‘½åè§„åˆ™çš„æ–‡ä»¶
            files_to_process = []
            for f in share_detail["list"]:
                if f["dir"]:
                    continue  # è·³è¿‡ç›®å½•
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç¬¦åˆå‘½åè§„åˆ™
                if sequence_pattern == "{}":
                    # å¯¹äºå•ç‹¬çš„{}ï¼Œæ£€æŸ¥æ–‡ä»¶åæ˜¯å¦ä¸ºçº¯æ•°å­—
                    file_name_without_ext = os.path.splitext(f["file_name"])[0]
                    if file_name_without_ext.isdigit():
                        # å¢åŠ åˆ¤æ–­ï¼šå¦‚æœæ˜¯æ—¥æœŸæ ¼å¼çš„çº¯æ•°å­—ï¼Œä¸è§†ä¸ºå·²å‘½å
                        if not is_date_format(file_name_without_ext):
                            continue  # è·³è¿‡å·²ç¬¦åˆå‘½åè§„åˆ™çš„æ–‡ä»¶
                elif re.match(regex_pattern, f["file_name"]):
                    continue  # è·³è¿‡å·²ç¬¦åˆå‘½åè§„åˆ™çš„æ–‡ä»¶
                
                # æ·»åŠ åˆ°å¾…å¤„ç†æ–‡ä»¶åˆ—è¡¨
                files_to_process.append(f)
            
            # æ ¹æ®æå–çš„æ’åºå€¼è¿›è¡Œæ’åº
            sorted_files = sorted(files_to_process, key=extract_sort_value)
            
            # åº”ç”¨è¿‡æ»¤è¯è¿‡æ»¤
            filterwords = regex.get("filterwords", "")
            if filterwords:
                # åŒæ—¶æ”¯æŒä¸­è‹±æ–‡é€—å·åˆ†éš”
                filterwords = filterwords.replace("ï¼Œ", ",")
                filterwords_list = [word.strip() for word in filterwords.split(',')]
                for item in sorted_files:
                    # è¢«è¿‡æ»¤çš„æ–‡ä»¶ä¸ä¼šæœ‰file_name_reï¼Œä¸ä¸åŒ¹é…æ­£åˆ™çš„æ–‡ä»¶æ˜¾ç¤ºä¸€è‡´
                    if any(word in item['file_name'] for word in filterwords_list):
                        item["filtered"] = True
            
            # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ†é…åºå·
            for file in sorted_files:
                if not file.get("filtered"):
                    # è·å–æ–‡ä»¶æ‰©å±•å
                    file_ext = os.path.splitext(file["file_name"])[1]
                    # ç”Ÿæˆé¢„è§ˆæ–‡ä»¶å
                    if sequence_pattern == "{}":
                        # å¯¹äºå•ç‹¬çš„{}ï¼Œç›´æ¥ä½¿ç”¨æ•°å­—åºå·ä½œä¸ºæ–‡ä»¶å
                        file["file_name_re"] = f"{current_sequence:02d}{file_ext}"
                    else:
                        # æ›¿æ¢æ‰€æœ‰çš„{}ä¸ºå½“å‰åºå·
                        file["file_name_re"] = sequence_pattern.replace("{}", f"{current_sequence:02d}") + file_ext
                    current_sequence += 1
            
            return share_detail
        elif regex.get("use_episode_naming") and regex.get("episode_naming"):
            # å‰§é›†å‘½åæ¨¡å¼é¢„è§ˆ
            episode_pattern = regex.get("episode_naming")
            episode_patterns = regex.get("episode_patterns", [])
            
            # æ·»åŠ ä¸­æ–‡æ•°å­—åŒ¹é…æ¨¡å¼
            chinese_patterns = [
                {"regex": r'ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)é›†'},
                {"regex": r'ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)æœŸ'},
                {"regex": r'ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)è¯'},
                {"regex": r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)é›†'},
                {"regex": r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)æœŸ'},
                {"regex": r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)è¯'}
            ]
            
            # åˆå¹¶ä¸­æ–‡æ¨¡å¼åˆ°episode_patterns
            if episode_patterns:
                episode_patterns.extend(chinese_patterns)
            else:
                episode_patterns = chinese_patterns
            
            # è°ƒç”¨å…¨å±€çš„é›†ç¼–å·æå–å‡½æ•°
            def extract_episode_number_local(filename):
                return extract_episode_number(filename, episode_patterns=episode_patterns)
            
            # æ„å»ºå‰§é›†å‘½åçš„æ­£åˆ™è¡¨è¾¾å¼ (ä¸»è¦ç”¨äºæ£€æµ‹å·²å‘½åæ–‡ä»¶)
            if episode_pattern == "[]":
                # å¯¹äºå•ç‹¬çš„[]ï¼Œä½¿ç”¨ç‰¹æ®ŠåŒ¹é…
                regex_pattern = "^(\\d+)$"  # åŒ¹é…çº¯æ•°å­—æ–‡ä»¶å
            elif "[]" in episode_pattern:
                # ç‰¹æ®Šå¤„ç†E[]ã€EP[]ç­‰å¸¸è§æ ¼å¼ï¼Œä½¿ç”¨æ›´å®½æ¾çš„åŒ¹é…æ–¹å¼
                if episode_pattern == "E[]":
                    # å¯¹äºE[]æ ¼å¼ï¼Œåªæ£€æŸ¥æ–‡ä»¶åä¸­æ˜¯å¦åŒ…å«å½¢å¦‚E01çš„éƒ¨åˆ†
                    regex_pattern = "^E(\\d+)$"  # åªåŒ¹é…çº¯E+æ•°å­—çš„æ–‡ä»¶åæ ¼å¼
                elif episode_pattern == "EP[]":
                    # å¯¹äºEP[]æ ¼å¼ï¼Œåªæ£€æŸ¥æ–‡ä»¶åä¸­æ˜¯å¦åŒ…å«å½¢å¦‚EP01çš„éƒ¨åˆ†
                    regex_pattern = "^EP(\\d+)$"  # åªåŒ¹é…çº¯EP+æ•°å­—çš„æ–‡ä»¶åæ ¼å¼
                else:
                    # å¯¹äºå…¶ä»–å¸¦[]çš„æ ¼å¼ï¼Œä½¿ç”¨å¸¸è§„è½¬ä¹‰å’Œæ›¿æ¢
                    regex_pattern = re.escape(episode_pattern).replace('\\[\\]', '(\\d+)')
            else:
                # å¦‚æœè¾“å…¥æ¨¡å¼ä¸åŒ…å«[]ï¼Œåˆ™ä½¿ç”¨ç®€å•åŒ¹é…æ¨¡å¼ï¼Œé¿å…æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯
                regex_pattern = "^" + re.escape(episode_pattern) + "(\\d+)$"
            
            # å®ç°é«˜çº§æ’åºç®—æ³•
            def extract_sorting_value(file):
                if file["dir"]:  # è·³è¿‡æ–‡ä»¶å¤¹
                    return (float('inf'), 0, 0, 0)  # è¿”å›å…ƒç»„ä»¥ç¡®ä¿ç±»å‹ä¸€è‡´æ€§
                
                filename = file["file_name"]
                
                # å°è¯•è·å–å‰§é›†åºå·
                episode_num = extract_episode_number_local(filename)
                if episode_num is not None:
                    # è¿”å›å…ƒç»„ä»¥ç¡®ä¿ç±»å‹ä¸€è‡´æ€§
                    return (0, episode_num, 0, 0)
                
                # å¦‚æœæ— æ³•æå–å‰§é›†å·ï¼Œåˆ™ä½¿ç”¨é€šç”¨çš„æ’åºå‡½æ•°
                return sort_file_by_name(file)
            
            # è¿‡æ»¤å‡ºéç›®å½•æ–‡ä»¶ï¼Œå¹¶ä¸”æ’é™¤å·²ç»ç¬¦åˆå‘½åè§„åˆ™çš„æ–‡ä»¶
            files_to_process = []
            for f in share_detail["list"]:
                if f["dir"]:
                    continue  # è·³è¿‡ç›®å½•
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç¬¦åˆå‘½åè§„åˆ™
                if episode_pattern == "[]":
                    # å¯¹äºå•ç‹¬çš„[]ï¼Œæ£€æŸ¥æ–‡ä»¶åæ˜¯å¦ä¸ºçº¯æ•°å­—
                    file_name_without_ext = os.path.splitext(f["file_name"])[0]
                    if file_name_without_ext.isdigit():
                        # å¢åŠ åˆ¤æ–­ï¼šå¦‚æœæ˜¯æ—¥æœŸæ ¼å¼çš„çº¯æ•°å­—ï¼Œä¸è§†ä¸ºå·²å‘½å
                        if not is_date_format(file_name_without_ext):
                            continue  # è·³è¿‡å·²ç¬¦åˆå‘½åè§„åˆ™çš„æ–‡ä»¶
                elif re.match(regex_pattern, f["file_name"]):
                    continue  # è·³è¿‡å·²ç¬¦åˆå‘½åè§„åˆ™çš„æ–‡ä»¶
                
                # æ·»åŠ åˆ°å¾…å¤„ç†æ–‡ä»¶åˆ—è¡¨
                files_to_process.append(f)
            
            # æ ¹æ®æå–çš„æ’åºå€¼è¿›è¡Œæ’åº
            sorted_files = sorted(files_to_process, key=extract_sorting_value)
            
            # åº”ç”¨è¿‡æ»¤è¯è¿‡æ»¤
            filterwords = regex.get("filterwords", "")
            if filterwords:
                # åŒæ—¶æ”¯æŒä¸­è‹±æ–‡é€—å·åˆ†éš”
                filterwords = filterwords.replace("ï¼Œ", ",")
                filterwords_list = [word.strip() for word in filterwords.split(',')]
                for item in sorted_files:
                    # è¢«è¿‡æ»¤çš„æ–‡ä»¶ä¸ä¼šæœ‰file_name_reï¼Œä¸ä¸åŒ¹é…æ­£åˆ™çš„æ–‡ä»¶æ˜¾ç¤ºä¸€è‡´
                    if any(word in item['file_name'] for word in filterwords_list):
                        item["filtered"] = True
            
            # ä¸ºæ¯ä¸ªæ–‡ä»¶ç”Ÿæˆæ–°æ–‡ä»¶åå¹¶å­˜å‚¨å‰§é›†ç¼–å·ç”¨äºæ’åº
            for file in sorted_files:
                if not file.get("filtered"):
                    # è·å–æ–‡ä»¶æ‰©å±•å
                    file_ext = os.path.splitext(file["file_name"])[1]
                    # å°è¯•æå–å‰§é›†å·
                    episode_num = extract_episode_number_local(file["file_name"])
                    if episode_num is not None:
                        # ç”Ÿæˆé¢„è§ˆæ–‡ä»¶å
                        if episode_pattern == "[]":
                            # å¯¹äºå•ç‹¬çš„[]ï¼Œç›´æ¥ä½¿ç”¨æ•°å­—åºå·ä½œä¸ºæ–‡ä»¶å
                            file["file_name_re"] = f"{episode_num:02d}{file_ext}"
                        else:
                            file["file_name_re"] = episode_pattern.replace("[]", f"{episode_num:02d}") + file_ext
                        # å­˜å‚¨åŸå§‹çš„å‰§é›†ç¼–å·ï¼Œç”¨äºæ•°å€¼æ’åº
                        file["episode_number"] = episode_num
                    else:
                        # æ— æ³•æå–å‰§é›†å·ï¼Œæ ‡è®°ä¸ºæ— æ³•å¤„ç†
                        file["file_name_re"] = "âŒ æ— æ³•è¯†åˆ«å‰§é›†å·"
                        file["episode_number"] = 9999999  # ç»™ä¸€ä¸ªå¾ˆå¤§çš„å€¼ï¼Œç¡®ä¿æ’åœ¨æœ€å
                    
            return share_detail
        else:
            # æ™®é€šæ­£åˆ™å‘½åé¢„è§ˆ
            pattern, replace = account.magic_regex_func(
                regex.get("pattern", ""),
                regex.get("replace", ""),
                regex.get("taskname", ""),
                regex.get("magic_regex", {}),
            )
            
            # åº”ç”¨è¿‡æ»¤è¯è¿‡æ»¤
            filterwords = regex.get("filterwords", "")
            if filterwords:
                # åŒæ—¶æ”¯æŒä¸­è‹±æ–‡é€—å·åˆ†éš”
                filterwords = filterwords.replace("ï¼Œ", ",")
                filterwords_list = [word.strip() for word in filterwords.split(',')]
                for item in share_detail["list"]:
                    # è¢«è¿‡æ»¤çš„æ–‡ä»¶ä¸ä¼šæœ‰file_name_reï¼Œä¸ä¸åŒ¹é…æ­£åˆ™çš„æ–‡ä»¶æ˜¾ç¤ºä¸€è‡´
                    if any(word in item['file_name'] for word in filterwords_list):
                        item["filtered"] = True
                
            # åº”ç”¨æ­£åˆ™å‘½å
            for item in share_detail["list"]:
                # åªå¯¹æœªè¢«è¿‡æ»¤çš„æ–‡ä»¶åº”ç”¨æ­£åˆ™å‘½å
                if not item.get("filtered") and re.search(pattern, item["file_name"]):
                    file_name = item["file_name"]
                    item["file_name_re"] = (
                        re.sub(pattern, replace, file_name) if replace != "" else file_name
                    )
            return share_detail

    share_detail = preview_regex(share_detail)

    return jsonify({"success": True, "data": share_detail})


@app.route("/get_savepath_detail")
def get_savepath_detail():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    account = Quark(config_data["cookie"][0], 0)
    paths = []
    if path := request.args.get("path"):
        if path == "/":
            fid = 0
        else:
            dir_names = path.split("/")
            if dir_names[0] == "":
                dir_names.pop(0)
            path_fids = []
            current_path = ""
            for dir_name in dir_names:
                current_path += "/" + dir_name
                path_fids.append(current_path)
            if get_fids := account.get_fids(path_fids):
                fid = get_fids[-1]["fid"]
                paths = [
                    {"fid": get_fid["fid"], "name": dir_name}
                    for get_fid, dir_name in zip(get_fids, dir_names)
                ]
            else:
                return jsonify({"success": False, "data": {"error": "è·å–fidå¤±è´¥"}})
    else:
        fid = request.args.get("fid", "0")
    file_list = {
        "list": account.ls_dir(fid),
        "paths": paths,
    }
    return jsonify({"success": True, "data": file_list})


@app.route("/delete_file", methods=["POST"])
def delete_file():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    account = Quark(config_data["cookie"][0], 0)
    if fid := request.json.get("fid"):
        response = account.delete([fid])
        
        # å¤„ç†delete_recordså‚æ•°
        if request.json.get("delete_records") and response.get("code") == 0:
            try:
                # åˆå§‹åŒ–æ•°æ®åº“
                db = RecordDB()
                
                # è·å–save_pathå‚æ•°
                save_path = request.json.get("save_path", "")
                
                # å¦‚æœæ²¡æœ‰æä¾›save_pathï¼Œåˆ™ä¸åˆ é™¤ä»»ä½•è®°å½•
                if not save_path:
                    response["deleted_records"] = 0
                    # logging.info(f">>> åˆ é™¤æ–‡ä»¶ {fid} ä½†æœªæä¾›save_pathï¼Œä¸åˆ é™¤ä»»ä½•è®°å½•")
                    return jsonify(response)
                
                # æŸ¥è¯¢ä¸è¯¥æ–‡ä»¶IDå’Œsave_pathç›¸å…³çš„æ‰€æœ‰è®°å½•
                cursor = db.conn.cursor()
                
                # ä½¿ç”¨file_idå’Œsave_pathè¿›è¡Œç²¾ç¡®åŒ¹é…
                cursor.execute("SELECT id FROM transfer_records WHERE file_id = ? AND save_path = ?", (fid, save_path))
                record_ids = [row[0] for row in cursor.fetchall()]
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„file_idè®°å½•ï¼Œå°è¯•é€šè¿‡æ–‡ä»¶åæŸ¥æ‰¾
                if not record_ids:
                    # è·å–æ–‡ä»¶åï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                    file_name = request.json.get("file_name", "")
                    if file_name:
                        # ä½¿ç”¨æ–‡ä»¶åå’Œsave_pathè¿›è¡Œç²¾ç¡®åŒ¹é…
                        cursor.execute("""
                            SELECT id FROM transfer_records 
                            WHERE (original_name = ? OR renamed_to = ?) 
                            AND save_path = ?
                        """, (file_name, file_name, save_path))
                        
                        record_ids = [row[0] for row in cursor.fetchall()]
                
                # åˆ é™¤æ‰¾åˆ°çš„æ‰€æœ‰è®°å½•
                deleted_count = 0
                for record_id in record_ids:
                    deleted_count += db.delete_record(record_id)
                
                # æ·»åŠ åˆ é™¤è®°å½•çš„ä¿¡æ¯åˆ°å“åº”ä¸­
                response["deleted_records"] = deleted_count
                # logging.info(f">>> åˆ é™¤æ–‡ä»¶ {fid} åŒæ—¶åˆ é™¤äº† {deleted_count} æ¡ç›¸å…³è®°å½•")
                
            except Exception as e:
                logging.error(f">>> åˆ é™¤è®°å½•æ—¶å‡ºé”™: {str(e)}")
                # ä¸å½±å“ä¸»æµç¨‹ï¼Œå³ä½¿åˆ é™¤è®°å½•å¤±è´¥ä¹Ÿè¿”å›æ–‡ä»¶åˆ é™¤æˆåŠŸ
    else:
        response = {"success": False, "message": "ç¼ºå¤±å¿…è¦å­—æ®µ: fid"}
    return jsonify(response)


# æ·»åŠ ä»»åŠ¡æ¥å£
@app.route("/api/add_task", methods=["POST"])
def add_task():
    global config_data
    # éªŒè¯token
    if not is_login():
        return jsonify({"success": False, "code": 1, "message": "æœªç™»å½•"}), 401
    # å¿…é€‰å­—æ®µ
    request_data = request.json
    required_fields = ["taskname", "shareurl", "savepath"]
    for field in required_fields:
        if field not in request_data or not request_data[field]:
            return (
                jsonify(
                    {"success": False, "code": 2, "message": f"ç¼ºå°‘å¿…è¦å­—æ®µ: {field}"}
                ),
                400,
            )
    # æ·»åŠ ä»»åŠ¡
    config_data["tasklist"].append(request_data)
    Config.write_json(CONFIG_PATH, config_data)
    logging.info(f">>> é€šè¿‡APIæ·»åŠ ä»»åŠ¡: {request_data['taskname']}")
    return jsonify(
        {"success": True, "code": 0, "message": "ä»»åŠ¡æ·»åŠ æˆåŠŸ", "data": request_data}
    )


# å®šæ—¶ä»»åŠ¡æ‰§è¡Œçš„å‡½æ•°
def run_python(args):
    logging.info(f">>> å®šæ—¶è¿è¡Œä»»åŠ¡")
    # æ£€æŸ¥æ˜¯å¦éœ€è¦éšæœºå»¶è¿Ÿæ‰§è¡Œ
    if delay := config_data.get("crontab_delay"):
        try:
            delay_seconds = int(delay)
            if delay_seconds > 0:
                # åœ¨0åˆ°è®¾å®šå€¼ä¹‹é—´éšæœºé€‰æ‹©ä¸€ä¸ªå»¶è¿Ÿæ—¶é—´
                random_delay = random.randint(0, delay_seconds)
                logging.info(f">>> éšæœºå»¶è¿Ÿæ‰§è¡Œ {random_delay}ç§’")
                time.sleep(random_delay)
        except (ValueError, TypeError):
            logging.warning(f">>> å»¶è¿Ÿæ‰§è¡Œè®¾ç½®æ— æ•ˆ: {delay}")
    
    os.system(f"{PYTHON_PATH} {args}")


# é‡æ–°åŠ è½½ä»»åŠ¡
def reload_tasks():
    # è¯»å–å®šæ—¶è§„åˆ™
    if crontab := config_data.get("crontab"):
        if scheduler.state == 1:
            scheduler.pause()  # æš‚åœè°ƒåº¦å™¨
        trigger = CronTrigger.from_crontab(crontab)
        scheduler.remove_all_jobs()
        scheduler.add_job(
            run_python,
            trigger=trigger,
            args=[f"{SCRIPT_PATH} {CONFIG_PATH}"],
            id=SCRIPT_PATH,
        )
        if scheduler.state == 0:
            scheduler.start()
        elif scheduler.state == 2:
            scheduler.resume()
        scheduler_state_map = {0: "åœæ­¢", 1: "è¿è¡Œ", 2: "æš‚åœ"}
        logging.info(">>> é‡è½½è°ƒåº¦å™¨")
        logging.info(f"è°ƒåº¦çŠ¶æ€: {scheduler_state_map[scheduler.state]}")
        logging.info(f"å®šæ—¶è§„åˆ™: {crontab}")
        # è®°å½•å»¶è¿Ÿæ‰§è¡Œè®¾ç½®
        if delay := config_data.get("crontab_delay"):
            logging.info(f"å»¶è¿Ÿæ‰§è¡Œ: 0-{delay}ç§’")
        logging.info(f"ç°æœ‰ä»»åŠ¡: {scheduler.get_jobs()}")
        return True
    else:
        logging.info(">>> no crontab")
        return False


def init():
    global config_data, task_plugins_config_default
    logging.info(f">>> åˆå§‹åŒ–é…ç½®")
    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(CONFIG_PATH):
        if not os.path.exists(os.path.dirname(CONFIG_PATH)):
            os.makedirs(os.path.dirname(CONFIG_PATH))
        with open("quark_config.json", "rb") as src, open(CONFIG_PATH, "wb") as dest:
            dest.write(src.read())

    # è¯»å–é…ç½®
    config_data = Config.read_json(CONFIG_PATH)
    Config.breaking_change_update(config_data)

    # é»˜è®¤ç®¡ç†è´¦å·
    config_data["webui"] = {
        "username": os.environ.get("WEBUI_USERNAME")
        or config_data.get("webui", {}).get("username", "admin"),
        "password": os.environ.get("WEBUI_PASSWORD")
        or config_data.get("webui", {}).get("password", "admin"),
    }

    # é»˜è®¤å®šæ—¶è§„åˆ™
    if not config_data.get("crontab"):
        config_data["crontab"] = "0 8,18,20 * * *"
    
    # é»˜è®¤å»¶è¿Ÿæ‰§è¡Œè®¾ç½®
    if "crontab_delay" not in config_data:
        config_data["crontab_delay"] = 0

    # åˆå§‹åŒ–æ’ä»¶é…ç½®
    _, plugins_config_default, task_plugins_config_default = Config.load_plugins()
    plugins_config_default.update(config_data.get("plugins", {}))
    config_data["plugins"] = plugins_config_default
    
    # è·å–ç¦ç”¨çš„æ’ä»¶åˆ—è¡¨
    disabled_plugins = set()
    if PLUGIN_FLAGS:
        disabled_plugins = {name.lstrip('-') for name in PLUGIN_FLAGS.split(',')}
    
    # æ¸…ç†æ‰€æœ‰ä»»åŠ¡ä¸­è¢«ç¦ç”¨æ’ä»¶çš„é…ç½®
    if config_data.get("tasklist"):
        for task in config_data["tasklist"]:
            if "addition" in task:
                for plugin_name in list(task["addition"].keys()):
                    if plugin_name in disabled_plugins:
                        del task["addition"][plugin_name]
    
    # åŒæ­¥æ›´æ–°ä»»åŠ¡çš„æ’ä»¶é…ç½®
    sync_task_plugins_config()

    # æ›´æ–°é…ç½®
    Config.write_json(CONFIG_PATH, config_data)


# è·å–å†å²è½¬å­˜è®°å½•
@app.route("/history_records")
def get_history_records():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
        
    # è·å–è¯·æ±‚å‚æ•°
    page = int(request.args.get("page", 1))
    page_size = int(request.args.get("page_size", 20))
    sort_by = request.args.get("sort_by", "transfer_time")
    order = request.args.get("order", "desc")
    
    # è·å–ç­›é€‰å‚æ•°
    task_name_filter = request.args.get("task_name", "")
    keyword_filter = request.args.get("keyword", "")
    
    # æ˜¯å¦åªè¯·æ±‚æ‰€æœ‰ä»»åŠ¡åç§°
    get_all_task_names = request.args.get("get_all_task_names", "").lower() in ["true", "1", "yes"]
    
    # åˆå§‹åŒ–æ•°æ®åº“
    db = RecordDB()
    
    # å¦‚æœè¯·æ±‚æ‰€æœ‰ä»»åŠ¡åç§°ï¼Œå•ç‹¬æŸ¥è¯¢å¹¶è¿”å›
    if get_all_task_names:
        cursor = db.conn.cursor()
        cursor.execute("SELECT DISTINCT task_name FROM transfer_records ORDER BY task_name")
        all_task_names = [row[0] for row in cursor.fetchall()]
        
        # å¦‚æœåŒæ—¶è¯·æ±‚åˆ†é¡µæ•°æ®ï¼Œç»§ç»­å¸¸è§„æŸ¥è¯¢
        if page > 0 and page_size > 0:
            result = db.get_records(
                page=page, 
                page_size=page_size, 
                sort_by=sort_by, 
                order=order,
                task_name_filter=task_name_filter,
                keyword_filter=keyword_filter
            )
            # æ·»åŠ æ‰€æœ‰ä»»åŠ¡åç§°åˆ°ç»“æœä¸­
            result["all_task_names"] = all_task_names
            
            # å¤„ç†è®°å½•æ ¼å¼åŒ–
            format_records(result["records"])
            
            return jsonify({"success": True, "data": result})
        else:
            # åªè¿”å›ä»»åŠ¡åç§°
            return jsonify({"success": True, "data": {"all_task_names": all_task_names}})
    
    # å¸¸è§„æŸ¥è¯¢
    result = db.get_records(
        page=page, 
        page_size=page_size, 
        sort_by=sort_by, 
        order=order,
        task_name_filter=task_name_filter,
        keyword_filter=keyword_filter
    )
    
    # å¤„ç†è®°å½•æ ¼å¼åŒ–
    format_records(result["records"])
    
    return jsonify({"success": True, "data": result})


# åˆ é™¤è½¬å­˜è®°å½•
@app.route("/delete_history_records", methods=["POST"])
def delete_history_records():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    # è·å–è¦åˆ é™¤çš„è®°å½•IDåˆ—è¡¨
    record_ids = request.json.get("record_ids", [])
    
    if not record_ids:
        return jsonify({"success": False, "message": "æœªæä¾›è¦åˆ é™¤çš„è®°å½•ID"})
    
    # åˆå§‹åŒ–æ•°æ®åº“
    db = RecordDB()
    
    # åˆ é™¤è®°å½•
    deleted_count = 0
    for record_id in record_ids:
        deleted_count += db.delete_record(record_id)
    
    return jsonify({
        "success": True, 
        "message": f"æˆåŠŸåˆ é™¤ {deleted_count} æ¡è®°å½•",
        "deleted_count": deleted_count
    })


# åˆ é™¤å•æ¡è½¬å­˜è®°å½•
@app.route("/delete_history_record", methods=["POST"])
def delete_history_record():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    # è·å–è¦åˆ é™¤çš„è®°å½•ID
    record_id = request.json.get("id")
    
    if not record_id:
        return jsonify({"success": False, "message": "æœªæä¾›è¦åˆ é™¤çš„è®°å½•ID"})
    
    # åˆå§‹åŒ–æ•°æ®åº“
    db = RecordDB()
    
    # åˆ é™¤è®°å½•
    deleted = db.delete_record(record_id)
    
    if deleted:
        return jsonify({
            "success": True, 
            "message": "æˆåŠŸåˆ é™¤ 1 æ¡è®°å½•",
        })
    else:
        return jsonify({
            "success": False, 
            "message": "è®°å½•åˆ é™¤å¤±è´¥ï¼Œå¯èƒ½è®°å½•ä¸å­˜åœ¨",
        })


# è¾…åŠ©å‡½æ•°ï¼šæ ¼å¼åŒ–è®°å½•
def format_records(records):
    for record in records:
        # æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸ºå¯è¯»å½¢å¼
        if "transfer_time" in record:
            try:
                # ç¡®ä¿æ—¶é—´æˆ³åœ¨åˆç†èŒƒå›´å†…
                timestamp = int(record["transfer_time"])
                if timestamp > 9999999999:  # æ£€æµ‹æ˜¯å¦ä¸ºæ¯«ç§’çº§æ—¶é—´æˆ³ï¼ˆ13ä½ï¼‰
                    timestamp = timestamp / 1000  # è½¬æ¢ä¸ºç§’çº§æ—¶é—´æˆ³
                
                if 0 < timestamp < 4102444800:  # ä»1970å¹´åˆ°2100å¹´çš„åˆç†æ—¶é—´æˆ³èŒƒå›´
                    record["transfer_time_readable"] = datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d %H:%M:%S")
                else:
                    record["transfer_time_readable"] = "æ— æ•ˆæ—¥æœŸ"
            except (ValueError, TypeError, OverflowError):
                record["transfer_time_readable"] = "æ— æ•ˆæ—¥æœŸ"
                
        if "modify_date" in record:
            try:
                # ç¡®ä¿æ—¶é—´æˆ³åœ¨åˆç†èŒƒå›´å†…
                timestamp = int(record["modify_date"])
                if timestamp > 9999999999:  # æ£€æµ‹æ˜¯å¦ä¸ºæ¯«ç§’çº§æ—¶é—´æˆ³ï¼ˆ13ä½ï¼‰
                    timestamp = timestamp / 1000  # è½¬æ¢ä¸ºç§’çº§æ—¶é—´æˆ³
                    
                if 0 < timestamp < 4102444800:  # ä»1970å¹´åˆ°2100å¹´çš„åˆç†æ—¶é—´æˆ³èŒƒå›´
                    record["modify_date_readable"] = datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d %H:%M:%S")
                else:
                    record["modify_date_readable"] = "æ— æ•ˆæ—¥æœŸ"
            except (ValueError, TypeError, OverflowError):
                record["modify_date_readable"] = "æ— æ•ˆæ—¥æœŸ"
                
        # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
        if "file_size" in record:
            try:
                record["file_size_readable"] = format_bytes(int(record["file_size"]))
            except (ValueError, TypeError):
                record["file_size_readable"] = "æœªçŸ¥å¤§å°"


@app.route("/get_user_info")
def get_user_info():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    user_info_list = []
    for idx, cookie in enumerate(config_data["cookie"]):
        account = Quark(cookie, idx)
        account_info = account.init()
        if account_info:
            user_info_list.append({
                "index": idx,
                "nickname": account_info["nickname"],
                "is_active": account.is_active
            })
        else:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç§»åŠ¨ç«¯å‚æ•°
            has_mparam = bool(account.mparam)
            user_info_list.append({
                "index": idx,
                "nickname": "",
                "is_active": False,
                "has_mparam": has_mparam
            })
    
    return jsonify({"success": True, "data": user_info_list})


# é‡ç½®æ–‡ä»¶å¤¹ï¼ˆåˆ é™¤æ–‡ä»¶å¤¹å†…æ‰€æœ‰æ–‡ä»¶å’Œç›¸å…³è®°å½•ï¼‰
@app.route("/reset_folder", methods=["POST"])
def reset_folder():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    # è·å–è¯·æ±‚å‚æ•°
    save_path = request.json.get("save_path", "")
    task_name = request.json.get("task_name", "")
    
    if not save_path:
        return jsonify({"success": False, "message": "ä¿å­˜è·¯å¾„ä¸èƒ½ä¸ºç©º"})
    
    try:
        # åˆå§‹åŒ–å¤¸å…‹ç½‘ç›˜å®¢æˆ·ç«¯
        account = Quark(config_data["cookie"][0], 0)
        
        # 1. è·å–æ–‡ä»¶å¤¹ID
        # å…ˆæ£€æŸ¥æ˜¯å¦å·²æœ‰ç¼“å­˜çš„æ–‡ä»¶å¤¹ID
        folder_fid = account.savepath_fid.get(save_path)
        
        # å¦‚æœæ²¡æœ‰ç¼“å­˜çš„IDï¼Œåˆ™å°è¯•åˆ›å»ºæ–‡ä»¶å¤¹ä»¥è·å–ID
        if not folder_fid:
            mkdir_result = account.mkdir(save_path)
            if mkdir_result.get("code") == 0:
                folder_fid = mkdir_result["data"]["fid"]
                account.savepath_fid[save_path] = folder_fid
            else:
                return jsonify({"success": False, "message": f"è·å–æ–‡ä»¶å¤¹IDå¤±è´¥: {mkdir_result.get('message', 'æœªçŸ¥é”™è¯¯')}"})
        
        # 2. è·å–æ–‡ä»¶å¤¹å†…çš„æ‰€æœ‰æ–‡ä»¶
        file_list = account.ls_dir(folder_fid)
        if isinstance(file_list, dict) and file_list.get("error"):
            return jsonify({"success": False, "message": f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {file_list.get('error', 'æœªçŸ¥é”™è¯¯')}"})
        
        # æ”¶é›†æ‰€æœ‰æ–‡ä»¶ID
        file_ids = []
        for item in file_list:
            file_ids.append(item["fid"])
        
        # 3. åˆ é™¤æ‰€æœ‰æ–‡ä»¶
        deleted_files = 0
        if file_ids:
            delete_result = account.delete(file_ids)
            if delete_result.get("code") == 0:
                deleted_files = len(file_ids)
        
        # 4. åˆ é™¤ç›¸å…³çš„å†å²è®°å½•
        deleted_records = 0
        try:
            # åˆå§‹åŒ–æ•°æ®åº“
            db = RecordDB()
            
            # æŸ¥è¯¢ä¸è¯¥ä¿å­˜è·¯å¾„ç›¸å…³çš„æ‰€æœ‰è®°å½•
            cursor = db.conn.cursor()
            cursor.execute("SELECT id FROM transfer_records WHERE save_path = ?", (save_path,))
            record_ids = [row[0] for row in cursor.fetchall()]
            
            # åˆ é™¤æ‰¾åˆ°çš„æ‰€æœ‰è®°å½•
            for record_id in record_ids:
                deleted_records += db.delete_record(record_id)
                
        except Exception as e:
            logging.error(f">>> åˆ é™¤è®°å½•æ—¶å‡ºé”™: {str(e)}")
            # å³ä½¿åˆ é™¤è®°å½•å¤±è´¥ï¼Œä¹Ÿè¿”å›æ–‡ä»¶åˆ é™¤æˆåŠŸ
        
        return jsonify({
            "success": True, 
            "message": f"é‡ç½®æˆåŠŸï¼Œåˆ é™¤äº† {deleted_files} ä¸ªæ–‡ä»¶å’Œ {deleted_records} æ¡è®°å½•",
            "deleted_files": deleted_files,
            "deleted_records": deleted_records
        })
        
    except Exception as e:
        logging.error(f">>> é‡ç½®æ–‡ä»¶å¤¹æ—¶å‡ºé”™: {str(e)}")
        return jsonify({"success": False, "message": f"é‡ç½®æ–‡ä»¶å¤¹æ—¶å‡ºé”™: {str(e)}"})


if __name__ == "__main__":
    init()
    reload_tasks()
    app.run(debug=DEBUG, host="0.0.0.0", port=PORT)
