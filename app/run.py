# !/usr/bin/env python3
# -*- coding: utf-8 -*-
from flask import (
    json,
    Flask,
    url_for,
    session,
    jsonify,
    request,
    redirect,
    Response,
    render_template,
    send_from_directory,
    stream_with_context,
)
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from sdk.cloudsaver import CloudSaver
from datetime import timedelta, datetime
import subprocess
import requests
import hashlib
import logging
import base64
import sys
import os
import re
import random
import time
import treelib
from functools import lru_cache
from threading import Lock

parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
sys.path.insert(0, parent_dir)
from quark_auto_save import Quark
from quark_auto_save import Config, format_bytes

# æ·»åŠ å¯¼å…¥å…¨å±€extract_episode_numberå’Œsort_file_by_nameå‡½æ•°
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from quark_auto_save import extract_episode_number, sort_file_by_name, chinese_to_arabic, is_date_format

# å¯¼å…¥æ•°æ®åº“æ¨¡å—
try:
    # å…ˆå°è¯•ç›¸å¯¹å¯¼å…¥
    from sdk.db import RecordDB
except ImportError:
    try:
        # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ä»appåŒ…å¯¼å…¥
        from app.sdk.db import RecordDB
    except ImportError:
        # å¦‚æœæ²¡æœ‰æ•°æ®åº“æ¨¡å—ï¼Œå®šä¹‰ä¸€ä¸ªç©ºç±»
        class RecordDB:
            def __init__(self, *args, **kwargs):
                pass
            
            def get_records(self, *args, **kwargs):
                return {"records": [], "pagination": {"total_records": 0, "total_pages": 0, "current_page": 1, "page_size": 20}}

# å¯¼å…¥å·¥å…·å‡½æ•°
try:
    # å…ˆå°è¯•ç›¸å¯¹å¯¼å…¥
    from sdk.utils import format_bytes, get_file_icon, format_file_display
except ImportError:
    try:
        # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ä»appåŒ…å¯¼å…¥
        from app.sdk.utils import format_bytes, get_file_icon, format_file_display
    except ImportError:
        # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å®ç°æˆ–ä»quark_auto_saveå¯¼å…¥
        # format_byteså·²ä»quark_auto_saveå¯¼å…¥
        def get_file_icon(file_name, is_dir=False):
            return "ğŸ“„" if not is_dir else "ğŸ“"
            
        def format_file_display(prefix, icon, name):
            return f"{prefix}{icon} {name}"


def get_app_ver():
    BUILD_SHA = os.environ.get("BUILD_SHA", "")
    BUILD_TAG = os.environ.get("BUILD_TAG", "")
    if BUILD_TAG[:1] == "v":
        return BUILD_TAG
    elif BUILD_SHA:
        return f"{BUILD_TAG}({BUILD_SHA[:7]})"
    else:
        return "dev"


# æ–‡ä»¶è·¯å¾„
PYTHON_PATH = "python3" if os.path.exists("/usr/bin/python3") else "python"
SCRIPT_PATH = os.environ.get("SCRIPT_PATH", "./quark_auto_save.py")
CONFIG_PATH = os.environ.get("CONFIG_PATH", "./config/quark_config.json")
PLUGIN_FLAGS = os.environ.get("PLUGIN_FLAGS", "")
DEBUG = os.environ.get("DEBUG", "false").lower() == "true"
# ä»ç¯å¢ƒå˜é‡è·å–ç«¯å£ï¼Œé»˜è®¤ä¸º5005
PORT = int(os.environ.get("PORT", "5005"))

config_data = {}
task_plugins_config_default = {}

# æ–‡ä»¶åˆ—è¡¨ç¼“å­˜
file_list_cache = {}
cache_lock = Lock()

# é»˜è®¤æ€§èƒ½å‚æ•°ï¼ˆå¦‚æœé…ç½®ä¸­æ²¡æœ‰è®¾ç½®ï¼‰
DEFAULT_PERFORMANCE_CONFIG = {
    "api_page_size": 200,
    "cache_expire_time": 30
}

def get_performance_config():
    """è·å–æ€§èƒ½é…ç½®å‚æ•°"""
    try:
        if config_data and "file_performance" in config_data:
            perf_config = config_data["file_performance"]
            # ç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯æ•´æ•°ç±»å‹
            result = {}
            for key, default_value in DEFAULT_PERFORMANCE_CONFIG.items():
                try:
                    result[key] = int(perf_config.get(key, default_value))
                except (ValueError, TypeError):
                    result[key] = default_value
            return result
    except Exception as e:
        print(f"è·å–æ€§èƒ½é…ç½®å¤±è´¥: {e}")
    return DEFAULT_PERFORMANCE_CONFIG

def cleanup_expired_cache():
    """æ¸…ç†æ‰€æœ‰è¿‡æœŸç¼“å­˜"""
    current_time = time.time()
    perf_config = get_performance_config()
    cache_expire_time = perf_config.get("cache_expire_time", 30)

    with cache_lock:
        expired_keys = [k for k, (_, t) in file_list_cache.items() if current_time - t > cache_expire_time]
        for k in expired_keys:
            del file_list_cache[k]
        return len(expired_keys)

app = Flask(__name__)
app.config["APP_VERSION"] = get_app_ver()
app.secret_key = "ca943f6db6dd34823d36ab08d8d6f65d"
app.config["SESSION_COOKIE_NAME"] = "QUARK_AUTO_SAVE_SESSION"
app.config["PERMANENT_SESSION_LIFETIME"] = timedelta(days=31)
app.json.ensure_ascii = False
app.json.sort_keys = False
app.jinja_env.variable_start_string = "[["
app.jinja_env.variable_end_string = "]]"

scheduler = BackgroundScheduler()
logging.basicConfig(
    level=logging.DEBUG if DEBUG else logging.INFO,
    format="[%(asctime)s][%(levelname)s] %(message)s",
    datefmt="%m-%d %H:%M:%S",
)
# è¿‡æ»¤werkzeugæ—¥å¿—è¾“å‡º
if not DEBUG:
    logging.getLogger("werkzeug").setLevel(logging.ERROR)


def gen_md5(string):
    md5 = hashlib.md5()
    md5.update(string.encode("utf-8"))
    return md5.hexdigest()


def get_login_token():
    username = config_data["webui"]["username"]
    password = config_data["webui"]["password"]
    return gen_md5(f"token{username}{password}+-*/")[8:24]


def is_login():
    login_token = get_login_token()
    if session.get("token") == login_token or request.args.get("token") == login_token:
        return True
    else:
        return False


# è®¾ç½®icon
@app.route("/favicon.ico")
def favicon():
    return send_from_directory(
        os.path.join(app.root_path, "static"),
        "favicon.ico",
        mimetype="image/vnd.microsoft.icon",
    )


# ç™»å½•é¡µé¢
@app.route("/login", methods=["GET", "POST"])
def login():
    if request.method == "POST":
        username = config_data["webui"]["username"]
        password = config_data["webui"]["password"]
        input_username = request.form.get("username")
        input_password = request.form.get("password")
        
        # éªŒè¯ç”¨æˆ·åå’Œå¯†ç 
        if not input_username or not input_password:
            logging.info(">>> ç™»å½•å¤±è´¥ï¼šç”¨æˆ·åæˆ–å¯†ç ä¸ºç©º")
            return render_template("login.html", message="ç”¨æˆ·åå’Œå¯†ç ä¸èƒ½ä¸ºç©º")
        elif username != input_username:
            logging.info(f">>> ç™»å½•å¤±è´¥ï¼šç”¨æˆ·åé”™è¯¯ {input_username}")
            return render_template("login.html", message="ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")
        elif password != input_password:
            logging.info(f">>> ç”¨æˆ· {input_username} ç™»å½•å¤±è´¥ï¼šå¯†ç é”™è¯¯")
            return render_template("login.html", message="ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")
        else:
            logging.info(f">>> ç”¨æˆ· {username} ç™»å½•æˆåŠŸ")
            session.permanent = True
            session["token"] = get_login_token()
            return redirect(url_for("index"))

    if is_login():
        return redirect(url_for("index"))
    return render_template("login.html", error=None)


# é€€å‡ºç™»å½•
@app.route("/logout")
def logout():
    session.pop("token", None)
    return redirect(url_for("login"))


# ç®¡ç†é¡µé¢
@app.route("/")
def index():
    if not is_login():
        return redirect(url_for("login"))
    return render_template(
        "index.html", version=app.config["APP_VERSION"], plugin_flags=PLUGIN_FLAGS
    )


# è·å–é…ç½®æ•°æ®
@app.route("/data")
def get_data():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    data = Config.read_json(CONFIG_PATH)

    # å¤„ç†æ’ä»¶é…ç½®ä¸­çš„å¤šè´¦å·æ”¯æŒå­—æ®µï¼Œå°†æ•°ç»„æ ¼å¼è½¬æ¢ä¸ºé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²ç”¨äºæ˜¾ç¤º
    if "plugins" in data:
        # å¤„ç†Plexçš„quark_root_path
        if "plex" in data["plugins"] and "quark_root_path" in data["plugins"]["plex"]:
            data["plugins"]["plex"]["quark_root_path"] = format_array_config_for_display(
                data["plugins"]["plex"]["quark_root_path"]
            )

        # å¤„ç†AListçš„storage_id
        if "alist" in data["plugins"] and "storage_id" in data["plugins"]["alist"]:
            data["plugins"]["alist"]["storage_id"] = format_array_config_for_display(
                data["plugins"]["alist"]["storage_id"]
            )

    # å‘é€webuiä¿¡æ¯ï¼Œä½†ä¸å‘é€å¯†ç åŸæ–‡
    data["webui"] = {
        "username": config_data["webui"]["username"],
        "password": config_data["webui"]["password"]
    }
    data["api_token"] = get_login_token()
    data["task_plugins_config_default"] = task_plugins_config_default
    return jsonify({"success": True, "data": data})


def sync_task_plugins_config():
    """åŒæ­¥æ›´æ–°æ‰€æœ‰ä»»åŠ¡çš„æ’ä»¶é…ç½®
    
    1. æ£€æŸ¥æ¯ä¸ªä»»åŠ¡çš„æ’ä»¶é…ç½®
    2. å¦‚æœæ’ä»¶é…ç½®ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
    3. å¦‚æœæ’ä»¶é…ç½®å­˜åœ¨ä½†ç¼ºå°‘æ–°çš„é…ç½®é¡¹ï¼Œæ·»åŠ é»˜è®¤å€¼
    4. ä¿ç•™åŸæœ‰çš„è‡ªå®šä¹‰é…ç½®
    5. åªå¤„ç†å·²å¯ç”¨çš„æ’ä»¶ï¼ˆé€šè¿‡PLUGIN_FLAGSæ£€æŸ¥ï¼‰
    6. æ¸…ç†è¢«ç¦ç”¨æ’ä»¶çš„é…ç½®
    """
    global config_data, task_plugins_config_default
    
    # å¦‚æœæ²¡æœ‰ä»»åŠ¡åˆ—è¡¨ï¼Œç›´æ¥è¿”å›
    if not config_data.get("tasklist"):
        return
        
    # è·å–ç¦ç”¨çš„æ’ä»¶åˆ—è¡¨
    disabled_plugins = set()
    if PLUGIN_FLAGS:
        disabled_plugins = {name.lstrip('-') for name in PLUGIN_FLAGS.split(',')}
        
    # éå†æ‰€æœ‰ä»»åŠ¡
    for task in config_data["tasklist"]:
        # ç¡®ä¿ä»»åŠ¡æœ‰additionå­—æ®µ
        if "addition" not in task:
            task["addition"] = {}
            
        # æ¸…ç†è¢«ç¦ç”¨æ’ä»¶çš„é…ç½®
        for plugin_name in list(task["addition"].keys()):
            if plugin_name in disabled_plugins:
                del task["addition"][plugin_name]
            
        # éå†æ‰€æœ‰æ’ä»¶çš„é»˜è®¤é…ç½®
        for plugin_name, default_config in task_plugins_config_default.items():
            # è·³è¿‡è¢«ç¦ç”¨çš„æ’ä»¶
            if plugin_name in disabled_plugins:
                continue
                
            # å¦‚æœä»»åŠ¡ä¸­æ²¡æœ‰è¯¥æ’ä»¶çš„é…ç½®ï¼Œæ·»åŠ é»˜è®¤é…ç½®
            if plugin_name not in task["addition"]:
                task["addition"][plugin_name] = default_config.copy()
            else:
                # å¦‚æœä»»åŠ¡ä¸­æœ‰è¯¥æ’ä»¶çš„é…ç½®ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„é…ç½®é¡¹
                current_config = task["addition"][plugin_name]
                # ç¡®ä¿current_configæ˜¯å­—å…¸ç±»å‹
                if not isinstance(current_config, dict):
                    # å¦‚æœä¸æ˜¯å­—å…¸ç±»å‹ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
                    task["addition"][plugin_name] = default_config.copy()
                    continue
                    
                # éå†é»˜è®¤é…ç½®çš„æ¯ä¸ªé”®å€¼å¯¹
                for key, default_value in default_config.items():
                    if key not in current_config:
                        current_config[key] = default_value


def parse_comma_separated_config(value):
    """è§£æé€—å·åˆ†éš”çš„é…ç½®å­—ç¬¦ä¸²ä¸ºæ•°ç»„"""
    if isinstance(value, str) and value.strip():
        # åˆ†å‰²å­—ç¬¦ä¸²ï¼Œå»é™¤ç©ºç™½å­—ç¬¦
        items = [item.strip() for item in value.split(',') if item.strip()]
        # å¦‚æœåªæœ‰ä¸€ä¸ªé¡¹ç›®ï¼Œè¿”å›å­—ç¬¦ä¸²ï¼ˆå‘åå…¼å®¹ï¼‰
        return items[0] if len(items) == 1 else items
    return value

def format_array_config_for_display(value):
    """å°†æ•°ç»„é…ç½®æ ¼å¼åŒ–ä¸ºé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²ç”¨äºæ˜¾ç¤º"""
    if isinstance(value, list):
        return ', '.join(value)
    return value

# æ›´æ–°æ•°æ®
@app.route("/update", methods=["POST"])
def update():
    global config_data
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    dont_save_keys = ["task_plugins_config_default", "api_token"]
    for key, value in request.json.items():
        if key not in dont_save_keys:
            if key == "webui":
                # æ›´æ–°webuiå‡­æ®
                config_data["webui"]["username"] = value.get("username", config_data["webui"]["username"])
                config_data["webui"]["password"] = value.get("password", config_data["webui"]["password"])
            elif key == "plugins":
                # å¤„ç†æ’ä»¶é…ç½®ä¸­çš„å¤šè´¦å·æ”¯æŒå­—æ®µ
                if "plex" in value and "quark_root_path" in value["plex"]:
                    value["plex"]["quark_root_path"] = parse_comma_separated_config(
                        value["plex"]["quark_root_path"]
                    )

                if "alist" in value and "storage_id" in value["alist"]:
                    value["alist"]["storage_id"] = parse_comma_separated_config(
                        value["alist"]["storage_id"]
                    )

                config_data.update({key: value})
            else:
                config_data.update({key: value})
    
    # åŒæ­¥æ›´æ–°ä»»åŠ¡çš„æ’ä»¶é…ç½®
    sync_task_plugins_config()
    
    Config.write_json(CONFIG_PATH, config_data)
    # æ›´æ–°session tokenï¼Œç¡®ä¿å½“å‰ä¼šè¯åœ¨ç”¨æˆ·åå¯†ç æ›´æ”¹åä»ç„¶æœ‰æ•ˆ
    session["token"] = get_login_token()
    # é‡æ–°åŠ è½½ä»»åŠ¡
    if reload_tasks():
        logging.info(f">>> é…ç½®æ›´æ–°æˆåŠŸ")
        return jsonify({"success": True, "message": "é…ç½®æ›´æ–°æˆåŠŸ"})
    else:
        logging.info(f">>> é…ç½®æ›´æ–°å¤±è´¥")
        return jsonify({"success": False, "message": "é…ç½®æ›´æ–°å¤±è´¥"})


# å¤„ç†è¿è¡Œè„šæœ¬è¯·æ±‚
@app.route("/run_script_now", methods=["POST"])
def run_script_now():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    tasklist = request.json.get("tasklist", [])
    command = [PYTHON_PATH, "-u", SCRIPT_PATH, CONFIG_PATH]
    logging.info(
        f">>> æ‰‹åŠ¨è¿è¡Œä»»åŠ¡ [{tasklist[0].get('taskname') if len(tasklist)>0 else 'ALL'}] å¼€å§‹æ‰§è¡Œ..."
    )

    def generate_output():
        # è®¾ç½®ç¯å¢ƒå˜é‡
        process_env = os.environ.copy()
        process_env["PYTHONIOENCODING"] = "utf-8"
        if tasklist:
            process_env["TASKLIST"] = json.dumps(tasklist, ensure_ascii=False)
            # æ·»åŠ åŸå§‹ä»»åŠ¡ç´¢å¼•çš„ç¯å¢ƒå˜é‡
            if len(tasklist) == 1 and 'original_index' in request.json:
                process_env["ORIGINAL_TASK_INDEX"] = str(request.json['original_index'])
        process = subprocess.Popen(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            encoding="utf-8",
            errors="replace",
            bufsize=1,
            env=process_env,
        )
        try:
            for line in iter(process.stdout.readline, ""):
                logging.info(line.strip())
                yield f"data: {line}\n\n"
            yield "data: [DONE]\n\n"
        finally:
            process.stdout.close()
            process.wait()

    return Response(
        stream_with_context(generate_output()),
        content_type="text/event-stream;charset=utf-8",
    )


# åˆ·æ–°Plexåª’ä½“åº“
@app.route("/refresh_plex_library", methods=["POST"])
def refresh_plex_library():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    task_index = request.json.get("task_index")
    if task_index is None:
        return jsonify({"success": False, "message": "ç¼ºå°‘ä»»åŠ¡ç´¢å¼•"})
        
    # è·å–ä»»åŠ¡ä¿¡æ¯
    task = config_data["tasklist"][task_index]
    if not task.get("savepath"):
        return jsonify({"success": False, "message": "ä»»åŠ¡æ²¡æœ‰ä¿å­˜è·¯å¾„"})
        
    # å¯¼å…¥Plexæ’ä»¶
    from plugins.plex import Plex
    
    # åˆå§‹åŒ–Plexæ’ä»¶
    plex = Plex(**config_data["plugins"]["plex"])
    if not plex.is_active:
        return jsonify({"success": False, "message": "Plex æ’ä»¶æœªæ­£ç¡®é…ç½®"})
        
    # æ‰§è¡Œåˆ·æ–°
    plex.run(task)
    
    return jsonify({"success": True, "message": "æˆåŠŸåˆ·æ–° Plex åª’ä½“åº“"})


# åˆ·æ–°AListç›®å½•
@app.route("/refresh_alist_directory", methods=["POST"])
def refresh_alist_directory():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    task_index = request.json.get("task_index")
    if task_index is None:
        return jsonify({"success": False, "message": "ç¼ºå°‘ä»»åŠ¡ç´¢å¼•"})
        
    # è·å–ä»»åŠ¡ä¿¡æ¯
    task = config_data["tasklist"][task_index]
    if not task.get("savepath"):
        return jsonify({"success": False, "message": "ä»»åŠ¡æ²¡æœ‰ä¿å­˜è·¯å¾„"})
        
    # å¯¼å…¥AListæ’ä»¶
    from plugins.alist import Alist
    
    # åˆå§‹åŒ–AListæ’ä»¶
    alist = Alist(**config_data["plugins"]["alist"])
    if not alist.is_active:
        return jsonify({"success": False, "message": "AList æ’ä»¶æœªæ­£ç¡®é…ç½®"})
        
    # æ‰§è¡Œåˆ·æ–°
    alist.run(task)
    
    return jsonify({"success": True, "message": "æˆåŠŸåˆ·æ–° AList ç›®å½•"})


# æ–‡ä»¶æ•´ç†é¡µé¢åˆ·æ–°Plexåª’ä½“åº“
@app.route("/refresh_filemanager_plex_library", methods=["POST"])
def refresh_filemanager_plex_library():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    folder_path = request.json.get("folder_path")
    account_index = request.json.get("account_index", 0)

    if not folder_path:
        return jsonify({"success": False, "message": "ç¼ºå°‘æ–‡ä»¶å¤¹è·¯å¾„"})

    # æ£€æŸ¥Plexæ’ä»¶é…ç½®
    if not config_data.get("plugins", {}).get("plex", {}).get("url"):
        return jsonify({"success": False, "message": "Plex æ’ä»¶æœªé…ç½®"})

    # å¯¼å…¥Plexæ’ä»¶
    from plugins.plex import Plex

    # åˆå§‹åŒ–Plexæ’ä»¶
    plex = Plex(**config_data["plugins"]["plex"])
    if not plex.is_active:
        return jsonify({"success": False, "message": "Plex æ’ä»¶æœªæ­£ç¡®é…ç½®"})

    # è·å–å¤¸å…‹è´¦å·ä¿¡æ¯
    try:
        account = Quark(config_data["cookie"][account_index], account_index)

        # å°†æ–‡ä»¶å¤¹è·¯å¾„è½¬æ¢ä¸ºå®é™…çš„ä¿å­˜è·¯å¾„
        # folder_pathæ˜¯ç›¸å¯¹äºå¤¸å…‹ç½‘ç›˜æ ¹ç›®å½•çš„è·¯å¾„
        # quark_root_pathæ˜¯å¤¸å…‹ç½‘ç›˜åœ¨æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿä¸­çš„æŒ‚è½½ç‚¹
        # æ ¹æ®è´¦å·ç´¢å¼•è·å–å¯¹åº”çš„å¤¸å…‹æ ¹è·¯å¾„
        quark_root_path = plex.get_quark_root_path(account_index)
        if not quark_root_path:
            return jsonify({"success": False, "message": f"Plex æ’ä»¶æœªé…ç½®è´¦å· {account_index} çš„å¤¸å…‹æ ¹è·¯å¾„"})

        if folder_path == "" or folder_path == "/":
            # ç©ºå­—ç¬¦ä¸²æˆ–æ ¹ç›®å½•è¡¨ç¤ºå¤¸å…‹ç½‘ç›˜æ ¹ç›®å½•
            full_path = quark_root_path
        else:
            # ç¡®ä¿è·¯å¾„æ ¼å¼æ­£ç¡®
            if not folder_path.startswith("/"):
                folder_path = "/" + folder_path

            # æ‹¼æ¥å®Œæ•´è·¯å¾„ï¼šå¤¸å…‹æ ¹è·¯å¾„ + ç›¸å¯¹è·¯å¾„
            import os
            full_path = os.path.normpath(os.path.join(quark_root_path, folder_path.lstrip("/"))).replace("\\", "/")

        # ç¡®ä¿åº“ä¿¡æ¯å·²åŠ è½½
        if plex._libraries is None:
            plex._libraries = plex._get_libraries()

        # æ‰§è¡Œåˆ·æ–°
        success = plex.refresh(full_path)

        if success:
            return jsonify({"success": True, "message": "æˆåŠŸåˆ·æ–° Plex åª’ä½“åº“"})
        else:
            return jsonify({"success": False, "message": "åˆ·æ–° Plex åª’ä½“åº“å¤±è´¥ï¼Œè¯·æ£€æŸ¥è·¯å¾„é…ç½®"})

    except Exception as e:
        return jsonify({"success": False, "message": f"åˆ·æ–° Plex åª’ä½“åº“å¤±è´¥: {str(e)}"})


# æ–‡ä»¶æ•´ç†é¡µé¢åˆ·æ–°AListç›®å½•
@app.route("/refresh_filemanager_alist_directory", methods=["POST"])
def refresh_filemanager_alist_directory():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    folder_path = request.json.get("folder_path")
    account_index = request.json.get("account_index", 0)

    if not folder_path:
        return jsonify({"success": False, "message": "ç¼ºå°‘æ–‡ä»¶å¤¹è·¯å¾„"})

    # æ£€æŸ¥AListæ’ä»¶é…ç½®
    if not config_data.get("plugins", {}).get("alist", {}).get("url"):
        return jsonify({"success": False, "message": "AList æ’ä»¶æœªé…ç½®"})

    # å¯¼å…¥AListæ’ä»¶
    from plugins.alist import Alist

    # åˆå§‹åŒ–AListæ’ä»¶
    alist = Alist(**config_data["plugins"]["alist"])
    if not alist.is_active:
        return jsonify({"success": False, "message": "AList æ’ä»¶æœªæ­£ç¡®é…ç½®"})

    # è·å–å¤¸å…‹è´¦å·ä¿¡æ¯
    try:
        account = Quark(config_data["cookie"][account_index], account_index)

        # å°†æ–‡ä»¶å¤¹è·¯å¾„è½¬æ¢ä¸ºå®é™…çš„ä¿å­˜è·¯å¾„
        # folder_pathæ˜¯ç›¸å¯¹äºå¤¸å…‹ç½‘ç›˜æ ¹ç›®å½•çš„è·¯å¾„ï¼Œå¦‚ "/" æˆ– "/æµ‹è¯•/æ–‡ä»¶å¤¹"
        # æ ¹æ®è´¦å·ç´¢å¼•è·å–å¯¹åº”çš„å­˜å‚¨é…ç½®
        storage_mount_path, quark_root_dir = alist.get_storage_config(account_index)

        if not storage_mount_path or not quark_root_dir:
            return jsonify({"success": False, "message": f"AList æ’ä»¶æœªé…ç½®è´¦å· {account_index} çš„å­˜å‚¨ä¿¡æ¯"})

        if folder_path == "/":
            # æ ¹ç›®å½•ï¼Œç›´æ¥ä½¿ç”¨å¤¸å…‹æ ¹è·¯å¾„
            full_path = quark_root_dir
        else:
            # å­ç›®å½•ï¼Œæ‹¼æ¥è·¯å¾„
            import os
            # ç§»é™¤folder_pathå¼€å¤´çš„/ï¼Œç„¶åæ‹¼æ¥
            relative_path = folder_path.lstrip("/")
            if quark_root_dir == "/":
                full_path = "/" + relative_path
            else:
                full_path = os.path.normpath(os.path.join(quark_root_dir, relative_path)).replace("\\", "/")

        # æ£€æŸ¥è·¯å¾„æ˜¯å¦åœ¨å¤¸å…‹æ ¹ç›®å½•å†…
        if quark_root_dir == "/" or full_path.startswith(quark_root_dir):
            # ä½¿ç”¨è´¦å·å¯¹åº”çš„å­˜å‚¨é…ç½®æ˜ å°„åˆ°AListè·¯å¾„
            # æ„å»ºAListè·¯å¾„
            if quark_root_dir == "/":
                relative_path = full_path.lstrip("/")
            else:
                relative_path = full_path.replace(quark_root_dir, "", 1).lstrip("/")

            alist_path = os.path.normpath(
                os.path.join(storage_mount_path, relative_path)
            ).replace("\\", "/")

            # æ‰§è¡Œåˆ·æ–°
            alist.refresh(alist_path)
            return jsonify({"success": True, "message": "æˆåŠŸåˆ·æ–° AList ç›®å½•"})
        else:
            return jsonify({"success": False, "message": "è·¯å¾„ä¸åœ¨AListé…ç½®çš„å¤¸å…‹æ ¹ç›®å½•å†…"})

    except Exception as e:
        return jsonify({"success": False, "message": f"åˆ·æ–° AList ç›®å½•å¤±è´¥: {str(e)}"})


@app.route("/task_suggestions")
def get_task_suggestions():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    query = request.args.get("q", "").lower()
    deep = request.args.get("d", "").lower()
    
    # æå–å‰§åï¼Œå»é™¤å­£æ•°ä¿¡æ¯
    def extract_show_name(task_name):
        # æ¸…ç†ä»»åŠ¡åç§°ä¸­çš„è¿ç»­ç©ºæ ¼å’Œç‰¹æ®Šç¬¦å·
        clean_name = task_name.replace('\u3000', ' ').replace('\t', ' ')
        clean_name = re.sub(r'\s+', ' ', clean_name).strip()
        
        # åŒ¹é…å¸¸è§çš„å­£æ•°æ ¼å¼
        # ä¾‹å¦‚ï¼šé»‘é•œ - S07ã€äººç”Ÿè‹¥å¦‚åˆè§ - S01ã€æŠ˜è…°.S01ã€éŸ³ä½ è€Œæ¥-S02ã€å¿«ä¹çš„å¤§äºº S02
        season_patterns = [
            r'^(.*?)[\s\.\-_]+S\d+$',  # é»‘é•œ - S07ã€æŠ˜è…°.S01ã€éŸ³ä½ è€Œæ¥-S02
            r'^(.*?)[\s\.\-_]+Season\s*\d+$',  # é»‘é•œ - Season 1
            r'^(.*?)\s+S\d+$',  # å¿«ä¹çš„å¤§äºº S02
            r'^(.*?)[\s\.\-_]+S\d+E\d+$',  # å¤„ç† S01E01 æ ¼å¼
            r'^(.*?)\s+ç¬¬\s*\d+\s*å­£$',  # å¤„ç† ç¬¬Nå­£ æ ¼å¼
            r'^(.*?)[\s\.\-_]+ç¬¬\s*\d+\s*å­£$',  # å¤„ç† - ç¬¬Nå­£ æ ¼å¼
            r'^(.*?)\s+ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åé›¶]+å­£$',  # å¤„ç† ç¬¬ä¸€å­£ã€ç¬¬äºŒå­£ æ ¼å¼
            r'^(.*?)[\s\.\-_]+ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åé›¶]+å­£$',  # å¤„ç† - ç¬¬ä¸€å­£ã€- ç¬¬äºŒå­£ æ ¼å¼
        ]
        
        for pattern in season_patterns:
            match = re.match(pattern, clean_name, re.IGNORECASE)
            if match:
                show_name = match.group(1).strip()
                # å»é™¤æœ«å°¾å¯èƒ½æ®‹ç•™çš„åˆ†éš”ç¬¦
                show_name = re.sub(r'[\s\.\-_]+$', '', show_name)
                return show_name
                
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°å­£æ•°æ ¼å¼ï¼Œè¿”å›åŸåç§°
        return clean_name
    
    # å¤„ç†æœç´¢å…³é”®è¯ï¼Œæå–å‰§å
    search_query = extract_show_name(query)
    
    try:
        cs_data = config_data.get("source", {}).get("cloudsaver", {})
        if (
            cs_data.get("server")
            and cs_data.get("username")
            and cs_data.get("password")
        ):
            cs = CloudSaver(cs_data.get("server"))
            cs.set_auth(
                cs_data.get("username", ""),
                cs_data.get("password", ""),
                cs_data.get("token", ""),
            )
            # ä½¿ç”¨å¤„ç†åçš„æœç´¢å…³é”®è¯
            search = cs.auto_login_search(search_query)
            if search.get("success"):
                if search.get("new_token"):
                    cs_data["token"] = search.get("new_token")
                    Config.write_json(CONFIG_PATH, config_data)
                search_results = cs.clean_search_results(search.get("data"))
                # åœ¨è¿”å›ç»“æœä¸­æ·»åŠ å®é™…ä½¿ç”¨çš„æœç´¢å…³é”®è¯
                return jsonify(
                    {
                        "success": True, 
                        "source": "CloudSaver", 
                        "data": search_results
                    }
                )
            else:
                return jsonify({"success": True, "message": search.get("message")})
        else:
            base_url = base64.b64decode("aHR0cHM6Ly9zLjkxNzc4OC54eXo=").decode()
            # ä½¿ç”¨å¤„ç†åçš„æœç´¢å…³é”®è¯
            url = f"{base_url}/task_suggestions?q={search_query}&d={deep}"
            response = requests.get(url)
            return jsonify(
                {
                    "success": True, 
                    "source": "ç½‘ç»œå…¬å¼€", 
                    "data": response.json()
                }
            )
    except Exception as e:
        return jsonify({"success": True, "message": f"error: {str(e)}"})


# è·å–åˆ†äº«è¯¦æƒ…æ¥å£
@app.route("/get_share_detail", methods=["GET", "POST"])
def get_share_detail():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    # æ”¯æŒGETå’ŒPOSTè¯·æ±‚
    if request.method == "GET":
        shareurl = request.args.get("shareurl", "")
        stoken = request.args.get("stoken", "")
    else:
        shareurl = request.json.get("shareurl", "")
        stoken = request.json.get("stoken", "")
        
    account = Quark("", 0)
    # è®¾ç½®accountçš„å¿…è¦å±æ€§
    account.episode_patterns = request.json.get("regex", {}).get("episode_patterns", []) if request.method == "POST" else []
    
    pwd_id, passcode, pdir_fid, paths = account.extract_url(shareurl)
    if not stoken:
        is_sharing, stoken = account.get_stoken(pwd_id, passcode)
        if not is_sharing:
            return jsonify({"success": False, "data": {"error": stoken}})
    share_detail = account.get_detail(pwd_id, stoken, pdir_fid, _fetch_share=1)
    share_detail["paths"] = paths
    share_detail["stoken"] = stoken

    # å¦‚æœæ˜¯GETè¯·æ±‚æˆ–è€…ä¸éœ€è¦é¢„è§ˆæ­£åˆ™ï¼Œç›´æ¥è¿”å›åˆ†äº«è¯¦æƒ…
    if request.method == "GET" or not request.json.get("regex"):
        return jsonify({"success": True, "data": share_detail})
        
    # æ­£åˆ™å‘½åé¢„è§ˆ
    def preview_regex(share_detail):
        regex = request.json.get("regex")
        # æ£€æŸ¥æ˜¯å¦ä¸ºé¡ºåºå‘½åæ¨¡å¼
        if regex.get("use_sequence_naming") and regex.get("sequence_naming"):
            # é¡ºåºå‘½åæ¨¡å¼é¢„è§ˆ
            sequence_pattern = regex.get("sequence_naming")
            current_sequence = 1
            
            # æ„å»ºé¡ºåºå‘½åçš„æ­£åˆ™è¡¨è¾¾å¼
            if sequence_pattern == "{}":
                # å¯¹äºå•ç‹¬çš„{}ï¼Œä½¿ç”¨ç‰¹æ®ŠåŒ¹é…
                regex_pattern = "(\\d+)"
            else:
                regex_pattern = re.escape(sequence_pattern).replace('\\{\\}', '(\\d+)')
            
            # å®ç°ä¸å®é™…é‡å‘½åç›¸åŒçš„æ’åºç®—æ³•
            def extract_sort_value(file):
                return sort_file_by_name(file)
            
            # è¿‡æ»¤å‡ºéç›®å½•æ–‡ä»¶ï¼Œå¹¶ä¸”æ’é™¤å·²ç»ç¬¦åˆå‘½åè§„åˆ™çš„æ–‡ä»¶
            files_to_process = []
            for f in share_detail["list"]:
                if f["dir"]:
                    continue  # è·³è¿‡ç›®å½•
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç¬¦åˆå‘½åè§„åˆ™
                if sequence_pattern == "{}":
                    # å¯¹äºå•ç‹¬çš„{}ï¼Œæ£€æŸ¥æ–‡ä»¶åæ˜¯å¦ä¸ºçº¯æ•°å­—
                    file_name_without_ext = os.path.splitext(f["file_name"])[0]
                    if file_name_without_ext.isdigit():
                        # å¢åŠ åˆ¤æ–­ï¼šå¦‚æœæ˜¯æ—¥æœŸæ ¼å¼çš„çº¯æ•°å­—ï¼Œä¸è§†ä¸ºå·²å‘½å
                        if not is_date_format(file_name_without_ext):
                            continue  # è·³è¿‡å·²ç¬¦åˆå‘½åè§„åˆ™çš„æ–‡ä»¶
                elif re.match(regex_pattern, f["file_name"]):
                    continue  # è·³è¿‡å·²ç¬¦åˆå‘½åè§„åˆ™çš„æ–‡ä»¶
                
                # æ·»åŠ åˆ°å¾…å¤„ç†æ–‡ä»¶åˆ—è¡¨
                files_to_process.append(f)
            
            # æ ¹æ®æå–çš„æ’åºå€¼è¿›è¡Œæ’åº
            sorted_files = sorted(files_to_process, key=extract_sort_value)
            
            # åº”ç”¨è¿‡æ»¤è¯è¿‡æ»¤
            filterwords = regex.get("filterwords", "")
            if filterwords:
                # åŒæ—¶æ”¯æŒä¸­è‹±æ–‡é€—å·åˆ†éš”
                filterwords = filterwords.replace("ï¼Œ", ",")
                filterwords_list = [word.strip() for word in filterwords.split(',')]
                for item in sorted_files:
                    # è¢«è¿‡æ»¤çš„æ–‡ä»¶ä¸ä¼šæœ‰file_name_reï¼Œä¸ä¸åŒ¹é…æ­£åˆ™çš„æ–‡ä»¶æ˜¾ç¤ºä¸€è‡´
                    if any(word in item['file_name'] for word in filterwords_list):
                        item["filtered"] = True
            
            # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ†é…åºå·
            for file in sorted_files:
                if not file.get("filtered"):
                    # è·å–æ–‡ä»¶æ‰©å±•å
                    file_ext = os.path.splitext(file["file_name"])[1]
                    # ç”Ÿæˆé¢„è§ˆæ–‡ä»¶å
                    if sequence_pattern == "{}":
                        # å¯¹äºå•ç‹¬çš„{}ï¼Œç›´æ¥ä½¿ç”¨æ•°å­—åºå·ä½œä¸ºæ–‡ä»¶å
                        file["file_name_re"] = f"{current_sequence:02d}{file_ext}"
                    else:
                        # æ›¿æ¢æ‰€æœ‰çš„{}ä¸ºå½“å‰åºå·
                        file["file_name_re"] = sequence_pattern.replace("{}", f"{current_sequence:02d}") + file_ext
                    current_sequence += 1
            
            return share_detail
        elif regex.get("use_episode_naming") and regex.get("episode_naming"):
            # å‰§é›†å‘½åæ¨¡å¼é¢„è§ˆ
            episode_pattern = regex.get("episode_naming")
            episode_patterns = regex.get("episode_patterns", [])
            
            # è·å–é»˜è®¤çš„å‰§é›†æ¨¡å¼
            default_episode_pattern = {"regex": 'ç¬¬(\\d+)é›†|ç¬¬(\\d+)æœŸ|ç¬¬(\\d+)è¯|(\\d+)é›†|(\\d+)æœŸ|(\\d+)è¯|[Ee][Pp]?(\\d+)|(\\d+)[-_\\s]*4[Kk]|\\[(\\d+)\\]|ã€(\\d+)ã€‘|_?(\\d+)_?'}
            
            # è·å–é…ç½®çš„å‰§é›†æ¨¡å¼ï¼Œç¡®ä¿æ¯ä¸ªæ¨¡å¼éƒ½æ˜¯å­—å…¸æ ¼å¼
            episode_patterns = []
            raw_patterns = config_data.get("episode_patterns", [default_episode_pattern])
            for p in raw_patterns:
                if isinstance(p, dict) and p.get("regex"):
                    episode_patterns.append(p)
                elif isinstance(p, str):
                    episode_patterns.append({"regex": p})
            
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„æ¨¡å¼ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å¼
            if not episode_patterns:
                episode_patterns = [default_episode_pattern]
                
            # æ·»åŠ ä¸­æ–‡æ•°å­—åŒ¹é…æ¨¡å¼
            chinese_patterns = [
                {"regex": r'ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)é›†'},
                {"regex": r'ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)æœŸ'},
                {"regex": r'ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)è¯'},
                {"regex": r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)é›†'},
                {"regex": r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)æœŸ'},
                {"regex": r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)è¯'}
            ]
            episode_patterns.extend(chinese_patterns)
            
            # åº”ç”¨è¿‡æ»¤è¯è¿‡æ»¤
            filterwords = regex.get("filterwords", "")
            if filterwords:
                # åŒæ—¶æ”¯æŒä¸­è‹±æ–‡é€—å·åˆ†éš”
                filterwords = filterwords.replace("ï¼Œ", ",")
                filterwords_list = [word.strip() for word in filterwords.split(',')]
                for item in share_detail["list"]:
                    # è¢«è¿‡æ»¤çš„æ–‡ä»¶æ˜¾ç¤ºä¸€ä¸ª Ã—
                    if any(word in item['file_name'] for word in filterwords_list):
                        item["filtered"] = True
                        item["file_name_re"] = "Ã—"
            
            # å¤„ç†æœªè¢«è¿‡æ»¤çš„æ–‡ä»¶
            for file in share_detail["list"]:
                if not file["dir"] and not file.get("filtered"):  # åªå¤„ç†æœªè¢«è¿‡æ»¤çš„éç›®å½•æ–‡ä»¶
                    extension = os.path.splitext(file["file_name"])[1]
                    # ä»æ–‡ä»¶åä¸­æå–é›†å·
                    episode_num = extract_episode_number(file["file_name"], episode_patterns=episode_patterns)
                    
                    if episode_num is not None:
                        file["file_name_re"] = episode_pattern.replace("[]", f"{episode_num:02d}") + extension
                    else:
                        # æ²¡æœ‰æå–åˆ°é›†å·ï¼Œæ˜¾ç¤ºæ— æ³•è¯†åˆ«çš„æç¤º
                        file["file_name_re"] = "Ã— æ— æ³•è¯†åˆ«å‰§é›†ç¼–å·"
            
            return share_detail
        else:
            # æ™®é€šæ­£åˆ™å‘½åé¢„è§ˆ
            pattern, replace = account.magic_regex_func(
                regex.get("pattern", ""),
                regex.get("replace", ""),
                regex.get("taskname", ""),
                regex.get("magic_regex", {}),
            )
            
            # åº”ç”¨è¿‡æ»¤è¯è¿‡æ»¤
            filterwords = regex.get("filterwords", "")
            if filterwords:
                # åŒæ—¶æ”¯æŒä¸­è‹±æ–‡é€—å·åˆ†éš”
                filterwords = filterwords.replace("ï¼Œ", ",")
                filterwords_list = [word.strip() for word in filterwords.split(',')]
                for item in share_detail["list"]:
                    # è¢«è¿‡æ»¤çš„æ–‡ä»¶ä¸ä¼šæœ‰file_name_reï¼Œä¸ä¸åŒ¹é…æ­£åˆ™çš„æ–‡ä»¶æ˜¾ç¤ºä¸€è‡´
                    if any(word in item['file_name'] for word in filterwords_list):
                        item["filtered"] = True
                
            # åº”ç”¨æ­£åˆ™å‘½å
            for item in share_detail["list"]:
                # åªå¯¹æœªè¢«è¿‡æ»¤çš„æ–‡ä»¶åº”ç”¨æ­£åˆ™å‘½å
                if not item.get("filtered") and re.search(pattern, item["file_name"]):
                    file_name = item["file_name"]
                    item["file_name_re"] = (
                        re.sub(pattern, replace, file_name) if replace != "" else file_name
                    )
            return share_detail

    share_detail = preview_regex(share_detail)

    return jsonify({"success": True, "data": share_detail})


@app.route("/get_savepath_detail")
def get_savepath_detail():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    # è·å–è´¦å·ç´¢å¼•å‚æ•°
    account_index = int(request.args.get("account_index", 0))

    # éªŒè¯è´¦å·ç´¢å¼•
    if account_index < 0 or account_index >= len(config_data["cookie"]):
        return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

    account = Quark(config_data["cookie"][account_index], account_index)
    paths = []
    if path := request.args.get("path"):
        if path == "/":
            fid = 0
        else:
            dir_names = path.split("/")
            if dir_names[0] == "":
                dir_names.pop(0)
            path_fids = []
            current_path = ""
            for dir_name in dir_names:
                current_path += "/" + dir_name
                path_fids.append(current_path)
            if get_fids := account.get_fids(path_fids):
                fid = get_fids[-1]["fid"]
                paths = [
                    {"fid": get_fid["fid"], "name": dir_name}
                    for get_fid, dir_name in zip(get_fids, dir_names)
                ]
            else:
                return jsonify({"success": False, "data": {"error": "è·å–fidå¤±è´¥"}})
    else:
        fid = request.args.get("fid", "0")
    file_list = {
        "list": account.ls_dir(fid),
        "paths": paths,
    }
    return jsonify({"success": True, "data": file_list})


@app.route("/delete_file", methods=["POST"])
def delete_file():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    # è·å–è´¦å·ç´¢å¼•å‚æ•°
    account_index = int(request.json.get("account_index", 0))

    # éªŒè¯è´¦å·ç´¢å¼•
    if account_index < 0 or account_index >= len(config_data["cookie"]):
        return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

    account = Quark(config_data["cookie"][account_index], account_index)
    if fid := request.json.get("fid"):
        response = account.delete([fid])
        
        # å¤„ç†delete_recordså‚æ•°
        if request.json.get("delete_records") and response.get("code") == 0:
            try:
                # åˆå§‹åŒ–æ•°æ®åº“
                db = RecordDB()
                
                # è·å–save_pathå‚æ•°
                save_path = request.json.get("save_path", "")
                
                # å¦‚æœæ²¡æœ‰æä¾›save_pathï¼Œåˆ™ä¸åˆ é™¤ä»»ä½•è®°å½•
                if not save_path:
                    response["deleted_records"] = 0
                    # logging.info(f">>> åˆ é™¤æ–‡ä»¶ {fid} ä½†æœªæä¾›save_pathï¼Œä¸åˆ é™¤ä»»ä½•è®°å½•")
                    return jsonify(response)
                
                # æŸ¥è¯¢ä¸è¯¥æ–‡ä»¶IDå’Œsave_pathç›¸å…³çš„æ‰€æœ‰è®°å½•
                cursor = db.conn.cursor()
                
                # ä½¿ç”¨file_idå’Œsave_pathè¿›è¡Œç²¾ç¡®åŒ¹é…
                cursor.execute("SELECT id FROM transfer_records WHERE file_id = ? AND save_path = ?", (fid, save_path))
                record_ids = [row[0] for row in cursor.fetchall()]
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„file_idè®°å½•ï¼Œå°è¯•é€šè¿‡æ–‡ä»¶åæŸ¥æ‰¾
                if not record_ids:
                    # è·å–æ–‡ä»¶åï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                    file_name = request.json.get("file_name", "")
                    if file_name:
                        # ä½¿ç”¨æ–‡ä»¶åå’Œsave_pathè¿›è¡Œç²¾ç¡®åŒ¹é…
                        cursor.execute("""
                            SELECT id FROM transfer_records 
                            WHERE (original_name = ? OR renamed_to = ?) 
                            AND save_path = ?
                        """, (file_name, file_name, save_path))
                        
                        record_ids = [row[0] for row in cursor.fetchall()]
                
                # åˆ é™¤æ‰¾åˆ°çš„æ‰€æœ‰è®°å½•
                deleted_count = 0
                for record_id in record_ids:
                    deleted_count += db.delete_record(record_id)
                
                # æ·»åŠ åˆ é™¤è®°å½•çš„ä¿¡æ¯åˆ°å“åº”ä¸­
                response["deleted_records"] = deleted_count
                # logging.info(f">>> åˆ é™¤æ–‡ä»¶ {fid} åŒæ—¶åˆ é™¤äº† {deleted_count} æ¡ç›¸å…³è®°å½•")
                
            except Exception as e:
                logging.error(f">>> åˆ é™¤è®°å½•æ—¶å‡ºé”™: {str(e)}")
                # ä¸å½±å“ä¸»æµç¨‹ï¼Œå³ä½¿åˆ é™¤è®°å½•å¤±è´¥ä¹Ÿè¿”å›æ–‡ä»¶åˆ é™¤æˆåŠŸ
    else:
        response = {"success": False, "message": "ç¼ºå¤±å¿…è¦å­—æ®µ: fid"}
    return jsonify(response)


# æ·»åŠ ä»»åŠ¡æ¥å£
@app.route("/api/add_task", methods=["POST"])
def add_task():
    global config_data
    # éªŒè¯token
    if not is_login():
        return jsonify({"success": False, "code": 1, "message": "æœªç™»å½•"}), 401
    # å¿…é€‰å­—æ®µ
    request_data = request.json
    required_fields = ["taskname", "shareurl", "savepath"]
    for field in required_fields:
        if field not in request_data or not request_data[field]:
            return (
                jsonify(
                    {"success": False, "code": 2, "message": f"ç¼ºå°‘å¿…è¦å­—æ®µ: {field}"}
                ),
                400,
            )
    # æ·»åŠ ä»»åŠ¡
    config_data["tasklist"].append(request_data)
    Config.write_json(CONFIG_PATH, config_data)
    logging.info(f">>> é€šè¿‡APIæ·»åŠ ä»»åŠ¡: {request_data['taskname']}")
    return jsonify(
        {"success": True, "code": 0, "message": "ä»»åŠ¡æ·»åŠ æˆåŠŸ", "data": request_data}
    )


# å®šæ—¶ä»»åŠ¡æ‰§è¡Œçš„å‡½æ•°
def run_python(args):
    logging.info(f">>> å®šæ—¶è¿è¡Œä»»åŠ¡")

    # åœ¨å®šæ—¶ä»»åŠ¡å¼€å§‹å‰æ¸…ç†è¿‡æœŸç¼“å­˜
    try:
        cleaned_count = cleanup_expired_cache()
        if cleaned_count > 0:
            logging.info(f">>> æ¸…ç†äº† {cleaned_count} ä¸ªè¿‡æœŸç¼“å­˜é¡¹")
    except Exception as e:
        logging.warning(f">>> æ¸…ç†ç¼“å­˜æ—¶å‡ºé”™: {e}")

    # æ£€æŸ¥æ˜¯å¦éœ€è¦éšæœºå»¶è¿Ÿæ‰§è¡Œ
    if delay := config_data.get("crontab_delay"):
        try:
            delay_seconds = int(delay)
            if delay_seconds > 0:
                # åœ¨0åˆ°è®¾å®šå€¼ä¹‹é—´éšæœºé€‰æ‹©ä¸€ä¸ªå»¶è¿Ÿæ—¶é—´
                random_delay = random.randint(0, delay_seconds)
                logging.info(f">>> éšæœºå»¶è¿Ÿæ‰§è¡Œ {random_delay}ç§’")
                time.sleep(random_delay)
        except (ValueError, TypeError):
            logging.warning(f">>> å»¶è¿Ÿæ‰§è¡Œè®¾ç½®æ— æ•ˆ: {delay}")

    os.system(f"{PYTHON_PATH} {args}")


# é‡æ–°åŠ è½½ä»»åŠ¡
def reload_tasks():
    # è¯»å–å®šæ—¶è§„åˆ™
    if crontab := config_data.get("crontab"):
        if scheduler.state == 1:
            scheduler.pause()  # æš‚åœè°ƒåº¦å™¨
        trigger = CronTrigger.from_crontab(crontab)
        scheduler.remove_all_jobs()
        scheduler.add_job(
            run_python,
            trigger=trigger,
            args=[f"{SCRIPT_PATH} {CONFIG_PATH}"],
            id=SCRIPT_PATH,
        )
        if scheduler.state == 0:
            scheduler.start()
        elif scheduler.state == 2:
            scheduler.resume()
        scheduler_state_map = {0: "åœæ­¢", 1: "è¿è¡Œ", 2: "æš‚åœ"}
        logging.info(">>> é‡è½½è°ƒåº¦å™¨")
        logging.info(f"è°ƒåº¦çŠ¶æ€: {scheduler_state_map[scheduler.state]}")
        logging.info(f"å®šæ—¶è§„åˆ™: {crontab}")
        # è®°å½•å»¶è¿Ÿæ‰§è¡Œè®¾ç½®
        if delay := config_data.get("crontab_delay"):
            logging.info(f"å»¶è¿Ÿæ‰§è¡Œ: 0-{delay}ç§’")
        logging.info(f"ç°æœ‰ä»»åŠ¡: {scheduler.get_jobs()}")
        return True
    else:
        logging.info(">>> no crontab")
        return False


def init():
    global config_data, task_plugins_config_default
    logging.info(f">>> åˆå§‹åŒ–é…ç½®")
    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(CONFIG_PATH):
        if not os.path.exists(os.path.dirname(CONFIG_PATH)):
            os.makedirs(os.path.dirname(CONFIG_PATH))
        with open("quark_config.json", "rb") as src, open(CONFIG_PATH, "wb") as dest:
            dest.write(src.read())

    # è¯»å–é…ç½®
    config_data = Config.read_json(CONFIG_PATH)
    Config.breaking_change_update(config_data)

    # é»˜è®¤ç®¡ç†è´¦å·
    config_data["webui"] = {
        "username": os.environ.get("WEBUI_USERNAME")
        or config_data.get("webui", {}).get("username", "admin"),
        "password": os.environ.get("WEBUI_PASSWORD")
        or config_data.get("webui", {}).get("password", "admin"),
    }

    # é»˜è®¤å®šæ—¶è§„åˆ™
    if not config_data.get("crontab"):
        config_data["crontab"] = "0 8,18,20 * * *"
    
    # é»˜è®¤å»¶è¿Ÿæ‰§è¡Œè®¾ç½®
    if "crontab_delay" not in config_data:
        config_data["crontab_delay"] = 0

    # åˆå§‹åŒ–æ’ä»¶é…ç½®
    _, plugins_config_default, task_plugins_config_default = Config.load_plugins()
    plugins_config_default.update(config_data.get("plugins", {}))
    config_data["plugins"] = plugins_config_default
    
    # è·å–ç¦ç”¨çš„æ’ä»¶åˆ—è¡¨
    disabled_plugins = set()
    if PLUGIN_FLAGS:
        disabled_plugins = {name.lstrip('-') for name in PLUGIN_FLAGS.split(',')}
    
    # æ¸…ç†æ‰€æœ‰ä»»åŠ¡ä¸­è¢«ç¦ç”¨æ’ä»¶çš„é…ç½®
    if config_data.get("tasklist"):
        for task in config_data["tasklist"]:
            if "addition" in task:
                for plugin_name in list(task["addition"].keys()):
                    if plugin_name in disabled_plugins:
                        del task["addition"][plugin_name]
    
    # åŒæ­¥æ›´æ–°ä»»åŠ¡çš„æ’ä»¶é…ç½®
    sync_task_plugins_config()

    # æ›´æ–°é…ç½®
    Config.write_json(CONFIG_PATH, config_data)


# è·å–å†å²è½¬å­˜è®°å½•
@app.route("/history_records")
def get_history_records():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
        
    # è·å–è¯·æ±‚å‚æ•°
    page = int(request.args.get("page", 1))
    page_size = int(request.args.get("page_size", 20))
    sort_by = request.args.get("sort_by", "transfer_time")
    order = request.args.get("order", "desc")
    
    # è·å–ç­›é€‰å‚æ•°
    task_name_filter = request.args.get("task_name", "")
    keyword_filter = request.args.get("keyword", "")
    
    # æ˜¯å¦åªè¯·æ±‚æ‰€æœ‰ä»»åŠ¡åç§°
    get_all_task_names = request.args.get("get_all_task_names", "").lower() in ["true", "1", "yes"]
    
    # åˆå§‹åŒ–æ•°æ®åº“
    db = RecordDB()
    
    # å¦‚æœè¯·æ±‚æ‰€æœ‰ä»»åŠ¡åç§°ï¼Œå•ç‹¬æŸ¥è¯¢å¹¶è¿”å›
    if get_all_task_names:
        cursor = db.conn.cursor()
        cursor.execute("SELECT DISTINCT task_name FROM transfer_records WHERE task_name NOT IN ('rename', 'undo_rename') ORDER BY task_name")
        all_task_names = [row[0] for row in cursor.fetchall()]
        
        # å¦‚æœåŒæ—¶è¯·æ±‚åˆ†é¡µæ•°æ®ï¼Œç»§ç»­å¸¸è§„æŸ¥è¯¢
        if page > 0 and page_size > 0:
            result = db.get_records(
                page=page, 
                page_size=page_size, 
                sort_by=sort_by, 
                order=order,
                task_name_filter=task_name_filter,
                keyword_filter=keyword_filter,
                exclude_task_names=["rename", "undo_rename"]
            )
            # æ·»åŠ æ‰€æœ‰ä»»åŠ¡åç§°åˆ°ç»“æœä¸­
            result["all_task_names"] = all_task_names
            
            # å¤„ç†è®°å½•æ ¼å¼åŒ–
            format_records(result["records"])
            
            return jsonify({"success": True, "data": result})
        else:
            # åªè¿”å›ä»»åŠ¡åç§°
            return jsonify({"success": True, "data": {"all_task_names": all_task_names}})
    
    # å¸¸è§„æŸ¥è¯¢
    result = db.get_records(
        page=page, 
        page_size=page_size, 
        sort_by=sort_by, 
        order=order,
        task_name_filter=task_name_filter,
        keyword_filter=keyword_filter,
        exclude_task_names=["rename", "undo_rename"]
    )
    
    # å¤„ç†è®°å½•æ ¼å¼åŒ–
    format_records(result["records"])
    
    return jsonify({"success": True, "data": result})


# åˆ é™¤è½¬å­˜è®°å½•
@app.route("/delete_history_records", methods=["POST"])
def delete_history_records():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    # è·å–è¦åˆ é™¤çš„è®°å½•IDåˆ—è¡¨
    record_ids = request.json.get("record_ids", [])
    
    if not record_ids:
        return jsonify({"success": False, "message": "æœªæä¾›è¦åˆ é™¤çš„è®°å½•ID"})
    
    # åˆå§‹åŒ–æ•°æ®åº“
    db = RecordDB()
    
    # åˆ é™¤è®°å½•
    deleted_count = 0
    for record_id in record_ids:
        deleted_count += db.delete_record(record_id)
    
    return jsonify({
        "success": True, 
        "message": f"æˆåŠŸåˆ é™¤ {deleted_count} æ¡è®°å½•",
        "deleted_count": deleted_count
    })


# åˆ é™¤å•æ¡è½¬å­˜è®°å½•
@app.route("/delete_history_record", methods=["POST"])
def delete_history_record():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    # è·å–è¦åˆ é™¤çš„è®°å½•ID
    record_id = request.json.get("id")
    
    if not record_id:
        return jsonify({"success": False, "message": "æœªæä¾›è¦åˆ é™¤çš„è®°å½•ID"})
    
    # åˆå§‹åŒ–æ•°æ®åº“
    db = RecordDB()
    
    # åˆ é™¤è®°å½•
    deleted = db.delete_record(record_id)
    
    if deleted:
        return jsonify({
            "success": True, 
            "message": "æˆåŠŸåˆ é™¤ 1 æ¡è®°å½•",
        })
    else:
        return jsonify({
            "success": False, 
            "message": "è®°å½•åˆ é™¤å¤±è´¥ï¼Œå¯èƒ½è®°å½•ä¸å­˜åœ¨",
        })


# è¾…åŠ©å‡½æ•°ï¼šæ ¼å¼åŒ–è®°å½•
def format_records(records):
    for record in records:
        # æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸ºå¯è¯»å½¢å¼
        if "transfer_time" in record:
            try:
                # ç¡®ä¿æ—¶é—´æˆ³åœ¨åˆç†èŒƒå›´å†…
                timestamp = int(record["transfer_time"])
                if timestamp > 9999999999:  # æ£€æµ‹æ˜¯å¦ä¸ºæ¯«ç§’çº§æ—¶é—´æˆ³ï¼ˆ13ä½ï¼‰
                    timestamp = timestamp / 1000  # è½¬æ¢ä¸ºç§’çº§æ—¶é—´æˆ³
                
                if 0 < timestamp < 4102444800:  # ä»1970å¹´åˆ°2100å¹´çš„åˆç†æ—¶é—´æˆ³èŒƒå›´
                    record["transfer_time_readable"] = datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d %H:%M:%S")
                else:
                    record["transfer_time_readable"] = "æ— æ•ˆæ—¥æœŸ"
            except (ValueError, TypeError, OverflowError):
                record["transfer_time_readable"] = "æ— æ•ˆæ—¥æœŸ"
                
        if "modify_date" in record:
            try:
                # ç¡®ä¿æ—¶é—´æˆ³åœ¨åˆç†èŒƒå›´å†…
                timestamp = int(record["modify_date"])
                if timestamp > 9999999999:  # æ£€æµ‹æ˜¯å¦ä¸ºæ¯«ç§’çº§æ—¶é—´æˆ³ï¼ˆ13ä½ï¼‰
                    timestamp = timestamp / 1000  # è½¬æ¢ä¸ºç§’çº§æ—¶é—´æˆ³
                    
                if 0 < timestamp < 4102444800:  # ä»1970å¹´åˆ°2100å¹´çš„åˆç†æ—¶é—´æˆ³èŒƒå›´
                    record["modify_date_readable"] = datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d %H:%M:%S")
                else:
                    record["modify_date_readable"] = "æ— æ•ˆæ—¥æœŸ"
            except (ValueError, TypeError, OverflowError):
                record["modify_date_readable"] = "æ— æ•ˆæ—¥æœŸ"
                
        # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
        if "file_size" in record:
            try:
                record["file_size_readable"] = format_bytes(int(record["file_size"]))
            except (ValueError, TypeError):
                record["file_size_readable"] = "æœªçŸ¥å¤§å°"


@app.route("/get_user_info")
def get_user_info():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    user_info_list = []
    for idx, cookie in enumerate(config_data["cookie"]):
        account = Quark(cookie, idx)
        account_info = account.init()
        if account_info:
            user_info_list.append({
                "index": idx,
                "nickname": account_info["nickname"],
                "is_active": account.is_active
            })
        else:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç§»åŠ¨ç«¯å‚æ•°
            has_mparam = bool(account.mparam)
            user_info_list.append({
                "index": idx,
                "nickname": "",
                "is_active": False,
                "has_mparam": has_mparam
            })

    return jsonify({"success": True, "data": user_info_list})


@app.route("/get_accounts_detail")
def get_accounts_detail():
    """è·å–æ‰€æœ‰è´¦å·çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ˜µç§°å’Œç©ºé—´ä½¿ç”¨æƒ…å†µ"""
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    accounts_detail = []
    for idx, cookie in enumerate(config_data["cookie"]):
        account = Quark(cookie, idx)
        account_info = account.init()

        # å¦‚æœæ— æ³•è·å–è´¦å·ä¿¡æ¯ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ç§»åŠ¨ç«¯å‚æ•°
        if not account_info:
            has_mparam = bool(account.mparam)
            # å¦‚æœåªæœ‰ç§»åŠ¨ç«¯å‚æ•°ï¼Œè·³è¿‡æ­¤è´¦å·ï¼ˆä¸æ˜¾ç¤ºåœ¨æ–‡ä»¶æ•´ç†é¡µé¢çš„è´¦å·é€‰æ‹©æ ä¸­ï¼‰
            if has_mparam:
                continue
            else:
                # å¦‚æœæ—¢æ²¡æœ‰è´¦å·ä¿¡æ¯ä¹Ÿæ²¡æœ‰ç§»åŠ¨ç«¯å‚æ•°ï¼Œæ˜¾ç¤ºä¸ºæœªç™»å½•
                account_detail = {
                    "index": idx,
                    "nickname": "",
                    "is_active": False,
                    "used_space": 0,
                    "total_space": 0,
                    "usage_rate": 0,
                    "display_text": f"è´¦å·{idx + 1}ï¼ˆæœªç™»å½•ï¼‰"
                }
                accounts_detail.append(account_detail)
                continue

        # æˆåŠŸè·å–è´¦å·ä¿¡æ¯çš„æƒ…å†µ
        account_detail = {
            "index": idx,
            "nickname": account_info["nickname"],
            "is_active": account.is_active,
            "used_space": 0,
            "total_space": 0,
            "usage_rate": 0,
            "display_text": ""
        }

        # æ£€æŸ¥æ˜¯å¦æœ‰ç§»åŠ¨ç«¯å‚æ•°
        has_mparam = bool(account.mparam)
        
        if has_mparam:
            # åŒæ—¶æœ‰cookieå’Œç§»åŠ¨ç«¯å‚æ•°ï¼Œå°è¯•è·å–ç©ºé—´ä¿¡æ¯
            try:
                growth_info = account.get_growth_info()
                if growth_info:
                    total_capacity = growth_info.get("total_capacity", 0)
                    account_detail["total_space"] = total_capacity
                    # æ˜¾ç¤ºæ˜µç§°å’Œæ€»å®¹é‡
                    total_str = format_bytes(total_capacity)
                    account_detail["display_text"] = f"{account_info['nickname']} Â· {total_str}"
                else:
                    # è·å–ç©ºé—´ä¿¡æ¯å¤±è´¥ï¼Œåªæ˜¾ç¤ºæ˜µç§°
                    account_detail["display_text"] = account_info["nickname"]
            except Exception as e:
                logging.error(f"è·å–è´¦å· {idx} ç©ºé—´ä¿¡æ¯å¤±è´¥: {str(e)}")
                # è·å–ç©ºé—´ä¿¡æ¯å¤±è´¥ï¼Œåªæ˜¾ç¤ºæ˜µç§°
                account_detail["display_text"] = account_info["nickname"]
        else:
            # åªæœ‰cookieï¼Œæ²¡æœ‰ç§»åŠ¨ç«¯å‚æ•°ï¼Œåªæ˜¾ç¤ºæ˜µç§°
            account_detail["display_text"] = account_info["nickname"]

        accounts_detail.append(account_detail)

    return jsonify({"success": True, "data": accounts_detail})


# é‡ç½®æ–‡ä»¶å¤¹ï¼ˆåˆ é™¤æ–‡ä»¶å¤¹å†…æ‰€æœ‰æ–‡ä»¶å’Œç›¸å…³è®°å½•ï¼‰
@app.route("/reset_folder", methods=["POST"])
def reset_folder():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    # è·å–è¯·æ±‚å‚æ•°
    save_path = request.json.get("save_path", "")
    account_index = int(request.json.get("account_index", 0))  # æ–°å¢è´¦å·ç´¢å¼•å‚æ•°

    if not save_path:
        return jsonify({"success": False, "message": "ä¿å­˜è·¯å¾„ä¸èƒ½ä¸ºç©º"})

    try:
        # éªŒè¯è´¦å·ç´¢å¼•
        if account_index < 0 or account_index >= len(config_data["cookie"]):
            return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

        # åˆå§‹åŒ–å¤¸å…‹ç½‘ç›˜å®¢æˆ·ç«¯
        account = Quark(config_data["cookie"][account_index], account_index)
        
        # 1. è·å–æ–‡ä»¶å¤¹ID
        # å…ˆæ£€æŸ¥æ˜¯å¦å·²æœ‰ç¼“å­˜çš„æ–‡ä»¶å¤¹ID
        folder_fid = account.savepath_fid.get(save_path)
        
        # å¦‚æœæ²¡æœ‰ç¼“å­˜çš„IDï¼Œåˆ™å°è¯•åˆ›å»ºæ–‡ä»¶å¤¹ä»¥è·å–ID
        if not folder_fid:
            mkdir_result = account.mkdir(save_path)
            if mkdir_result.get("code") == 0:
                folder_fid = mkdir_result["data"]["fid"]
                account.savepath_fid[save_path] = folder_fid
            else:
                return jsonify({"success": False, "message": f"è·å–æ–‡ä»¶å¤¹IDå¤±è´¥: {mkdir_result.get('message', 'æœªçŸ¥é”™è¯¯')}"})
        
        # 2. è·å–æ–‡ä»¶å¤¹å†…çš„æ‰€æœ‰æ–‡ä»¶
        file_list = account.ls_dir(folder_fid)
        if isinstance(file_list, dict) and file_list.get("error"):
            return jsonify({"success": False, "message": f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {file_list.get('error', 'æœªçŸ¥é”™è¯¯')}"})
        
        # æ”¶é›†æ‰€æœ‰æ–‡ä»¶ID
        file_ids = []
        for item in file_list:
            file_ids.append(item["fid"])
        
        # 3. åˆ é™¤æ‰€æœ‰æ–‡ä»¶
        deleted_files = 0
        if file_ids:
            delete_result = account.delete(file_ids)
            if delete_result.get("code") == 0:
                deleted_files = len(file_ids)
        
        # 4. åˆ é™¤ç›¸å…³çš„å†å²è®°å½•
        deleted_records = 0
        try:
            # åˆå§‹åŒ–æ•°æ®åº“
            db = RecordDB()
            
            # æŸ¥è¯¢ä¸è¯¥ä¿å­˜è·¯å¾„ç›¸å…³çš„æ‰€æœ‰è®°å½•
            cursor = db.conn.cursor()
            cursor.execute("SELECT id FROM transfer_records WHERE save_path = ?", (save_path,))
            record_ids = [row[0] for row in cursor.fetchall()]
            
            # åˆ é™¤æ‰¾åˆ°çš„æ‰€æœ‰è®°å½•
            for record_id in record_ids:
                deleted_records += db.delete_record(record_id)
                
        except Exception as e:
            logging.error(f">>> åˆ é™¤è®°å½•æ—¶å‡ºé”™: {str(e)}")
            # å³ä½¿åˆ é™¤è®°å½•å¤±è´¥ï¼Œä¹Ÿè¿”å›æ–‡ä»¶åˆ é™¤æˆåŠŸ
        
        return jsonify({
            "success": True, 
            "message": f"é‡ç½®æˆåŠŸï¼Œåˆ é™¤äº† {deleted_files} ä¸ªæ–‡ä»¶å’Œ {deleted_records} æ¡è®°å½•",
            "deleted_files": deleted_files,
            "deleted_records": deleted_records
        })
        
    except Exception as e:
        logging.error(f">>> é‡ç½®æ–‡ä»¶å¤¹æ—¶å‡ºé”™: {str(e)}")
        return jsonify({"success": False, "message": f"é‡ç½®æ–‡ä»¶å¤¹æ—¶å‡ºé”™: {str(e)}"})


# è·å–æ–‡ä»¶åˆ—è¡¨
@app.route("/file_list")
def get_file_list():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    # è·å–è¯·æ±‚å‚æ•°
    folder_id = request.args.get("folder_id", "root")
    sort_by = request.args.get("sort_by", "file_name")
    order = request.args.get("order", "asc")
    page = int(request.args.get("page", 1))
    page_size = int(request.args.get("page_size", 15))
    account_index = int(request.args.get("account_index", 0))
    force_refresh = request.args.get("force_refresh", "false").lower() == "true"  # æ–°å¢è´¦å·ç´¢å¼•å‚æ•°

    try:
        # éªŒè¯è´¦å·ç´¢å¼•
        if account_index < 0 or account_index >= len(config_data["cookie"]):
            return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

        # åˆå§‹åŒ–å¤¸å…‹ç½‘ç›˜å®¢æˆ·ç«¯
        account = Quark(config_data["cookie"][account_index], account_index)

        # è·å–æ–‡ä»¶åˆ—è¡¨
        if folder_id == "root":
            folder_id = "0"  # æ ¹ç›®å½•çš„IDä¸º0
            paths = []  # æ ¹ç›®å½•æ²¡æœ‰è·¯å¾„
        else:
            # è·å–å½“å‰æ–‡ä»¶å¤¹çš„è·¯å¾„
            paths = account.get_paths(folder_id)

        # è·å–æ€§èƒ½é…ç½®
        perf_config = get_performance_config()
        api_page_size = perf_config.get("api_page_size", 200)
        cache_expire_time = perf_config.get("cache_expire_time", 30)

        # ç¼“å­˜é”®
        cache_key = f"{account_index}_{folder_id}_{sort_by}_{order}"
        current_time = time.time()

        # æ£€æŸ¥ç¼“å­˜ï¼ˆé™¤éå¼ºåˆ¶åˆ·æ–°ï¼‰
        if not force_refresh:
            with cache_lock:
                if cache_key in file_list_cache:
                    cache_data, cache_time = file_list_cache[cache_key]
                    if current_time - cache_time < cache_expire_time:
                        # ä½¿ç”¨ç¼“å­˜æ•°æ®
                        cached_files = cache_data
                        total = len(cached_files)
                        start_idx = (page - 1) * page_size
                        end_idx = min(start_idx + page_size, total)
                        paginated_files = cached_files[start_idx:end_idx]

                        return jsonify({
                            "success": True,
                            "data": {
                                "list": paginated_files,
                                "total": total,
                                "paths": paths
                            }
                        })
        else:
            # å¼ºåˆ¶åˆ·æ–°æ—¶ï¼Œæ¸…é™¤å½“å‰ç›®å½•çš„ç¼“å­˜
            with cache_lock:
                if cache_key in file_list_cache:
                    del file_list_cache[cache_key]

        # æ— è®ºåˆ†é¡µè¿˜æ˜¯å…¨éƒ¨æ¨¡å¼ï¼Œéƒ½å¿…é¡»è·å–æ‰€æœ‰æ–‡ä»¶æ‰èƒ½è¿›è¡Œæ­£ç¡®çš„å…¨å±€æ’åº
        files = account.ls_dir(folder_id, page_size=api_page_size)

        if isinstance(files, dict) and files.get("error"):
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®å½•ä¸å­˜åœ¨çš„é”™è¯¯
            error_msg = files.get('error', 'æœªçŸ¥é”™è¯¯')
            if "ä¸å­˜åœ¨" in error_msg or "æ— æ•ˆ" in error_msg or "æ‰¾ä¸åˆ°" in error_msg:
                return jsonify({"success": False, "message": f"ç›®å½•ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®: {error_msg}"})
            else:
                return jsonify({"success": False, "message": f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {error_msg}"})

        # è®¡ç®—æ€»æ•°
        total = len(files)

        # ä¼˜åŒ–æ’åºï¼šä½¿ç”¨æ›´é«˜æ•ˆçš„æ’åºæ–¹æ³•
        def get_sort_key(file_item):
            if sort_by == "file_name":
                return file_item["file_name"].lower()
            elif sort_by == "file_size":
                return file_item["size"] if not file_item["dir"] else 0
            else:  # updated_at
                return file_item["updated_at"]

        # åˆ†ç¦»æ–‡ä»¶å¤¹å’Œæ–‡ä»¶ä»¥ä¼˜åŒ–æ’åº
        if sort_by == "updated_at":
            # ä¿®æ”¹æ—¥æœŸæ’åºæ—¶ä¸¥æ ¼æŒ‰ç…§æ—¥æœŸæ’åºï¼Œä¸åŒºåˆ†æ–‡ä»¶å¤¹å’Œæ–‡ä»¶
            files.sort(key=get_sort_key, reverse=(order == "desc"))
            sorted_files = files
        else:
            # å…¶ä»–æ’åºæ—¶ç›®å½•å§‹ç»ˆåœ¨å‰é¢ï¼Œåˆ†åˆ«æ’åºä»¥æé«˜æ•ˆç‡
            directories = [f for f in files if f["dir"]]
            normal_files = [f for f in files if not f["dir"]]

            directories.sort(key=get_sort_key, reverse=(order == "desc"))
            normal_files.sort(key=get_sort_key, reverse=(order == "desc"))

            sorted_files = directories + normal_files

        # æ›´æ–°ç¼“å­˜
        with cache_lock:
            file_list_cache[cache_key] = (sorted_files, current_time)

        # åˆ†é¡µ
        start_idx = (page - 1) * page_size
        end_idx = min(start_idx + page_size, total)
        paginated_files = sorted_files[start_idx:end_idx]

        return jsonify({
            "success": True,
            "data": {
                "list": paginated_files,
                "total": total,
                "paths": paths
            }
        })
        
    except Exception as e:
        logging.error(f">>> è·å–æ–‡ä»¶åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}")
        return jsonify({"success": False, "message": f"è·å–æ–‡ä»¶åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}"})


# é¢„è§ˆé‡å‘½å
@app.route("/preview_rename")
def preview_rename():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    # è·å–è¯·æ±‚å‚æ•°
    folder_id = request.args.get("folder_id", "root")
    pattern = request.args.get("pattern", "")
    replace = request.args.get("replace", "")
    naming_mode = request.args.get("naming_mode", "regex")  # regex, sequence, episode
    include_folders = request.args.get("include_folders", "false") == "true"
    filterwords = request.args.get("filterwords", "")
    account_index = int(request.args.get("account_index", 0))  # æ–°å¢è´¦å·ç´¢å¼•å‚æ•°

    if not pattern:
        pattern = ".*"

    try:
        # éªŒè¯è´¦å·ç´¢å¼•
        if account_index < 0 or account_index >= len(config_data["cookie"]):
            return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

        # åˆå§‹åŒ–å¤¸å…‹ç½‘ç›˜å®¢æˆ·ç«¯
        account = Quark(config_data["cookie"][account_index], account_index)
        
        # è·å–æ–‡ä»¶åˆ—è¡¨
        if folder_id == "root":
            folder_id = "0"  # æ ¹ç›®å½•çš„IDä¸º0
        
        files = account.ls_dir(folder_id)
        if isinstance(files, dict) and files.get("error"):
            return jsonify({"success": False, "message": f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {files.get('error', 'æœªçŸ¥é”™è¯¯')}"})
        
        # è¿‡æ»¤è¦æ’é™¤çš„æ–‡ä»¶
        # æ›¿æ¢ä¸­æ–‡é€—å·ä¸ºè‹±æ–‡é€—å·
        filterwords = filterwords.replace("ï¼Œ", ",") 
        filter_list = [keyword.strip() for keyword in filterwords.split(",") if keyword.strip()]
        filtered_files = []
        for file in files:
            # å¦‚æœä¸åŒ…å«æ–‡ä»¶å¤¹ä¸”å½“å‰é¡¹æ˜¯æ–‡ä»¶å¤¹ï¼Œè·³è¿‡
            if not include_folders and file["dir"]:
                continue
                
            # æ£€æŸ¥æ˜¯å¦åŒ…å«è¿‡æ»¤å…³é”®è¯
            should_filter = False
            for keyword in filter_list:
                if keyword and keyword in file["file_name"]:
                    should_filter = True
                    break
                    
            if not should_filter:
                filtered_files.append(file)
        
        # æŒ‰ä¸åŒå‘½åæ¨¡å¼å¤„ç†
        preview_results = []
        
        if naming_mode == "sequence":
            # é¡ºåºå‘½åæ¨¡å¼
            # æ’åºæ–‡ä»¶ï¼ˆæŒ‰æ–‡ä»¶åæˆ–ä¿®æ”¹æ—¶é—´ï¼‰
            filtered_files.sort(key=lambda x: sort_file_by_name(x["file_name"]))
            
            sequence = 1
            for file in filtered_files:
                extension = os.path.splitext(file["file_name"])[1] if not file["dir"] else ""
                new_name = pattern.replace("{}", f"{sequence:02d}") + extension
                preview_results.append({
                    "original_name": file["file_name"],
                    "new_name": new_name,
                    "file_id": file["fid"]
                })
                sequence += 1
                
        elif naming_mode == "episode":
            # å‰§é›†å‘½åæ¨¡å¼
            # è·å–é»˜è®¤çš„å‰§é›†æ¨¡å¼
            default_episode_pattern = {"regex": 'ç¬¬(\\d+)é›†|ç¬¬(\\d+)æœŸ|ç¬¬(\\d+)è¯|(\\d+)é›†|(\\d+)æœŸ|(\\d+)è¯|[Ee][Pp]?(\\d+)|(\\d+)[-_\\s]*4[Kk]|\\[(\\d+)\\]|ã€(\\d+)ã€‘|_?(\\d+)_?'}
            
            # è·å–é…ç½®çš„å‰§é›†æ¨¡å¼ï¼Œç¡®ä¿æ¯ä¸ªæ¨¡å¼éƒ½æ˜¯å­—å…¸æ ¼å¼
            episode_patterns = []
            raw_patterns = config_data.get("episode_patterns", [default_episode_pattern])
            for p in raw_patterns:
                if isinstance(p, dict) and p.get("regex"):
                    episode_patterns.append(p)
                elif isinstance(p, str):
                    episode_patterns.append({"regex": p})
            
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„æ¨¡å¼ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å¼
            if not episode_patterns:
                episode_patterns = [default_episode_pattern]
                
            # æ·»åŠ ä¸­æ–‡æ•°å­—åŒ¹é…æ¨¡å¼
            chinese_patterns = [
                {"regex": r'ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)é›†'},
                {"regex": r'ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)æœŸ'},
                {"regex": r'ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)è¯'},
                {"regex": r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)é›†'},
                {"regex": r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)æœŸ'},
                {"regex": r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)è¯'}
            ]
            episode_patterns.extend(chinese_patterns)
            
            # å¤„ç†æ¯ä¸ªæ–‡ä»¶
            for file in filtered_files:
                extension = os.path.splitext(file["file_name"])[1] if not file["dir"] else ""
                # ä»æ–‡ä»¶åä¸­æå–é›†å·
                episode_num = extract_episode_number(file["file_name"], episode_patterns=episode_patterns)
                
                if episode_num is not None:
                    new_name = pattern.replace("[]", f"{episode_num:02d}") + extension
                    preview_results.append({
                        "original_name": file["file_name"],
                        "new_name": new_name,
                        "file_id": file["fid"]
                    })
                else:
                    # æ²¡æœ‰æå–åˆ°é›†å·ï¼Œæ˜¾ç¤ºæ— æ³•è¯†åˆ«çš„æç¤º
                    preview_results.append({
                        "original_name": file["file_name"],
                        "new_name": "Ã— æ— æ³•è¯†åˆ«å‰§é›†ç¼–å·",
                        "file_id": file["fid"]
                    })
        
        else:
            # æ­£åˆ™å‘½åæ¨¡å¼
            for file in filtered_files:
                try:
                    # åº”ç”¨æ­£åˆ™è¡¨è¾¾å¼
                    if replace:
                        new_name = re.sub(pattern, replace, file["file_name"])
                    else:
                        # å¦‚æœæ²¡æœ‰æä¾›æ›¿æ¢è¡¨è¾¾å¼ï¼Œåˆ™æ£€æŸ¥æ˜¯å¦åŒ¹é…
                        if re.search(pattern, file["file_name"]):
                            new_name = file["file_name"]  # åŒ¹é…ä½†ä¸æ›¿æ¢
                        else:
                            new_name = ""  # è¡¨ç¤ºä¸åŒ¹é…
                            
                    preview_results.append({
                        "original_name": file["file_name"],
                        "new_name": new_name if new_name != file["file_name"] else "",  # å¦‚æœæ²¡æœ‰æ”¹å˜ï¼Œè¿”å›ç©ºè¡¨ç¤ºä¸é‡å‘½å
                        "file_id": file["fid"]
                    })
                except Exception as e:
                    # æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯
                    preview_results.append({
                        "original_name": file["file_name"],
                        "new_name": "",  # è¡¨ç¤ºæ— æ³•é‡å‘½å
                        "file_id": file["fid"],
                        "error": str(e)
                    })
        
        return jsonify({
            "success": True, 
            "data": preview_results
        })
        
    except Exception as e:
        logging.error(f">>> é¢„è§ˆé‡å‘½åæ—¶å‡ºé”™: {str(e)}")
        return jsonify({"success": False, "message": f"é¢„è§ˆé‡å‘½åæ—¶å‡ºé”™: {str(e)}"})


# æ‰¹é‡é‡å‘½å
@app.route("/batch_rename", methods=["POST"])
def batch_rename():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    # è·å–è¯·æ±‚å‚æ•°
    data = request.json
    files = data.get("files", [])
    account_index = int(data.get("account_index", 0))  # æ–°å¢è´¦å·ç´¢å¼•å‚æ•°

    if not files:
        return jsonify({"success": False, "message": "æ²¡æœ‰æ–‡ä»¶éœ€è¦é‡å‘½å"})

    try:
        # éªŒè¯è´¦å·ç´¢å¼•
        if account_index < 0 or account_index >= len(config_data["cookie"]):
            return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

        # åˆå§‹åŒ–å¤¸å…‹ç½‘ç›˜å®¢æˆ·ç«¯
        account = Quark(config_data["cookie"][account_index], account_index)
        
        # æ‰¹é‡é‡å‘½å
        success_count = 0
        failed_files = []
        save_path = data.get("save_path", "")
        batch_time = int(time.time() * 1000)  # æ‰¹æ¬¡æ—¶é—´æˆ³ï¼Œç¡®ä¿åŒä¸€æ‰¹transfer_timeä¸€è‡´
        for file_item in files:
            file_id = file_item.get("file_id")
            new_name = file_item.get("new_name")
            original_name = file_item.get("old_name") or ""
            if file_id and new_name:
                try:
                    result = account.rename(file_id, new_name)
                    if result.get("code") == 0:
                        success_count += 1
                        # è®°å½•é‡å‘½å
                        record_db.add_record(
                            task_name="rename",
                            original_name=original_name,
                            renamed_to=new_name,
                            file_size=0,
                            modify_date=int(time.time()),
                            file_id=file_id,
                            file_type="file",
                            save_path=save_path,
                            transfer_time=batch_time
                        )
                    else:
                        failed_files.append({
                            "file_id": file_id,
                            "new_name": new_name,
                            "error": result.get("message", "æœªçŸ¥é”™è¯¯")
                        })
                except Exception as e:
                    failed_files.append({
                        "file_id": file_id,
                        "new_name": new_name,
                        "error": str(e)
                    })
        
        return jsonify({
            "success": True, 
            "message": f"æˆåŠŸé‡å‘½å {success_count} ä¸ªæ–‡ä»¶ï¼Œå¤±è´¥ {len(failed_files)} ä¸ª",
            "success_count": success_count,
            "failed_files": failed_files
        })
        
    except Exception as e:
        logging.error(f">>> æ‰¹é‡é‡å‘½åæ—¶å‡ºé”™: {str(e)}")
        return jsonify({"success": False, "message": f"æ‰¹é‡é‡å‘½åæ—¶å‡ºé”™: {str(e)}"})


# æ’¤é”€é‡å‘½åæ¥å£
@app.route("/undo_rename", methods=["POST"])
def undo_rename():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    data = request.json
    save_path = data.get("save_path", "")
    account_index = int(data.get("account_index", 0))  # æ–°å¢è´¦å·ç´¢å¼•å‚æ•°

    if not save_path:
        return jsonify({"success": False, "message": "ç¼ºå°‘ç›®å½•å‚æ•°"})

    try:
        # éªŒè¯è´¦å·ç´¢å¼•
        if account_index < 0 or account_index >= len(config_data["cookie"]):
            return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

        account = Quark(config_data["cookie"][account_index], account_index)
        # æŸ¥è¯¢è¯¥ç›®å½•ä¸‹æœ€è¿‘ä¸€æ¬¡é‡å‘½åï¼ˆæŒ‰transfer_timeåˆ†ç»„ï¼Œtask_name=renameï¼‰
        records = record_db.get_records_by_save_path(save_path)
        rename_records = [r for r in records if r["task_name"] == "rename"]
        if not rename_records:
            return jsonify({"success": False, "message": "æ²¡æœ‰å¯æ’¤é”€çš„é‡å‘½åè®°å½•"})
        # æ‰¾åˆ°æœ€è¿‘ä¸€æ‰¹ï¼ˆtransfer_timeæœ€å¤§å€¼ï¼‰
        latest_time = max(r["transfer_time"] for r in rename_records)
        latest_batch = [r for r in rename_records if r["transfer_time"] == latest_time]
        success_count = 0
        failed_files = []
        deleted_ids = []
        for rec in latest_batch:
            file_id = rec["file_id"]
            old_name = rec["original_name"]
            try:
                result = account.rename(file_id, old_name)
                if result.get("code") == 0:
                    success_count += 1
                    deleted_ids.append(rec["id"])
                else:
                    failed_files.append({
                        "file_id": file_id,
                        "old_name": old_name,
                        "error": result.get("message", "æœªçŸ¥é”™è¯¯")
                    })
            except Exception as e:
                failed_files.append({
                    "file_id": file_id,
                    "old_name": old_name,
                    "error": str(e)
                })
        # æ’¤é”€æˆåŠŸçš„ï¼Œç›´æ¥åˆ é™¤å¯¹åº”renameè®°å½•
        for rid in deleted_ids:
            record_db.delete_record(rid)
        return jsonify({
            "success": True,
            "message": f"æˆåŠŸæ’¤é”€ {success_count} ä¸ªæ–‡ä»¶é‡å‘½åï¼Œå¤±è´¥ {len(failed_files)} ä¸ª",
            "success_count": success_count,
            "failed_files": failed_files
        })
    except Exception as e:
        logging.error(f">>> æ’¤é”€é‡å‘½åæ—¶å‡ºé”™: {str(e)}")
        return jsonify({"success": False, "message": f"æ’¤é”€é‡å‘½åæ—¶å‡ºé”™: {str(e)}"})


@app.route("/api/has_rename_record")
def has_rename_record():
    save_path = request.args.get("save_path", "")
    db = RecordDB()
    records = db.get_records_by_save_path(save_path)
    has_rename = any(r["task_name"] == "rename" for r in records)
    return jsonify({"has_rename": has_rename})


if __name__ == "__main__":
    init()
    reload_tasks()
    # åˆå§‹åŒ–å…¨å±€dbå¯¹è±¡ï¼Œç¡®ä¿æ‰€æœ‰æ¥å£å¯ç”¨
    record_db = RecordDB()
    app.run(debug=DEBUG, host="0.0.0.0", port=PORT)
