# !/usr/bin/env python3
# -*- coding: utf-8 -*-
from flask import (
    json,
    Flask,
    url_for,
    session,
    jsonify,
    request,
    redirect,
    Response,
    render_template,
    send_from_directory,
    stream_with_context,
)
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.interval import IntervalTrigger
from apscheduler.triggers.date import DateTrigger
from queue import Queue
from collections import deque
from sdk.cloudsaver import CloudSaver
try:
    from sdk.pansou import PanSou
except Exception:
    PanSou = None
from datetime import timedelta, datetime
import subprocess
import requests
import hashlib
import logging
from logging.handlers import RotatingFileHandler
import base64
import sys
import os
import re
import random
import time
import treelib
from functools import lru_cache
from threading import Lock, Thread

parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
sys.path.insert(0, parent_dir)
from quark_auto_save import Quark
from quark_auto_save import Config, format_bytes

# æ·»åŠ å¯¼å…¥å…¨å±€extract_episode_numberå’Œsort_file_by_nameå‡½æ•°
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from quark_auto_save import extract_episode_number, sort_file_by_name, chinese_to_arabic, is_date_format, apply_subtitle_naming_rule

# å¯¼å…¥è±†ç“£æœåŠ¡
from sdk.douban_service import douban_service

# å¯¼å…¥è¿½å‰§æ—¥å†ç›¸å…³æ¨¡å—
from utils.task_extractor import TaskExtractor
from sdk.tmdb_service import TMDBService
from sdk.trakt_service import TraktService
from sdk.db import CalendarDB
from sdk.db import RecordDB
from utils.task_extractor import TaskExtractor

def _get_local_timezone() -> str:
    """
    è·å–æœ¬åœ°æ—¶åŒºé…ç½®ï¼Œç”¨äº Trakt æ’­å‡ºæ—¶é—´è½¬æ¢ä¸æœ¬åœ°æ—¶é—´åˆ¤æ–­ã€‚
    é»˜è®¤ä¸º Asia/Shanghaiï¼ˆåŒ—äº¬æ—¶é—´ï¼‰ï¼Œä¿è¯å‘åå…¼å®¹ã€‚
    """
    try:
        if isinstance(config_data, dict):
            tz = config_data.get("local_timezone") or "Asia/Shanghai"
            return str(tz) or "Asia/Shanghai"
    except Exception:
        pass
    return "Asia/Shanghai"

def is_episode_aired(tmdb_id: int, season_number: int, episode_number: int, now_local_dt) -> bool:
    """
    å•é›†æ˜¯å¦å·²æ’­å‡ºåˆ¤å®šï¼š
    1. å§‹ç»ˆä½¿ç”¨ air_date_localï¼ˆå·²è€ƒè™‘ air_date_offsetï¼‰ä½œä¸ºæ—¥æœŸåˆ¤æ–­
    2. å¦‚æœ air_date_local ä¸å­˜åœ¨ï¼Œè¯´æ˜æ’­å‡ºæ—¶é—´æœªçŸ¥ï¼Œè¿”å› False
    3. å§‹ç»ˆä½¿ç”¨ local_air_time ä½œä¸ºæ—¶é—´åˆ¤æ–­ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨æ’­å‡ºé›†æ•°åˆ·æ–°æ—¶é—´
    """
    try:
        tmdb_id = int(tmdb_id)
        season_number = int(season_number)
        episode_number = int(episode_number)
    except Exception:
        return False

    # ä»æ•°æ®åº“è·å–é›†çš„æ’­å‡ºæ—¶é—´ä¿¡æ¯
    try:
        cal_db = CalendarDB()
        cur = cal_db.conn.cursor()
        cur.execute(
            """
            SELECT air_date_local
            FROM episodes
            WHERE tmdb_id=? AND season_number=? AND episode_number=?
            """,
            (tmdb_id, season_number, episode_number),
        )
        row = cur.fetchone()
        if not row:
            return False
        air_date_local = row[0]
    except Exception:
        return False

    # å¦‚æœ air_date_local ä¸å­˜åœ¨ï¼Œè¯´æ˜æ’­å‡ºæ—¶é—´æœªçŸ¥ï¼Œè¿”å› False
    if not air_date_local:
        return False

    # è·å–èŠ‚ç›®çº§æ’­å‡ºæ—¶é—´é…ç½®
    schedule = {}
    try:
        schedule = CalendarDB().get_show_air_schedule(tmdb_id) or {}
    except Exception:
        schedule = {}
    
    # ä¼˜å…ˆä½¿ç”¨ local_air_timeï¼Œå¦‚æœä¸å­˜åœ¨ï¼ˆä¸ºç©ºæˆ– Noneï¼‰åˆ™ä½¿ç”¨å…¨å±€æ’­å‡ºé›†æ•°åˆ·æ–°æ—¶é—´
    local_air_time = (schedule.get("local_air_time") or "").strip() or None
    perf = config_data.get("performance", {}) if isinstance(config_data, dict) else {}
    refresh_time_str = perf.get("aired_refresh_time", "00:00")
    
    # å§‹ç»ˆä½¿ç”¨ local_air_timeï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨æ’­å‡ºé›†æ•°åˆ·æ–°æ—¶é—´
    time_to_use = local_air_time if local_air_time else refresh_time_str
    
    # è§£ææ—¶é—´ï¼ˆHH:MMï¼‰
    hh, mm = 0, 0
    try:
        parts = str(time_to_use).split(":")
        if len(parts) == 2:
            hh = int(parts[0])
            mm = int(parts[1])
    except Exception:
        hh, mm = 0, 0

    # ç»„åˆæ—¥æœŸå’Œæ—¶é—´
    try:
        dt_str = f"{air_date_local} {hh:02d}:{mm:02d}:00"
        dt_ep_local = datetime.strptime(dt_str, "%Y-%m-%d %H:%M:%S")
        # å¦‚æœ now_local_dt æœ‰æ—¶åŒºä¿¡æ¯ï¼Œä¸º dt_ep_local ä¹Ÿæ·»åŠ ç›¸åŒçš„æ—¶åŒºä¿¡æ¯
        if getattr(now_local_dt, "tzinfo", None) is not None:
            dt_ep_local = dt_ep_local.replace(tzinfo=now_local_dt.tzinfo)
        result = dt_ep_local.timestamp() <= now_local_dt.timestamp()
        return result
    except Exception as _e:
        logging.debug(f"is_episode_aired æ—¥æœŸ+æ—¶é—´åˆ¤å®šå¼‚å¸¸: tmdb_id={tmdb_id}, season={season_number}, ep={episode_number}, error={_e}")
        import traceback
        logging.debug(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
        return False

def compute_aired_count_by_episode_check(tmdb_id: int, season_number: int, now_local_dt=None) -> int:
    """
    é€šè¿‡é€é›†è°ƒç”¨ is_episode_aired è®¡ç®—å·²æ’­å‡ºé›†æ•°ï¼ˆè€ƒè™‘æ’­å‡ºæ—¶é—´ï¼‰
    è¿™æ˜¯æ­£ç¡®çš„è®¡ç®—æ–¹å¼ï¼Œåº”è¯¥æ›¿ä»£æ‰€æœ‰ç®€å•çš„æ—¥æœŸæ¯”è¾ƒé€»è¾‘
    """
    try:
        from zoneinfo import ZoneInfo as _ZoneInfo
        local_tz = _ZoneInfo(_get_local_timezone())
        if now_local_dt is None:
            now_local_dt = datetime.now(local_tz)
    except Exception:
        if now_local_dt is None:
            now_local_dt = datetime.now()
    
    try:
        cal_db = CalendarDB()
        cur = cal_db.conn.cursor()
        cur.execute(
            """
            SELECT episode_number FROM episodes
            WHERE tmdb_id=? AND season_number=?
            """,
            (int(tmdb_id), int(season_number)),
        )
        aired_count = 0
        for (ep_no,) in cur.fetchall() or []:
            try:
                if is_episode_aired(int(tmdb_id), int(season_number), int(ep_no), now_local_dt):
                    aired_count += 1
            except Exception:
                continue
        return aired_count
    except Exception:
        return 0

def enrich_tasks_with_calendar_meta(tasks_info: list) -> list:
    """ä¸ºä»»åŠ¡åˆ—è¡¨æ³¨å…¥æ—¥å†ç›¸å…³å…ƒæ•°æ®ï¼šèŠ‚ç›®çŠ¶æ€ã€æœ€æ–°å­£å¤„ç†ååç§°ã€å·²è½¬å­˜/å·²æ’­å‡º/æœ¬å­£æ€»é›†æ•°ã€‚
    è¿”å›æ–°çš„ä»»åŠ¡å­—å…¸åˆ—è¡¨ï¼Œå¢åŠ ä»¥ä¸‹å­—æ®µï¼š
    - matched_status: èŠ‚ç›®çŠ¶æ€ï¼ˆå¦‚ æ’­å‡ºä¸­ ç­‰ï¼‰
    - latest_season_name: æœ€æ–°å­£åç§°ï¼ˆå¤„ç†åï¼‰
    - season_counts: { transferred_count, aired_count, total_count }
    """
    try:
        if not tasks_info:
            return tasks_info
        db = CalendarDB()
        # é¢„å– shows ä¸ seasons æ•°æ®
        cur = db.conn.cursor()
        cur.execute('SELECT tmdb_id, status, latest_season_number FROM shows')
        rows = cur.fetchall() or []
        show_meta = {int(r[0]): {'status': r[1], 'latest_season_number': int(r[2])} for r in rows}

        cur.execute('SELECT tmdb_id, season_number, season_name, episode_count FROM seasons')
        rows = cur.fetchall() or []
        season_meta = {}
        for tid, sn, sname, ecount in rows:
            season_meta[(int(tid), int(sn))] = {'season_name': sname or '', 'episode_count': int(ecount or 0)}

        # ç»Ÿè®¡"å·²è½¬å­˜é›†æ•°"ï¼šåŸºäºè½¬å­˜è®°å½•æœ€æ–°è¿›åº¦æ„å»ºæ˜ å°„ï¼ˆæŒ‰ä»»åŠ¡åï¼‰
        transferred_by_task = {}
        try:
            rdb = RecordDB()
            cursor = rdb.conn.cursor()
            cursor.execute(
                """
                SELECT task_name, MAX(transfer_time) as latest_transfer_time
                FROM transfer_records
                WHERE task_name NOT IN ('rename', 'undo_rename')
                GROUP BY task_name
                """
            )
            latest_times = cursor.fetchall() or []
            extractor = TaskExtractor()
            for task_name, latest_time in latest_times:
                if latest_time:
                    cursor.execute(
                        """
                        SELECT renamed_to, original_name, transfer_time, modify_date
                        FROM transfer_records
                        WHERE task_name = ? AND transfer_time >= ? AND transfer_time <= ?
                        ORDER BY id DESC
                        """,
                        (task_name, latest_time - 60000, latest_time + 60000)
                    )
                    files = cursor.fetchall() or []
                    best = files[0][0] if files else ''
                    if len(files) > 1:
                        file_list = [{'file_name': f[0], 'original_name': f[1], 'updated_at': f[2]} for f in files]
                        try:
                            best = sorted(file_list, key=sort_file_by_name)[-1]['file_name']
                        except Exception:
                            best = files[0][0]
                    if best:
                        name_wo_ext = os.path.splitext(best)[0]
                        processed = process_season_episode_info(name_wo_ext, task_name)
                        parsed = extractor.extract_progress_from_latest_file(processed)
                        if parsed and parsed.get('episode_number'):
                            # åŒ…å«é›†æ•°çš„æƒ…å†µ
                            transferred_by_task[task_name] = int(parsed['episode_number'])
                        elif parsed and parsed.get('air_date'):
                            # åªæœ‰æ—¥æœŸçš„æƒ…å†µï¼šé€šè¿‡æŸ¥è¯¢æ•°æ®åº“è·å–å¯¹åº”æ—¥æœŸçš„æœ€å¤§é›†æ•°
                            air_date = parsed['air_date']
                            try:
                                # æŸ¥æ‰¾è¯¥ä»»åŠ¡å¯¹åº”çš„èŠ‚ç›®åç§°
                                task_info = next((t for t in tasks_info if (t.get('task_name') or t.get('taskname')) == task_name), None)
                                if task_info:
                                    show_name = (task_info.get('matched_show_name') or task_info.get('show_name') or '').strip()
                                    if show_name:
                                        # æŸ¥è¯¢è¯¥èŠ‚ç›®åœ¨è¯¥æ—¥æœŸæ’­å‡ºçš„æœ€å¤§é›†æ•°
                                        cur.execute(
                                            """
                                            SELECT MAX(CAST(episode_number AS INTEGER))
                                            FROM episodes
                                            WHERE show_name = ? AND air_date = ?
                                            """,
                                            (show_name, air_date)
                                        )
                                        result = cur.fetchone()
                                        if result and result[0] is not None:
                                            transferred_by_task[task_name] = int(result[0])
                            except Exception:
                                pass
            rdb.close()
        except Exception:
            transferred_by_task = {}

        # ç»Ÿè®¡"å·²æ’­å‡ºé›†æ•°"ï¼šä½¿ç”¨ is_episode_aired é€é›†åˆ¤æ–­ï¼ˆè€ƒè™‘æ’­å‡ºæ—¶é—´ï¼‰
        # ä¿®å¤ï¼šä¸å†ä½¿ç”¨ç®€å•çš„æ—¥æœŸæ¯”è¾ƒï¼Œè€Œæ˜¯é€é›†è°ƒç”¨ is_episode_aired åˆ¤æ–­æ˜¯å¦å·²æ’­å‡º
        from datetime import datetime as _dt
        try:
            from zoneinfo import ZoneInfo as _ZoneInfo
            local_tz = _ZoneInfo(_get_local_timezone())
            now_local_dt = datetime.now(local_tz)
        except Exception:
            now_local_dt = datetime.now()
        
        aired_by_show_season = {}
        try:
            # è·å–æ‰€æœ‰æœ‰å‰§é›†çš„èŠ‚ç›®å’Œå­£
            cur.execute(
                """
                SELECT DISTINCT tmdb_id, season_number FROM episodes
                WHERE tmdb_id IS NOT NULL AND season_number IS NOT NULL
                """
            )
            for tid, sn in (cur.fetchall() or []):
                try:
                    aired_count = compute_aired_count_by_episode_check(int(tid), int(sn), now_local_dt)
                    aired_by_show_season[(int(tid), int(sn))] = aired_count
                except Exception:
                    continue
        except Exception:
            aired_by_show_season = {}

        # è¯»å– season_metrics ç¼“å­˜ï¼ˆä¼˜å…ˆä½¿ç”¨ç¼“å­˜å›å¡«å±•ç¤ºï¼›è‹¥ç¼“å­˜æ—¥æœŸæ—©äºä»Šå¤©ï¼Œåˆ™å¼ºåˆ¶ä½¿ç”¨ä»Šæ—¥å³æ—¶ç»Ÿè®¡è¦†ç›–å·²æ’­å‡ºé›†æ•°ï¼Œå¹¶åœ¨ä¸‹æ–¹å†™å›ï¼‰
        season_metrics_map = {}
        try:
            cur.execute('SELECT tmdb_id, season_number, transferred_count, aired_count, total_count, updated_at FROM season_metrics')
            for tid, sn, tc, ac, tc2, ua in (cur.fetchall() or []):
                season_metrics_map[(int(tid), int(sn))] = {
                    'transferred_count': 0 if tc is None else int(tc),
                    'aired_count': 0 if ac is None else int(ac),
                    'total_count': 0 if tc2 is None else int(tc2),
                    'updated_at': 0 if ua is None else int(ua),
                }
        except Exception:
            season_metrics_map = {}

        # æ³¨å…¥åˆ°ä»»åŠ¡
        enriched = []
        for t in tasks_info:
            tmdb_id = t.get('match_tmdb_id') or ((t.get('calendar_info') or {}).get('match') or {}).get('tmdb_id')
            task_name = t.get('task_name') or t.get('taskname') or ''
            status = ''
            latest_sn = None
            latest_season_name = ''
            total_count = None
            transferred_count = None
            aired_count = None

            try:
                if tmdb_id and int(tmdb_id) in show_meta:
                    meta = show_meta[int(tmdb_id)]
                    status = meta.get('status') or ''
                    # ä»…ä½¿ç”¨ä»»åŠ¡åŒ¹é…åˆ°çš„å­£å·ï¼›æ— åŒ¹é…åˆ™ä¸è®¡ç®—è¯¥ä»»åŠ¡çš„å­£çº§æ•°æ®
                    season_no_to_use = None
                    try:
                        if t.get('matched_latest_season_number') is not None:
                            v = int(t.get('matched_latest_season_number'))
                            if v > 0:
                                season_no_to_use = v
                    except Exception:
                        season_no_to_use = None
                    if season_no_to_use is not None:
                        latest_sn = season_no_to_use
                        sm = season_meta.get((int(tmdb_id), latest_sn)) or {}
                        latest_season_name = sm.get('season_name') or ''
                        # ä¼˜å…ˆç”¨ season_metrics ä¸­ç¼“å­˜çš„ total/air/transferredï¼ˆæŒ‰åŒ¹é…å­£ï¼‰
                        _metrics = season_metrics_map.get((int(tmdb_id), latest_sn)) or {}
                        total_count = _metrics.get('total_count')
                        aired_count = _metrics.get('aired_count')
                        _cached_transferred = _metrics.get('transferred_count')
                        _updated_at = _metrics.get('updated_at')
                        # fallbackï¼šæ— ç¼“å­˜åˆ™ç”¨å³æ—¶è®¡ç®—ï¼ˆæŒ‰åŒ¹é…å­£ï¼‰
                        if total_count in (None, 0):
                            total_count = sm.get('episode_count')
                        # ä¸€è‡´æ€§å¼ºåŒ–ï¼šåœ¨â€œæœªåˆ°åˆ·æ–°æ—¶é—´â€æ—¶ï¼Œå§‹ç»ˆä½¿ç”¨æŒ‰æœ‰æ•ˆæ—¥æœŸç»Ÿè®¡çš„å€¼è¦†ç›–/æ ¡æ­£ç¼“å­˜ï¼Œ
                        # é¿å…å‡ºç°æå‰è®¡å…¥å½“æ—¥é›†æ•°çš„å±•ç¤ºåå·®
                        try:
                            _aired_effective = aired_by_show_season.get((int(tmdb_id), latest_sn))
                            if _aired_effective is not None:
                                if not allow_refresh:
                                    # åˆ·æ–°æ—¶é—´ä¹‹å‰ï¼šæ— æ¡ä»¶é‡‡ç”¨æœ‰æ•ˆæ—¥æœŸå£å¾„
                                    aired_count = _aired_effective
                                else:
                                    # åˆ·æ–°æ—¶é—´ä¹‹åï¼šè‹¥ç¼“å­˜ä¸ºéå½“æ—¥æˆ–ç¼ºå¤±ï¼Œåˆ™é‡‡ç”¨æœ‰æ•ˆæ—¥æœŸå£å¾„å›å¡«
                                    _ua_date = None
                                    if _updated_at:
                                        _ua_date = _dt.fromtimestamp(int(_updated_at)).strftime('%Y-%m-%d')
                                    if ((_ua_date is None) or (_ua_date != today)):
                                        aired_count = _aired_effective
                        except Exception:
                            pass
                        if aired_count in (None, 0):
                            aired_count = aired_by_show_season.get((int(tmdb_id), latest_sn))
                    else:
                        # æœªåŒ¹é…åˆ°å­£ï¼šä¸è®¡ç®—è¯¥ä»»åŠ¡çš„å­£çº§æ•°æ®
                        latest_sn = None
                        latest_season_name = ''
                        total_count = 0
                        aired_count = 0
            except Exception:
                pass

            if task_name in transferred_by_task:
                transferred_count = transferred_by_task[task_name]

            # å°†çŠ¶æ€æœ¬åœ°åŒ–ï¼šreturning_series ç”¨æœ¬åœ°å·²æ’­/æ€»é›†æ•°åˆ¤æ–­ï¼›å…¶ä½™é€šè¿‡ TMDBService çš„å•è¡¨æ˜ å°„
            try:
                raw = (status or '').strip()
                key = raw.lower().replace(' ', '_')
                if key == 'returning_series':
                    # æ–°è§„åˆ™ï¼šå­˜åœ¨ finale ç±»å‹ ä¸” å·²æ’­å‡ºé›†æ•° â‰¥ æœ¬å­£æ€»é›†æ•° => æœ¬å­£ç»ˆï¼›å¦åˆ™ æ’­å‡ºä¸­
                    has_finale = False
                    try:
                        if tmdb_id and latest_sn:
                            cur.execute(
                                """
                                SELECT 1 FROM episodes
                                WHERE tmdb_id=? AND season_number=? AND LOWER(COALESCE(type, '')) LIKE '%finale%'
                                LIMIT 1
                                """,
                                (int(tmdb_id), int(latest_sn))
                            )
                            has_finale = cur.fetchone() is not None
                    except Exception:
                        has_finale = False

                    try:
                        aired = int(aired_count or 0)
                        total = int(total_count or 0)
                    except Exception:
                        aired, total = 0, 0

                    status = 'æœ¬å­£ç»ˆ' if (has_finale and total > 0 and aired >= total) else 'æ’­å‡ºä¸­'
                else:
                    try:
                        # ä»…ç”¨åˆ°é™æ€æ˜ å°„ï¼Œä¸è§¦å‘ç½‘ç»œè¯·æ±‚
                        _svc = TMDBService(config_data.get('tmdb_api_key', ''), get_poster_language_setting())
                        status = _svc.map_show_status_cn(raw)
                    except Exception:
                        status = raw
            except Exception:
                pass

            t['matched_status'] = status
            t['latest_season_name'] = latest_season_name

            # åç«¯å…œåº•ï¼šå½“æ–‡ä»¶åæ— é›†åºå·ä½†å«æ—¥æœŸæ—¶ï¼Œå°è¯•ç”¨ tmdb_id + season + air_date æ¨å¯¼å·²è½¬å­˜é›†æ•°
            # è¿™æ ·ä¸å‰ç«¯å±•ç¤ºå£å¾„ä¸€è‡´ï¼Œé¿å…æŠŠ transferred_count è¯¯å†™ä¸º 0
            try:
                _effective_transferred = int(transferred_count or 0)
            except Exception:
                _effective_transferred = 0

            # ä¿æŠ¤ï¼šå¦‚æœæœ¬æ¬¡è§£æä¸åˆ°æœ‰æ•ˆé›†æ•°ï¼ˆ_effective_transferred ä¸º 0ï¼‰ï¼Œ
            # ä¸” metrics ä¸­å·²ç»æœ‰ç¼“å­˜çš„ transferred_count > 0ï¼Œåˆ™ä¼˜å…ˆä¿ç•™ç¼“å­˜å€¼ï¼Œ
            # é¿å…å®æ—¶åˆ·æ–°æ—¶çŸ­æš‚æŠŠå·²è½¬å­˜é›†æ•°å›è½ä¸º 0ã€‚
            try:
                if (not _effective_transferred) and (locals().get('_cached_transferred') not in (None, 0)):
                    _effective_transferred = int(locals().get('_cached_transferred') or 0)
            except Exception:
                pass

            if (not _effective_transferred) and task_name and tmdb_id and latest_sn:
                try:
                    # å–æœ€è¿‘ä¸€æ¡è½¬å­˜è®°å½•çš„æ–‡ä»¶åï¼Œè§£æå‡ºæ—¥æœŸ
                    rdb2 = RecordDB()
                    cur2 = rdb2.conn.cursor()
                    cur2.execute(
                        """
                        SELECT MAX(transfer_time) as latest_transfer_time
                        FROM transfer_records
                        WHERE task_name = ? AND task_name NOT IN ('rename', 'undo_rename')
                        """,
                        (task_name,)
                    )
                    _row = cur2.fetchone()
                    _lt = _row[0] if _row else None
                    _best = None
                    if _lt:
                        cur2.execute(
                            """
                            SELECT renamed_to, original_name, transfer_time, modify_date
                            FROM transfer_records
                            WHERE task_name = ? AND transfer_time >= ? AND transfer_time <= ?
                            ORDER BY id DESC
                            """,
                            (task_name, _lt - 60000, _lt + 60000)
                        )
                        _files = cur2.fetchall() or []
                        if _files:
                            _best = _files[0][0]
                    rdb2.close()

                    if _best:
                        _name_wo_ext = os.path.splitext(_best)[0]
                        _processed = process_season_episode_info(_name_wo_ext, task_name)
                        _parsed = TaskExtractor().extract_progress_from_latest_file(_processed)
                        if _parsed and (not _parsed.get('episode_number')) and _parsed.get('air_date'):
                            _air_date = _parsed.get('air_date')
                            # ç”¨ tmdb_id + season + air_date æŸ¥æ‰¾å½“å¤©å¯¹åº”çš„æœ€å¤§é›†å·
                            cur.execute(
                                """
                                SELECT MAX(CAST(episode_number AS INTEGER))
                                FROM episodes
                                WHERE tmdb_id = ? AND season_number = ? AND air_date = ?
                                """,
                                (int(tmdb_id), int(latest_sn), _air_date)
                            )
                            _res = cur.fetchone()
                            if _res and _res[0] is not None:
                                _effective_transferred = int(_res[0])
                except Exception:
                    pass

            t['season_counts'] = {
                'transferred_count': _effective_transferred,
                'aired_count': aired_count or 0,
                'total_count': total_count or 0,
            }
            # å†™å› season_metricsï¼ˆä»¥è¯¥ä»»åŠ¡è‡ªèº«åŒ¹é…åˆ°çš„å­£å·ä¸ºé”®ï¼›æ— åŒ¹é…åˆ™è·³è¿‡ï¼‰
            try:
                if tmdb_id and latest_sn:
                    from time import time as _now
                    # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”ï¼šä»¥ min(aired, total) ä¸ºåˆ†æ¯ï¼›åˆ†æ¯<=0 åˆ™ä¸º 0
                    try:
                        _trans = int(_effective_transferred or 0)
                        _aired = int(aired_count or 0)
                        _total = int(total_count or 0)
                        denom = min(_aired, _total)
                        progress_pct = (100 * min(_trans, denom) // denom) if denom > 0 else 0
                    except Exception:
                        progress_pct = 0
                    CalendarDB().upsert_season_metrics(int(tmdb_id), int(latest_sn), int(_effective_transferred or 0), int(aired_count or 0), int(total_count or 0), int(progress_pct), int(_now()))
            except Exception:
                pass
            try:
                if task_name and tmdb_id and latest_sn:
                    from time import time as _now
                    # åŒä¸€å¥—ç™¾åˆ†æ¯”å£å¾„
                    try:
                        _trans = int(_effective_transferred or 0)
                        _aired = int(aired_count or 0)
                        _total = int(total_count or 0)
                        denom = min(_aired, _total)
                        progress_pct = (100 * min(_trans, denom) // denom) if denom > 0 else 0
                    except Exception:
                        progress_pct = 0
                    CalendarDB().upsert_task_metrics(task_name, int(tmdb_id), int(latest_sn), int(_effective_transferred or 0), int(progress_pct), int(_now()))
            except Exception:
                pass
            
            # è¡¥å……æœ€æ–°å­£å·ç»™å‰ç«¯ï¼ˆç”¨äºä¸‹ä¸€é›†æŸ¥æ‰¾é€»è¾‘ï¼‰
            if latest_sn:
                t['latest_season_number'] = int(latest_sn)
                
            enriched.append(t)
        return enriched
    except Exception:
        return tasks_info

# å†…éƒ¨ï¼šæ ¹æ® task_name é‡æ–°è®¡ç®—è½¬å­˜è¿›åº¦ï¼Œå¹¶å†™å› metrics ä¸æ¨é€å˜æ›´
def recompute_task_metrics_and_notify(task_name: str) -> bool:
    try:
        if not task_name:
            return False
        rdb = RecordDB()
        cursor = rdb.conn.cursor()
        cursor.execute(
            """
            SELECT MAX(transfer_time) as latest_transfer_time
            FROM transfer_records
            WHERE task_name = ? AND task_name NOT IN ('rename', 'undo_rename')
            """,
            (task_name,)
        )
        row = cursor.fetchone()
        latest_time = row[0] if row else None
        latest_file = None
        if latest_time:
            time_window = 60000
            cursor.execute(
                """
                SELECT renamed_to, original_name, transfer_time, modify_date
                FROM transfer_records
                WHERE task_name = ? AND transfer_time >= ? AND transfer_time <= ?
                ORDER BY id DESC
                """,
                (task_name, latest_time - time_window, latest_time + time_window)
            )
            files = cursor.fetchall() or []
            if files:
                if len(files) == 1:
                    latest_file = files[0][0]
                else:
                    # é€€åŒ–ï¼šæŒ‰ id DESC å·²è¿‘ä¼¼æœ€æ–°ï¼Œå–ç¬¬ä¸€æ¡ renamed_to
                    latest_file = files[0][0]
        rdb.close()

        ep_no = None
        parsed_air_date = None
        if latest_file:
            try:
                extractor = TaskExtractor()
                parsed = extractor.extract_progress_from_latest_file((latest_file or '').split('.')[0])
                if parsed and parsed.get('episode_number') is not None:
                    ep_no = int(parsed.get('episode_number'))
                elif parsed and parsed.get('air_date'):
                    # æš‚å­˜æ—¥æœŸï¼Œå¾…è§£æå‡º tmdb_id ä¸ season åæ®æ­¤æ¨å¯¼é›†å·
                    parsed_air_date = parsed.get('air_date')
            except Exception:
                ep_no = None

        cal_db = CalendarDB()
        cur = cal_db.conn.cursor()
        # ä»…ä»ä»»åŠ¡é…ç½®è§£æ tmdb ä¸å­£å·ï¼šå¼ºåˆ¶è¦æ±‚ matched_latest_season_number å­˜åœ¨ï¼Œå¦åˆ™è§†ä¸ºæœªåŒ¹é…
        tmdb_id = None
        season_no = None
        try:
            tasks = (config_data or {}).get('tasklist', [])
        except Exception:
            tasks = []
        try:
            tgt = next((t for t in tasks if (t.get('taskname') or t.get('task_name') or '') == task_name), None)
        except Exception:
            tgt = None
        if tgt:
            try:
                match = ((tgt.get('calendar_info') or {}).get('match') or {})
            except Exception:
                match = {}
            # tmdb_id å¿…é¡»æ¥è‡ªåŒ¹é…ä¿¡æ¯
            try:
                if match.get('tmdb_id'):
                    tmdb_id = int(match.get('tmdb_id'))
            except Exception:
                tmdb_id = None
            # season ä»…ä½¿ç”¨ matched_latest_season_number
            try:
                if tgt.get('matched_latest_season_number') is not None:
                    v = int(tgt.get('matched_latest_season_number'))
                    if v > 0:
                        season_no = v
            except Exception:
                season_no = None
        # æœªåŒ¹é…åˆ™è·³è¿‡
        if tmdb_id is None or season_no is None or int(season_no) <= 0:
            return False

        from time import time as _now
        now_ts = int(_now())
        # è‹¥ä»…æœ‰æ—¥æœŸä½†æ— é›†å·ï¼Œå°è¯•ç”¨ tmdb_id + season + air_date æ¨å¯¼é›†å·
        if ep_no is None and parsed_air_date:
            try:
                cur.execute(
                    """
                    SELECT MAX(CAST(episode_number AS INTEGER))
                    FROM episodes
                    WHERE tmdb_id = ? AND season_number = ? AND air_date = ?
                    """,
                    (int(tmdb_id), int(season_no), parsed_air_date)
                )
                _row = cur.fetchone()
                if _row and _row[0] is not None:
                    ep_no = int(_row[0])
            except Exception:
                pass

        # æ›´æ–° task_metrics çš„ transferred_count
        if ep_no is not None:
            cal_db.upsert_task_metrics(task_name, tmdb_id, season_no, ep_no, None, now_ts)

        # è¯»å– season_metrics/æˆ–åŠ¨æ€è®¡ç®—ï¼Œå†™å› progress_pct
        try:
            # è·å– aired/total
            metrics = cal_db.get_season_metrics(tmdb_id, season_no) or {}
            aired = metrics.get('aired_count')
            total = metrics.get('total_count')
            if aired in (None, 0) or total in (None, 0):
                # åŠ¨æ€å›é€€ï¼šä½¿ç”¨ is_episode_aired é€é›†åˆ¤æ–­è®¡ç®—å·²æ’­å‡ºé›†æ•°ï¼ˆè€ƒè™‘æ’­å‡ºæ—¶é—´ï¼‰
                # ä¿®å¤ï¼šä¸å†ä½¿ç”¨ç®€å•çš„æ—¥æœŸæ¯”è¾ƒï¼Œè€Œæ˜¯é€é›†è°ƒç”¨ is_episode_aired åˆ¤æ–­æ˜¯å¦å·²æ’­å‡º
                try:
                    from zoneinfo import ZoneInfo as _ZoneInfo
                    local_tz = _ZoneInfo(_get_local_timezone())
                    now_local_dt = datetime.now(local_tz)
                except Exception:
                    now_local_dt = datetime.now()
                aired = compute_aired_count_by_episode_check(tmdb_id, season_no, now_local_dt)
                cur.execute('SELECT episode_count FROM seasons WHERE tmdb_id=? AND season_number=?', (tmdb_id, season_no))
                row2 = cur.fetchone()
                total = int((row2 or [0])[0]) if row2 else 0
            trans = int(ep_no or 0)
            denom = min(int(aired or 0), int(total or 0))
            progress_pct = (100 * min(trans, denom) // denom) if denom > 0 else 0
            # æ›´æ–° season_metrics æ—¶ï¼Œéœ€è¦ä¼ å…¥ transferred_countï¼ˆå·²è½¬å­˜é›†æ•°ï¼‰ï¼Œä¸èƒ½ä¼  None
            cal_db.upsert_season_metrics(tmdb_id, season_no, trans, aired, total, progress_pct, now_ts)
            cal_db.upsert_task_metrics(task_name, tmdb_id, season_no, trans, progress_pct, now_ts)
        except Exception:
            pass

        try:
            notify_calendar_changed('transfer_update')
        except Exception:
            pass
        return True
    except Exception:
        return False


def register_metrics_sync_routes(app):
    @app.route('/api/calendar/metrics/sync_task', methods=['POST'])
    def api_sync_task_metrics():
        try:
            data = request.get_json(silent=True) or {}
            task_name = data.get('task_name') or request.args.get('task_name')
            ok = recompute_task_metrics_and_notify(task_name)
            return jsonify({'success': bool(ok)})
        except Exception as e:
            return jsonify({'success': False, 'message': str(e)})

def advanced_filter_files(file_list, filterwords):
    """
    é«˜çº§è¿‡æ»¤å‡½æ•°ï¼Œæ”¯æŒä¿ç•™è¯å’Œè¿‡æ»¤è¯
    
    Args:
        file_list: æ–‡ä»¶åˆ—è¡¨
        filterwords: è¿‡æ»¤è§„åˆ™å­—ç¬¦ä¸²ï¼Œæ”¯æŒä»¥ä¸‹æ ¼å¼ï¼š
            - "åŠ æ›´ï¼Œä¼åˆ’ï¼Œè¶…å‰ï¼Œ(1)ï¼Œmkvï¼Œnfo"  # åªæœ‰è¿‡æ»¤è¯
            - "æœŸ|åŠ æ›´ï¼Œä¼åˆ’ï¼Œè¶…å‰ï¼Œ(1)ï¼Œmkvï¼Œnfo"  # ä¿ç•™è¯|è¿‡æ»¤è¯
            - "æœŸï¼Œ2160P|åŠ æ›´ï¼Œä¼åˆ’ï¼Œè¶…å‰ï¼Œ(1)ï¼Œmkvï¼Œnfo"  # å¤šä¸ªä¿ç•™è¯(æˆ–å…³ç³»)|è¿‡æ»¤è¯
            - "æœŸ|2160P|åŠ æ›´ï¼Œä¼åˆ’ï¼Œè¶…å‰ï¼Œ(1)ï¼Œmkvï¼Œnfo"  # å¤šä¸ªä¿ç•™è¯(å¹¶å…³ç³»)|è¿‡æ»¤è¯
            - "æœŸï¼Œ2160P|"  # åªæœ‰ä¿ç•™è¯ï¼Œæ— è¿‡æ»¤è¯
    
    Returns:
        è¿‡æ»¤åçš„æ–‡ä»¶åˆ—è¡¨
    """
    if not filterwords or not filterwords.strip():
        return file_list
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«åˆ†éš”ç¬¦ |
    if '|' not in filterwords:
        # åªæœ‰è¿‡æ»¤è¯çš„æƒ…å†µ
        filterwords = filterwords.replace("ï¼Œ", ",")
        filterwords_list = [word.strip().lower() for word in filterwords.split(',') if word.strip()]
        
        filtered_files = []
        for file in file_list:
            file_name = file['file_name'].lower()
            file_ext = os.path.splitext(file_name)[1].lower().lstrip('.')
            
            # æ£€æŸ¥è¿‡æ»¤è¯æ˜¯å¦å­˜åœ¨äºæ–‡ä»¶åä¸­ï¼Œæˆ–è€…è¿‡æ»¤è¯ç­‰äºæ‰©å±•å
            if not any(word in file_name for word in filterwords_list) and not any(word == file_ext for word in filterwords_list):
                filtered_files.append(file)
        
        return filtered_files
    
    # åŒ…å«åˆ†éš”ç¬¦çš„æƒ…å†µï¼Œéœ€è¦è§£æä¿ç•™è¯å’Œè¿‡æ»¤è¯
    parts = filterwords.split('|')
    if len(parts) < 2:
        # æ ¼å¼é”™è¯¯ï¼Œè¿”å›åŸåˆ—è¡¨
        return file_list
    
    # æœ€åä¸€ä¸ª|åé¢çš„æ˜¯è¿‡æ»¤è¯
    filter_part = parts[-1].strip()
    # å‰é¢çš„éƒ½æ˜¯ä¿ç•™è¯
    keep_parts = [part.strip() for part in parts[:-1] if part.strip()]
    
    # è§£æè¿‡æ»¤è¯
    filterwords_list = []
    if filter_part:
        filter_part = filter_part.replace("ï¼Œ", ",")
        filterwords_list = [word.strip().lower() for word in filter_part.split(',') if word.strip()]
    
    # è§£æä¿ç•™è¯ï¼šæ¯ä¸ª|åˆ†éš”çš„éƒ¨åˆ†éƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ç­›é€‰æ¡ä»¶
    # è¿™äº›æ¡ä»¶éœ€è¦æŒ‰é¡ºåºä¾æ¬¡åº”ç”¨ï¼Œå½¢æˆé“¾å¼ç­›é€‰
    keep_conditions = []
    for part in keep_parts:
        if part.strip():
            if ',' in part or 'ï¼Œ' in part:
                # åŒ…å«é€—å·ï¼Œè¡¨ç¤ºæˆ–å…³ç³»
                part = part.replace("ï¼Œ", ",")
                or_words = [word.strip().lower() for word in part.split(',') if word.strip()]
                keep_conditions.append(("or", or_words))
            else:
                # ä¸åŒ…å«é€—å·ï¼Œè¡¨ç¤ºå•ä¸ªè¯
                keep_conditions.append(("single", [part.strip().lower()]))
    
    # ç¬¬ä¸€æ­¥ï¼šåº”ç”¨ä¿ç•™è¯ç­›é€‰ï¼ˆé“¾å¼ç­›é€‰ï¼‰
    if keep_conditions:
        for condition_type, words in keep_conditions:
            filtered_by_keep = []
            for file in file_list:
                file_name = file['file_name'].lower()
                
                if condition_type == "or":
                    # æˆ–å…³ç³»ï¼šåŒ…å«ä»»æ„ä¸€ä¸ªè¯å³å¯
                    if any(word in file_name for word in words):
                        filtered_by_keep.append(file)
                elif condition_type == "single":
                    # å•ä¸ªè¯ï¼šå¿…é¡»åŒ…å«
                    if words[0] in file_name:
                        filtered_by_keep.append(file)
            
            file_list = filtered_by_keep
    
    # ç¬¬äºŒæ­¥ï¼šåº”ç”¨è¿‡æ»¤è¯è¿‡æ»¤
    if filterwords_list:
        filtered_files = []
        for file in file_list:
            file_name = file['file_name'].lower()
            file_ext = os.path.splitext(file_name)[1].lower().lstrip('.')
            
            # æ£€æŸ¥è¿‡æ»¤è¯æ˜¯å¦å­˜åœ¨äºæ–‡ä»¶åä¸­ï¼Œæˆ–è€…è¿‡æ»¤è¯ç­‰äºæ‰©å±•å
            if not any(word in file_name for word in filterwords_list) and not any(word == file_ext for word in filterwords_list):
                filtered_files.append(file)
        
        return filtered_files
    
    return file_list


def process_season_episode_info(filename, task_name=None):
    """
    å¤„ç†æ–‡ä»¶åä¸­çš„å­£æ•°å’Œé›†æ•°ä¿¡æ¯

    Args:
        filename: æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        task_name: å¯é€‰çš„ä»»åŠ¡åç§°ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦å·²åŒ…å«å­£æ•°ä¿¡æ¯

    Returns:
        å¤„ç†åçš„æ˜¾ç¤ºåç§°
    """

    def task_contains_season_info(task_name):
        """
        åˆ¤æ–­ä»»åŠ¡åç§°ä¸­æ˜¯å¦åŒ…å«å­£æ•°ä¿¡æ¯
        """
        if not task_name:
            return False

        # æ¸…ç†ä»»åŠ¡åç§°ä¸­çš„è¿ç»­ç©ºæ ¼å’Œç‰¹æ®Šç¬¦å·
        clean_name = task_name.replace('\u3000', ' ').replace('\t', ' ')
        clean_name = re.sub(r'\s+', ' ', clean_name).strip()

        # åŒ¹é…å¸¸è§çš„å­£æ•°æ ¼å¼
        season_patterns = [
            r'^(.*?)[\s\.\-_]+S\d+$',  # é»‘é•œ - S07ã€æŠ˜è…°.S01ã€éŸ³ä½ è€Œæ¥-S02
            r'^(.*?)[\s\.\-_]+Season\s*\d+$',  # é»‘é•œ - Season 1
            r'^(.*?)\s+S\d+$',  # å¿«ä¹çš„å¤§äºº S02
            r'^(.*?)[\s\.\-_]+S\d+E\d+$',  # å¤„ç† S01E01 æ ¼å¼
            r'^(.*?)\s+ç¬¬\s*\d+\s*å­£$',  # å¤„ç† ç¬¬Nå­£ æ ¼å¼
            r'^(.*?)[\s\.\-_]+ç¬¬\s*\d+\s*å­£$',  # å¤„ç† - ç¬¬Nå­£ æ ¼å¼
            r'^(.*?)\s+ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åé›¶]+å­£$',  # å¤„ç† ç¬¬ä¸€å­£ã€ç¬¬äºŒå­£ æ ¼å¼
            r'^(.*?)[\s\.\-_]+ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åé›¶]+å­£$',  # å¤„ç† - ç¬¬ä¸€å­£ã€- ç¬¬äºŒå­£ æ ¼å¼
        ]

        for pattern in season_patterns:
            if re.match(pattern, clean_name, re.IGNORECASE):
                return True

        return False

    # åŒ¹é… SxxExx æ ¼å¼ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    # æ”¯æŒ S1E1, S01E01, s13e10, S100E1000 ç­‰æ ¼å¼
    season_episode_match = re.search(r'[Ss](\d+)[Ee](\d+)', filename)
    if season_episode_match:
        season = season_episode_match.group(1).zfill(2)  # ç¡®ä¿ä¸¤ä½æ•°
        episode = season_episode_match.group(2).zfill(2)  # ç¡®ä¿ä¸¤ä½æ•°

        # å¦‚æœä»»åŠ¡åç§°ä¸­å·²åŒ…å«å­£æ•°ä¿¡æ¯ï¼Œåªæ˜¾ç¤ºé›†æ•°
        if task_contains_season_info(task_name):
            return f"E{episode}"
        else:
            return f"S{season}E{episode}"

    # åŒ¹é…åªæœ‰ Exx æˆ– EPxx æ ¼å¼ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    # æ”¯æŒ E1, E01, EP1, EP01, e10, ep10, E1000 ç­‰æ ¼å¼
    episode_only_match = re.search(r'[Ee][Pp]?(\d+)', filename)
    if episode_only_match:
        episode = episode_only_match.group(1).zfill(2)  # ç¡®ä¿ä¸¤ä½æ•°
        return f"E{episode}"

    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°å­£æ•°é›†æ•°ä¿¡æ¯ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦å»é™¤ä¸ä»»åŠ¡åç§°ç›¸åŒçš„å‰ç¼€
    if task_name:
        task_name_clean = task_name.strip()

        # é¦–å…ˆå°è¯•å®Œæ•´ä»»åŠ¡ååŒ¹é…
        if filename.startswith(task_name_clean):
            # å»é™¤ä»»åŠ¡åå‰ç¼€
            remaining = filename[len(task_name_clean):].strip()

            # å¦‚æœå‰©ä½™éƒ¨åˆ†ä»¥å¸¸è§åˆ†éš”ç¬¦å¼€å¤´ï¼Œä¹Ÿå»é™¤åˆ†éš”ç¬¦
            separators = [' - ', ' Â· ', '.', '_', '-', ' ']
            for sep in separators:
                if remaining.startswith(sep):
                    remaining = remaining[len(sep):].strip()
                    break

            # å¦‚æœå‰©ä½™éƒ¨åˆ†ä¸ä¸ºç©ºï¼Œè¿”å›å‰©ä½™éƒ¨åˆ†ï¼›å¦åˆ™è¿”å›åŸæ–‡ä»¶å
            return remaining if remaining else filename

        # å¦‚æœå®Œæ•´ä»»åŠ¡åä¸åŒ¹é…ï¼Œå°è¯•æå–å‰§åéƒ¨åˆ†è¿›è¡ŒåŒ¹é…
        # åŒ¹é…å¸¸è§çš„å­£æ•°æ ¼å¼ï¼Œæå–å‰§åéƒ¨åˆ†
        season_patterns = [
            r'^(.*?)[\s\.\-_]+S\d+$',  # ä½ å¥½ï¼Œæ˜ŸæœŸå…­ - S04
            r'^(.*?)[\s\.\-_]+Season\s*\d+$',  # é»‘é•œ - Season 1
            r'^(.*?)\s+S\d+$',  # å¿«ä¹çš„å¤§äºº S02
            r'^(.*?)[\s\.\-_]+S\d+E\d+$',  # å¤„ç† S01E01 æ ¼å¼
            r'^(.*?)\s+ç¬¬\s*\d+\s*å­£$',  # å¤„ç† ç¬¬Nå­£ æ ¼å¼
            r'^(.*?)[\s\.\-_]+ç¬¬\s*\d+\s*å­£$',  # å¤„ç† - ç¬¬Nå­£ æ ¼å¼
            r'^(.*?)\s+ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åé›¶]+å­£$',  # å¤„ç† ç¬¬ä¸€å­£ã€ç¬¬äºŒå­£ æ ¼å¼
            r'^(.*?)[\s\.\-_]+ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åé›¶]+å­£$',  # å¤„ç† - ç¬¬ä¸€å­£ã€- ç¬¬äºŒå­£ æ ¼å¼
        ]

        for pattern in season_patterns:
            match = re.match(pattern, task_name_clean, re.IGNORECASE)
            if match:
                show_name = match.group(1).strip()
                # å»é™¤æœ«å°¾å¯èƒ½æ®‹ç•™çš„åˆ†éš”ç¬¦
                show_name = re.sub(r'[\s\.\-_]+$', '', show_name)

                # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦ä»¥å‰§åå¼€å¤´
                if filename.startswith(show_name):
                    # å»é™¤å‰§åå‰ç¼€
                    remaining = filename[len(show_name):].strip()

                    # å¦‚æœå‰©ä½™éƒ¨åˆ†ä»¥å¸¸è§åˆ†éš”ç¬¦å¼€å¤´ï¼Œä¹Ÿå»é™¤åˆ†éš”ç¬¦
                    separators = [' - ', ' Â· ', '.', '_', '-', ' ']
                    for sep in separators:
                        if remaining.startswith(sep):
                            remaining = remaining[len(sep):].strip()
                            break

                    # å¦‚æœå‰©ä½™éƒ¨åˆ†ä¸ä¸ºç©ºï¼Œè¿”å›å‰©ä½™éƒ¨åˆ†ï¼›å¦åˆ™è¿”å›åŸæ–‡ä»¶å
                    return remaining if remaining else filename

    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°å­£æ•°é›†æ•°ä¿¡æ¯ï¼Œä¸”æ²¡æœ‰æ‰¾åˆ°ç›¸åŒå‰ç¼€ï¼Œè¿”å›åŸæ–‡ä»¶å
    return filename

# å¯¼å…¥æ‹¼éŸ³æ’åºå·¥å…·
try:
    from utils.pinyin_sort import get_filename_pinyin_sort_key
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„å°å†™æ’åºä½œä¸ºå¤‡ç”¨
    def get_filename_pinyin_sort_key(filename):
        return filename.lower()

# å¯¼å…¥æ•°æ®åº“æ¨¡å—
try:
    # å…ˆå°è¯•ç›¸å¯¹å¯¼å…¥
    from sdk.db import RecordDB
except ImportError:
    try:
        # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ä»appåŒ…å¯¼å…¥
        from app.sdk.db import RecordDB
    except ImportError:
        # å¦‚æœæ²¡æœ‰æ•°æ®åº“æ¨¡å—ï¼Œå®šä¹‰ä¸€ä¸ªç©ºç±»
        class RecordDB:
            def __init__(self, *args, **kwargs):
                pass
            
            def get_records(self, *args, **kwargs):
                return {"records": [], "pagination": {"total_records": 0, "total_pages": 0, "current_page": 1, "page_size": 20}}

# å¯¼å…¥å·¥å…·å‡½æ•°
try:
    # å…ˆå°è¯•ç›¸å¯¹å¯¼å…¥
    from sdk.utils import format_bytes, get_file_icon, format_file_display
except ImportError:
    try:
        # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ä»appåŒ…å¯¼å…¥
        from app.sdk.utils import format_bytes, get_file_icon, format_file_display
    except ImportError:
        # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å®ç°æˆ–ä»quark_auto_saveå¯¼å…¥
        # format_byteså·²ä»quark_auto_saveå¯¼å…¥
        def get_file_icon(file_name, is_dir=False):
            return "ğŸ“„" if not is_dir else "ğŸ“"
            
        def format_file_display(prefix, icon, name):
            return f"{prefix}{icon} {name}"


def get_app_ver():
    BUILD_SHA = os.environ.get("BUILD_SHA", "")
    BUILD_TAG = os.environ.get("BUILD_TAG", "")
    if BUILD_TAG[:1] == "v":
        return BUILD_TAG
    elif BUILD_SHA:
        return f"{BUILD_TAG}({BUILD_SHA[:7]})"
    else:
        return "dev"


# æ–‡ä»¶è·¯å¾„
PYTHON_PATH = "python3" if os.path.exists("/usr/bin/python3") else "python"
SCRIPT_PATH = os.environ.get("SCRIPT_PATH", "./quark_auto_save.py")
CONFIG_PATH = os.environ.get("CONFIG_PATH", "./config/quark_config.json")
PLUGIN_FLAGS = os.environ.get("PLUGIN_FLAGS", "")
DEBUG = os.environ.get("DEBUG", "false").lower() == "true"
# ä»ç¯å¢ƒå˜é‡è·å–ç«¯å£ï¼Œé»˜è®¤ä¸º5005
PORT = int(os.environ.get("PORT", "5005"))
LOG_DIR = os.path.join(parent_dir, "config", "logs")
LOG_FILE_PATH = os.path.join(LOG_DIR, "runtime.log")
MAX_RUNTIME_LOG_LINES = 2000
RUNTIME_LOG_PATTERN = re.compile(
    r'^\[(?P<timestamp>\d{2}-\d{2} \d{2}:\d{2}:\d{2})\]\[(?P<level>[A-Z]+)\]\s?(?P<message>.*)$'
)
os.makedirs(LOG_DIR, exist_ok=True)

config_data = {}
task_plugins_config_default = {}

# æ–‡ä»¶åˆ—è¡¨ç¼“å­˜
file_list_cache = {}
cache_lock = Lock()

# é»˜è®¤æ€§èƒ½å‚æ•°ï¼ˆå¦‚æœé…ç½®ä¸­æ²¡æœ‰è®¾ç½®ï¼‰
DEFAULT_PERFORMANCE_CONFIG = {
    "api_page_size": 200,
    "cache_expire_time": 30
}

def get_performance_config():
    """è·å–æ€§èƒ½é…ç½®å‚æ•°"""
    try:
        if config_data and "file_performance" in config_data:
            perf_config = config_data["file_performance"]
            # ç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯æ•´æ•°ç±»å‹
            result = {}
            for key, default_value in DEFAULT_PERFORMANCE_CONFIG.items():
                try:
                    result[key] = int(perf_config.get(key, default_value))
                except (ValueError, TypeError):
                    result[key] = default_value
            return result
    except Exception as e:
        print(f"è·å–æ€§èƒ½é…ç½®å¤±è´¥: {e}")
    return DEFAULT_PERFORMANCE_CONFIG

def cleanup_expired_cache():
    """æ¸…ç†æ‰€æœ‰è¿‡æœŸç¼“å­˜"""
    current_time = time.time()
    perf_config = get_performance_config()
    cache_expire_time = perf_config.get("cache_expire_time", 30)

    with cache_lock:
        expired_keys = [k for k, (_, t) in file_list_cache.items() if current_time - t > cache_expire_time]
        for k in expired_keys:
            del file_list_cache[k]
        return len(expired_keys)

app = Flask(__name__)
app.config["APP_VERSION"] = get_app_ver()
app.secret_key = "ca943f6db6dd34823d36ab08d8d6f65d"
try:
    register_metrics_sync_routes(app)
except Exception:
    pass
app.config["SESSION_COOKIE_NAME"] = "QUARK_AUTO_SAVE_X_SESSION"
app.config["PERMANENT_SESSION_LIFETIME"] = timedelta(days=31)
# é…ç½®ä¼šè¯ cookie ä»¥ç¡®ä¿æŒä¹…åŒ–
app.config["SESSION_COOKIE_HTTPONLY"] = True
app.config["SESSION_COOKIE_SAMESITE"] = "Lax"
# SESSION_COOKIE_SECURE å°†é€šè¿‡ before_request é’©å­åŠ¨æ€è®¾ç½®ï¼Œä»¥åŒæ—¶æ”¯æŒ HTTP å’Œ HTTPS
app.json.ensure_ascii = False
app.json.sort_keys = False
app.jinja_env.variable_start_string = "[["
app.jinja_env.variable_end_string = "]]"

# æ³¨å†Œ AVIF MIME ç±»å‹ï¼Œç¡®ä¿é™æ€è·¯ç”±èƒ½æ­£ç¡®è¿”å› Content-Type
try:
    import mimetypes
    mimetypes.add_type('image/avif', '.avif')
except Exception:
    pass

# ---- Aired count safeguard: æç®€æŒ‰éœ€æ ¡æ­£ ----
def _aired_stamp_path():
    try:
        return os.path.abspath(os.path.join(app.root_path, '..', 'config', '.aired_done'))
    except Exception:
        return '.aired_done'

def _read_aired_effective_stamp():
    try:
        p = _aired_stamp_path()
        if os.path.exists(p):
            with open(p, 'r', encoding='utf-8') as f:
                return (f.read() or '').strip()
    except Exception:
        pass
    return ''

def _write_aired_effective_stamp(effective_date_str: str):
    try:
        p = _aired_stamp_path()
        with open(p, 'w', encoding='utf-8') as f:
            f.write(str(effective_date_str or ''))
    except Exception:
        pass

def ensure_today_aired_done_if_due_once(trigger_reason: str = ''):
    """ä»…åœ¨éœ€è¦æ—¶ã€ä¸”è‡³å¤šæ¯æ—¥ä¸€æ¬¡æŒ‰éœ€è¡¥ç®—ã€‚æ— å®šæ—¶è½®è¯¢ï¼Œæ— é«˜é¢‘æ£€æŸ¥ã€‚"""
    global _aired_on_demand_checked_date
    try:
        # ç›´æ¥ä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸä½œä¸ºæ ‡è®°ï¼ˆç°åœ¨é›†çš„æ’­å‡ºæ—¥æœŸå·²ç»æ˜¯æœ¬åœ°æ—¥æœŸï¼Œä¸éœ€è¦é€šè¿‡æ’­å‡ºé›†æ•°åˆ·æ–°æ—¶é—´é™åˆ¶ï¼‰
        from datetime import datetime as _dt
        now = _dt.now()
        today = now.strftime('%Y-%m-%d')
        # è¿›ç¨‹å†…å·²æ£€æŸ¥è¿‡ä»Šæ—¥ï¼Œç›´æ¥è·³è¿‡
        if _aired_on_demand_checked_date == today:
            return
        # ä»…å½“å·²è¿‡åˆ·æ–°æ—¶é—´æ—¶æ‰å…è®¸è¡¥ç®—ï¼ˆé¿å…æå‰ï¼‰
        perf = config_data.get('performance', {}) if isinstance(config_data, dict) else {}
        time_str = perf.get('aired_refresh_time', '00:00')
        try:
            hh, mm = [int(x) for x in time_str.split(':')]
            allow = (now.hour > hh) or (now.hour == hh and now.minute >= mm)
        except Exception:
            allow = True
        if not allow:
            # æœªåˆ°åˆ·æ–°ç‚¹ï¼Œä¸åšä»»ä½•äº‹
            return
        # å·²è®°å½•çš„ä¸Šæ¬¡å®Œæˆæ—¥æœŸ
        stamped = _read_aired_effective_stamp()
        if stamped != today:
            # éœ€è¦è¡¥ç®—ä¸€æ¬¡
            logging.debug(f"æ£€æµ‹åˆ°å½“æ—¥å°šæœªç”Ÿæ•ˆï¼ˆè§¦å‘:{trigger_reason or 'on_demand'}ï¼‰ï¼Œæ‰§è¡Œä¸€æ¬¡è¡¥å¿åˆ·æ–°â€¦")
            recompute_all_seasons_aired_daily()
            # æˆåŠŸå recompute å†…éƒ¨ä¼šå†™ stampï¼›æ­¤å¤„å°†è¿›ç¨‹å†…è®°ä¸ºå·²æ£€æŸ¥ï¼Œé¿å…å¤šæ¬¡è§¦å‘
            _aired_on_demand_checked_date = today
        else:
            # å·²å®Œæˆï¼Œæ ‡è®°ä»Šæ—¥å·²æ£€æŸ¥ï¼Œé¿å…é‡å¤
            _aired_on_demand_checked_date = today
    except Exception:
        pass


def _is_after_refresh_time(now_dt):
    try:
        perf = config_data.get('performance', {}) if isinstance(config_data, dict) else {}
        time_str = perf.get('aired_refresh_time', '00:00')
        hh, mm = [int(x) for x in time_str.split(':')]
        return (now_dt.hour > hh) or (now_dt.hour == hh and now_dt.minute >= mm)
    except Exception:
        return True

def _is_today_aired_done() -> bool:
    try:
        from datetime import datetime as _dt
        now = _dt.now()
        if not _is_after_refresh_time(now):
            return False
        # ç›´æ¥ä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸä½œä¸ºæ ‡è®°ï¼ˆç°åœ¨é›†çš„æ’­å‡ºæ—¥æœŸå·²ç»æ˜¯æœ¬åœ°æ—¥æœŸï¼Œä¸éœ€è¦é€šè¿‡æ’­å‡ºé›†æ•°åˆ·æ–°æ—¶é—´é™åˆ¶ï¼‰
        today = now.strftime('%Y-%m-%d')
        stamped = _read_aired_effective_stamp()
        return stamped == today
    except Exception:
        return False


def _schedule_aired_retry_in(minutes_delay: int = 10):
    try:
        from datetime import datetime as _dt, timedelta as _td
        # ç§»é™¤å·²æœ‰çš„é‡è¯•ä»»åŠ¡ï¼Œé¿å…é‡å¤å †ç§¯
        try:
            scheduler.remove_job('daily_aired_retry')
        except Exception:
            pass
        run_at = _dt.now() + _td(minutes=max(1, int(minutes_delay)))
        scheduler.add_job(
            func=lambda: recompute_all_seasons_aired_daily(),
            trigger=DateTrigger(run_date=run_at),
            id='daily_aired_retry',
            replace_existing=True,
            coalesce=True,
            max_instances=1,
        )
        if scheduler.state == 0:
            scheduler.start()
        logging.debug(f"å·²å®‰æ’æ’­å‡ºé›†æ•°è¡¥å¿é‡è¯•ä»»åŠ¡ï¼Œæ—¶é—´ {run_at.strftime('%Y-%m-%d %H:%M')}" )
    except Exception as e:
        logging.warning(f"å®‰æ’æ’­å‡ºé›†æ•°è¡¥å¿é‡è¯•ä»»åŠ¡å¤±è´¥: {e}")

def _schedule_show_retry_in(tmdb_id: int, minutes_delay: int = 10):
    """ä¸ºå•ä¸ªèŠ‚ç›®å®‰æ’æ’­å‡ºè¿›åº¦åˆ·æ–°é‡è¯•ä»»åŠ¡"""
    try:
        from datetime import datetime as _dt, timedelta as _td
        job_id = f'show_aired_retry_{tmdb_id}'
        # ç§»é™¤å·²æœ‰çš„é‡è¯•ä»»åŠ¡ï¼Œé¿å…é‡å¤å †ç§¯
        try:
            scheduler.remove_job(job_id)
        except Exception:
            pass
        run_at = _dt.now() + _td(minutes=max(1, int(minutes_delay)))
        scheduler.add_job(
            func=lambda _tid=int(tmdb_id): recompute_show_aired_progress(_tid),
            trigger=DateTrigger(run_date=run_at),
            id=job_id,
            replace_existing=True,
            coalesce=True,
            max_instances=1,
        )
        if scheduler.state == 0:
            scheduler.start()
        logging.debug(f"å·²å®‰æ’èŠ‚ç›®æ’­å‡ºè¿›åº¦è¡¥å¿é‡è¯•ä»»åŠ¡ tmdb_id={tmdb_id}ï¼Œæ—¶é—´ {run_at.strftime('%Y-%m-%d %H:%M')}" )
    except Exception as e:
        logging.warning(f"å®‰æ’èŠ‚ç›®æ’­å‡ºè¿›åº¦è¡¥å¿é‡è¯•ä»»åŠ¡å¤±è´¥ tmdb_id={tmdb_id}: {e}")

# æ˜¯å¦ä¸º Flask ä¸»æœåŠ¡è¿›ç¨‹ï¼ˆä»…è¯¥è¿›ç¨‹è¾“å‡ºæŸäº›æç¤ºï¼‰
IS_FLASK_SERVER_PROCESS = False

scheduler = BackgroundScheduler(
    job_defaults={
        # å…è®¸åœ¨ç³»ç»Ÿå”¤é†’åè¡¥å¿æ‰§è¡Œå…¨éƒ¨é”™è¿‡çš„ä»»åŠ¡
        "misfire_grace_time": None,
        # ä¼‘çœ æœŸé—´å³ä¾¿é”™è¿‡å¤šæ¬¡è§¦å‘ï¼Œä¹Ÿä»…è¡¥å¿æ‰§è¡Œä¸€æ¬¡ï¼Œé¿å…å †ç§¯
        "coalesce": True,
    }
)

# å®šæ—¶ä»»åŠ¡è¿›ç¨‹/çº¿ç¨‹è·Ÿè¸ªï¼šç”¨äºæ£€æµ‹å’Œæ¸…ç†æœªå®Œæˆçš„ä»»åŠ¡
_crontab_task_process = None  # å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡çš„è¿›ç¨‹å¯¹è±¡
_calendar_refresh_thread = None  # è¿½å‰§æ—¥å†è‡ªåŠ¨åˆ·æ–°çš„çº¿ç¨‹å¯¹è±¡
# è®°å½•æ¯æ—¥ä»»åŠ¡ä¸Šæ¬¡ç”Ÿæ•ˆçš„æ—¶é—´ï¼Œé¿å…é‡å¤æ—¥å¿—
_daily_aired_last_time_str = None
_calendar_refresh_last_interval = None
_last_crontab = None
_last_crontab_delay = None
_aired_on_demand_checked_date = None  # æœ¬è¿›ç¨‹å†…ï¼Œå½“å¤©æ˜¯å¦å·²è¿›è¡Œè¿‡ä¸€æ¬¡æŒ‰éœ€æ£€æŸ¥
logging.basicConfig(
    level=logging.DEBUG if DEBUG else logging.INFO,
    format="[%(asctime)s][%(levelname)s] %(message)s",
    datefmt="%m-%d %H:%M:%S",
)
# é™ä½ç¬¬ä¸‰æ–¹ç½‘ç»œåº“çš„é‡è¯•å™ªéŸ³ï¼šå°† urllib3/requests çš„æ—¥å¿—è°ƒä¸º ERRORï¼Œå¹¶æŠŠ"Retrying ..."æ¶ˆæ¯é™çº§ä¸º DEBUG
try:
    logging.getLogger("urllib3").setLevel(logging.ERROR)
    logging.getLogger("requests").setLevel(logging.ERROR)

    class _RetryWarningToDebug(logging.Filter):
        def filter(self, record: logging.LogRecord) -> bool:
            try:
                msg = str(record.getMessage())
                if "Retrying (Retry(" in msg or "Retrying (" in msg:
                    # å°†æ­¤æ¡è®°å½•çš„ç­‰çº§é™åˆ° DEBUG
                    record.levelno = logging.DEBUG
                    record.levelname = "DEBUG"
            except Exception:
                pass
            return True

    _urllib3_logger = logging.getLogger("urllib3.connectionpool")
    _urllib3_logger.addFilter(_RetryWarningToDebug())
except Exception:
    pass
# æ·»åŠ è¿‡æ»¤å™¨ï¼Œè¿‡æ»¤HTTPè®¿é—®æ—¥å¿—ï¼ˆæ ¼å¼ï¼šIP - - [æ—¶é—´] "METHOD /path HTTP/1.1" çŠ¶æ€ç ï¼‰
class _HTTPAccessLogFilter(logging.Filter):
    """è¿‡æ»¤HTTPè®¿é—®æ—¥å¿—ï¼Œé¿å…è¾“å‡ºåˆ°æ—¥å¿—æ–‡ä»¶"""
    def filter(self, record: logging.LogRecord) -> bool:
        try:
            msg = str(record.getMessage())
            # åŒ¹é…HTTPè®¿é—®æ—¥å¿—æ ¼å¼ï¼šIP - - [æ—¶é—´] "METHOD /path HTTP/1.1" çŠ¶æ€ç 
            if re.match(r'^\d+\.\d+\.\d+\.\d+\s+-\s+-\s+\[.*?\]\s+"(GET|POST|PUT|DELETE|PATCH|HEAD|OPTIONS)\s+.*?\s+HTTP/1\.\d"\s+\d+', msg):
                return False  # è¿‡æ»¤æ‰HTTPè®¿é—®æ—¥å¿—
        except Exception:
            pass
        return True

# è¿‡æ»¤werkzeugæ—¥å¿—è¾“å‡ºï¼ˆåŒ…æ‹¬HTTPè®¿é—®æ—¥å¿—ï¼‰
# æ— è®ºæ˜¯å¦DEBUGæ¨¡å¼ï¼Œéƒ½ç¦ç”¨werkzeugçš„è®¿é—®æ—¥å¿—ï¼Œåªä¿ç•™ERRORçº§åˆ«ä»¥ä¸Šçš„æ—¥å¿—
_werkzeug_logger = logging.getLogger("werkzeug")
_werkzeug_logger.setLevel(logging.ERROR)
# å°†è¿‡æ»¤å™¨æ·»åŠ åˆ°werkzeugæ—¥å¿—è®°å½•å™¨ï¼Œè¿‡æ»¤HTTPè®¿é—®æ—¥å¿—
try:
    _werkzeug_logger.addFilter(_HTTPAccessLogFilter())
except Exception:
    pass

# å°†è¿‡æ»¤å™¨ä¹Ÿæ·»åŠ åˆ°æ ¹æ—¥å¿—è®°å½•å™¨ï¼Œç¡®ä¿æ‰€æœ‰HTTPè®¿é—®æ—¥å¿—éƒ½è¢«è¿‡æ»¤
try:
    _root_logger = logging.getLogger()
    _root_logger.addFilter(_HTTPAccessLogFilter())
except Exception:
    pass

# é™éŸ³ APScheduler çš„æ™®é€šä¿¡æ¯æ—¥å¿—ï¼Œé¿å… "Adding job tentatively" ç­‰å™ªéŸ³
try:
    logging.getLogger("apscheduler").setLevel(logging.WARNING)
except Exception:
    pass

# ç»Ÿä¸€æ‰€æœ‰å·²æœ‰å¤„ç†å™¨ï¼ˆåŒ…æ‹¬ werkzeugã€apschedulerï¼‰çš„æ—¥å¿—æ ¼å¼
_root_logger = logging.getLogger()
_standard_formatter = logging.Formatter(
    fmt="[%(asctime)s][%(levelname)s] %(message)s",
    datefmt="%m-%d %H:%M:%S",
)
for _handler in list(_root_logger.handlers):
    try:
        _handler.setFormatter(_standard_formatter)
    except Exception:
        pass

for _name in ("werkzeug", "apscheduler", "gunicorn.error", "gunicorn.access"):
    _logger = logging.getLogger(_name)
    for _handler in list(_logger.handlers):
        try:
            _handler.setFormatter(_standard_formatter)
        except Exception:
            pass

# å†™å…¥è¿è¡Œæ—¥å¿—æ–‡ä»¶ï¼Œä¾¿äºå‰ç«¯å®æ—¶æŸ¥çœ‹
try:
    _runtime_log_handler = RotatingFileHandler(
        LOG_FILE_PATH,
        maxBytes=5 * 1024 * 1024,
        backupCount=2,
        encoding="utf-8"
    )
    _runtime_log_handler.setFormatter(_standard_formatter)
    _root_logger.addHandler(_runtime_log_handler)
except Exception as e:
    logging.warning(f"åˆå§‹åŒ–è¿è¡Œæ—¥å¿—æ–‡ä»¶å¤„ç†å™¨å¤±è´¥: {e}")


def _parse_runtime_log_line(line: str) -> dict:
    """è§£æå•è¡Œæ—¥å¿—æ–‡æœ¬ï¼Œæå–æ—¶é—´ã€çº§åˆ«ä¸å†…å®¹ã€‚"""
    text = (line or "").rstrip("\n")
    entry = {
        "raw": text,
        "timestamp": "",
        "level": "INFO",
        "message": text
    }
    if not text:
        return entry
    match = RUNTIME_LOG_PATTERN.match(text.strip())
    if match:
        entry["timestamp"] = match.group("timestamp")
        entry["level"] = match.group("level")
        entry["message"] = match.group("message")
    return entry


def get_recent_runtime_logs(limit: int = None, days: float = None) -> list:
    """è·å–æœ€è¿‘çš„è¿è¡Œæ—¥å¿—è¡Œã€‚
    
    Args:
        limit: æŒ‰æ¡æ•°é™åˆ¶ï¼Œé»˜è®¤ Noneï¼ˆä¸ä½¿ç”¨æ¡æ•°é™åˆ¶ï¼‰
        days: æŒ‰æ—¶é—´èŒƒå›´é™åˆ¶ï¼ˆå¤©æ•°ï¼‰ï¼Œé»˜è®¤ Noneï¼ˆä¸ä½¿ç”¨æ—¶é—´é™åˆ¶ï¼‰
              å¦‚æœåŒæ—¶æŒ‡å®š limit å’Œ daysï¼Œä¼˜å…ˆä½¿ç”¨ days å‚æ•°
    
    Returns:
        æ—¥å¿—æ¡ç›®åˆ—è¡¨
    """
    if not os.path.exists(LOG_FILE_PATH):
        return []
    
    # å¦‚æœæŒ‡å®šäº† days å‚æ•°ï¼ŒæŒ‰æ—¶é—´èŒƒå›´ç­›é€‰
    if days is not None:
        try:
            days_float = float(days)
            if days_float <= 0:
                days_float = 1.0  # é»˜è®¤1å¤©
        except (ValueError, TypeError):
            days_float = 1.0
        
        # è®¡ç®—æ—¶é—´é˜ˆå€¼ï¼ˆå½“å‰æ—¶é—´å¾€å‰æ¨æŒ‡å®šå¤©æ•°ï¼‰
        time_threshold = datetime.now() - timedelta(days=days_float)
        current_year = datetime.now().year
        
        logs = []
        try:
            with open(LOG_FILE_PATH, "r", encoding="utf-8", errors="replace") as fp:
                for raw_line in fp:
                    line = raw_line.rstrip("\n")
                    if not line:
                        continue
                    
                    entry = _parse_runtime_log_line(line)
                    timestamp_str = entry.get("timestamp", "")
                    
                    # è§£ææ—¶é—´æˆ³ï¼ˆæ ¼å¼ï¼šMM-DD HH:MM:SSï¼‰
                    if timestamp_str:
                        try:
                            # å°è¯•è§£ææ—¶é—´æˆ³ï¼Œéœ€è¦åŠ ä¸Šå½“å‰å¹´ä»½
                            log_time = datetime.strptime(f"{current_year}-{timestamp_str}", "%Y-%m-%d %H:%M:%S")
                            
                            # å¦‚æœè§£æå‡ºçš„æ—¶é—´æ¯”å½“å‰æ—¶é—´è¿˜æ™šï¼ˆè·¨å¹´æƒ…å†µï¼‰ï¼Œåˆ™å‡ä¸€å¹´
                            if log_time > datetime.now():
                                log_time = datetime.strptime(f"{current_year - 1}-{timestamp_str}", "%Y-%m-%d %H:%M:%S")
                            
                            # åªä¿ç•™åœ¨æ—¶é—´èŒƒå›´å†…çš„æ—¥å¿—
                            if log_time >= time_threshold:
                                entry["id"] = f"{len(logs)}-{hashlib.md5((line + str(len(logs))).encode('utf-8', 'ignore')).hexdigest()}"
                                logs.append(entry)
                        except (ValueError, TypeError):
                            # å¦‚æœæ—¶é—´æˆ³è§£æå¤±è´¥ï¼Œä¿ç•™è¯¥æ—¥å¿—ï¼ˆå…¼å®¹æ²¡æœ‰æ—¶é—´æˆ³çš„æ—¥å¿—ï¼‰
                            entry["id"] = f"{len(logs)}-{hashlib.md5((line + str(len(logs))).encode('utf-8', 'ignore')).hexdigest()}"
                            logs.append(entry)
                    else:
                        # æ²¡æœ‰æ—¶é—´æˆ³çš„æ—¥å¿—ä¹Ÿä¿ç•™
                        entry["id"] = f"{len(logs)}-{hashlib.md5((line + str(len(logs))).encode('utf-8', 'ignore')).hexdigest()}"
                        logs.append(entry)
        except Exception as exc:
            logging.warning(f"è¯»å–è¿è¡Œæ—¥å¿—å¤±è´¥: {exc}")
            return []
        
        return logs
    
    # å¦‚æœæŒ‡å®šäº† limit å‚æ•°ï¼ŒæŒ‰æ¡æ•°é™åˆ¶ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
    if limit is not None:
        try:
            limit_int = int(limit)
        except (ValueError, TypeError):
            limit_int = 600
        limit_int = max(100, min(limit_int, MAX_RUNTIME_LOG_LINES))
        
        lines = deque(maxlen=limit_int)
        try:
            with open(LOG_FILE_PATH, "r", encoding="utf-8", errors="replace") as fp:
                for raw_line in fp:
                    lines.append(raw_line.rstrip("\n"))
        except Exception as exc:
            logging.warning(f"è¯»å–è¿è¡Œæ—¥å¿—å¤±è´¥: {exc}")
            return []
        
        logs = []
        for idx, raw_line in enumerate(lines):
            entry = _parse_runtime_log_line(raw_line)
            entry["id"] = f"{idx}-{hashlib.md5((raw_line + str(idx)).encode('utf-8', 'ignore')).hexdigest()}"
            logs.append(entry)
        return logs
    
    # å¦‚æœä¸¤ä¸ªå‚æ•°éƒ½æ²¡æœ‰æŒ‡å®šï¼Œè¿”å›æ‰€æœ‰æ—¥å¿—ï¼ˆä¸æ¨èï¼Œä½†ä¿æŒå…¼å®¹æ€§ï¼‰
    logs = []
    try:
        with open(LOG_FILE_PATH, "r", encoding="utf-8", errors="replace") as fp:
            for raw_line in fp:
                line = raw_line.rstrip("\n")
                if not line:
                    continue
                entry = _parse_runtime_log_line(line)
                entry["id"] = f"{len(logs)}-{hashlib.md5((line + str(len(logs))).encode('utf-8', 'ignore')).hexdigest()}"
                logs.append(entry)
    except Exception as exc:
        logging.warning(f"è¯»å–è¿è¡Œæ—¥å¿—å¤±è´¥: {exc}")
        return []
    
    return logs


# --------- æ¯æ—¥ä»»åŠ¡ï¼šåœ¨ç”¨æˆ·è®¾ç½®çš„åˆ·æ–°æ—¶é—´é‡ç®—æ‰€æœ‰å­£çš„å·²æ’­å‡ºé›†æ•°å¹¶æ›´æ–°è¿›åº¦ ---------
def recompute_all_seasons_aired_daily():
    logging.info(f">>> å¼€å§‹æ‰§è¡Œæ’­å‡ºé›†æ•°è‡ªåŠ¨åˆ·æ–°")
    try:
        from time import time as _now
        now_ts = int(_now())

        # å½“å‰æœ¬åœ°æ—¶é—´ï¼ˆç”¨äºç²¾ç¡®â€œæ˜¯å¦å·²æ’­å‡ºâ€åˆ¤æ–­ï¼‰
        try:
            from zoneinfo import ZoneInfo as _ZoneInfo
            local_tz = _get_local_timezone()
            now_local_dt = datetime.now(_ZoneInfo(local_tz))
        except Exception:
            now_local_dt = datetime.now()

        cal_db = CalendarDB()
        cur = cal_db.conn.cursor()
        # éå†æœ¬åœ°æ‰€æœ‰å­£
        cur.execute('SELECT tmdb_id, season_number, episode_count FROM seasons')
        rows = cur.fetchall() or []
        for tmdb_id, season_no, total in rows:
            try:
                tmdb_id_i = int(tmdb_id)
                season_no_i = int(season_no)
                total_i = int(total or 0)

                # é€é›†åˆ¤æ–­æ˜¯å¦å·²æ’­å‡ºï¼ˆä¼˜å…ˆä½¿ç”¨ Trakt æœ¬åœ°æ—¶é—´ï¼Œå…¶æ¬¡èŠ‚ç›®çº§æœ¬åœ°æ—¶é—´ï¼Œæœ€å TMDB æ—¥æœŸï¼‰
                aired_i = 0
                cur.execute(
                    """
                    SELECT episode_number FROM episodes
                    WHERE tmdb_id=? AND season_number=?
                    """,
                    (tmdb_id_i, season_no_i),
                )
                for (ep_no,) in cur.fetchall() or []:
                    try:
                        if is_episode_aired(tmdb_id_i, season_no_i, int(ep_no), now_local_dt):
                            aired_i += 1
                    except Exception:
                        continue

                # å–å·²è½¬å­˜é›†æ•°ç”¨äºè®¡ç®—è¿›åº¦
                metrics = cal_db.get_season_metrics(tmdb_id_i, season_no_i) or {}
                transferred_i = int(metrics.get('transferred_count') or 0)
                denom = min(int(aired_i or 0), int(total_i or 0))
                progress_pct = (100 * min(transferred_i, denom) // denom) if denom > 0 else 0
                # å†™å›ç¼“å­˜ï¼šä»…æ›´æ–° aired/total/progress_pct ä¸æ—¶é—´æˆ³
                cal_db.upsert_season_metrics(tmdb_id_i, season_no_i, None, aired_i, total_i, progress_pct, now_ts)
            except Exception:
                continue
        # æˆåŠŸåå†™å…¥å½“æ—¥å®Œæˆæ ‡è®°ï¼ˆä½¿ç”¨ stamp æ–‡ä»¶ï¼Œé¿å…å¼•å…¥ DB ç»“æ„å˜æ›´ï¼‰
        try:
            # ç›´æ¥ä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸä½œä¸ºæ ‡è®°ï¼ˆç°åœ¨é›†çš„æ’­å‡ºæ—¥æœŸå·²ç»æ˜¯æœ¬åœ°æ—¥æœŸï¼Œä¸éœ€è¦é€šè¿‡æ’­å‡ºé›†æ•°åˆ·æ–°æ—¶é—´é™åˆ¶ï¼‰
            from datetime import datetime as _dt
            today = _dt.now().strftime('%Y-%m-%d')
            _write_aired_effective_stamp(today)
        except Exception:
            pass
        try:
            notify_calendar_changed('daily_aired_update')
        except Exception:
            pass
        # éªŒè¯å½“æ—¥æ˜¯å¦å·²ç”Ÿæ•ˆï¼ŒæˆåŠŸåˆ™æ¸…ç†é‡è¯•ä»»åŠ¡ï¼›å¦åˆ™å®‰æ’ä¸‹ä¸€æ¬¡è¡¥å¿é‡è¯•
        try:
            if _is_today_aired_done():
                try:
                    scheduler.remove_job('daily_aired_retry')
                except Exception:
                    pass
            else:
                _schedule_aired_retry_in(10)
        except Exception:
            pass
        logging.info(f">>> æ’­å‡ºé›†æ•°è‡ªåŠ¨åˆ·æ–°æ‰§è¡ŒæˆåŠŸ")
    except Exception as e:
        logging.warning(f">>> æ’­å‡ºé›†æ•°è‡ªåŠ¨åˆ·æ–°æ‰§è¡Œå¼‚å¸¸: {e}")
        # å‘ç”Ÿå¼‚å¸¸ä¹Ÿå®‰æ’ä¸€æ¬¡è¡¥å¿é‡è¯•
        try:
            _schedule_aired_retry_in(10)
        except Exception:
            pass


def recompute_show_aired_progress(tmdb_id: int, now_local_dt=None, season_number: int = None, episode_number: int = None):
    """æŒ‰èŠ‚ç›®ç»´åº¦é‡ç®—æ’­å‡º/è¿›åº¦ï¼Œä¾›æŒ‰æ’­å‡ºæ—¶é—´è§¦å‘ä¸è¡¥å¿ä½¿ç”¨
    
    Args:
        tmdb_id: èŠ‚ç›®ID
        now_local_dt: å½“å‰æœ¬åœ°æ—¶é—´ï¼Œå¯é€‰
        season_number: å­£å·ï¼Œå¯é€‰ã€‚å¦‚æœæä¾›ï¼Œåªåˆ·æ–°æŒ‡å®šçš„å­£
        episode_number: é›†å·ï¼Œå¯é€‰ã€‚å¦‚æœæä¾›ï¼Œæ—¥å¿—ä¸­ä¼šæ˜¾ç¤ºé›†å·ä¿¡æ¯
    """
    try:
        from time import time as _now
        now_ts = int(_now())
        try:
            from zoneinfo import ZoneInfo as _ZoneInfo
            local_tz = _ZoneInfo(_get_local_timezone())
            if now_local_dt is None:
                now_local_dt = datetime.now(local_tz)
        except Exception:
            if now_local_dt is None:
                now_local_dt = datetime.now()

        cal_db = CalendarDB()
        cur = cal_db.conn.cursor()
        # è·å–èŠ‚ç›®åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼Œä»…å½±å“å¯è¯»æ€§ï¼‰
        show_name = str(tmdb_id)
        try:
            cur.execute("SELECT name FROM shows WHERE tmdb_id=? LIMIT 1", (int(tmdb_id),))
            row = cur.fetchone()
            if row and row[0]:
                show_name = str(row[0])
        except Exception:
            pass
        
        # å¦‚æœæŒ‡å®šäº†å­£å·ï¼Œåªå¤„ç†è¯¥å­£ï¼›å¦åˆ™å¤„ç†æ‰€æœ‰å­£
        if season_number is not None:
            cur.execute(
                "SELECT season_number, episode_count FROM seasons WHERE tmdb_id=? AND season_number=?",
                (int(tmdb_id), int(season_number)),
            )
        else:
            cur.execute(
                "SELECT season_number, episode_count FROM seasons WHERE tmdb_id=?",
                (int(tmdb_id),),
            )
        rows = cur.fetchall() or []
        for season_no, total in rows:
            try:
                season_no_i = int(season_no)
                total_i = int(total or 0)
                
                # æ„å»ºæ—¥å¿—æ˜¾ç¤ºåç§°ï¼šå¦‚æœæä¾›äº†é›†å·ï¼Œåœ¨æ—¥å¿—ä¸­æ˜¾ç¤ºé›†å·
                log_name = f"{show_name} Â· ç¬¬ {season_no_i} å­£"
                if episode_number is not None:
                    log_name = f"{show_name} Â· ç¬¬ {season_no_i} å­£ Â· ç¬¬ {int(episode_number)} é›†"
                
                try:
                    logging.info(f">>> å¼€å§‹æ‰§è¡Œ [{log_name}] æ’­å‡ºçŠ¶æ€åˆ·æ–°ä»»åŠ¡")
                except Exception:
                    pass
                aired_i = 0
                cur.execute(
                    """
                    SELECT episode_number FROM episodes
                    WHERE tmdb_id=? AND season_number=?
                    """,
                    (int(tmdb_id), season_no_i),
                )
                for (ep_no,) in cur.fetchall() or []:
                    try:
                        if is_episode_aired(int(tmdb_id), season_no_i, int(ep_no), now_local_dt):
                            aired_i += 1
                    except Exception:
                        continue
                metrics = cal_db.get_season_metrics(int(tmdb_id), season_no_i) or {}
                transferred_i = int(metrics.get('transferred_count') or 0)
                denom = min(int(aired_i or 0), int(total_i or 0))
                progress_pct = (100 * min(transferred_i, denom) // denom) if denom > 0 else 0
                cal_db.upsert_season_metrics(int(tmdb_id), season_no_i, None, aired_i, total_i, progress_pct, now_ts)
                try:
                    logging.info(f">>> [{log_name}] æ’­å‡ºçŠ¶æ€åˆ·æ–°ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ")
                except Exception:
                    pass
            except Exception:
                continue
        try:
            notify_calendar_changed('aired_on_demand')
        except Exception:
            pass
        # æˆåŠŸåæ¸…ç†è¯¥èŠ‚ç›®çš„é‡è¯•ä»»åŠ¡
        try:
            job_id = f'show_aired_retry_{int(tmdb_id)}'
            scheduler.remove_job(job_id)
        except Exception:
            pass
    except Exception as e:
        logging.warning(f">>> å‰§é›†æ’­å‡ºçŠ¶æ€åˆ·æ–°æ‰§è¡Œå¼‚å¸¸ tmdb_id={tmdb_id}: {e}")
        # å‘ç”Ÿå¼‚å¸¸ä¹Ÿå®‰æ’ä¸€æ¬¡è¡¥å¿é‡è¯•
        try:
            _schedule_show_retry_in(int(tmdb_id), minutes_delay=10)
        except Exception:
            pass


def _build_episode_local_air_dt(tmdb_id, air_datetime_local, air_date_local, air_date):
    """
    æ ¹æ®æœ¬åœ°æ’­å‡ºæ—¶é—´å­—æ®µå’Œå…œåº•é…ç½®ç”Ÿæˆæœ¬åœ°æ’­å‡º datetime
    è¿”å› (datetime_or_none, used_time_str_or_none)ï¼Œç”¨äºä¸Šå±‚åˆ¤æ–­æ˜¯å¦ä¸å…¨å±€åˆ·æ–°æ—¶é—´é‡å 
    """
    try:
        from zoneinfo import ZoneInfo as _ZoneInfo
        local_tz = _ZoneInfo(_get_local_timezone())
    except Exception:
        local_tz = None

    try:
        if air_datetime_local:
            dt = datetime.fromisoformat(str(air_datetime_local))
            if dt.tzinfo is None and local_tz:
                dt = dt.replace(tzinfo=local_tz)
            return dt, None
    except Exception:
        pass

    date_str = (air_date_local or air_date or '').strip()
    if not date_str:
        return None, None
    try:
        date_obj = datetime.strptime(date_str, "%Y-%m-%d").date()
    except Exception:
        return None, None

    schedule = {}
    try:
        schedule = CalendarDB().get_show_air_schedule(int(tmdb_id)) or {}
    except Exception:
        schedule = {}
    perf = config_data.get('performance', {}) if isinstance(config_data, dict) else {}
    fallback_time = (schedule.get("local_air_time") or perf.get("aired_refresh_time") or "00:00").strip()
    try:
        hh, mm = [int(x) for x in str(fallback_time).split(":")]
    except Exception:
        hh, mm = 0, 0
    try:
        dt = datetime.combine(date_obj, datetime.min.time()).replace(hour=hh, minute=mm, second=0)
        if local_tz:
            dt = dt.replace(tzinfo=local_tz)
        return dt, fallback_time
    except Exception:
        return None, fallback_time


def schedule_airtime_based_refresh_jobs(days_back: int = 2, days_forward: int = 14, tmdb_id: int = None):
    """
    ä¸ºæ¯ä¸ªèŠ‚ç›®æŒ‰æœ¬åœ°æ’­å‡ºæ—¶é—´è°ƒåº¦å•èŠ‚ç›®åˆ·æ–°ï¼Œå«é”™è¿‡è¡¥å¿ï¼š
    - æœªæ¥çš„æ’­å‡ºæ—¶é—´ï¼šæ³¨å†Œ DateTriggerï¼Œç¡®ä¿åˆ°ç‚¹ç«‹å³é‡ç®—
    - å·²ç»è¿‡æœŸä½†å½“å¤©æœªåˆ·æ–°ï¼šç«‹å³é‡ç®—ä¸€æ¬¡è¡¥å¿
    """
    try:
        try:
            from zoneinfo import ZoneInfo as _ZoneInfo
            local_tz = _ZoneInfo(_get_local_timezone())
            now_local = datetime.now(local_tz)
        except Exception:
            local_tz = None
            now_local = datetime.now()

        cal_db = CalendarDB()
        cur = cal_db.conn.cursor()
        base_sql = """
            SELECT tmdb_id, season_number, episode_number, air_datetime_local, air_date_local, air_date
            FROM episodes
            WHERE ((air_datetime_local IS NOT NULL AND air_datetime_local != '')
               OR (air_date_local IS NOT NULL AND air_date_local != '')
               OR (air_date IS NOT NULL AND air_date != ''))
        """
        params = []
        if tmdb_id is not None:
            base_sql += " AND tmdb_id = ?"
            params.append(int(tmdb_id))
        cur.execute(base_sql, params)
        rows = cur.fetchall() or []
        if not rows:
            return

        # å…¨å±€æ’­å‡ºé›†æ•°åˆ·æ–°æ—¶é—´ï¼Œç”¨äºä¸èŠ‚ç›®çº§æ—¶é—´å¯¹æ¯”ï¼Œé¿å…é‡å¤è°ƒåº¦
        perf = config_data.get('performance', {}) if isinstance(config_data, dict) else {}
        global_refresh_time = (perf.get('aired_refresh_time') or "00:00").strip()

        # æ¸…ç†æ—§çš„æ’­å‡ºæ—¶é—´è°ƒåº¦ï¼Œé¿å…å•ä¸€ job è¦†ç›–å¤šé›†
        try:
            _removed = 0
            prefix = f"aired_refresh_{int(tmdb_id)}_" if tmdb_id is not None else "aired_refresh_"
            for _job in scheduler.get_jobs():
                try:
                    if str(getattr(_job, "id", "")).startswith(prefix):
                        scheduler.remove_job(_job.id)
                        _removed += 1
                except Exception:
                    continue
            if _removed > 0:
                if tmdb_id is None:
                    logging.debug(f"å·²æ¸…ç† {_removed} ä¸ªè¿‡æœŸçš„å‰§é›†æ’­å‡ºçŠ¶æ€åˆ·æ–°ä»»åŠ¡")
                else:
                    logging.debug(f"å·²æ¸…ç† {_removed} ä¸ªè¿‡æœŸçš„å‰§é›†æ’­å‡ºçŠ¶æ€åˆ·æ–°ä»»åŠ¡ (tmdb_id={int(tmdb_id)})")
        except Exception:
            pass

        min_date = (now_local.date() - timedelta(days=max(0, days_back))).isoformat()
        max_date = (now_local.date() + timedelta(days=max(0, days_forward))).isoformat()
        # ç”¨äºè®°å½•éœ€è¦è¡¥å¿åˆ·æ–°çš„èŠ‚ç›®ï¼Œkey ä¸º tmdb_idï¼Œvalue ä¸ºæœ€æ—©éœ€è¦è¡¥å¿çš„æ’­å‡ºæ—¶é—´
        shows_need_catch = {}
        scheduled = 0
        
        # é¢„åŠ è½½æ‰€æœ‰å­£çš„åˆ·æ–°æ—¶é—´æˆ³ä¸å½“å‰å·²æ’­é›†æ•°ï¼Œç”¨äºæ£€æŸ¥æ˜¯å¦å·²ç»åˆ·æ–°è¿‡
        season_refresh_times = {}
        try:
            cur.execute('SELECT tmdb_id, season_number, updated_at, aired_count FROM season_metrics')
            for tid, sn, ua, ac in (cur.fetchall() or []):
                key = (int(tid), int(sn))
                if ua:
                    season_refresh_times[key] = {"updated_at": int(ua), "aired_count": 0 if ac is None else int(ac)}
        except Exception:
            pass
        
        for tmdb_id, season_number, episode_number, air_dt_local, air_date_local, air_date in rows:
            target_dt, used_time = _build_episode_local_air_dt(tmdb_id, air_dt_local, air_date_local, air_date)
            if not target_dt:
                continue
            # è‹¥ä½¿ç”¨çš„æ’­å‡ºæ—¶é—´ä¸å…¨å±€åˆ·æ–°æ—¶é—´ç›¸åŒï¼Œåˆ™äº¤ç”±å…¨å±€ä»»åŠ¡å¤„ç†ï¼Œé¿å…é‡å¤è°ƒåº¦
            try:
                if used_time and str(used_time).strip() == global_refresh_time:
                    continue
            except Exception:
                pass
            try:
                d_str = target_dt.date().isoformat()
                if d_str < min_date or d_str > max_date:
                    continue
            except Exception:
                pass

            job_id = f"aired_refresh_{tmdb_id}_{season_number}_{episode_number}_{target_dt.strftime('%Y%m%d%H%M')}"

            # å¯¹äºå·²è¿‡æœŸçš„æ’­å‡ºæ—¶é—´ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦è¡¥å¿åˆ·æ–°
            if target_dt <= now_local:
                tmdb_id_i = int(tmdb_id)
                season_no_i = int(season_number)
                
                # æ£€æŸ¥è¯¥å­£æ˜¯å¦å·²ç»åˆ·æ–°è¿‡ï¼ˆé€šè¿‡ season_metrics çš„ updated_at å’Œå·²æ’­é›†æ•°ï¼‰
                need_refresh = True
                try:
                    refresh_info = season_refresh_times.get((tmdb_id_i, season_no_i)) or {}
                    refresh_ts = refresh_info.get("updated_at")
                    aired_cached = refresh_info.get("aired_count")
                    # å°†æ’­å‡ºæ—¶é—´è½¬æ¢ä¸ºæ—¶é—´æˆ³è¿›è¡Œæ¯”è¾ƒ
                    target_ts = int(target_dt.timestamp())
                    if refresh_ts:
                        # å¦‚æœåˆ·æ–°æ—¶é—´æ™šäºæ’­å‡ºæ—¶é—´ï¼Œä¸”å·²æ’­é›†æ•°å·²è¦†ç›–è¯¥é›†ï¼Œåˆ™è§†ä¸ºå·²åˆ·æ–°
                        if refresh_ts >= target_ts and aired_cached is not None:
                            try:
                                if int(aired_cached) >= int(episode_number):
                                    need_refresh = False
                            except Exception:
                                need_refresh = False
                except Exception:
                    # æ£€æŸ¥å¤±è´¥ï¼Œä¿å®ˆå¤„ç†ï¼šæ‰§è¡Œè¡¥å¿åˆ·æ–°
                    pass
                
                if need_refresh:
                    # è®°å½•éœ€è¦è¡¥å¿çš„èŠ‚ç›®ï¼Œå¹¶è®°å½•æœ€æ—©éœ€è¦è¡¥å¿çš„æ’­å‡ºæ—¶é—´ï¼ˆç”¨äºæ—¥å¿—ï¼‰
                    if tmdb_id_i not in shows_need_catch:
                        shows_need_catch[tmdb_id_i] = target_dt
                    elif target_dt < shows_need_catch[tmdb_id_i]:
                        shows_need_catch[tmdb_id_i] = target_dt
                continue

            # æœªæ¥çš„æ’­å‡ºæ—¶é—´ï¼šæ³¨å†Œ DateTrigger
            try:
                _tmdb_id = int(tmdb_id)
                _season_no = int(season_number)
                _ep_no = int(episode_number)
                scheduler.add_job(
                    func=lambda _tid=_tmdb_id, _sn=_season_no, _ep=_ep_no: recompute_show_aired_progress(_tid, season_number=_sn, episode_number=_ep),
                    trigger=DateTrigger(run_date=target_dt),
                    id=job_id,
                    replace_existing=True,
                    coalesce=True,
                    max_instances=1,
                    misfire_grace_time=None,
                )
                scheduled += 1
            except Exception as _e:
                logging.debug(f"å®‰æ’å‰§é›†æ’­å‡ºçŠ¶æ€åˆ·æ–°å¤±è´¥ tmdb_id={tmdb_id}: {_e}")
                continue

        # æ‰§è¡Œè¡¥å¿åˆ·æ–°ï¼šå¯¹äºéœ€è¦è¡¥å¿çš„èŠ‚ç›®ï¼Œç«‹å³åˆ·æ–°
        if shows_need_catch:
            for tid, earliest_dt in shows_need_catch.items():
                try:
                    logging.debug(f"è¡¥å¿åˆ·æ–°èŠ‚ç›® tmdb_id={tid}ï¼Œæœ€æ—©é”™è¿‡æ’­å‡ºæ—¶é—´: {earliest_dt.strftime('%Y-%m-%d %H:%M')}")
                    recompute_show_aired_progress(int(tid), now_local_dt=now_local)
                except Exception as _e:
                    logging.debug(f"è¡¥å¿åˆ·æ–°å¤±è´¥ tmdb_id={tid}: {_e}")

        if scheduler.state == 0:
            scheduler.start()
        if scheduled > 0:
            logging.debug(f"å·²æ›´æ–° {scheduled} ä¸ªå‰§é›†æ’­å‡ºçŠ¶æ€åˆ·æ–°ä»»åŠ¡")
    except Exception as e:
        logging.warning(f"æŒ‰æ’­å‡ºæ—¶é—´è°ƒåº¦åˆ·æ–°å¤±è´¥: {e}")


def _trigger_airtime_reschedule(reason: str = "", tmdb_id: int = None):
    """ç»Ÿä¸€åŒ…è£…ï¼Œä¾¿äºåœ¨æ•°æ®æ›´æ–°åé‡æ–°è®¡ç®—æ’­å‡ºæ—¶é—´è°ƒåº¦"""
    try:
        schedule_airtime_based_refresh_jobs(tmdb_id=tmdb_id)
        if reason:
            if tmdb_id is None:
                logging.debug(f"å·²é‡æ–°å®‰æ’å‰§é›†æ’­å‡ºçŠ¶æ€åˆ·æ–°ä»»åŠ¡ï¼ŒåŸå› : {reason}")
            else:
                logging.debug(f"å·²é‡æ–°å®‰æ’å‰§é›†æ’­å‡ºçŠ¶æ€åˆ·æ–°ä»»åŠ¡ï¼ŒåŸå› : {reason}, tmdb_id={int(tmdb_id)}")
    except Exception as e:
        logging.debug(f"é‡æ–°å®‰æ’å‰§é›†æ’­å‡ºçŠ¶æ€åˆ·æ–°ä»»åŠ¡å¤±è´¥({reason}): {e}")


def restart_daily_aired_update_job():
    try:
        global _daily_aired_last_time_str
        try:
            scheduler.remove_job('daily_aired_update')
        except Exception:
            pass
        # ä»é…ç½®è¯»å–åˆ·æ–°æ—¶é—´ï¼Œé»˜è®¤ 00:00
        perf = config_data.get('performance', {}) if isinstance(config_data, dict) else {}
        time_str = perf.get('aired_refresh_time', '00:00')
        # è§£ææ—¶é—´æ ¼å¼ HH:MM
        try:
            parts = time_str.split(':')
            if len(parts) == 2:
                hour = int(parts[0])
                minute = int(parts[1])
                if 0 <= hour <= 23 and 0 <= minute <= 59:
                    trigger = CronTrigger(hour=hour, minute=minute)
                else:
                    trigger = CronTrigger(hour=0, minute=0)
                    hour, minute = 0, 0
            else:
                trigger = CronTrigger(hour=0, minute=0)
                hour, minute = 0, 0
        except Exception:
            trigger = CronTrigger(hour=0, minute=0)
            hour, minute = 0, 0
        scheduler.add_job(
            recompute_all_seasons_aired_daily,
            trigger=trigger,
            id='daily_aired_update',
            replace_existing=True,
            coalesce=True,
            max_instances=1,
            misfire_grace_time=None
        )
        if scheduler.state == 0:
            scheduler.start()
        # å‹å¥½æç¤ºï¼šæ¯æ—¥ä»»åŠ¡å·²å¯åŠ¨ï¼ˆä»…åœ¨æ—¶é—´å˜åŒ–æ—¶è¾“å‡ºï¼Œä¸”ä»…åœ¨ Flask ä¸»è¿›ç¨‹ä¸­æ‰“å°ï¼Œé¿å…å­è¿›ç¨‹å™ªéŸ³ï¼‰
        try:
            if IS_FLASK_SERVER_PROCESS:
                _time_str = f"{hour:02d}:{minute:02d}"
                if _daily_aired_last_time_str != _time_str:
                    logging.info(f"å·²å¯åŠ¨æ’­å‡ºé›†æ•°è‡ªåŠ¨åˆ·æ–°ï¼Œæ—¶é—´ {_time_str}")
                    _daily_aired_last_time_str = _time_str
        except Exception:
            pass
    except Exception as e:
        logging.warning(f"å¯åŠ¨æ’­å‡ºé›†æ•°è‡ªåŠ¨åˆ·æ–°å¤±è´¥: {e}")


# åº”ç”¨å¯åŠ¨æ—¶æ³¨å†Œæ¯æ—¥ä»»åŠ¡
try:
    restart_daily_aired_update_job()
    # å¯åŠ¨æ—¶åšä¸€æ¬¡æç®€æŒ‰éœ€è¡¥å¿æ£€æŸ¥ï¼ˆä»…ä¸€æ¬¡ï¼‰
    ensure_today_aired_done_if_due_once('startup')
    # å¯åŠ¨æ—¶åŒæ­¥ä¸€æ¬¡æ’­å‡ºæ—¶é—´è§¦å‘è°ƒåº¦ï¼Œç¡®ä¿æ–°ä¸€é›†èƒ½æŒ‰æ’­å‡ºæ—¶é—´åˆ·æ–°
    _trigger_airtime_reschedule('startup')
    # å–æ¶ˆä½é¢‘å¥åº·æ£€æŸ¥æ–¹æ¡ˆï¼Œæ”¹ä¸ºå¤±è´¥åæŒ‰éœ€é‡è¯•è°ƒåº¦
except Exception:
    pass

# ç¼“å­˜ç›®å½•ï¼šæ”¾åœ¨ /app/config/cache ä¸‹ï¼Œç”¨æˆ·æ— éœ€æ–°å¢æ˜ å°„
CACHE_DIR = os.path.abspath(os.path.join(app.root_path, '..', 'config', 'cache'))
CACHE_IMAGES_DIR = os.path.join(CACHE_DIR, 'images')
os.makedirs(CACHE_IMAGES_DIR, exist_ok=True)


# --------- è¿½å‰§æ—¥å†ï¼šSSE äº‹ä»¶ä¸­å¿ƒï¼Œç”¨äºå®æ—¶é€šçŸ¥å‰ç«¯ DB å˜åŒ– ---------
calendar_subscribers = set()

def notify_calendar_changed(reason: str = ""):
    try:
        # å¦‚æœæ˜¯ä¼šå½±å“ä»»åŠ¡åˆ—è¡¨æ•°æ®æˆ–å‰§é›†æ•°æ®çš„å˜æ›´ï¼Œæ¸…é™¤æ‰€æœ‰ç¼“å­˜ï¼Œç¡®ä¿æ•°æ®å®æ—¶æ›´æ–°
        # åŒ…æ‹¬ï¼šè½¬å­˜ç›¸å…³ã€å…ƒæ•°æ®ç¼–è¾‘ã€ä»»åŠ¡é…ç½®å˜æ›´ã€å‰§é›†æ•°æ®åˆ·æ–°ã€è®°å½•åˆ é™¤ç­‰
        if reason in ('transfer_update', 'transfer_record_created', 'transfer_record_updated', 
                     'batch_rename_completed', 'crontab_task_completed', 'manual_task_completed',
                     'edit_metadata', 'daily_aired_update', 'aired_on_demand', 'bootstrap', 
                     'refresh_latest_season', 'refresh_episode', 'refresh_season', 'refresh_show', 
                     'auto_refresh', 'status_updated', 'aired_refresh_time_changed', 'update_airtime',
                     'trakt_airtime_synced', 'purge_tmdb', 'purge_by_task', 'purge_orphans',
                     'delete_records', 'reset_folder'):
            try:
                clear_all_calendar_cache()
            except Exception:
                pass
        
        for q in list(calendar_subscribers):
            try:
                q.put_nowait({'type': 'calendar_changed', 'reason': reason})
            except Exception:
                pass
    except Exception:
        pass

@app.route('/api/calendar/notify', methods=['POST'])
def api_calendar_notify():
    """ä¾›å†…éƒ¨è„šæœ¬è°ƒç”¨çš„ç®€æ˜“é€šçŸ¥å…¥å£ï¼šé€šè¿‡ HTTP è§¦å‘æ—¥å†/ä»»åŠ¡åˆ—è¡¨ SSE äº‹ä»¶"""
    try:
        data = request.get_json(silent=True) or {}
        reason = data.get('reason') or ''
        notify_calendar_changed(reason)
        return jsonify({'success': True})
    except Exception as e:
        return jsonify({'success': False, 'message': str(e)})

@app.route('/api/calendar/stream')
def calendar_stream():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    # åœ¨é¦–ä¸ªå»ºç«‹ SSE çš„å…¥å£å¤„è§¦å‘ä¸€æ¬¡æç®€æŒ‰éœ€æ£€æŸ¥ï¼ˆæ— éœ€å…¨å±€æ¯è¯·æ±‚æ£€æŸ¥ï¼‰
    try:
        ensure_today_aired_done_if_due_once('calendar_stream')
    except Exception:
        pass

    def event_stream():
        q = Queue()
        calendar_subscribers.add(q)
        try:
            # è¿æ¥å»ºç«‹åç«‹å³å‘ä¸€æ¡å¿ƒè·³ï¼Œä¾¿äºå‰ç«¯ç«‹åˆ»è§¦å‘ä¸€æ¬¡æ£€æŸ¥
            yield f"event: ping\n" f"data: connected\n\n"
            import time as _t
            last_heartbeat = _t.time()
            while True:
                try:
                    item = q.get(timeout=15)
                    yield f"event: calendar_changed\n" f"data: {json.dumps(item, ensure_ascii=False)}\n\n"
                except Exception:
                    # å¿ƒè·³
                    now = _t.time()
                    if now - last_heartbeat >= 15:
                        last_heartbeat = now
                        yield f"event: ping\n" f"data: keepalive\n\n"
        except GeneratorExit:
            pass
        finally:
            try:
                calendar_subscribers.discard(q)
            except Exception:
                pass

    return Response(stream_with_context(event_stream()), content_type='text/event-stream;charset=utf-8')

def gen_md5(string):
    md5 = hashlib.md5()
    md5.update(string.encode("utf-8"))
    return md5.hexdigest()


def get_login_token():
    username = config_data["webui"]["username"]
    password = config_data["webui"]["password"]
    return gen_md5(f"token{username}{password}+-*/")[8:24]


def is_login():
    login_token = get_login_token()
    if session.get("token") == login_token or request.args.get("token") == login_token:
        return True
    else:
        return False
DEFAULT_REFRESH_SECONDS = 21600



# è®¾ç½®icon åŠç¼“å­˜é™æ€æ˜ å°„
@app.route("/favicon.ico")
def favicon():
    return send_from_directory(
        os.path.join(app.root_path, "static", "images"),
        "favicon.ico",
        mimetype="image/vnd.microsoft.icon",
    )

# å°† /cache/images/* æ˜ å°„åˆ°å®¿ä¸»ç¼“å­˜ç›®å½•ï¼Œä¾›å‰ç«¯è®¿é—®
@app.route('/cache/images/<path:filename>')
def serve_cache_images(filename):
    resp = send_from_directory(CACHE_IMAGES_DIR, filename)
    try:
        # å¯ç”¨é•¿æœŸç¼“å­˜ï¼šä¾èµ–å‰ç«¯é€šè¿‡ `?t=` ç©¿é€å‚æ•°åœ¨å˜æ›´æ—¶åˆ·æ–°
        # è¯´æ˜ï¼šå›¾ç‰‡æ–‡ä»¶åç¨³å®šä¸”å†…å®¹ç¨³å®šï¼Œæ­£å¸¸æƒ…å†µåº”å‘½ä¸­æµè§ˆå™¨ç¼“å­˜ï¼›
        # å½“ç”¨æˆ·ä¸»åŠ¨æ›´æ¢æµ·æŠ¥æ—¶ï¼Œå‰ç«¯ä¼šä¸ºè¯¥èŠ‚ç›®ç”Ÿæˆæ–°çš„æ—¶é—´æˆ³å‚æ•°ï¼Œå½¢æˆæ–°çš„ URLï¼Œä»è€Œè§¦å‘é‡æ–°ä¸‹è½½ã€‚
        resp.headers['Cache-Control'] = 'public, max-age=31536000, immutable'
        # æ¸…ç†å¯èƒ½çš„å†å²å­—æ®µï¼ˆéƒ¨åˆ†ä»£ç†å¯èƒ½ä¿ç•™ï¼‰
        resp.headers.pop('Pragma', None)
        resp.headers.pop('Expires', None)
    except Exception:
        pass
    return resp


# ç™»å½•é¡µé¢
@app.route("/login", methods=["GET", "POST"])
def login():
    if request.method == "POST":
        username = config_data["webui"]["username"]
        password = config_data["webui"]["password"]
        input_username = request.form.get("username")
        input_password = request.form.get("password")
        
        # éªŒè¯ç”¨æˆ·åå’Œå¯†ç 
        if not input_username or not input_password:
            logging.info(">>> ç™»å½•å¤±è´¥ï¼šç”¨æˆ·åæˆ–å¯†ç ä¸ºç©º")
            return render_template("login.html", message="ç”¨æˆ·åå’Œå¯†ç ä¸èƒ½ä¸ºç©º")
        elif username != input_username:
            logging.info(f">>> ç™»å½•å¤±è´¥ï¼šç”¨æˆ·åé”™è¯¯ {input_username}")
            return render_template("login.html", message="ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")
        elif password != input_password:
            logging.info(f">>> ç”¨æˆ· {input_username} ç™»å½•å¤±è´¥ï¼šå¯†ç é”™è¯¯")
            return render_template("login.html", message="ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")
        else:
            logging.info(f">>> ç”¨æˆ· {username} ç™»å½•æˆåŠŸ")
            session.permanent = True
            session["token"] = get_login_token()
            return redirect(url_for("index"))

    if is_login():
        return redirect(url_for("index"))
    return render_template("login.html", error=None)


# ç¡®ä¿å·²ç™»å½•ç”¨æˆ·çš„ä¼šè¯ä¿æŒæ°¸ä¹…çŠ¶æ€ï¼Œå¹¶åŠ¨æ€è®¾ç½® cookie secure æ ‡å¿—
@app.before_request
def make_session_permanent():
    """ç¡®ä¿å·²ç™»å½•ç”¨æˆ·çš„ä¼šè¯ä¿æŒæ°¸ä¹…çŠ¶æ€ï¼Œå¹¶æ ¹æ®è¯·æ±‚åè®®åŠ¨æ€è®¾ç½® secure æ ‡å¿—"""
    if session.get("token"):
        session.permanent = True
    
    # åŠ¨æ€æ£€æµ‹æ˜¯å¦ä½¿ç”¨ HTTPSï¼ˆæ”¯æŒåå‘ä»£ç†åœºæ™¯ï¼‰
    is_secure = False
    if request.is_secure:
        # ç›´æ¥ä½¿ç”¨ HTTPS
        is_secure = True
    elif request.headers.get('X-Forwarded-Proto') == 'https':
        # é€šè¿‡åå‘ä»£ç†ä½¿ç”¨ HTTPSï¼ˆå¦‚ Nginxã€Apache ç­‰ï¼‰
        is_secure = True
    elif request.headers.get('X-Forwarded-Scheme') == 'https':
        # å¦ä¸€ç§å¸¸è§çš„ä»£ç†å¤´
        is_secure = True
    
    # åŠ¨æ€è®¾ç½® SESSION_COOKIE_SECUREï¼Œè®© Flask è‡ªåŠ¨å¤„ç† cookie çš„ secure æ ‡å¿—
    app.config["SESSION_COOKIE_SECURE"] = is_secure


# é€€å‡ºç™»å½•
@app.route("/logout")
def logout():
    session.pop("token", None)
    return redirect(url_for("login"))


# ç®¡ç†é¡µé¢
@app.route("/")
def index():
    if not is_login():
        return redirect(url_for("login"))
    return render_template(
        "index.html", version=app.config["APP_VERSION"], plugin_flags=PLUGIN_FLAGS
    )


# å·²ç§»é™¤å›¾ç‰‡ä»£ç†é€»è¾‘ï¼ˆæµ‹è¯•ç‰ˆä¸å†éœ€è¦è·¨åŸŸä»£ç†ï¼‰


# è·å–é…ç½®æ•°æ®
@app.route("/data")
def get_data():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    data = Config.read_json(CONFIG_PATH)
    # ç¡®ä¿æœ‰ç§’çº§åˆ·æ–°é»˜è®¤å€¼ï¼ˆä¸åšè¿ç§»é€»è¾‘ï¼‰
    perf = data.get('performance') if isinstance(data, dict) else None
    if not isinstance(perf, dict):
        data['performance'] = {'calendar_refresh_interval_seconds': DEFAULT_REFRESH_SECONDS, 'aired_refresh_time': '00:00'}
    else:
        if 'calendar_refresh_interval_seconds' not in perf:
            data['performance']['calendar_refresh_interval_seconds'] = DEFAULT_REFRESH_SECONDS
        if 'aired_refresh_time' not in perf:
            data['performance']['aired_refresh_time'] = '00:00'
    
    # ç¡®ä¿æµ·æŠ¥è¯­è¨€æœ‰é»˜è®¤å€¼
    if 'poster_language' not in data:
        data['poster_language'] = 'zh-CN'

    # åˆå§‹åŒ–è¿½å‰§æ—¥å†æ—¶åŒºæ¨¡å¼ï¼ˆåŸå§‹æ—¶åŒº / æœ¬åœ°æ—¶åŒºï¼‰
    if 'calendar_timezone_mode' not in data:
        data['calendar_timezone_mode'] = 'original'
    # åˆå§‹åŒ–æœ¬åœ°æ—¶åŒºï¼ˆç”¨äº Trakt æ’­å‡ºæ—¶é—´è½¬æ¢ä¸æœ¬åœ°æ—¶é—´åˆ¤æ–­ï¼‰
    if 'local_timezone' not in data:
        # é»˜è®¤æŒ‰ç…§åŒ—äº¬æ—¶é—´å¤„ç†ï¼Œä¹Ÿæ”¯æŒç”¨æˆ·åç»­åœ¨é…ç½®æ–‡ä»¶ä¸­æ‰‹åŠ¨ä¿®æ”¹
        data['local_timezone'] = 'Asia/Shanghai'

    # åˆå§‹åŒ– Trakt é…ç½®
    if 'trakt' not in data or not isinstance(data.get('trakt'), dict):
        data['trakt'] = {'client_id': ''}
    else:
        data['trakt'].setdefault('client_id', '')

    # å¤„ç†æ’ä»¶é…ç½®ä¸­çš„å¤šè´¦å·æ”¯æŒå­—æ®µï¼Œå°†æ•°ç»„æ ¼å¼è½¬æ¢ä¸ºé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²ç”¨äºæ˜¾ç¤º
    if "plugins" in data:
        # å¤„ç†Plexçš„quark_root_path
        if "plex" in data["plugins"] and "quark_root_path" in data["plugins"]["plex"]:
            data["plugins"]["plex"]["quark_root_path"] = format_array_config_for_display(
                data["plugins"]["plex"]["quark_root_path"]
            )

        # å¤„ç†AListçš„storage_id
        if "alist" in data["plugins"] and "storage_id" in data["plugins"]["alist"]:
            data["plugins"]["alist"]["storage_id"] = format_array_config_for_display(
                data["plugins"]["alist"]["storage_id"]
            )

    # åˆå§‹åŒ–æ’ä»¶é…ç½®æ¨¡å¼ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if "plugin_config_mode" not in data:
        data["plugin_config_mode"] = {
            "aria2": "independent",
            "alist_strm_gen": "independent",
            "emby": "independent"
        }
    
    # åˆå§‹åŒ–å…¨å±€æ’ä»¶é…ç½®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if "global_plugin_config" not in data:
        data["global_plugin_config"] = {
            "aria2": {
                "auto_download": True,
                "pause": False,
                "auto_delete_quark_files": False
            },
            "alist_strm_gen": {
                "auto_gen": True
            },
            "emby": {
                "try_match": True,
                "media_id": ""
            }
        }

    # åˆå§‹åŒ–æ¨é€é€šçŸ¥ç±»å‹é…ç½®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if "push_notify_type" not in data:
        data["push_notify_type"] = "full"

    # åˆå§‹åŒ–TMDBé…ç½®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if "tmdb_api_key" not in data:
        data["tmdb_api_key"] = ""

    # åˆå§‹åŒ–æœç´¢æ¥æºé»˜è®¤ç»“æ„
    if "source" not in data or not isinstance(data.get("source"), dict):
        data["source"] = {}
    # CloudSaver é»˜è®¤å­—æ®µ
    data["source"].setdefault("cloudsaver", {"server": "", "username": "", "password": "", "token": ""})
    # PanSou é»˜è®¤å­—æ®µ
    data["source"].setdefault("pansou", {"server": "https://so.252035.xyz"})

    # å‘é€webuiä¿¡æ¯ï¼Œä½†ä¸å‘é€å¯†ç åŸæ–‡
    data["webui"] = {
        "username": config_data["webui"]["username"],
        "password": config_data["webui"]["password"]
    }
    data["api_token"] = get_login_token()
    data["task_plugins_config_default"] = task_plugins_config_default
    return jsonify({"success": True, "data": data})


def sync_task_plugins_config():
    """åŒæ­¥æ›´æ–°æ‰€æœ‰ä»»åŠ¡çš„æ’ä»¶é…ç½®
    
    1. æ£€æŸ¥æ¯ä¸ªä»»åŠ¡çš„æ’ä»¶é…ç½®
    2. å¦‚æœæ’ä»¶é…ç½®ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
    3. å¦‚æœæ’ä»¶é…ç½®å­˜åœ¨ä½†ç¼ºå°‘æ–°çš„é…ç½®é¡¹ï¼Œæ·»åŠ é»˜è®¤å€¼
    4. ä¿ç•™åŸæœ‰çš„è‡ªå®šä¹‰é…ç½®
    5. åªå¤„ç†å·²å¯ç”¨çš„æ’ä»¶ï¼ˆé€šè¿‡PLUGIN_FLAGSæ£€æŸ¥ï¼‰
    6. æ¸…ç†è¢«ç¦ç”¨æ’ä»¶çš„é…ç½®
    7. åº”ç”¨å…¨å±€æ’ä»¶é…ç½®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    """
    global config_data, task_plugins_config_default
    
    # å¦‚æœæ²¡æœ‰ä»»åŠ¡åˆ—è¡¨ï¼Œç›´æ¥è¿”å›
    if not config_data.get("tasklist"):
        return
        
    # è·å–ç¦ç”¨çš„æ’ä»¶åˆ—è¡¨
    disabled_plugins = set()
    if PLUGIN_FLAGS:
        disabled_plugins = {name.lstrip('-') for name in PLUGIN_FLAGS.split(',')}
    
    # è·å–æ’ä»¶é…ç½®æ¨¡å¼
    plugin_config_mode = config_data.get("plugin_config_mode", {})
    global_plugin_config = config_data.get("global_plugin_config", {})
        
    # éå†æ‰€æœ‰ä»»åŠ¡
    for task in config_data["tasklist"]:
        # ç¡®ä¿ä»»åŠ¡æœ‰additionå­—æ®µ
        if "addition" not in task:
            task["addition"] = {}
            
        # æ¸…ç†è¢«ç¦ç”¨æ’ä»¶çš„é…ç½®
        for plugin_name in list(task["addition"].keys()):
            if plugin_name in disabled_plugins:
                del task["addition"][plugin_name]
            
        # éå†æ‰€æœ‰æ’ä»¶çš„é»˜è®¤é…ç½®
        for plugin_name, default_config in task_plugins_config_default.items():
            # è·³è¿‡è¢«ç¦ç”¨çš„æ’ä»¶
            if plugin_name in disabled_plugins:
                continue
            
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨å…¨å±€é…ç½®æ¨¡å¼
            if plugin_name in plugin_config_mode and plugin_config_mode[plugin_name] == "global":
                # ä½¿ç”¨å…¨å±€é…ç½®
                if plugin_name in global_plugin_config:
                    task["addition"][plugin_name] = global_plugin_config[plugin_name].copy()
                else:
                    task["addition"][plugin_name] = default_config.copy()
            else:
                # ä½¿ç”¨ç‹¬ç«‹é…ç½®
                if plugin_name not in task["addition"]:
                    task["addition"][plugin_name] = default_config.copy()
                else:
                    # å¦‚æœä»»åŠ¡ä¸­æœ‰è¯¥æ’ä»¶çš„é…ç½®ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„é…ç½®é¡¹
                    current_config = task["addition"][plugin_name]
                    # ç¡®ä¿current_configæ˜¯å­—å…¸ç±»å‹
                    if not isinstance(current_config, dict):
                        # å¦‚æœä¸æ˜¯å­—å…¸ç±»å‹ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
                        task["addition"][plugin_name] = default_config.copy()
                        continue
                        
                    # éå†é»˜è®¤é…ç½®çš„æ¯ä¸ªé”®å€¼å¯¹
                    for key, default_value in default_config.items():
                        if key not in current_config:
                            current_config[key] = default_value


def parse_comma_separated_config(value):
    """è§£æé€—å·åˆ†éš”çš„é…ç½®å­—ç¬¦ä¸²ä¸ºæ•°ç»„"""
    if isinstance(value, str) and value.strip():
        # åˆ†å‰²å­—ç¬¦ä¸²ï¼Œå»é™¤ç©ºç™½å­—ç¬¦
        items = [item.strip() for item in value.split(',') if item.strip()]
        # å¦‚æœåªæœ‰ä¸€ä¸ªé¡¹ç›®ï¼Œè¿”å›å­—ç¬¦ä¸²ï¼ˆå‘åå…¼å®¹ï¼‰
        return items[0] if len(items) == 1 else items
    return value

def format_array_config_for_display(value):
    """å°†æ•°ç»„é…ç½®æ ¼å¼åŒ–ä¸ºé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²ç”¨äºæ˜¾ç¤º"""
    if isinstance(value, list):
        return ', '.join(value)
    return value

# æ›´æ–°æ•°æ®
@app.route("/update", methods=["POST"])
def update():
    global config_data
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    # ä¿å­˜å‰å…ˆè®°å½•æ—§ä»»åŠ¡åä¸å…¶ tmdb ç»‘å®šï¼Œç”¨äºè‡ªåŠ¨æ¸…ç†
    old_tasks = config_data.get("tasklist", [])
    old_task_map = {}
    for t in old_tasks:
        name = t.get("taskname") or t.get("task_name") or ""
        cal = (t.get("calendar_info") or {})
        match = (cal.get("match") or {})
        if name:
            old_task_map[name] = {
                "tmdb_id": match.get("tmdb_id") or cal.get("tmdb_id")
            }
    
    # è®°å½•æ—§çš„æµ·æŠ¥è¯­è¨€è®¾ç½®
    old_poster_language = config_data.get('poster_language', 'zh-CN')
    # è®°å½•æ—§çš„æ’­å‡ºé›†æ•°åˆ·æ–°æ—¶é—´è®¾ç½®
    old_perf = config_data.get('performance', {}) if isinstance(config_data, dict) else {}
    old_aired_refresh_time = old_perf.get('aired_refresh_time', '00:00')
    # è®°å½•æ—§çš„ Trakt Client IDï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦é¦–æ¬¡é…ç½®
    old_trakt_client_id = ''
    try:
        old_trakt_client_id = (config_data.get("trakt", {}) or {}).get("client_id", "") or ""
        old_trakt_client_id = str(old_trakt_client_id).strip()
    except Exception:
        old_trakt_client_id = ''
    dont_save_keys = ["task_plugins_config_default", "api_token"]
    for key, value in request.json.items():
        if key not in dont_save_keys:
            if key == "webui":
                # æ›´æ–°webuiå‡­æ®
                config_data["webui"]["username"] = value.get("username", config_data["webui"]["username"])
                config_data["webui"]["password"] = value.get("password", config_data["webui"]["password"])
            elif key == "plugins":
                # å¤„ç†æ’ä»¶é…ç½®ä¸­çš„å¤šè´¦å·æ”¯æŒå­—æ®µ
                if "plex" in value and "quark_root_path" in value["plex"]:
                    value["plex"]["quark_root_path"] = parse_comma_separated_config(
                        value["plex"]["quark_root_path"]
                    )

                if "alist" in value and "storage_id" in value["alist"]:
                    value["alist"]["storage_id"] = parse_comma_separated_config(
                        value["alist"]["storage_id"]
                    )

                config_data.update({key: value})
            elif key == "tmdb_api_key":
                # æ›´æ–°TMDB APIå¯†é’¥
                config_data[key] = value
            elif key == "trakt":
                # æ›´æ–° Trakt é…ç½®ï¼Œä»…æ¥æ”¶ client_id å­—æ®µï¼Œå…¶å®ƒå­—æ®µå¿½ç•¥
                if not isinstance(value, dict):
                    value = {}
                trakt_cfg = config_data.get("trakt") if isinstance(config_data.get("trakt"), dict) else {}
                trakt_cfg["client_id"] = (value.get("client_id") or "").strip()
                config_data["trakt"] = trakt_cfg
            else:
                config_data.update({key: value})
    
    # åŒæ­¥æ›´æ–°ä»»åŠ¡çš„æ’ä»¶é…ç½®
    sync_task_plugins_config()
    
    # è®°å½•æ–°çš„ Trakt Client ID
    try:
        new_trakt_client_id = (config_data.get("trakt", {}) or {}).get("client_id", "") or ""
        new_trakt_client_id = str(new_trakt_client_id).strip()
    except Exception:
        new_trakt_client_id = ''
    
    # ä¿å­˜é…ç½®çš„æ‰§è¡Œæ­¥éª¤ï¼Œå¼‚æ­¥æ‰§è¡Œ
    try:
        prev_tmdb = (config_data.get('tmdb_api_key') or '').strip()
        new_tmdb = None
        for key, value in request.json.items():
            if key == 'tmdb_api_key':
                new_tmdb = (value or '').strip()
                break
    except Exception:
        prev_tmdb, new_tmdb = '', None

    import threading
    def _post_update_tasks(old_task_map_snapshot, prev_tmdb_value, new_tmdb_value, old_poster_lang, old_aired_refresh_time_value, prev_trakt_client_id_value, new_trakt_client_id_value):
        # æ£€æŸ¥æµ·æŠ¥è¯­è¨€è®¾ç½®æ˜¯å¦æ”¹å˜
        new_poster_language = config_data.get('poster_language', 'zh-CN')
        if old_poster_lang != new_poster_language:
            try:
                # æ¸…ç©ºç°æœ‰æµ·æŠ¥
                clear_all_posters()
                # é‡æ–°ä¸‹è½½æ‰€æœ‰æµ·æŠ¥
                redownload_all_posters()
            except Exception as e:
                logging.error(f"é‡æ–°ä¸‹è½½æµ·æŠ¥å¤±è´¥: {e}")
        
        # æ£€æŸ¥æ’­å‡ºé›†æ•°åˆ·æ–°æ—¶é—´æ˜¯å¦æ”¹å˜
        new_perf = config_data.get('performance', {}) if isinstance(config_data, dict) else {}
        new_aired_refresh_time = new_perf.get('aired_refresh_time', '00:00')
        if old_aired_refresh_time_value != new_aired_refresh_time:
            try:
                # ç«‹å³é‡æ–°è®¡ç®—æ‰€æœ‰å·²æ’­å‡ºé›†æ•°ï¼Œä½¿ç”¨æ–°çš„åˆ·æ–°æ—¶é—´è®¾ç½®
                recompute_all_seasons_aired_daily()
                # é€šçŸ¥å‰ç«¯æ—¥å†æ•°æ®å·²æ›´æ–°
                notify_calendar_changed('aired_refresh_time_changed')
                logging.info(f"æ’­å‡ºé›†æ•°åˆ·æ–°æ—¶é—´å·²æ›´æ”¹ ({old_aired_refresh_time_value} -> {new_aired_refresh_time})ï¼Œå·²é‡æ–°è®¡ç®—å·²æ’­å‡ºé›†æ•°")
            except Exception as e:
                logging.warning(f"é‡æ–°è®¡ç®—å·²æ’­å‡ºé›†æ•°å¤±è´¥: {e}")
        
        # åœ¨ä¿å­˜é…ç½®æ—¶è‡ªåŠ¨è¿›è¡Œä»»åŠ¡ä¿¡æ¯æå–ä¸TMDBåŒ¹é…ï¼ˆè‹¥ç¼ºå¤±åˆ™è¡¥é½ï¼‰
        try:
            changed = ensure_calendar_info_for_tasks()
        except Exception as e:
            logging.warning(f"ensure_calendar_info_for_tasks å‘ç”Ÿå¼‚å¸¸: {e}")

        # åœ¨æ¸…ç†é€»è¾‘ä¹‹å‰ï¼Œå…ˆåŒæ­¥æ•°æ®åº“ç»‘å®šå…³ç³»åˆ°ä»»åŠ¡é…ç½®
        try:
            sync_task_config_with_database_bindings()
        except Exception as e:
            logging.warning(f"åŒæ­¥ä»»åŠ¡é…ç½®å¤±è´¥: {e}")
        
        # åŒæ­¥å†…å®¹ç±»å‹æ•°æ®
        try:
            sync_content_type_between_config_and_database()
        except Exception as e:
            logging.warning(f"åŒæ­¥å†…å®¹ç±»å‹å¤±è´¥: {e}")

        # åŸºäºä»»åŠ¡å˜æ›´è¿›è¡Œè‡ªåŠ¨æ¸…ç†ï¼šåˆ é™¤çš„ä»»åŠ¡ã€æˆ– tmdb ç»‘å®šå˜æ›´çš„æ—§ç»‘å®š
        try:
            current_tasks = config_data.get('tasklist', [])
            current_map = {}
            for t in current_tasks:
                name = t.get('taskname') or t.get('task_name') or ''
                cal = (t.get('calendar_info') or {})
                match = (cal.get('match') or {})
                if name:
                    current_map[name] = {
                        'tmdb_id': match.get('tmdb_id') or cal.get('tmdb_id')
                    }
            # è¢«åˆ é™¤çš„ä»»åŠ¡
            for name, info in (old_task_map_snapshot or {}).items():
                if name not in current_map:
                    tid = info.get('tmdb_id')
                    if tid:
                        purge_calendar_by_tmdb_id_internal(int(tid))
            # ç»‘å®šå˜æ›´ï¼šæ—§ä¸æ–° tmdb_id ä¸åŒï¼Œæ¸…ç†æ—§çš„
            for name, info in (old_task_map_snapshot or {}).items():
                if name in current_map:
                    old_tid = info.get('tmdb_id')
                    new_tid = current_map[name].get('tmdb_id')
                    if old_tid and old_tid != new_tid:
                        purge_calendar_by_tmdb_id_internal(int(old_tid))
        except Exception as e:
            logging.warning(f"è‡ªåŠ¨æ¸…ç†æœ¬åœ°æ—¥å†ç¼“å­˜å¤±è´¥: {e}")

        # åŸºäºæœ€æ–°ä»»åŠ¡æ˜ å°„æ¸…ç†å­¤å„¿ metrics/seasonsï¼ˆé¿å…æ®‹ç•™ï¼‰
        try:
            tasks = config_data.get('tasklist', [])
            valid_names = []
            valid_pairs = []
            for t in tasks:
                name = t.get('taskname') or t.get('task_name') or ''
                cal = (t.get('calendar_info') or {})
                match = (cal.get('match') or {})
                tid = match.get('tmdb_id') or cal.get('tmdb_id')
                sn = match.get('latest_season_number') or cal.get('latest_season_number')
                if name:
                    valid_names.append(name)
                if tid and sn:
                    try:
                        valid_pairs.append((int(tid), int(sn)))
                    except Exception:
                        pass
            try:
                from app.sdk.db import CalendarDB as _CalDB
                _CalDB().cleanup_orphan_data(valid_pairs, valid_names)
                # æ¸…ç†å­¤ç«‹æ•°æ®åï¼Œä¹Ÿæ¸…ç†å¯èƒ½æ®‹ç•™çš„å­¤ç«‹æµ·æŠ¥æ–‡ä»¶
                try:
                    cleanup_orphaned_posters()
                except Exception:
                    pass
            except Exception:
                pass
        except Exception as e:
            logging.warning(f"è‡ªåŠ¨æ¸…ç†å­¤å„¿å­£ä¸æŒ‡æ ‡å¤±è´¥: {e}")


        # æ¸…é™¤æ‰€æœ‰è¿½å‰§æ—¥å†ç¼“å­˜ï¼Œç¡®ä¿ä¸‹æ¬¡è¯·æ±‚è·å–æœ€æ–°æ•°æ®
        try:
            clear_all_calendar_cache()
        except Exception as e:
            logging.debug(f"æ¸…é™¤ç¼“å­˜å¤±è´¥ï¼ˆä¸å½±å“åŠŸèƒ½ï¼‰: {e}")

        # æ ¹æ®æœ€æ–°æ€§èƒ½é…ç½®é‡å¯è‡ªåŠ¨åˆ·æ–°ä»»åŠ¡
        try:
            restart_calendar_refresh_job()
        except Exception as e:
            logging.warning(f"é‡å¯è¿½å‰§æ—¥å†è‡ªåŠ¨åˆ·æ–°ä»»åŠ¡å¤±è´¥: {e}")
        
        # æ ¹æ®æœ€æ–°æ€§èƒ½é…ç½®é‡å¯å·²æ’­å‡ºé›†æ•°æ›´æ–°ä»»åŠ¡
        try:
            restart_daily_aired_update_job()
        except Exception as e:
            logging.warning(f"é‡å¯å·²æ’­å‡ºé›†æ•°æ›´æ–°ä»»åŠ¡å¤±è´¥: {e}")

        # è‹¥é¦–æ¬¡é…ç½® Trakt Client IDï¼Œåˆ™ä¸ºæ‰€æœ‰èŠ‚ç›®è¡¥é½æ’­å‡ºæ—¶é—´
        try:
            if (not prev_trakt_client_id_value) and new_trakt_client_id_value:
                logging.info("é¦–æ¬¡é…ç½® Trakt Client IDï¼Œå¼€å§‹å…¨é‡åŒæ­¥èŠ‚ç›®æ’­å‡ºæ—¶é—´")
                sync_trakt_airtime_for_all_shows()
        except Exception as e:
            logging.warning(f"é¦–æ¬¡é…ç½® Trakt æ’­å‡ºæ—¶é—´åŒæ­¥å¤±è´¥: {e}")

        # å¦‚æœ TMDB API ä»æ— åˆ°æœ‰ï¼Œè‡ªåŠ¨æ‰§è¡Œä¸€æ¬¡ bootstrap
        try:
            if (prev_tmdb_value == '' or prev_tmdb_value is None) and new_tmdb_value and new_tmdb_value != '':
                success, msg = do_calendar_bootstrap()
                logging.info(f"é¦–æ¬¡é…ç½® TMDB APIï¼Œè‡ªåŠ¨åˆå§‹åŒ–: {success}, {msg}")
            else:
                # è‹¥æ­¤æ¬¡æ›´æ–°äº§ç”Ÿäº†æ–°çš„åŒ¹é…ç»‘å®šï¼Œä¹Ÿæ‰§è¡Œä¸€æ¬¡è½»é‡åˆå§‹åŒ–ï¼Œç¡®ä¿å‰ç«¯èƒ½ç«‹åˆ»è¯»åˆ°æœ¬åœ°æ•°æ®
                try:
                    if 'changed' in locals() and changed:
                        # åªå¤„ç†æ–°å¢çš„ä»»åŠ¡ï¼Œä¸å¤„ç†æ‰€æœ‰ä»»åŠ¡
                        process_new_tasks_async()
                except Exception as _e:
                    logging.warning(f"é…ç½®æ›´æ–°è§¦å‘æ—¥å†åˆå§‹åŒ–å¤±è´¥: {_e}")
        except Exception as e:
            logging.warning(f"è‡ªåŠ¨åˆå§‹åŒ– bootstrap å¤±è´¥: {e}")

    threading.Thread(target=_post_update_tasks, args=(old_task_map, prev_tmdb, new_tmdb, old_poster_language, old_aired_refresh_time, old_trakt_client_id, new_trakt_client_id), daemon=True).start()
    
    # ç¡®ä¿æ€§èƒ½é…ç½®åŒ…å«ç§’çº§å­—æ®µ
    if not isinstance(config_data.get('performance'), dict):
        config_data['performance'] = {'calendar_refresh_interval_seconds': DEFAULT_REFRESH_SECONDS, 'aired_refresh_time': '00:00'}
    else:
        config_data['performance'].setdefault('calendar_refresh_interval_seconds', DEFAULT_REFRESH_SECONDS)
        config_data['performance'].setdefault('aired_refresh_time', '00:00')
    Config.write_json(CONFIG_PATH, config_data)
    # æ›´æ–°session tokenï¼Œç¡®ä¿å½“å‰ä¼šè¯åœ¨ç”¨æˆ·åå¯†ç æ›´æ”¹åä»ç„¶æœ‰æ•ˆ
    session["token"] = get_login_token()
    # é‡æ–°åŠ è½½ä»»åŠ¡
    if reload_tasks():
        # é€šçŸ¥å‰ç«¯ä»»åŠ¡æ•°æ®å·²æ›´æ–°ï¼Œè§¦å‘å†…å®¹ç®¡ç†é¡µé¢çƒ­æ›´æ–°
        try:
            notify_calendar_changed('task_updated')
        except Exception:
            pass
        
        # ç«‹å³å¯åŠ¨æ–°ä»»åŠ¡çš„å¼‚æ­¥å¤„ç†ï¼Œä¸ç­‰å¾…
        threading.Thread(target=process_new_tasks_async, daemon=True).start()
        
        logging.info(f">>> é…ç½®æ›´æ–°æˆåŠŸ")
        return jsonify({"success": True, "message": "é…ç½®æ›´æ–°æˆåŠŸ"})
    else:
        logging.info(f">>> é…ç½®æ›´æ–°å¤±è´¥")
        return jsonify({"success": False, "message": "é…ç½®æ›´æ–°å¤±è´¥"})


# å¤„ç†è¿è¡Œè„šæœ¬è¯·æ±‚
@app.route("/run_script_now", methods=["POST"])
def run_script_now():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    tasklist = request.json.get("tasklist", [])
    command = [PYTHON_PATH, "-u", SCRIPT_PATH, CONFIG_PATH]
    logging.info(
        f">>> å¼€å§‹æ‰§è¡Œæ‰‹åŠ¨è¿è¡Œä»»åŠ¡ [{tasklist[0].get('taskname') if len(tasklist)>0 else 'ALL'}]"
    )

    def generate_output():
        # å…¨å±€å˜é‡ï¼šè·Ÿè¸ªä¸Šä¸€æ¬¡è¾“å‡ºæ˜¯å¦æ˜¯ç©ºè¡Œ
        last_was_empty = False
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        process_env = os.environ.copy()
        process_env["PYTHONIOENCODING"] = "utf-8"
        if tasklist:
            process_env["TASKLIST"] = json.dumps(tasklist, ensure_ascii=False)
            # æ·»åŠ åŸå§‹ä»»åŠ¡ç´¢å¼•çš„ç¯å¢ƒå˜é‡
            if len(tasklist) == 1:
                # å•ä»»åŠ¡æ‰‹åŠ¨è¿è¡Œï¼šå‰ç«¯ä¼ å…¥ original_indexï¼Œç”¨äºæ—¥å¿—å±•ç¤º
                if 'original_index' in request.json:
                    process_env["ORIGINAL_TASK_INDEX"] = str(request.json['original_index'])
                # å•ä»»åŠ¡æ‰‹åŠ¨è¿è¡Œåº”å¿½ç•¥æ‰§è¡Œå‘¨æœŸå’Œä»»åŠ¡è¿›åº¦é™åˆ¶ï¼ˆåŒ…æ‹¬è‡ªåŠ¨æ¨¡å¼ä¸‹è¿›åº¦100%ä¹Ÿè¦æ‰§è¡Œï¼‰
                process_env["IGNORE_EXECUTION_RULES"] = "1"
        process = subprocess.Popen(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            encoding="utf-8",
            errors="replace",
            bufsize=1,
            env=process_env,
        )
        try:
            for line in iter(process.stdout.readline, ""):
                stripped_line = line.strip()
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç©ºè¡Œ
                is_empty = not stripped_line
                
                # å¦‚æœæ˜¯ç©ºè¡Œä¸”ä¸Šä¸€æ¬¡ä¹Ÿæ˜¯ç©ºè¡Œï¼Œè·³è¿‡æœ¬æ¬¡è¾“å‡º
                if is_empty and last_was_empty:
                    continue
                
                # è¾“å‡ºæ—¥å¿—ï¼ˆç©ºè¡Œä¹Ÿè¾“å‡ºï¼Œä½†é¿å…è¿ç»­ç©ºè¡Œï¼‰
                if is_empty:
                    logging.info("")
                    last_was_empty = True
                else:
                    logging.info(stripped_line)
                    last_was_empty = False
                
                yield f"data: {line}\n\n"
            yield "data: [DONE]\n\n"
        finally:
            process.stdout.close()
            process.wait()
            # ç»“æŸé€šçŸ¥ï¼šä»…åœ¨æ­£å¸¸é€€å‡ºæ—¶è®°å½•æˆåŠŸæ—¥å¿—ï¼Œéé›¶é€€å‡ºç è®°å½•è­¦å‘Š
            try:
                task_name = tasklist[0].get('taskname') if len(tasklist) > 0 else 'ALL'
            except Exception:
                task_name = 'ALL'
            if process.returncode == 0:
                logging.info(f">>> æ‰‹åŠ¨è¿è¡Œä»»åŠ¡ [{task_name}] æ‰§è¡ŒæˆåŠŸ")
                # æ‰‹åŠ¨è¿è¡Œä»»åŠ¡å®Œæˆåï¼Œæ¸…é™¤ç¼“å­˜ä»¥ç¡®ä¿å‰ç«¯èƒ½è·å–åˆ°æœ€æ–°çš„å·²è½¬å­˜æ•°
                try:
                    notify_calendar_changed('manual_task_completed')
                except Exception:
                    pass
            else:
                logging.warning(f">>> æ‰‹åŠ¨è¿è¡Œä»»åŠ¡ [{task_name}] æ‰§è¡Œå®Œæˆä½†è¿”å›éé›¶é€€å‡ºç : {process.returncode}")

    return Response(
        stream_with_context(generate_output()),
        content_type="text/event-stream;charset=utf-8",
    )


@app.route("/api/runtime_logs")
def api_runtime_logs():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"}), 401
    # ä¼˜å…ˆä½¿ç”¨ days å‚æ•°ï¼ˆæŒ‰æ—¶é—´èŒƒå›´ï¼‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ limit å‚æ•°ï¼ˆæŒ‰æ¡æ•°ï¼Œä¿æŒå‘åå…¼å®¹ï¼‰
    days = request.args.get("days")
    limit = request.args.get("limit")
    
    if days is not None:
        try:
            days_float = float(days)
            logs = get_recent_runtime_logs(days=days_float)
        except (ValueError, TypeError):
            # å¦‚æœ days å‚æ•°æ— æ•ˆï¼Œå›é€€åˆ° limit å‚æ•°
            limit = limit or 600
            logs = get_recent_runtime_logs(limit=limit)
    else:
        # å¦‚æœæ²¡æœ‰ days å‚æ•°ï¼Œä½¿ç”¨ limit å‚æ•°ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
        limit = limit or 600
        logs = get_recent_runtime_logs(limit=limit)
    
    return jsonify({"success": True, "logs": logs})


# -------------------- è¿½å‰§æ—¥å†ï¼šä»»åŠ¡æå–ä¸åŒ¹é…è¾…åŠ© --------------------
def purge_calendar_by_tmdb_id_internal(tmdb_id: int, force: bool = False) -> bool:
    """å†…éƒ¨å·¥å…·ï¼šæŒ‰ tmdb_id æ¸…ç† shows/seasons/episodesï¼Œå¹¶å°è¯•åˆ é™¤æœ¬åœ°æµ·æŠ¥æ–‡ä»¶
    :param force: True æ—¶æ— è§†æ˜¯å¦ä»è¢«å…¶ä»–ä»»åŠ¡å¼•ç”¨ï¼Œå¼ºåˆ¶åˆ é™¤
    """
    try:
        # è‹¥ä»æœ‰å…¶ä»–ä»»åŠ¡å¼•ç”¨åŒä¸€ tmdb_idï¼Œåˆ™ï¼ˆé»˜è®¤ï¼‰è·³è¿‡åˆ é™¤ä»¥é¿å…è¯¯åˆ å…±äº«èµ„æºï¼›å¸¦ force åˆ™ç»§ç»­
        if not force:
            try:
                tasks = config_data.get('tasklist', [])
                for t in tasks:
                    cal = (t.get('calendar_info') or {})
                    match = (cal.get('match') or {})
                    bound = match.get('tmdb_id') or cal.get('tmdb_id')
                    if bound and int(bound) == int(tmdb_id):
                        # è·å–æµ·æŠ¥æ–‡ä»¶åç”¨äºæ—¥å¿—æç¤º
                        try:
                            db = CalendarDB()
                            show = db.get_show(int(tmdb_id))
                            poster_path = show.get('poster_local_path', '') if show else ''
                            if poster_path and poster_path.startswith('/cache/images/'):
                                poster_filename = poster_path.replace('/cache/images/', '')
                            else:
                                poster_filename = f"poster_{tmdb_id}"
                        except Exception:
                            poster_filename = f"poster_{tmdb_id}"
                        logging.debug(f"è·³è¿‡æ¸…ç†æµ·æŠ¥æ–‡ä»¶ {poster_filename}ï¼ˆä»è¢«å…¶ä»–ä»»åŠ¡å¼•ç”¨ï¼‰")
                        return True
            except Exception:
                pass
        db = CalendarDB()
        # åˆ é™¤æ•°æ®åº“å‰ï¼Œå°è¯•åˆ é™¤æœ¬åœ°æµ·æŠ¥æ–‡ä»¶
        try:
            show = db.get_show(int(tmdb_id))
            poster_rel = (show or {}).get('poster_local_path') or ''
            if poster_rel and poster_rel.startswith('/cache/images/'):
                fname = poster_rel.replace('/cache/images/', '')
                fpath = os.path.join(CACHE_IMAGES_DIR, fname)
                if os.path.exists(fpath):
                    os.remove(fpath)
        except Exception as e:
            logging.warning(f"åˆ é™¤æµ·æŠ¥æ–‡ä»¶å¤±è´¥: {e}")
        db.delete_show(int(tmdb_id))
        return True
    except Exception as e:
        logging.warning(f"å†…éƒ¨æ¸…ç†å¤±è´¥ tmdb_id={tmdb_id}: {e}")
        return False


def purge_orphan_calendar_shows_internal() -> int:
    """åˆ é™¤æœªè¢«ä»»ä½•ä»»åŠ¡å¼•ç”¨çš„ showsï¼ˆè¿å¸¦ seasons/episodes ä¸æµ·æŠ¥ï¼‰ï¼Œè¿”å›æ¸…ç†æ•°é‡"""
    try:
        tasks = config_data.get('tasklist', [])
        referenced = set()
        for t in tasks:
            cal = (t.get('calendar_info') or {})
            match = (cal.get('match') or {})
            tid = match.get('tmdb_id') or cal.get('tmdb_id')
            if tid:
                try: referenced.add(int(tid))
                except Exception: pass
        db = CalendarDB()
        cur = db.conn.cursor()
        try:
            cur.execute('SELECT tmdb_id FROM shows')
            ids = [int(r[0]) for r in cur.fetchall()]
        except Exception:
            ids = []
        removed = 0
        for tid in ids:
            if tid not in referenced:
                if purge_calendar_by_tmdb_id_internal(int(tid), force=True):
                    removed += 1
        return removed
    except Exception:
        return 0
def sync_content_type_between_config_and_database() -> bool:
    """åŒæ­¥ä»»åŠ¡é…ç½®å’Œæ•°æ®åº“ä¹‹é—´çš„å†…å®¹ç±»å‹æ•°æ®ã€‚
    ç¡®ä¿ä¸¤ä¸ªæ•°æ®æºçš„ content_type ä¿æŒä¸€è‡´ã€‚
    """
    try:
        from app.sdk.db import CalendarDB
        cal_db = CalendarDB()
        
        tasks = config_data.get('tasklist', [])
        changed = False
        local_air_time_changed = False
        synced_count = 0
        
        for task in tasks:
            task_name = task.get('taskname') or task.get('task_name') or ''
            if not task_name:
                continue
                
            # è·å–ä»»åŠ¡é…ç½®ä¸­çš„å†…å®¹ç±»å‹
            cal = task.get('calendar_info') or {}
            extracted = cal.get('extracted') or {}
            config_content_type = extracted.get('content_type', '')
            
            # é€šè¿‡ä»»åŠ¡åç§°æŸ¥æ‰¾ç»‘å®šçš„èŠ‚ç›®
            bound_show = cal_db.get_show_by_task_name(task_name)
            
            if bound_show:
                # ä»»åŠ¡å·²ç»‘å®šåˆ°æ•°æ®åº“ä¸­çš„èŠ‚ç›®
                tmdb_id = bound_show['tmdb_id']
                db_content_type = bound_show.get('content_type', '')
                
                # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰å†…å®¹ç±»å‹ï¼Œä½†ä»»åŠ¡é…ç½®ä¸­æœ‰ï¼Œåˆ™åŒæ­¥åˆ°æ•°æ®åº“
                if not db_content_type and config_content_type:
                    cal_db.update_show_content_type(tmdb_id, config_content_type)
                    changed = True
                    synced_count += 1
                    logging.debug(f"åŒæ­¥å†…å®¹ç±»å‹åˆ°æ•°æ®åº“ - ä»»åŠ¡: '{task_name}', ç±»å‹: '{config_content_type}', tmdb_id: {tmdb_id}")
                
                # è‹¥ä¸¤è¾¹ä¸ä¸€è‡´ï¼šä»¥ä»»åŠ¡é…ç½®ä¼˜å…ˆï¼ŒåŒæ­¥åˆ°æ•°æ®åº“
                elif db_content_type and config_content_type and db_content_type != config_content_type:
                    cal_db.update_show_content_type(tmdb_id, config_content_type)
                    changed = True
                    synced_count += 1
                    logging.debug(f"è¦†ç›–æ•°æ®åº“å†…å®¹ç±»å‹ä¸ºä»»åŠ¡é…ç½®å€¼ - ä»»åŠ¡: '{task_name}', é…ç½®: '{config_content_type}', åŸDB: '{db_content_type}', tmdb_id: {tmdb_id}")
                # å¦‚æœæ•°æ®åº“æœ‰ç±»å‹ä½†ä»»åŠ¡é…ç½®æ²¡æœ‰ï¼Œåˆ™å›å¡«åˆ°é…ç½®
                elif db_content_type and not config_content_type:
                    if 'calendar_info' not in task:
                        task['calendar_info'] = {}
                    if 'extracted' not in task['calendar_info']:
                        task['calendar_info']['extracted'] = {}
                    task['calendar_info']['extracted']['content_type'] = db_content_type
                    changed = True
                    synced_count += 1
                    logging.debug(f"åŒæ­¥å†…å®¹ç±»å‹åˆ°ä»»åŠ¡é…ç½® - ä»»åŠ¡: '{task_name}', ç±»å‹: '{db_content_type}', tmdb_id: {tmdb_id}")
            else:
                # ä»»åŠ¡æ²¡æœ‰ç»‘å®šåˆ°æ•°æ®åº“ä¸­çš„èŠ‚ç›®ï¼Œä½†ä»»åŠ¡é…ç½®ä¸­æœ‰å†…å®¹ç±»å‹
                # è¿™ç§æƒ…å†µéœ€è¦å…ˆé€šè¿‡ TMDB åŒ¹é…å»ºç«‹ç»‘å®šå…³ç³»ï¼Œç„¶ååŒæ­¥å†…å®¹ç±»å‹
                if config_content_type:
                    # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦æœ‰ TMDB åŒ¹é…ä¿¡æ¯
                    match = cal.get('match') or {}
                    tmdb_id = match.get('tmdb_id')
                    
                    if tmdb_id:
                        # ä»»åŠ¡æœ‰ TMDB åŒ¹é…ä¿¡æ¯ï¼Œæ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦æœ‰å¯¹åº”çš„èŠ‚ç›®
                        show = cal_db.get_show(tmdb_id)
                        if show:
                            # èŠ‚ç›®å­˜åœ¨ï¼Œå»ºç«‹ç»‘å®šå…³ç³»å¹¶è®¾ç½®å†…å®¹ç±»å‹
                            cal_db.bind_task_to_show(tmdb_id, task_name)
                            cal_db.update_show_content_type(tmdb_id, config_content_type)
                            changed = True
                            synced_count += 1
                            logging.debug(f"å»ºç«‹ç»‘å®šå…³ç³»å¹¶åŒæ­¥å†…å®¹ç±»å‹ - ä»»åŠ¡: '{task_name}', ç±»å‹: '{config_content_type}', tmdb_id: {tmdb_id}")
                        else:
                            logging.debug(f"ä»»åŠ¡é…ç½®ä¸­çš„ TMDB ID åœ¨æ•°æ®åº“ä¸­ä¸å­˜åœ¨ - ä»»åŠ¡: '{task_name}', tmdb_id: {tmdb_id}")
        
        if changed:
            logging.debug(f"å†…å®¹ç±»å‹åŒæ­¥å®Œæˆï¼Œå…±åŒæ­¥äº† {synced_count} ä¸ªä»»åŠ¡")
            Config.write_json(CONFIG_PATH, config_data)
            
        return changed
        
    except Exception as e:
        logging.debug(f"å†…å®¹ç±»å‹åŒæ­¥å¤±è´¥: {e}")
        return False

def sync_task_config_with_database_bindings() -> bool:
    """åŒå‘åŒæ­¥ä»»åŠ¡é…ç½®å’Œæ•°æ®åº“ä¹‹é—´çš„ TMDB åŒ¹é…ä¿¡æ¯ã€‚
    ç¡®ä¿ä¸¤ä¸ªæ•°æ®æºçš„ TMDB ç»‘å®šå…³ç³»ä¿æŒä¸€è‡´ã€‚
    """
    try:
        from app.sdk.db import CalendarDB
        cal_db = CalendarDB()
        
        tasks = config_data.get('tasklist', [])
        changed = False
        synced_count = 0
        
        for task in tasks:
            task_name = task.get('taskname') or task.get('task_name') or ''
            if not task_name:
                continue
                
            # è·å–ä»»åŠ¡é…ç½®ä¸­çš„ TMDB åŒ¹é…ä¿¡æ¯
            cal = task.get('calendar_info') or {}
            match = cal.get('match') or {}
            config_tmdb_id = match.get('tmdb_id')
            
            # é€šè¿‡ä»»åŠ¡åç§°æŸ¥æ‰¾æ•°æ®åº“ä¸­çš„ç»‘å®šå…³ç³»
            bound_show = cal_db.get_show_by_task_name(task_name)
            db_tmdb_id = bound_show['tmdb_id'] if bound_show else None
            
            # åŒå‘åŒæ­¥é€»è¾‘
            if config_tmdb_id and not db_tmdb_id:
                # ä»»åŠ¡é…ç½®ä¸­æœ‰ TMDB IDï¼Œä½†æ•°æ®åº“ä¸­æ²¡æœ‰ç»‘å®šå…³ç³» â†’ åŒæ­¥åˆ°æ•°æ®åº“
                # é¦–å…ˆæ£€æŸ¥è¯¥ TMDB ID å¯¹åº”çš„èŠ‚ç›®æ˜¯å¦å­˜åœ¨
                show = cal_db.get_show(config_tmdb_id)
                if show:
                    # èŠ‚ç›®å­˜åœ¨ï¼Œå»ºç«‹ç»‘å®šå…³ç³»
                    cal_db.bind_task_to_show(config_tmdb_id, task_name)
                    changed = True
                    synced_count += 1
                    logging.debug(f"åŒæ­¥ç»‘å®šå…³ç³»åˆ°æ•°æ®åº“ - ä»»åŠ¡: '{task_name}', tmdb_id: {config_tmdb_id}, èŠ‚ç›®: '{show.get('name', '')}'")
                else:
                    logging.debug(f"ä»»åŠ¡é…ç½®ä¸­çš„ TMDB ID åœ¨æ•°æ®åº“ä¸­ä¸å­˜åœ¨ - ä»»åŠ¡: '{task_name}', tmdb_id: {config_tmdb_id}")
                    
            elif db_tmdb_id and not config_tmdb_id:
                # æ•°æ®åº“ä¸­æœ‰ç»‘å®šå…³ç³»ï¼Œä½†ä»»åŠ¡é…ç½®ä¸­æ²¡æœ‰ TMDB ID â†’ åŒæ­¥åˆ°ä»»åŠ¡é…ç½®
                show = cal_db.get_show(db_tmdb_id)
                if show:
                    # ç¡®ä¿ calendar_info ç»“æ„å­˜åœ¨
                    if 'calendar_info' not in task:
                        task['calendar_info'] = {}
                    if 'match' not in task['calendar_info']:
                        task['calendar_info']['match'] = {}
                    
                    # åŒæ­¥æ•°æ®åº“ä¿¡æ¯åˆ°ä»»åŠ¡é…ç½®
                    latest_season_number = show.get('latest_season_number', 1)  # ä½¿ç”¨æ•°æ®åº“ä¸­çš„å®é™…å­£æ•°
                    task['calendar_info']['match'].update({
                        'tmdb_id': db_tmdb_id,
                        'matched_show_name': show.get('name', ''),
                        'matched_year': show.get('year', ''),
                        'latest_season_fetch_url': f"/tv/{db_tmdb_id}/season/{latest_season_number}",
                        'latest_season_number': latest_season_number
                    })
                    
                    changed = True
                    synced_count += 1
                    logging.debug(f"åŒæ­¥ TMDB åŒ¹é…ä¿¡æ¯åˆ°ä»»åŠ¡é…ç½® - ä»»åŠ¡: '{task_name}', tmdb_id: {db_tmdb_id}, èŠ‚ç›®: '{show.get('name', '')}'")
                    
            elif config_tmdb_id and db_tmdb_id and config_tmdb_id != db_tmdb_id:
                # ä¸¤ä¸ªæ•°æ®æºéƒ½æœ‰ TMDB IDï¼Œä½†ä¸ä¸€è‡´ â†’ ä»¥æ•°æ®åº“ä¸ºå‡†ï¼ˆå› ä¸ºæ•°æ®åº“æ˜¯æƒå¨æ•°æ®æºï¼‰
                show = cal_db.get_show(db_tmdb_id)
                if show:
                    # ç¡®ä¿ calendar_info ç»“æ„å­˜åœ¨
                    if 'calendar_info' not in task:
                        task['calendar_info'] = {}
                    if 'match' not in task['calendar_info']:
                        task['calendar_info']['match'] = {}
                    
                    # ä»¥æ•°æ®åº“ä¸ºå‡†ï¼Œæ›´æ–°ä»»åŠ¡é…ç½®
                    latest_season_number = show.get('latest_season_number', 1)  # ä½¿ç”¨æ•°æ®åº“ä¸­çš„å®é™…å­£æ•°
                    task['calendar_info']['match'].update({
                        'tmdb_id': db_tmdb_id,
                        'matched_show_name': show.get('name', ''),
                        'matched_year': show.get('year', ''),
                        'latest_season_fetch_url': f"/tv/{db_tmdb_id}/season/{latest_season_number}",
                        'latest_season_number': latest_season_number
                    })
                    
                    changed = True
                    synced_count += 1
                    logging.debug(f"ç»Ÿä¸€ TMDB åŒ¹é…ä¿¡æ¯ï¼ˆä»¥æ•°æ®åº“ä¸ºå‡†ï¼‰ - ä»»åŠ¡: '{task_name}', åŸé…ç½®: {config_tmdb_id}, æ•°æ®åº“: {db_tmdb_id}, èŠ‚ç›®: '{show.get('name', '')}'")
        
        if changed:
            logging.debug(f"TMDB åŒ¹é…ä¿¡æ¯åŒå‘åŒæ­¥å®Œæˆï¼Œå…±åŒæ­¥äº† {synced_count} ä¸ªä»»åŠ¡")
            Config.write_json(CONFIG_PATH, config_data)
            
        return changed
        
    except Exception as e:
        logging.debug(f"TMDB åŒ¹é…ä¿¡æ¯åŒæ­¥å¤±è´¥: {e}")
        return False

def ensure_calendar_info_for_tasks() -> bool:
    """ä¸ºæ‰€æœ‰ä»»åŠ¡ç¡®ä¿å­˜åœ¨ calendar_info.extracted ä¸ calendar_info.match ä¿¡æ¯ã€‚
    - extracted: ä»ä»»åŠ¡ä¿å­˜è·¯å¾„/åç§°æå–çš„å‰§åã€å¹´ä»½ã€ç±»å‹ï¼ˆåªåœ¨ç¼ºå¤±æ—¶æå–ï¼‰
    - match: ä½¿ç”¨ TMDB è¿›è¡ŒåŒ¹é…ï¼ˆåªåœ¨ç¼ºå¤±æ—¶åŒ¹é…ï¼‰
    """
    tasks = config_data.get('tasklist', [])
    if not tasks:
        return

    extractor = TaskExtractor()
    tmdb_api_key = config_data.get('tmdb_api_key', '')
    poster_language = get_poster_language_setting()
    tmdb_service = TMDBService(tmdb_api_key, poster_language) if tmdb_api_key else None

    changed = False
    # ç®€å•å»é‡ç¼“å­˜ï¼Œé¿å…åŒä¸€åç§°/å¹´ä»½é‡å¤è¯·æ±‚ TMDB
    search_cache = {}
    details_cache = {}
    for task in tasks:
        # è·³è¿‡æ ‡è®°ä¸ºæ— éœ€å‚ä¸æ—¥å†åŒ¹é…çš„ä»»åŠ¡
        if task.get('skip_calendar') is True:
            continue
        task_name = task.get('taskname') or task.get('task_name') or ''
        save_path = task.get('savepath', '')

        cal = task.get('calendar_info') or {}
        extracted = cal.get('extracted') or {}

        # æå– extractedï¼ˆä»…åœ¨ç¼ºå¤±æ—¶ï¼‰
        need_extract = not extracted or not extracted.get('show_name')
        if need_extract:
            info = extractor.extract_show_info_from_path(save_path)
            extracted = {
                'show_name': info.get('show_name', ''),
                'year': info.get('year', ''),
                'content_type': info.get('type', 'other'),
            }
            cal['extracted'] = extracted
            changed = True

        # åŒ¹é… TMDBï¼ˆä»…åœ¨ç¼ºå¤±æ—¶ï¼‰
        match = cal.get('match') or {}
        if tmdb_service and not match.get('tmdb_id') and extracted.get('show_name'):
            try:
                key = (extracted.get('show_name') or '', extracted.get('year') or '')
                if key in search_cache:
                    search = search_cache[key]
                else:
                    search = tmdb_service.search_tv_show(extracted.get('show_name'), extracted.get('year') or None)
                    search_cache[key] = search
                if search and search.get('id'):
                    tmdb_id = search['id']
                    if tmdb_id in details_cache:
                        details = details_cache[tmdb_id]
                    else:
                        details = tmdb_service.get_tv_show_details(tmdb_id) or {}
                        details_cache[tmdb_id] = details
                    seasons = details.get('seasons', [])
                    logging.debug(f"TMDBå­£æ•°æ•°æ®: {seasons}")
                    
                    # é€‰æ‹©å·²æ’­å‡ºçš„å­£ä¸­æœ€æ–°çš„ä¸€å­£
                    # ä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸåˆ¤æ–­å­£æ˜¯å¦å·²æ’­å‡ºï¼ˆç°åœ¨é›†çš„æ’­å‡ºæ—¥æœŸå·²ç»æ˜¯æœ¬åœ°æ—¥æœŸï¼Œä¸éœ€è¦é€šè¿‡æ’­å‡ºé›†æ•°åˆ·æ–°æ—¶é—´é™åˆ¶ï¼‰
                    from datetime import datetime as _dt
                    today_date = _dt.now().date()
                    latest_season_number = 0
                    latest_air_date = None
                    
                    for s in seasons:
                        sn = s.get('season_number', 0)
                        air_date = s.get('air_date')
                        logging.debug(f"å­£æ•°: {sn}, æ’­å‡ºæ—¥æœŸ: {air_date}, ç±»å‹: {type(sn)}")
                        
                        # åªè€ƒè™‘å·²æ’­å‡ºçš„å­£ï¼ˆæœ‰air_dateä¸”æ—©äºæˆ–ç­‰äºä»Šå¤©çš„æ—¥æœŸï¼‰
                        if sn and sn > 0 and air_date:  # æ’é™¤ç¬¬0å­£ï¼ˆç‰¹æ®Šå­£ï¼‰
                            try:
                                season_air_date = datetime.strptime(air_date, '%Y-%m-%d').date()
                                if season_air_date <= today_date:
                                    # é€‰æ‹©æ’­å‡ºæ—¥æœŸæœ€æ–°çš„å­£
                                    if latest_air_date is None or season_air_date > latest_air_date:
                                        latest_season_number = sn
                                        latest_air_date = season_air_date
                            except (ValueError, TypeError):
                                # æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè·³è¿‡
                                continue
                    
                    logging.debug(f"è®¡ç®—å‡ºçš„æœ€æ–°å·²æ’­å­£æ•°: {latest_season_number}")
                    
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å·²æ’­å‡ºçš„å­£ï¼Œå›é€€åˆ°ç¬¬1å­£
                    if latest_season_number == 0:
                        latest_season_number = 1
                        logging.debug(f"æ²¡æœ‰æ‰¾åˆ°å·²æ’­å‡ºçš„å­£ï¼Œå›é€€åˆ°ç¬¬1å­£: {latest_season_number}")

                    # ä½¿ç”¨æ–°çš„æ–¹æ³•è·å–ä¸­æ–‡æ ‡é¢˜ï¼Œæ”¯æŒä»åˆ«åä¸­è·å–ä¸­å›½åœ°åŒºçš„åˆ«å
                    chinese_title = tmdb_service.get_chinese_title_with_fallback(tmdb_id, extracted.get('show_name', ''))
                    
                    cal['match'] = {
                        'matched_show_name': chinese_title,
                        'matched_year': (details.get('first_air_date') or '')[:4],
                        'tmdb_id': tmdb_id,
                        'latest_season_number': latest_season_number,
                        'latest_season_fetch_url': f"/tv/{tmdb_id}/season/{latest_season_number}",
                    }
                    changed = True
            except Exception as e:
                logging.warning(f"TMDB åŒ¹é…å¤±è´¥: task={task_name}, err={e}")

        if cal and task.get('calendar_info') != cal:
            task['calendar_info'] = cal

    if changed:
        config_data['tasklist'] = tasks
    return changed


# åˆ·æ–°Plexåª’ä½“åº“
@app.route("/refresh_plex_library", methods=["POST"])
def refresh_plex_library():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    task_index = request.json.get("task_index")
    if task_index is None:
        return jsonify({"success": False, "message": "ç¼ºå°‘ä»»åŠ¡ç´¢å¼•"})
        
    # è·å–ä»»åŠ¡ä¿¡æ¯
    task = config_data["tasklist"][task_index]
    if not task.get("savepath"):
        return jsonify({"success": False, "message": "ä»»åŠ¡æ²¡æœ‰ä¿å­˜è·¯å¾„"})
        
    # å¯¼å…¥Plexæ’ä»¶
    from plugins.plex import Plex
    
    # åˆå§‹åŒ–Plexæ’ä»¶
    plex = Plex(**config_data["plugins"]["plex"])
    if not plex.is_active:
        return jsonify({"success": False, "message": "Plex æ’ä»¶æœªæ­£ç¡®é…ç½®"})
        
    # æ‰§è¡Œåˆ·æ–°
    plex.run(task)
    
    return jsonify({"success": True, "message": "æˆåŠŸåˆ·æ–° Plex åª’ä½“åº“"})


# åˆ·æ–°AListç›®å½•
@app.route("/refresh_alist_directory", methods=["POST"])
def refresh_alist_directory():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    task_index = request.json.get("task_index")
    if task_index is None:
        return jsonify({"success": False, "message": "ç¼ºå°‘ä»»åŠ¡ç´¢å¼•"})
        
    # è·å–ä»»åŠ¡ä¿¡æ¯
    task = config_data["tasklist"][task_index]
    if not task.get("savepath"):
        return jsonify({"success": False, "message": "ä»»åŠ¡æ²¡æœ‰ä¿å­˜è·¯å¾„"})
        
    # å¯¼å…¥AListæ’ä»¶
    from plugins.alist import Alist
    
    # åˆå§‹åŒ–AListæ’ä»¶
    alist = Alist(**config_data["plugins"]["alist"])
    if not alist.is_active:
        return jsonify({"success": False, "message": "AList æ’ä»¶æœªæ­£ç¡®é…ç½®"})
        
    # æ‰§è¡Œåˆ·æ–°
    alist.run(task)
    
    return jsonify({"success": True, "message": "æˆåŠŸåˆ·æ–° AList ç›®å½•"})


# æ–‡ä»¶æ•´ç†é¡µé¢åˆ·æ–°Plexåª’ä½“åº“
@app.route("/refresh_filemanager_plex_library", methods=["POST"])
def refresh_filemanager_plex_library():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    folder_path = request.json.get("folder_path")
    account_index = request.json.get("account_index", 0)

    if not folder_path:
        return jsonify({"success": False, "message": "ç¼ºå°‘æ–‡ä»¶å¤¹è·¯å¾„"})

    # æ£€æŸ¥Plexæ’ä»¶é…ç½®
    if not config_data.get("plugins", {}).get("plex", {}).get("url"):
        return jsonify({"success": False, "message": "Plex æ’ä»¶æœªé…ç½®"})

    # å¯¼å…¥Plexæ’ä»¶
    from plugins.plex import Plex

    # åˆå§‹åŒ–Plexæ’ä»¶
    plex = Plex(**config_data["plugins"]["plex"])
    if not plex.is_active:
        return jsonify({"success": False, "message": "Plex æ’ä»¶æœªæ­£ç¡®é…ç½®"})

    # è·å–å¤¸å…‹è´¦å·ä¿¡æ¯
    try:
        account = Quark(config_data["cookie"][account_index], account_index)

        # å°†æ–‡ä»¶å¤¹è·¯å¾„è½¬æ¢ä¸ºå®é™…çš„ä¿å­˜è·¯å¾„
        # folder_pathæ˜¯ç›¸å¯¹äºå¤¸å…‹ç½‘ç›˜æ ¹ç›®å½•çš„è·¯å¾„
        # quark_root_pathæ˜¯å¤¸å…‹ç½‘ç›˜åœ¨æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿä¸­çš„æŒ‚è½½ç‚¹
        # æ ¹æ®è´¦å·ç´¢å¼•è·å–å¯¹åº”çš„å¤¸å…‹æ ¹è·¯å¾„
        quark_root_path = plex.get_quark_root_path(account_index)
        if not quark_root_path:
            return jsonify({"success": False, "message": f"Plex æ’ä»¶æœªé…ç½®è´¦å· {account_index} çš„å¤¸å…‹æ ¹è·¯å¾„"})

        if folder_path == "" or folder_path == "/":
            # ç©ºå­—ç¬¦ä¸²æˆ–æ ¹ç›®å½•è¡¨ç¤ºå¤¸å…‹ç½‘ç›˜æ ¹ç›®å½•
            full_path = quark_root_path
        else:
            # ç¡®ä¿è·¯å¾„æ ¼å¼æ­£ç¡®
            if not folder_path.startswith("/"):
                folder_path = "/" + folder_path

            # æ‹¼æ¥å®Œæ•´è·¯å¾„ï¼šå¤¸å…‹æ ¹è·¯å¾„ + ç›¸å¯¹è·¯å¾„
            import os
            full_path = os.path.normpath(os.path.join(quark_root_path, folder_path.lstrip("/"))).replace("\\", "/")

        # ç¡®ä¿åº“ä¿¡æ¯å·²åŠ è½½
        if plex._libraries is None:
            plex._libraries = plex._get_libraries()

        # æ‰§è¡Œåˆ·æ–°
        success = plex.refresh(full_path)

        if success:
            return jsonify({"success": True, "message": "æˆåŠŸåˆ·æ–° Plex åª’ä½“åº“"})
        else:
            return jsonify({"success": False, "message": "åˆ·æ–° Plex åª’ä½“åº“å¤±è´¥ï¼Œè¯·æ£€æŸ¥è·¯å¾„é…ç½®"})

    except Exception as e:
        return jsonify({"success": False, "message": f"åˆ·æ–° Plex åª’ä½“åº“å¤±è´¥: {str(e)}"})


# æ–‡ä»¶æ•´ç†é¡µé¢åˆ·æ–°AListç›®å½•
@app.route("/refresh_filemanager_alist_directory", methods=["POST"])
def refresh_filemanager_alist_directory():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    folder_path = request.json.get("folder_path")
    account_index = request.json.get("account_index", 0)

    if not folder_path:
        return jsonify({"success": False, "message": "ç¼ºå°‘æ–‡ä»¶å¤¹è·¯å¾„"})

    # æ£€æŸ¥AListæ’ä»¶é…ç½®
    if not config_data.get("plugins", {}).get("alist", {}).get("url"):
        return jsonify({"success": False, "message": "AList æ’ä»¶æœªé…ç½®"})

    # å¯¼å…¥AListæ’ä»¶
    from plugins.alist import Alist

    # åˆå§‹åŒ–AListæ’ä»¶
    alist = Alist(**config_data["plugins"]["alist"])
    if not alist.is_active:
        return jsonify({"success": False, "message": "AList æ’ä»¶æœªæ­£ç¡®é…ç½®"})

    # è·å–å¤¸å…‹è´¦å·ä¿¡æ¯
    try:
        account = Quark(config_data["cookie"][account_index], account_index)

        # å°†æ–‡ä»¶å¤¹è·¯å¾„è½¬æ¢ä¸ºå®é™…çš„ä¿å­˜è·¯å¾„
        # folder_pathæ˜¯ç›¸å¯¹äºå¤¸å…‹ç½‘ç›˜æ ¹ç›®å½•çš„è·¯å¾„ï¼Œå¦‚ "/" æˆ– "/æµ‹è¯•/æ–‡ä»¶å¤¹"
        # æ ¹æ®è´¦å·ç´¢å¼•è·å–å¯¹åº”çš„å­˜å‚¨é…ç½®
        storage_mount_path, quark_root_dir = alist.get_storage_config(account_index)

        if not storage_mount_path or not quark_root_dir:
            return jsonify({"success": False, "message": f"AList æ’ä»¶æœªé…ç½®è´¦å· {account_index} çš„å­˜å‚¨ä¿¡æ¯"})

        if folder_path == "/":
            # æ ¹ç›®å½•ï¼Œç›´æ¥ä½¿ç”¨å¤¸å…‹æ ¹è·¯å¾„
            full_path = quark_root_dir
        else:
            # å­ç›®å½•ï¼Œæ‹¼æ¥è·¯å¾„
            import os
            # ç§»é™¤folder_pathå¼€å¤´çš„/ï¼Œç„¶åæ‹¼æ¥
            relative_path = folder_path.lstrip("/")
            if quark_root_dir == "/":
                full_path = "/" + relative_path
            else:
                full_path = os.path.normpath(os.path.join(quark_root_dir, relative_path)).replace("\\", "/")

        # æ£€æŸ¥è·¯å¾„æ˜¯å¦åœ¨å¤¸å…‹æ ¹ç›®å½•å†…
        if quark_root_dir == "/" or full_path.startswith(quark_root_dir):
            # ä½¿ç”¨è´¦å·å¯¹åº”çš„å­˜å‚¨é…ç½®æ˜ å°„åˆ°AListè·¯å¾„
            # æ„å»ºAListè·¯å¾„
            if quark_root_dir == "/":
                relative_path = full_path.lstrip("/")
            else:
                relative_path = full_path.replace(quark_root_dir, "", 1).lstrip("/")

            alist_path = os.path.normpath(
                os.path.join(storage_mount_path, relative_path)
            ).replace("\\", "/")

            # æ‰§è¡Œåˆ·æ–°
            alist.refresh(alist_path)
            return jsonify({"success": True, "message": "æˆåŠŸåˆ·æ–° AList ç›®å½•"})
        else:
            return jsonify({"success": False, "message": "è·¯å¾„ä¸åœ¨AListé…ç½®çš„å¤¸å…‹æ ¹ç›®å½•å†…"})

    except Exception as e:
        return jsonify({"success": False, "message": f"åˆ·æ–° AList ç›®å½•å¤±è´¥: {str(e)}"})


@app.route("/task_suggestions")
def get_task_suggestions():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    query = request.args.get("q", "").lower()
    deep = request.args.get("d", "").lower()
    
    # æå–å‰§åï¼Œå»é™¤å­£æ•°ä¿¡æ¯
    def extract_show_name(task_name):
        # æ¸…ç†ä»»åŠ¡åç§°ä¸­çš„è¿ç»­ç©ºæ ¼å’Œç‰¹æ®Šç¬¦å·
        clean_name = task_name.replace('\u3000', ' ').replace('\t', ' ')
        clean_name = re.sub(r'\s+', ' ', clean_name).strip()
        
        # åŒ¹é…å¸¸è§çš„å­£æ•°æ ¼å¼
        # ä¾‹å¦‚ï¼šé»‘é•œ - S07ã€äººç”Ÿè‹¥å¦‚åˆè§ - S01ã€æŠ˜è…°.S01ã€éŸ³ä½ è€Œæ¥-S02ã€å¿«ä¹çš„å¤§äºº S02
        season_patterns = [
            r'^(.*?)[\s\.\-_]+S\d+$',  # é»‘é•œ - S07ã€æŠ˜è…°.S01ã€éŸ³ä½ è€Œæ¥-S02
            r'^(.*?)[\s\.\-_]+Season\s*\d+$',  # é»‘é•œ - Season 1
            r'^(.*?)\s+S\d+$',  # å¿«ä¹çš„å¤§äºº S02
            r'^(.*?)[\s\.\-_]+S\d+E\d+$',  # å¤„ç† S01E01 æ ¼å¼
            r'^(.*?)\s+ç¬¬\s*\d+\s*å­£$',  # å¤„ç† ç¬¬Nå­£ æ ¼å¼
            r'^(.*?)[\s\.\-_]+ç¬¬\s*\d+\s*å­£$',  # å¤„ç† - ç¬¬Nå­£ æ ¼å¼
            r'^(.*?)\s+ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åé›¶]+å­£$',  # å¤„ç† ç¬¬ä¸€å­£ã€ç¬¬äºŒå­£ æ ¼å¼
            r'^(.*?)[\s\.\-_]+ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åé›¶]+å­£$',  # å¤„ç† - ç¬¬ä¸€å­£ã€- ç¬¬äºŒå­£ æ ¼å¼
        ]
        
        for pattern in season_patterns:
            match = re.match(pattern, clean_name, re.IGNORECASE)
            if match:
                show_name = match.group(1).strip()
                # å»é™¤æœ«å°¾å¯èƒ½æ®‹ç•™çš„åˆ†éš”ç¬¦
                show_name = re.sub(r'[\s\.\-_]+$', '', show_name)
                return show_name
                
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°å­£æ•°æ ¼å¼ï¼Œè¿”å›åŸåç§°
        return clean_name
    
    # å¤„ç†æœç´¢å…³é”®è¯ï¼Œæå–å‰§å
    search_query = extract_show_name(query)
    
    try:
        sources_cfg = config_data.get("source", {}) or {}
        cs_data = sources_cfg.get("cloudsaver", {})
        ps_data = sources_cfg.get("pansou", {})

        merged = []
        providers = []

        # CloudSaver
        if (
            cs_data.get("server")
            and cs_data.get("username")
            and cs_data.get("password")
        ):
            cs = CloudSaver(cs_data.get("server"))
            cs.set_auth(
                cs_data.get("username", ""),
                cs_data.get("password", ""),
                cs_data.get("token", ""),
            )
            search = cs.auto_login_search(search_query)
            if search.get("success"):
                if search.get("new_token"):
                    cs_data["token"] = search.get("new_token")
                    Config.write_json(CONFIG_PATH, config_data)
                search_results = cs.clean_search_results(search.get("data"))
                if isinstance(search_results, list):
                    # ä¸º CloudSaver ç»“æœè¡¥é½æ¥æºå­—æ®µ
                    for it in search_results:
                        try:
                            if not it.get("source"):
                                it["source"] = "CloudSaver"
                        except Exception:
                            pass
                    merged.extend(search_results)
                    providers.append("CloudSaver")

        # PanSou
        if ps_data and ps_data.get("server") and PanSou is not None:
            try:
                ps = PanSou(ps_data.get("server"))
                result = ps.search(search_query)
                if result.get("success") and isinstance(result.get("data"), list):
                    # ä¸º PanSou ç»“æœè¡¥é½æ¥æºå­—æ®µ
                    for it in result.get("data"):
                        try:
                            if not it.get("source"):
                                it["source"] = "PanSou"
                        except Exception:
                            pass
                    merged.extend(result.get("data"))
                    providers.append("PanSou")
            except Exception as e:
                logging.warning(f"PanSou æœç´¢å¤±è´¥: {str(e)}")

        # å»é‡å¹¶ç»Ÿä¸€æ—¶é—´å­—æ®µä¸º publish_date
        # è§„åˆ™ï¼š
        # 1) é¦–è½®ä»…æŒ‰ shareurl å½’å¹¶ï¼šåŒä¸€é“¾æ¥ä¿ç•™å‘å¸ƒæ—¶é—´æœ€æ–°çš„ä¸€æ¡ï¼ˆå±•ç¤ºä»¥è¯¥æ¡ä¸ºå‡†ï¼‰
        # 2) å…œåº•ï¼ˆæå°‘ï¼‰ï¼šæ— é“¾æ¥æ—¶æŒ‰å®Œæ•´æŒ‡çº¹ï¼ˆshareurl|title|date|sourceï¼‰å½’å¹¶
        # 3) äºŒæ¬¡å½’å¹¶ï¼šå¯¹æ‰€æœ‰å€™é€‰ç»“æœå†æŒ‰ æ ‡é¢˜+å‘å¸ƒæ—¶é—´ åšä¸€æ¬¡å½’å¹¶ï¼ˆæ— è®º shareurl æ˜¯å¦ç›¸åŒï¼‰ï¼Œå–æœ€æ–°
        # æ³¨æ„ï¼šå½“å‘ç”Ÿå½’å¹¶å†²çªæ—¶ï¼Œå§‹ç»ˆä¿ç•™å‘å¸ƒæ—¶é—´æœ€æ–°çš„è®°å½•
        dedup_map = {}          # æŒ‰ shareurl å½’å¹¶ï¼Œå€¼ä¸º {item, _sources:set}
        fingerprint_map = {}    # å…œåº•ï¼šå®Œæ•´æŒ‡çº¹å½’å¹¶ï¼ˆä»…å½“ç¼ºå¤±é“¾æ¥æ—¶ï¼‰ï¼ŒåŒä¸Š
        # è§„èŒƒåŒ–å·¥å…·
        def normalize_shareurl(url: str) -> str:
            try:
                if not url:
                    return ""
                u = url.strip()
                # ä»…å–å¤¸å…‹åˆ†äº«ID: pan.quark.cn/s/<id>[?...]
                # åŒæ—¶æ”¯æŒç›´æ¥ä¼ å…¥IDçš„æƒ…å†µ
                match = re.search(r"/s/([^\?/#\s]+)", u)
                if match:
                    return match.group(1)
                # å¦‚æœæ²¡æœ‰åŸŸåè·¯å¾„ï¼Œå°è¯•å»æ‰æŸ¥è¯¢å‚æ•°
                return u.split('?')[0]
            except Exception:
                return url or ""
        def normalize_title(title: str) -> str:
            try:
                if not title:
                    return ""
                import unicodedata
                t = unicodedata.normalize('NFKC', title)
                t = t.replace('\u3000', ' ').replace('\t', ' ')
                t = re.sub(r"\s+", " ", t).strip()
                return t
            except Exception:
                return title or ""
        def normalize_date(date_str: str) -> str:
            try:
                if not date_str:
                    return ""
                import unicodedata
                ds = unicodedata.normalize('NFKC', date_str).strip()
                return ds
            except Exception:
                return (date_str or "").strip()
        # è§£ææ—¶é—´ä¾›æ¯”è¾ƒ
        def to_ts(datetime_str):
            if not datetime_str:
                return 0
            try:
                s = str(datetime_str).strip()
                from datetime import datetime
                try:
                    return datetime.strptime(s, "%Y-%m-%d %H:%M:%S").timestamp()
                except Exception:
                    pass
                try:
                    return datetime.strptime(s, "%Y-%m-%d").timestamp()
                except Exception:
                    pass
                try:
                    s2 = s.replace('Z', '+00:00')
                    return datetime.fromisoformat(s2).timestamp()
                except Exception:
                    return 0
            except Exception:
                return 0

        for item in merged:
            if not isinstance(item, dict):
                continue
            # ç»Ÿä¸€æ—¶é—´å­—æ®µï¼šä¼˜å…ˆä½¿ç”¨å·²å­˜åœ¨çš„ publish_dateï¼Œå¦åˆ™ä½¿ç”¨ datetimeï¼Œå¹¶å†™å› publish_date
            try:
                if not item.get("publish_date") and item.get("datetime"):
                    item["publish_date"] = item.get("datetime")
            except Exception:
                pass

            shareurl = normalize_shareurl(item.get("shareurl") or "")
            title = normalize_title(item.get("taskname") or "")
            pubdate = normalize_date(item.get("publish_date") or "")
            source = (item.get("source") or "").strip()

            timestamp = to_ts(pubdate)

            # æ¡ä»¶1ï¼šæŒ‰ shareurl å½’å¹¶ï¼Œå–æœ€æ–°
            if shareurl:
                existed = dedup_map.get(shareurl)
                if not existed or to_ts(existed["item"].get("publish_date")) < timestamp:
                    dedup_map[shareurl] = {"item": item, "_sources": set([src for src in [source] if src])}
                else:
                    # æ›´æ–°æ—¶é—´è¾ƒæ—§ä½†æ¥æºéœ€è¦åˆå¹¶
                    try:
                        if source:
                            existed["_sources"].add(source)
                    except Exception:
                        pass
            else:
                # æ¡ä»¶2ï¼ˆå…œåº•ï¼‰ï¼šå®Œæ•´æŒ‡çº¹å½’å¹¶ï¼ˆæå°‘å‘ç”Ÿï¼‰ï¼Œä¾ç„¶å–æœ€æ–°
                fingerprint = f"{shareurl}|{title}|{pubdate}|{source}"
                existed = fingerprint_map.get(fingerprint)
                if not existed or to_ts(existed["item"].get("publish_date")) < timestamp:
                    fingerprint_map[fingerprint] = {"item": item, "_sources": set([src for src in [source] if src])}
                else:
                    try:
                        if source:
                            existed["_sources"].add(source)
                    except Exception:
                        pass

        # ç¬¬ä¸€è½®ï¼šæ±‡æ€»å½’å¹¶åçš„å€™é€‰ç»“æœ
        candidates = list(dedup_map.values()) + list(fingerprint_map.values())

        # ç¬¬äºŒè½®ï¼šæ— è®º shareurl æ˜¯å¦ç›¸åŒï¼Œå†æŒ‰ æ ‡é¢˜+å‘å¸ƒæ—¶é—´ å½’å¹¶ä¸€æ¬¡ï¼ˆä½¿ç”¨æ—¶é—´æˆ³ä½œä¸ºé”®ï¼Œå…¼å®¹ä¸åŒæ—¶é—´æ ¼å¼ï¼‰ï¼Œä¿ç•™æœ€æ–°
        final_map = {}
        for pack in candidates:
            try:
                item = pack.get("item") if isinstance(pack, dict) else pack
                src_set = pack.get("_sources") if isinstance(pack, dict) else set([ (item.get("source") or "").strip() ])
                t = normalize_title(item.get("taskname") or "")
                d = normalize_date(item.get("publish_date") or "")
                s = normalize_shareurl(item.get("shareurl") or "")
                src = (item.get("source") or "").strip()
                # ä¼˜å…ˆé‡‡ç”¨ æ ‡é¢˜+æ—¶é—´ ä½œä¸ºå½’å¹¶é”®
                ts_val = to_ts(d)
                if t and ts_val:
                    key = f"TD::{t}||{int(ts_val)}"
                elif s:
                    key = f"URL::{s}"
                else:
                    key = f"FP::{s}|{t}|{d}|{src}"
                existed = final_map.get(key)
                current_ts = to_ts(item.get("publish_date"))
                if not existed:
                    # åˆæ¬¡æ”¾å…¥æ—¶å¸¦ä¸Šæ¥æºé›†åˆ
                    item_copy = dict(item)
                    item_copy["_sources"] = set([*list(src_set)])
                    final_map[key] = item_copy
                else:
                    existed_ts = to_ts(existed.get("publish_date"))
                    if current_ts > existed_ts:
                        item_copy = dict(item)
                        # ç»§æ‰¿æ—§æ¥æºå¹¶åˆå¹¶æ–°æ¥æº
                        merged_sources = set(list(existed.get("_sources") or set()))
                        for ssrc in list(src_set):
                            if ssrc:
                                merged_sources.add(ssrc)
                        item_copy["_sources"] = merged_sources
                        final_map[key] = item_copy
                    elif current_ts == existed_ts:
                        # æ—¶é—´å®Œå…¨ç›¸åŒï¼Œä½¿ç”¨ç¡®å®šæ€§ä¼˜å…ˆçº§æ‰“ç ´å¹³æ‰‹
                        source_priority = {"CloudSaver": 2, "PanSou": 1}
                        existed_pri = source_priority.get((existed.get("source") or "").strip(), 0)
                        current_pri = source_priority.get(src, 0)
                        # æ— è®ºè°èƒœå‡ºï¼Œéƒ½è¦åˆå¹¶æ¥æºé›†åˆ
                        if current_pri > existed_pri:
                            item_copy = dict(item)
                            merged_sources = set(list(existed.get("_sources") or set()))
                            for ssrc in list(src_set):
                                if ssrc:
                                    merged_sources.add(ssrc)
                            item_copy["_sources"] = merged_sources
                            final_map[key] = item_copy
                        elif current_pri == existed_pri:
                            # è¿›ä¸€æ­¥æ¯”è¾ƒä¿¡æ¯ä¸°å¯Œåº¦ï¼ˆcontent é•¿åº¦ï¼‰
                            if len(str(item.get("content") or "")) > len(str(existed.get("content") or "")):
                                item_copy = dict(item)
                                # åˆå¹¶æ¥æº
                                merged_sources = set(list(existed.get("_sources") or set()))
                                for ssrc in list(src_set):
                                    if ssrc:
                                        merged_sources.add(ssrc)
                                item_copy["_sources"] = merged_sources
                                final_map[key] = item_copy
                            else:
                                # å³ä¾¿ä¸æ›¿æ¢ä¸»ä½“ï¼Œä¹Ÿåˆå¹¶æ¥æº
                                try:
                                    merged_sources = set(list(existed.get("_sources") or set()))
                                    for ssrc in list(src_set):
                                        if ssrc:
                                            merged_sources.add(ssrc)
                                    existed["_sources"] = merged_sources
                                except Exception:
                                    pass
            except Exception:
                # å‡ºç°å¼‚å¸¸åˆ™è·³è¿‡è¯¥é¡¹
                continue

        # è¾“å‡ºå‰ï¼šå°†æ¥æºé›†åˆå‹ç¼©ä¸ºå±•ç¤ºå­—ç¬¦ä¸²
        dedup = []
        for v in final_map.values():
            try:
                srcs = sorted([s for s in list(v.get("_sources") or []) if s])
                v.pop("_sources", None)
                if srcs:
                    v["source"] = " Â· ".join(srcs)
                dedup.append(v)
            except Exception:
                dedup.append(v)

        # ä»…åœ¨æ’åºæ—¶å¯¹å¤šç§æ ¼å¼è¿›è¡Œè§£æï¼ˆä¼˜å…ˆè§£æ YYYY-MM-DD HH:mm:ssï¼Œå…¶æ¬¡ ISOï¼‰
        if dedup:
            def parse_datetime_for_sort(item):
                """è§£ææ—¶é—´å­—æ®µï¼Œè¿”å›å¯æ¯”è¾ƒçš„æ—¶é—´æˆ³ï¼ˆç»Ÿä¸€ä»¥ publish_date ä¸ºå‡†ï¼‰"""
                datetime_str = item.get("publish_date")
                if not datetime_str:
                    return 0  # æ²¡æœ‰æ—¶é—´çš„æ’åœ¨æœ€å
                from datetime import datetime
                s = str(datetime_str).strip()
                # ä¼˜å…ˆè§£ææ ‡å‡†æ˜¾ç¤ºæ ¼å¼
                try:
                    dt = datetime.strptime(s, "%Y-%m-%d %H:%M:%S")
                    return dt.timestamp()
                except Exception:
                    pass
                # è¡¥å……è§£æä»…æ—¥æœŸæ ¼å¼
                try:
                    dt = datetime.strptime(s, "%Y-%m-%d")
                    return dt.timestamp()
                except Exception:
                    pass
                # å…¶æ¬¡å°è¯• ISOï¼ˆæ”¯æŒ Z/åç§»ï¼‰
                try:
                    s2 = s.replace('Z', '+00:00')
                    dt = datetime.fromisoformat(s2)
                    return dt.timestamp()
                except Exception:
                    return 0  # è§£æå¤±è´¥æ’åœ¨æœ€å
            
            # æŒ‰æ—¶é—´å€’åºæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            dedup.sort(key=parse_datetime_for_sort, reverse=True)
            
            return jsonify({
                "success": True,
                "source": ", ".join(providers) if providers else "èšåˆ",
                "data": dedup
            })

        # è‹¥æ— æœ¬åœ°å¯ç”¨æ¥æºï¼Œå›é€€åˆ°å…¬å¼€ç½‘ç»œ
        base_url = base64.b64decode("aHR0cHM6Ly9zLjkxNzc4OC54eXo=").decode()
        url = f"{base_url}/task_suggestions?q={search_query}&d={deep}"
        response = requests.get(url)
        return jsonify({
            "success": True,
            "source": "ç½‘ç»œå…¬å¼€",
            "data": response.json()
        })

    except Exception as e:
        return jsonify({"success": True, "message": f"error: {str(e)}"})


def _resolve_qoark_redirect(url: str) -> str:
    """
    è§£æ pan.qoark.cn é“¾æ¥çš„é‡å®šå‘åœ°å€
    å¦‚æœé“¾æ¥æ˜¯ pan.qoark.cnï¼Œåˆ™è·å–é‡å®šå‘åçš„çœŸå®åœ°å€
    å¦‚æœä¸æ˜¯ï¼Œåˆ™ç›´æ¥è¿”å›åŸé“¾æ¥
    """
    if not isinstance(url, str) or "pan.qoark.cn" not in url:
        return url
    
    try:
        # åˆ›å»ºæ–°çš„ session ç”¨äºé‡å®šå‘è§£æ
        redirect_session = requests.Session()
        redirect_session.max_redirects = 10
        # åªè·å–å¤´ä¿¡æ¯ï¼Œä¸è·å–å®Œæ•´å†…å®¹ï¼ˆHEAD è¯·æ±‚æ›´å¿«ï¼‰
        resp = redirect_session.head(url, allow_redirects=True, timeout=10)
        
        # å¦‚æœæˆåŠŸé‡å®šå‘åˆ° pan.quark.cnï¼Œè¿”å›é‡å®šå‘åçš„åœ°å€
        if resp.status_code == 200 and "pan.quark.cn" in resp.url:
            return resp.url
        # å¦‚æœ HEAD è¯·æ±‚å¤±è´¥ï¼Œå°è¯• GET è¯·æ±‚ï¼ˆæŸäº›æœåŠ¡å™¨å¯èƒ½ä¸æ”¯æŒ HEADï¼‰
        elif resp.status_code != 200:
            resp = redirect_session.get(url, allow_redirects=True, timeout=10)
            if resp.status_code == 200 and "pan.quark.cn" in resp.url:
                return resp.url
        
        # å¦‚æœé‡å®šå‘å¤±è´¥æˆ–æ²¡æœ‰é‡å®šå‘åˆ° pan.quark.cnï¼Œè¿”å›åŸé“¾æ¥
        return url
    except Exception as e:
        # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸé“¾æ¥ï¼ˆé¿å…å½±å“å…¶ä»–åŠŸèƒ½ï¼‰
        logging.warning(f"è§£æ pan.qoark.cn é‡å®šå‘å¤±è´¥: {str(e)}")
        return url


# è·å–åˆ†äº«è¯¦æƒ…æ¥å£
@app.route("/get_share_detail", methods=["GET", "POST"])
def get_share_detail():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    # æ”¯æŒGETå’ŒPOSTè¯·æ±‚
    if request.method == "GET":
        shareurl = request.args.get("shareurl", "")
        stoken = request.args.get("stoken", "")
    else:
        shareurl = request.json.get("shareurl", "")
        stoken = request.json.get("stoken", "")
    
    # è§£æ pan.qoark.cn é“¾æ¥çš„é‡å®šå‘åœ°å€
    if shareurl and "pan.qoark.cn" in shareurl:
        shareurl = _resolve_qoark_redirect(shareurl)
        
    account = Quark("", 0)
    # è®¾ç½®accountçš„å¿…è¦å±æ€§
    account.episode_patterns = request.json.get("regex", {}).get("episode_patterns", []) if request.method == "POST" else []
    
    pwd_id, passcode, pdir_fid, paths = account.extract_url(shareurl)
    if not stoken:
        is_sharing, stoken = account.get_stoken(pwd_id, passcode)
        if not is_sharing:
            return jsonify({"success": False, "data": {"error": stoken}})
    share_detail = account.get_detail(pwd_id, stoken, pdir_fid, _fetch_share=1)
    # ç»Ÿä¸€é”™è¯¯è¿”å›ï¼Œé¿å…å‰ç«¯å´©æºƒ
    if isinstance(share_detail, dict) and share_detail.get("error"):
        return jsonify({"success": False, "data": {"error": share_detail.get("error")}})

    share_detail["paths"] = paths
    share_detail["stoken"] = stoken

    # å¤„ç†æ–‡ä»¶å¤¹çš„include_itemså­—æ®µï¼Œç¡®ä¿ç©ºæ–‡ä»¶å¤¹æ˜¾ç¤ºä¸º0é¡¹è€Œä¸æ˜¯undefined
    if "list" in share_detail and isinstance(share_detail["list"], list):
        for file_item in share_detail["list"]:
            if file_item.get("dir", False):
                # å¦‚æœæ˜¯æ–‡ä»¶å¤¹ï¼Œç¡®ä¿include_itemså­—æ®µå­˜åœ¨ä¸”ä¸ºæ•°å­—
                if "include_items" not in file_item or file_item["include_items"] is None:
                    file_item["include_items"] = 0
                elif not isinstance(file_item["include_items"], (int, float)):
                    # å¦‚æœinclude_itemsä¸æ˜¯æ•°å­—ç±»å‹ï¼Œå°è¯•è½¬æ¢ä¸ºæ•´æ•°ï¼Œå¤±è´¥åˆ™è®¾ä¸º0
                    try:
                        file_item["include_items"] = int(file_item["include_items"])
                    except (ValueError, TypeError):
                        file_item["include_items"] = 0

    # å¦‚æœæ˜¯GETè¯·æ±‚æˆ–è€…ä¸éœ€è¦é¢„è§ˆæ­£åˆ™ï¼Œç›´æ¥è¿”å›åˆ†äº«è¯¦æƒ…
    if request.method == "GET" or not request.json.get("regex"):
        return jsonify({"success": True, "data": share_detail})
        
    # æ­£åˆ™å‘½åé¢„è§ˆ
    def preview_regex(share_detail):
        regex = request.json.get("regex")
        # æ£€æŸ¥æ˜¯å¦ä¸ºé¡ºåºå‘½åæ¨¡å¼
        if regex.get("use_sequence_naming") and regex.get("sequence_naming"):
            # é¡ºåºå‘½åæ¨¡å¼é¢„è§ˆ
            sequence_pattern = regex.get("sequence_naming")
            current_sequence = 1
            
            # æ„å»ºé¡ºåºå‘½åçš„æ­£åˆ™è¡¨è¾¾å¼
            if sequence_pattern == "{}":
                # å¯¹äºå•ç‹¬çš„{}ï¼Œä½¿ç”¨ç‰¹æ®ŠåŒ¹é…
                regex_pattern = "(\\d+)"
            else:
                regex_pattern = re.escape(sequence_pattern).replace('\\{\\}', '(\\d+)')
            
            # å®ç°ä¸å®é™…é‡å‘½åç›¸åŒçš„æ’åºç®—æ³•
            def extract_sort_value(file):
                return sort_file_by_name(file)
            
            # è¿‡æ»¤å‡ºéç›®å½•æ–‡ä»¶ï¼Œå¹¶ä¸”æ’é™¤å·²ç»ç¬¦åˆå‘½åè§„åˆ™çš„æ–‡ä»¶
            files_to_process = []
            for f in share_detail["list"]:
                if f["dir"]:
                    continue  # è·³è¿‡ç›®å½•
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç¬¦åˆå‘½åè§„åˆ™
                if sequence_pattern == "{}":
                    # å¯¹äºå•ç‹¬çš„{}ï¼Œæ£€æŸ¥æ–‡ä»¶åæ˜¯å¦ä¸ºçº¯æ•°å­—
                    file_name_without_ext = os.path.splitext(f["file_name"])[0]
                    if file_name_without_ext.isdigit():
                        # å¢åŠ åˆ¤æ–­ï¼šå¦‚æœæ˜¯æ—¥æœŸæ ¼å¼çš„çº¯æ•°å­—ï¼Œä¸è§†ä¸ºå·²å‘½å
                        if not is_date_format(file_name_without_ext):
                            continue  # è·³è¿‡å·²ç¬¦åˆå‘½åè§„åˆ™çš„æ–‡ä»¶
                elif re.match(regex_pattern, f["file_name"]):
                    continue  # è·³è¿‡å·²ç¬¦åˆå‘½åè§„åˆ™çš„æ–‡ä»¶
                
                # æ·»åŠ åˆ°å¾…å¤„ç†æ–‡ä»¶åˆ—è¡¨
                files_to_process.append(f)
            
            # æ ¹æ®æå–çš„æ’åºå€¼è¿›è¡Œæ’åº
            sorted_files = sorted(files_to_process, key=extract_sort_value)
            
            # åº”ç”¨é«˜çº§è¿‡æ»¤è¯è¿‡æ»¤
            filterwords = regex.get("filterwords", "")
            if filterwords:
                # ä½¿ç”¨é«˜çº§è¿‡æ»¤å‡½æ•°
                filtered_files = advanced_filter_files(sorted_files, filterwords)
                # æ ‡è®°è¢«è¿‡æ»¤çš„æ–‡ä»¶
                for item in sorted_files:
                    if item not in filtered_files:
                        item["filtered"] = True
            
            # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ†é…åºå·
            for file in sorted_files:
                if not file.get("filtered"):
                    # è·å–æ–‡ä»¶æ‰©å±•å
                    file_ext = os.path.splitext(file["file_name"])[1]
                    # ç”Ÿæˆé¢„è§ˆæ–‡ä»¶å
                    if sequence_pattern == "{}":
                        # å¯¹äºå•ç‹¬çš„{}ï¼Œç›´æ¥ä½¿ç”¨æ•°å­—åºå·ä½œä¸ºæ–‡ä»¶å
                        file["file_name_re"] = f"{current_sequence:02d}{file_ext}"
                    else:
                        # æ›¿æ¢æ‰€æœ‰çš„{}ä¸ºå½“å‰åºå·
                        file["file_name_re"] = sequence_pattern.replace("{}", f"{current_sequence:02d}") + file_ext
                    
                    # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                    file["file_name_re"] = apply_subtitle_naming_rule(file["file_name_re"], config_data["task_settings"])
                    current_sequence += 1
            
            return share_detail
        elif regex.get("use_episode_naming") and regex.get("episode_naming"):
            # å‰§é›†å‘½åæ¨¡å¼é¢„è§ˆ
            episode_pattern = regex.get("episode_naming")
            episode_patterns = regex.get("episode_patterns", [])
            
            # è·å–ç”¨æˆ·è¡¥å……çš„å‰§é›†æ¨¡å¼ï¼ˆé»˜è®¤æ¨¡å¼ç”±åç«¯å†…éƒ¨æä¾›ï¼Œè¿™é‡Œåªå¤„ç†ç”¨æˆ·è¡¥å……ï¼‰
            episode_patterns = []
            raw_patterns = config_data.get("episode_patterns", [])
            for p in raw_patterns:
                if isinstance(p, dict) and p.get("regex"):
                    episode_patterns.append(p)
                elif isinstance(p, str):
                    episode_patterns.append({"regex": p})
                
            
            # åº”ç”¨é«˜çº§è¿‡æ»¤è¯è¿‡æ»¤
            filterwords = regex.get("filterwords", "")
            if filterwords:
                # ä½¿ç”¨é«˜çº§è¿‡æ»¤å‡½æ•°
                filtered_files = advanced_filter_files(share_detail["list"], filterwords)
                # æ ‡è®°è¢«è¿‡æ»¤çš„æ–‡ä»¶
                for item in share_detail["list"]:
                    if item not in filtered_files:
                        item["filtered"] = True
                        item["file_name_re"] = "Ã—"
            
            # å¤„ç†æœªè¢«è¿‡æ»¤çš„æ–‡ä»¶
            for file in share_detail["list"]:
                if not file["dir"] and not file.get("filtered"):  # åªå¤„ç†æœªè¢«è¿‡æ»¤çš„éç›®å½•æ–‡ä»¶
                    extension = os.path.splitext(file["file_name"])[1]
                    # ä»æ–‡ä»¶åä¸­æå–é›†å·
                    episode_num = extract_episode_number(file["file_name"], episode_patterns=episode_patterns)

                    if episode_num is not None:
                        file["file_name_re"] = episode_pattern.replace("[]", f"{episode_num:02d}") + extension
                        # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                        file["file_name_re"] = apply_subtitle_naming_rule(file["file_name_re"], config_data["task_settings"])
                        # æ·»åŠ episode_numberå­—æ®µç”¨äºå‰ç«¯æ’åº
                        file["episode_number"] = episode_num
                    else:
                        # æ²¡æœ‰æå–åˆ°é›†å·ï¼Œæ˜¾ç¤ºæ— æ³•è¯†åˆ«çš„æç¤º
                        file["file_name_re"] = "Ã— æ— æ³•è¯†åˆ«å‰§é›†ç¼–å·"
            
            return share_detail
        else:
            # æ™®é€šæ­£åˆ™å‘½åé¢„è§ˆ
            pattern, replace = account.magic_regex_func(
                regex.get("pattern", ""),
                regex.get("replace", ""),
                regex.get("taskname", ""),
                regex.get("magic_regex", {}),
            )
            
            # åº”ç”¨é«˜çº§è¿‡æ»¤è¯è¿‡æ»¤
            filterwords = regex.get("filterwords", "")
            if filterwords:
                # ä½¿ç”¨é«˜çº§è¿‡æ»¤å‡½æ•°
                filtered_files = advanced_filter_files(share_detail["list"], filterwords)
                # æ ‡è®°è¢«è¿‡æ»¤çš„æ–‡ä»¶
                for item in share_detail["list"]:
                    if item not in filtered_files:
                        item["filtered"] = True
                
            # åº”ç”¨æ­£åˆ™å‘½å
            for item in share_detail["list"]:
                # åªå¯¹æœªè¢«è¿‡æ»¤çš„æ–‡ä»¶åº”ç”¨æ­£åˆ™å‘½å
                if not item.get("filtered") and re.search(pattern, item["file_name"]):
                    file_name = item["file_name"]
                    item["file_name_re"] = (
                        re.sub(pattern, replace, file_name) if replace != "" else file_name
                    )
                    # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                    item["file_name_re"] = apply_subtitle_naming_rule(item["file_name_re"], config_data["task_settings"])
            return share_detail

    share_detail = preview_regex(share_detail)

    # å†æ¬¡å¤„ç†æ–‡ä»¶å¤¹çš„include_itemså­—æ®µï¼Œç¡®ä¿é¢„è§ˆåçš„æ•°æ®ä¹Ÿæ­£ç¡®
    if "list" in share_detail and isinstance(share_detail["list"], list):
        for file_item in share_detail["list"]:
            if file_item.get("dir", False):
                # å¦‚æœæ˜¯æ–‡ä»¶å¤¹ï¼Œç¡®ä¿include_itemså­—æ®µå­˜åœ¨ä¸”ä¸ºæ•°å­—
                if "include_items" not in file_item or file_item["include_items"] is None:
                    file_item["include_items"] = 0
                elif not isinstance(file_item["include_items"], (int, float)):
                    # å¦‚æœinclude_itemsä¸æ˜¯æ•°å­—ç±»å‹ï¼Œå°è¯•è½¬æ¢ä¸ºæ•´æ•°ï¼Œå¤±è´¥åˆ™è®¾ä¸º0
                    try:
                        file_item["include_items"] = int(file_item["include_items"])
                    except (ValueError, TypeError):
                        file_item["include_items"] = 0

    return jsonify({"success": True, "data": share_detail})


@app.route("/get_savepath_detail")
def get_savepath_detail():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    # è·å–è´¦å·ç´¢å¼•å‚æ•°
    account_index = int(request.args.get("account_index", 0))

    # éªŒè¯è´¦å·ç´¢å¼•
    if account_index < 0 or account_index >= len(config_data["cookie"]):
        return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

    account = Quark(config_data["cookie"][account_index], account_index)
    paths = []
    if path := request.args.get("path"):
        if path == "/":
            fid = 0
        else:
            dir_names = path.split("/")
            if dir_names[0] == "":
                dir_names.pop(0)
            path_fids = []
            current_path = ""
            for dir_name in dir_names:
                current_path += "/" + dir_name
                path_fids.append(current_path)
            if get_fids := account.get_fids(path_fids):
                fid = get_fids[-1]["fid"]
                paths = [
                    {"fid": get_fid["fid"], "name": dir_name}
                    for get_fid, dir_name in zip(get_fids, dir_names)
                ]
            else:
                return jsonify({"success": False, "data": {"error": "è·å–fidå¤±è´¥"}})
    else:
        fid = request.args.get("fid", "0")

    # è·å–æ–‡ä»¶åˆ—è¡¨
    files = account.ls_dir(fid)

    # å¤„ç†æ–‡ä»¶å¤¹çš„include_itemså­—æ®µï¼Œç¡®ä¿ç©ºæ–‡ä»¶å¤¹æ˜¾ç¤ºä¸º0é¡¹è€Œä¸æ˜¯undefined
    if isinstance(files, list):
        for file_item in files:
            if file_item.get("dir", False):
                # å¦‚æœæ˜¯æ–‡ä»¶å¤¹ï¼Œç¡®ä¿include_itemså­—æ®µå­˜åœ¨ä¸”ä¸ºæ•°å­—
                if "include_items" not in file_item or file_item["include_items"] is None:
                    file_item["include_items"] = 0
                elif not isinstance(file_item["include_items"], (int, float)):
                    # å¦‚æœinclude_itemsä¸æ˜¯æ•°å­—ç±»å‹ï¼Œå°è¯•è½¬æ¢ä¸ºæ•´æ•°ï¼Œå¤±è´¥åˆ™è®¾ä¸º0
                    try:
                        file_item["include_items"] = int(file_item["include_items"])
                    except (ValueError, TypeError):
                        file_item["include_items"] = 0

    file_list = {
        "list": files,
        "paths": paths,
    }
    return jsonify({"success": True, "data": file_list})


@app.route("/delete_file", methods=["POST"])
def delete_file():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    # è·å–è´¦å·ç´¢å¼•å‚æ•°
    account_index = int(request.json.get("account_index", 0))

    # éªŒè¯è´¦å·ç´¢å¼•
    if account_index < 0 or account_index >= len(config_data["cookie"]):
        return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

    account = Quark(config_data["cookie"][account_index], account_index)
    if fid := request.json.get("fid"):
        response = account.delete([fid])
        
        # å¤„ç†delete_recordså‚æ•°
        if request.json.get("delete_records") and response.get("code") == 0:
            try:
                # åˆå§‹åŒ–æ•°æ®åº“
                db = RecordDB()
                
                # è·å–save_pathå‚æ•°
                save_path = request.json.get("save_path", "")
                
                # å¦‚æœæ²¡æœ‰æä¾›save_pathï¼Œåˆ™ä¸åˆ é™¤ä»»ä½•è®°å½•
                if not save_path:
                    response["deleted_records"] = 0
                    # logging.info(f">>> åˆ é™¤æ–‡ä»¶ {fid} ä½†æœªæä¾›save_pathï¼Œä¸åˆ é™¤ä»»ä½•è®°å½•")
                    return jsonify(response)
                
                # æŸ¥è¯¢ä¸è¯¥æ–‡ä»¶IDå’Œsave_pathç›¸å…³çš„æ‰€æœ‰è®°å½•
                cursor = db.conn.cursor()
                
                # ä½¿ç”¨file_idå’Œsave_pathè¿›è¡Œç²¾ç¡®åŒ¹é…
                cursor.execute("SELECT id FROM transfer_records WHERE file_id = ? AND save_path = ?", (fid, save_path))
                record_ids = [row[0] for row in cursor.fetchall()]
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„file_idè®°å½•ï¼Œå°è¯•é€šè¿‡æ–‡ä»¶åæŸ¥æ‰¾
                if not record_ids:
                    # è·å–æ–‡ä»¶åï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                    file_name = request.json.get("file_name", "")
                    if file_name:
                        # ä½¿ç”¨æ–‡ä»¶åå’Œsave_pathè¿›è¡Œç²¾ç¡®åŒ¹é…
                        cursor.execute("""
                            SELECT id FROM transfer_records 
                            WHERE (original_name = ? OR renamed_to = ?) 
                            AND save_path = ?
                        """, (file_name, file_name, save_path))
                        
                        record_ids = [row[0] for row in cursor.fetchall()]
                
                # åˆ é™¤æ‰¾åˆ°çš„æ‰€æœ‰è®°å½•
                deleted_count = 0
                for record_id in record_ids:
                    deleted_count += db.delete_record(record_id)
                # çƒ­æ›´æ–°ï¼šæŒ‰ä¿å­˜è·¯å¾„æ¨æ–­ä»»åŠ¡åé›†åˆå¹¶è§¦å‘è¿›åº¦é‡ç®—
                try:
                    if deleted_count > 0:
                        cursor.execute("SELECT DISTINCT task_name FROM transfer_records WHERE save_path = ?", (save_path,))
                        task_names = [row[0] for row in (cursor.fetchall() or []) if row and row[0]]
                        for tn in task_names:
                            recompute_task_metrics_and_notify(tn)
                except Exception:
                    pass
                
                # æ·»åŠ åˆ é™¤è®°å½•çš„ä¿¡æ¯åˆ°å“åº”ä¸­
                response["deleted_records"] = deleted_count
                # logging.info(f">>> åˆ é™¤æ–‡ä»¶ {fid} åŒæ—¶åˆ é™¤äº† {deleted_count} æ¡ç›¸å…³è®°å½•")
                # è‹¥å­˜åœ¨è®°å½•åˆ é™¤ï¼Œé€šçŸ¥å‰ç«¯åˆ·æ–°ï¼ˆå½±å“ï¼šæœ€è¿‘è½¬å­˜ã€è¿›åº¦ã€ä»Šæ—¥æ›´æ–°ç­‰ï¼‰
                try:
                    if deleted_count > 0:
                        notify_calendar_changed('delete_records')
                except Exception:
                    pass
                
            except Exception as e:
                logging.error(f">>> åˆ é™¤è®°å½•æ—¶å‡ºé”™: {str(e)}")
                # ä¸å½±å“ä¸»æµç¨‹ï¼Œå³ä½¿åˆ é™¤è®°å½•å¤±è´¥ä¹Ÿè¿”å›æ–‡ä»¶åˆ é™¤æˆåŠŸ
    else:
        response = {"success": False, "message": "ç¼ºå¤±å¿…è¦å­—æ®µ: fid"}
    return jsonify(response)


@app.route("/move_file", methods=["POST"])
def move_file():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    # è·å–è´¦å·ç´¢å¼•å‚æ•°
    account_index = int(request.json.get("account_index", 0))

    # éªŒè¯è´¦å·ç´¢å¼•
    if account_index < 0 or account_index >= len(config_data["cookie"]):
        return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

    account = Quark(config_data["cookie"][account_index], account_index)

    # è·å–å‚æ•°
    file_ids = request.json.get("file_ids", [])
    target_folder_id = request.json.get("target_folder_id")

    if not file_ids:
        return jsonify({"success": False, "message": "ç¼ºå°‘æ–‡ä»¶IDåˆ—è¡¨"})

    if not target_folder_id:
        return jsonify({"success": False, "message": "ç¼ºå°‘ç›®æ ‡æ–‡ä»¶å¤¹ID"})

    try:
        # è°ƒç”¨å¤¸å…‹ç½‘ç›˜çš„ç§»åŠ¨API
        response = account.move(file_ids, target_folder_id)

        if response["code"] == 0:
            return jsonify({
                "success": True,
                "message": f"æˆåŠŸç§»åŠ¨ {len(file_ids)} ä¸ªæ–‡ä»¶",
                "moved_count": len(file_ids)
            })
        else:
            return jsonify({
                "success": False,
                "message": response.get("message", "ç§»åŠ¨å¤±è´¥")
            })
    except Exception as e:
        return jsonify({
            "success": False,
            "message": f"ç§»åŠ¨æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"
        })


@app.route("/create_folder", methods=["POST"])
def create_folder():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    # è·å–è¯·æ±‚å‚æ•°
    data = request.json
    parent_folder_id = data.get("parent_folder_id")
    folder_name = data.get("folder_name", "æ–°å»ºæ–‡ä»¶å¤¹")
    account_index = int(data.get("account_index", 0))

    # éªŒè¯å‚æ•°
    if not parent_folder_id:
        return jsonify({"success": False, "message": "ç¼ºå°‘çˆ¶ç›®å½•ID"})

    # éªŒè¯è´¦å·ç´¢å¼•
    if account_index < 0 or account_index >= len(config_data["cookie"]):
        return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

    try:
        # åˆå§‹åŒ–å¤¸å…‹ç½‘ç›˜å®¢æˆ·ç«¯
        account = Quark(config_data["cookie"][account_index], account_index)

        # è°ƒç”¨æ–°å»ºæ–‡ä»¶å¤¹API
        response = account.mkdir_in_folder(parent_folder_id, folder_name)

        if response.get("code") == 0:
            # åˆ›å»ºæˆåŠŸï¼Œè¿”å›æ–°æ–‡ä»¶å¤¹ä¿¡æ¯
            new_folder = response.get("data", {})
            return jsonify({
                "success": True,
                "message": "æ–‡ä»¶å¤¹åˆ›å»ºæˆåŠŸ",
                "data": {
                    "fid": new_folder.get("fid"),
                    "file_name": new_folder.get("file_name", folder_name),
                    "dir": True,
                    "size": 0,
                    "updated_at": new_folder.get("updated_at"),
                    "include_items": 0
                }
            })
        else:
            # å¤„ç†ç‰¹å®šçš„é”™è¯¯ä¿¡æ¯
            error_message = response.get("message", "åˆ›å»ºæ–‡ä»¶å¤¹å¤±è´¥")

            # æ£€æŸ¥æ˜¯å¦æ˜¯åŒåæ–‡ä»¶å¤¹å†²çª
            if "åŒå" in error_message or "å·²å­˜åœ¨" in error_message or "é‡å¤" in error_message or "doloading" in error_message:
                error_message = "å·²å­˜åœ¨åŒåæ–‡ä»¶å¤¹ï¼Œè¯·ä¿®æ”¹åç§°åå†è¯•"

            return jsonify({
                "success": False,
                "message": error_message
            })

    except Exception as e:
        logging.error(f">>> åˆ›å»ºæ–‡ä»¶å¤¹æ—¶å‡ºé”™: {str(e)}")
        return jsonify({
            "success": False,
            "message": f"åˆ›å»ºæ–‡ä»¶å¤¹æ—¶å‡ºé”™: {str(e)}"
        })


# æ·»åŠ ä»»åŠ¡æ¥å£
@app.route("/api/add_task", methods=["POST"])
def add_task():
    global config_data
    # éªŒè¯token
    if not is_login():
        return jsonify({"success": False, "code": 1, "message": "æœªç™»å½•"}), 401
    # å¿…é€‰å­—æ®µ
    request_data = request.json
    required_fields = ["taskname", "shareurl", "savepath"]
    for field in required_fields:
        if field not in request_data or not request_data[field]:
            return (
                jsonify(
                    {"success": False, "code": 2, "message": f"ç¼ºå°‘å¿…è¦å­—æ®µ: {field}"}
                ),
                400,
            )
    # æ·»åŠ ä»»åŠ¡
    config_data["tasklist"].append(request_data)
    Config.write_json(CONFIG_PATH, config_data)
    logging.info(f">>> é€šè¿‡APIæ·»åŠ ä»»åŠ¡: {request_data['taskname']}")
    return jsonify(
        {"success": True, "code": 0, "message": "ä»»åŠ¡æ·»åŠ æˆåŠŸ", "data": request_data}
    )


# å®šæ—¶ä»»åŠ¡æ‰§è¡Œçš„å‡½æ•°
def run_python(args):
    global _crontab_task_process
    
    logging.info(f">>> å¼€å§‹æ‰§è¡Œå®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡")
    
    # æ£€æŸ¥ä¸Šä¸€æ¬¡ä»»åŠ¡æ˜¯å¦è¿˜åœ¨è¿è¡Œï¼Œå¦‚æœæ˜¯åˆ™å¼ºåˆ¶ç»ˆæ­¢
    if _crontab_task_process is not None:
        try:
            # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œï¼ˆpoll() è¿”å› None è¡¨ç¤ºè¿˜åœ¨è¿è¡Œï¼Œè¿”å›é€€å‡ºç è¡¨ç¤ºå·²ç»“æŸï¼‰
            poll_result = _crontab_task_process.poll()
            if poll_result is None:  # è¿›ç¨‹è¿˜åœ¨è¿è¡Œ
                logging.warning(f">>> æ£€æµ‹åˆ°ä¸Šä¸€æ¬¡å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡ä»åœ¨è¿è¡Œï¼Œæ­£åœ¨å¼ºåˆ¶ç»ˆæ­¢...")
                _crontab_task_process.kill()
                _crontab_task_process.wait(timeout=10)
                logging.warning(f">>> å·²å¼ºåˆ¶ç»ˆæ­¢ä¸Šä¸€æ¬¡å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡")
            else:  # è¿›ç¨‹å·²ç»“æŸï¼ˆæ­£å¸¸æˆ–å¼‚å¸¸é€€å‡ºï¼‰
                logging.debug(f">>> ä¸Šä¸€æ¬¡å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡å·²ç»“æŸï¼ˆé€€å‡ºç : {poll_result}ï¼‰")
        except ProcessLookupError:
            # è¿›ç¨‹ä¸å­˜åœ¨ï¼ˆå¯èƒ½å·²è¢«ç³»ç»Ÿæ¸…ç†ï¼‰
            logging.debug(f">>> ä¸Šä¸€æ¬¡å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡è¿›ç¨‹å·²ä¸å­˜åœ¨/å·²è‡ªåŠ¨æ¸…ç†")
        except Exception as e:
            logging.warning(f">>> æ£€æŸ¥/ç»ˆæ­¢ä¸Šä¸€æ¬¡å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡æ—¶å‡ºé”™: {e}")
        finally:
            # æ— è®ºä»€ä¹ˆæƒ…å†µï¼Œéƒ½æ¸…é™¤è¿›ç¨‹å¯¹è±¡ï¼Œç¡®ä¿ä¸‹æ¬¡èƒ½æ­£å¸¸è¿è¡Œ
            _crontab_task_process = None

    # åœ¨å®šæ—¶ä»»åŠ¡å¼€å§‹å‰æ¸…ç†è¿‡æœŸç¼“å­˜
    try:
        cleaned_count = cleanup_expired_cache()
        if cleaned_count > 0:
            logging.info(f">>> æ¸…ç†äº† {cleaned_count} ä¸ªè¿‡æœŸç¼“å­˜é¡¹")
    except Exception as e:
        logging.warning(f">>> æ¸…ç†ç¼“å­˜æ—¶å‡ºé”™: {e}")

    # æ£€æŸ¥æ˜¯å¦éœ€è¦éšæœºå»¶è¿Ÿæ‰§è¡Œ
    if delay := config_data.get("crontab_delay"):
        try:
            delay_seconds = int(delay)
            if delay_seconds > 0:
                # åœ¨0åˆ°è®¾å®šå€¼ä¹‹é—´éšæœºé€‰æ‹©ä¸€ä¸ªå»¶è¿Ÿæ—¶é—´
                random_delay = random.randint(0, delay_seconds)
                logging.info(f">>> éšæœºå»¶è¿Ÿæ‰§è¡Œ {random_delay} ç§’")
                time.sleep(random_delay)
        except (ValueError, TypeError):
            logging.warning(f">>> å»¶è¿Ÿæ‰§è¡Œè®¾ç½®æ— æ•ˆ: {delay}")

    # å†…éƒ¨å‡½æ•°ï¼šæ‰§è¡Œä¸€æ¬¡ä»»åŠ¡
    def execute_task():
        """æ‰§è¡Œä¸€æ¬¡å®šæ—¶ä»»åŠ¡ï¼Œè¿”å›é€€å‡ºç """
        global _crontab_task_process
        
        process_env = os.environ.copy()
        process_env["PYTHONIOENCODING"] = "utf-8"
        
        # æ„å»ºå‘½ä»¤
        if isinstance(args, str):
            import shlex
            args_list = shlex.split(args)
            command = [PYTHON_PATH] + args_list
        else:
            command = [PYTHON_PATH] + list(args)
        
        # å¯åŠ¨è¿›ç¨‹å¹¶è®°å½•ï¼Œå®æ—¶è¾“å‡ºæ—¥å¿—
        _crontab_task_process = subprocess.Popen(
            command,
            env=process_env,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            encoding="utf-8",
            errors="replace",
            bufsize=1,  # è¡Œç¼“å†²ï¼Œç¡®ä¿å®æ—¶è¾“å‡º
        )
        
        # å®æ—¶è¯»å–è¾“å‡ºå¹¶å†™å…¥æ—¥å¿—ï¼Œä¿ç•™å®Œæ•´æ—¥å¿—åŠŸèƒ½
        # å…¨å±€å˜é‡ï¼šè·Ÿè¸ªä¸Šä¸€æ¬¡è¾“å‡ºæ˜¯å¦æ˜¯ç©ºè¡Œ
        last_was_empty = False
        
        try:
            for line in iter(_crontab_task_process.stdout.readline, ""):
                stripped_line = line.rstrip()
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç©ºè¡Œï¼ˆå»é™¤æ¢è¡Œç¬¦åæ˜¯å¦ä¸ºç©ºï¼‰
                is_empty = not stripped_line
                
                # å¦‚æœæ˜¯ç©ºè¡Œä¸”ä¸Šä¸€æ¬¡ä¹Ÿæ˜¯ç©ºè¡Œï¼Œè·³è¿‡æœ¬æ¬¡è¾“å‡º
                if is_empty and last_was_empty:
                    continue
                
                # è¾“å‡ºæ—¥å¿—ï¼ˆç©ºè¡Œä¹Ÿè¾“å‡ºï¼Œä½†é¿å…è¿ç»­ç©ºè¡Œï¼‰
                if is_empty:
                    logging.info("")
                    last_was_empty = True
                else:
                    logging.info(stripped_line)
                    last_was_empty = False
        finally:
            _crontab_task_process.stdout.close()
        
        # ç­‰å¾…è¿›ç¨‹å®Œæˆå¹¶è¿”å›é€€å‡ºç 
        returncode = _crontab_task_process.wait()
        return returncode

    # æ‰§è¡Œä»»åŠ¡ï¼Œæ”¯æŒé‡è¯•æœºåˆ¶
    max_retries = 1  # æœ€å¤šé‡è¯•1æ¬¡ï¼ˆå³æ€»å…±æ‰§è¡Œ2æ¬¡ï¼‰
    retry_count = 0
    returncode = None
    
    try:
        # ç¬¬ä¸€æ¬¡æ‰§è¡Œ
        returncode = execute_task()
        
        if returncode == 0:
            logging.info(f">>> å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ")
        else:
            logging.warning(f">>> å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡æ‰§è¡Œå®Œæˆä½†è¿”å›éé›¶é€€å‡ºç : {returncode}")
            
            # å¦‚æœè¿”å›éé›¶é€€å‡ºç ï¼Œè¿›è¡Œé‡è¯•
            if retry_count < max_retries:
                retry_count += 1
                logging.warning(f">>> æ£€æµ‹åˆ°éé›¶é€€å‡ºç ï¼Œå°†åœ¨ 5 ç§’åè‡ªåŠ¨é‡è¯•ä¸€æ¬¡å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡...")
                time.sleep(5)  # é‡è¯•å‰ç­‰å¾…5ç§’ï¼Œé¿å…ç«‹å³é‡è¯•
                logging.info(f">>> å¼€å§‹é‡è¯•å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡")
                
                # é‡è¯•æ‰§è¡Œ
                returncode = execute_task()
                
                if returncode == 0:
                    logging.info(f">>> å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡é‡è¯•æˆåŠŸ")
                else:
                    logging.warning(f">>> å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡é‡è¯•å®Œæˆä½†è¿”å›éé›¶é€€å‡ºç : {returncode}")
        
        # å®šæ—¶ä»»åŠ¡æ‰§è¡Œå®Œæ¯•åï¼Œé€šçŸ¥å‰ç«¯æ›´æ–°ï¼ˆåŒ…æ‹¬å·²è½¬å­˜é›†æ•°å’Œå½“æ—¥æ›´æ–°æ ‡è¯†ï¼‰
        # æ³¨æ„ï¼šæ¯ä¸ªè½¬å­˜æˆåŠŸæ—¶å·²ç»é€šè¿‡ /api/calendar/metrics/sync_task æ›´æ–°äº†æ•°æ®åº“å¹¶å‘é€äº†é€šçŸ¥
        # è¿™é‡Œåªéœ€è¦å‘é€ä¸€ä¸ªæ€»ä½“çš„å®Œæˆé€šçŸ¥ï¼Œè®©å‰ç«¯çŸ¥é“å®šæ—¶ä»»åŠ¡å·²å®Œæˆï¼Œå¯ä»¥ç»Ÿä¸€åˆ·æ–°æ•°æ®
        try:
            notify_calendar_changed('crontab_task_completed')
            logging.debug(f">>> å·²é€šçŸ¥å‰ç«¯æ›´æ–°å·²è½¬å­˜é›†æ•°å’Œå½“æ—¥æ›´æ–°æ ‡è¯†ï¼ˆå®šæ—¶ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼‰")
        except Exception as e:
            logging.warning(f">>> é€šçŸ¥å‰ç«¯æ›´æ–°å·²è½¬å­˜é›†æ•°å’Œå½“æ—¥æ›´æ–°æ ‡è¯†å¤±è´¥: {e}")
    except Exception as e:
        logging.error(f">>> å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {str(e)}")
        import traceback
        logging.error(f">>> å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
    finally:
        # ä»»åŠ¡å®Œæˆï¼Œæ¸…é™¤è¿›ç¨‹å¯¹è±¡
        _crontab_task_process = None


# é‡æ–°åŠ è½½ä»»åŠ¡
def reload_tasks():
    global _last_crontab, _last_crontab_delay
    # è¯»å–å®šæ—¶è§„åˆ™
    if crontab := config_data.get("crontab"):
        if scheduler.state == 1:
            scheduler.pause()  # æš‚åœè°ƒåº¦å™¨
        trigger = CronTrigger.from_crontab(crontab)
        scheduler.remove_all_jobs()
        scheduler.add_job(
            run_python,
            trigger=trigger,
            args=[f"{SCRIPT_PATH} {CONFIG_PATH}"],
            id=SCRIPT_PATH,
            misfire_grace_time=None,
            coalesce=True,
            max_instances=1,
        )
        if scheduler.state == 0:
            scheduler.start()
        elif scheduler.state == 2:
            scheduler.resume()
        
        # è¯»å–å»¶è¿Ÿæ‰§è¡Œè®¾ç½®
        delay = config_data.get("crontab_delay")
        delay_str = str(delay) if delay is not None else None
        
        # ä»…åœ¨é…ç½®çœŸæ­£æ”¹å˜æ—¶è¾“å‡ºæ—¥å¿—ï¼ˆé¿å…é‡å¤è¾“å‡ºï¼‰
        crontab_changed = (_last_crontab != crontab)
        delay_changed = (_last_crontab_delay != delay_str)
        
        if crontab_changed or delay_changed:
            scheduler_state_map = {0: "åœæ­¢", 1: "è¿è¡Œ", 2: "æš‚åœ"}
            logging.info(">>> é‡è½½è°ƒåº¦å™¨")
            logging.info(f"è°ƒåº¦çŠ¶æ€: {scheduler_state_map[scheduler.state]}")
            # åˆå¹¶è¾“å‡ºï¼šå®šæ—¶è§„åˆ™ + ä»»åŠ¡è¯´æ˜
            logging.info(f"å·²å¯åŠ¨å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡ï¼Œå®šæ—¶è§„åˆ™ {crontab}")
            # è®°å½•å»¶è¿Ÿæ‰§è¡Œè®¾ç½®
            if delay:
                logging.info(f"å»¶è¿Ÿæ‰§è¡Œ: 0-{delay}ç§’")
            # æ›´æ–°è®°å½•çš„å€¼
            _last_crontab = crontab
            _last_crontab_delay = delay_str

        # æ¯æ¬¡ reload_tasks() ä¼šè°ƒç”¨ scheduler.remove_all_jobs()ï¼Œä¼šæŠŠâ€œæŒ‰æ’­å‡ºæ—¶é—´â€çš„ DateTrigger ä¸€èµ·æ¸…æ‰ã€‚
        # è¿™é‡Œå‚è€ƒ __main__ ä¸­çš„å¯åŠ¨æµç¨‹ï¼Œåœ¨é‡è½½åç«‹å³é‡æ–°æ³¨å†Œï¼š
        try:
            restart_calendar_refresh_job()
        except Exception:
            pass
        try:
            restart_daily_aired_update_job()
        except Exception:
            pass
        try:
            # é‡æ–°è®¡ç®—å¹¶æ³¨å†Œæ‰€æœ‰èŠ‚ç›®/æŒ‡å®šèŠ‚ç›®çš„â€œæ’­å‡ºçŠ¶æ€åˆ·æ–°ä»»åŠ¡â€
            _trigger_airtime_reschedule('startup')
        except Exception:
            pass

        # ä¸å†å†—ä½™è¾“å‡ºç°æœ‰ä»»åŠ¡åˆ—è¡¨
        return True
    else:
        # crontab è¢«ç§»é™¤çš„æƒ…å†µ
        if _last_crontab is not None:
            logging.info(">>> no crontab")
            _last_crontab = None
            _last_crontab_delay = None
        return False


def init():
    global config_data, task_plugins_config_default
    logging.info(f">>> åˆå§‹åŒ–é…ç½®")
    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(CONFIG_PATH):
        if not os.path.exists(os.path.dirname(CONFIG_PATH)):
            os.makedirs(os.path.dirname(CONFIG_PATH))
        with open("quark_config.json", "rb") as src, open(CONFIG_PATH, "wb") as dest:
            dest.write(src.read())

    # è¯»å–é…ç½®
    config_data = Config.read_json(CONFIG_PATH)
    Config.breaking_change_update(config_data)
    
    # è‡ªåŠ¨æ¸…ç†å‰§é›†è¯†åˆ«è§„åˆ™é…ç½®
    cleanup_episode_patterns_config(config_data)

    # é»˜è®¤ç®¡ç†è´¦å·
    config_data["webui"] = {
        "username": os.environ.get("WEBUI_USERNAME")
        or config_data.get("webui", {}).get("username", "admin"),
        "password": os.environ.get("WEBUI_PASSWORD")
        or config_data.get("webui", {}).get("password", "admin"),
    }

    # é»˜è®¤å®šæ—¶è§„åˆ™
    if not config_data.get("crontab"):
        config_data["crontab"] = "0 8,18,20 * * *"
    
    # é»˜è®¤å»¶è¿Ÿæ‰§è¡Œè®¾ç½®
    if "crontab_delay" not in config_data:
        config_data["crontab_delay"] = 0
    
    # é»˜è®¤æ‰§è¡Œå‘¨æœŸæ¨¡å¼è®¾ç½®
    if "execution_mode" not in config_data:
        config_data["execution_mode"] = "manual"

    # åˆå§‹åŒ–è¿½å‰§æ—¥å†æ—¶åŒºæ¨¡å¼ï¼ˆåŸå§‹æ—¶åŒº / æœ¬åœ°æ—¶åŒºï¼‰
    if "calendar_timezone_mode" not in config_data:
        config_data["calendar_timezone_mode"] = "original"
    # åˆå§‹åŒ–æœ¬åœ°æ—¶åŒºï¼ˆç”¨äº Trakt æ’­å‡ºæ—¶é—´è½¬æ¢ä¸æœ¬åœ°æ—¶é—´åˆ¤æ–­ï¼‰
    if "local_timezone" not in config_data:
        # é»˜è®¤æŒ‰ç…§åŒ—äº¬æ—¶é—´å¤„ç†ï¼Œä¹Ÿæ”¯æŒç”¨æˆ·åç»­åœ¨é…ç½®æ–‡ä»¶ä¸­æ‰‹åŠ¨ä¿®æ”¹
        config_data["local_timezone"] = "Asia/Shanghai"

    # åˆå§‹åŒ– Trakt é…ç½®ï¼ˆä»…å­˜å‚¨ Client IDï¼Œç”¨äºè°ƒç”¨èŠ‚ç›®æ’­å‡ºæ—¶é—´ APIï¼‰
    if "trakt" not in config_data or not isinstance(config_data.get("trakt"), dict):
        config_data["trakt"] = {"client_id": ""}
    else:
        config_data["trakt"].setdefault("client_id", "")

    # åˆå§‹åŒ–æ’ä»¶é…ç½®
    _, plugins_config_default, task_plugins_config_default = Config.load_plugins()
    plugins_config_default.update(config_data.get("plugins", {}))
    config_data["plugins"] = plugins_config_default
    
    # è·å–ç¦ç”¨çš„æ’ä»¶åˆ—è¡¨
    disabled_plugins = set()
    if PLUGIN_FLAGS:
        disabled_plugins = {name.lstrip('-') for name in PLUGIN_FLAGS.split(',')}
    
    # æ¸…ç†æ‰€æœ‰ä»»åŠ¡ä¸­è¢«ç¦ç”¨æ’ä»¶çš„é…ç½®
    if config_data.get("tasklist"):
        for task in config_data["tasklist"]:
            if "addition" in task:
                for plugin_name in list(task["addition"].keys()):
                    if plugin_name in disabled_plugins:
                        del task["addition"][plugin_name]
    
    # åˆå§‹åŒ–æ’ä»¶é…ç½®æ¨¡å¼ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if "plugin_config_mode" not in config_data:
        config_data["plugin_config_mode"] = {
            "aria2": "independent",
            "alist_strm_gen": "independent",
            "emby": "independent"
        }
    
    # åˆå§‹åŒ–å…¨å±€æ’ä»¶é…ç½®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if "global_plugin_config" not in config_data:
        config_data["global_plugin_config"] = {
            "aria2": {
                "auto_download": True,
                "pause": False,
                "auto_delete_quark_files": False
            },
            "alist_strm_gen": {
                "auto_gen": True
            },
            "emby": {
                "try_match": True,
                "media_id": ""
            }
        }

    # åˆå§‹åŒ–æ¨é€é€šçŸ¥ç±»å‹é…ç½®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if "push_notify_type" not in config_data:
        config_data["push_notify_type"] = "full"

    # åŒæ­¥æ›´æ–°ä»»åŠ¡çš„æ’ä»¶é…ç½®
    sync_task_plugins_config()

    # æ›´æ–°é…ç½®
    Config.write_json(CONFIG_PATH, config_data)


# è·å–å†å²è½¬å­˜è®°å½•
@app.route("/history_records")
def get_history_records():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
        
    # è·å–è¯·æ±‚å‚æ•°
    page = int(request.args.get("page", 1))
    page_size = int(request.args.get("page_size", 20))
    sort_by = request.args.get("sort_by", "transfer_time")
    order = request.args.get("order", "desc")
    
    # è·å–ç­›é€‰å‚æ•°
    task_name_filter = request.args.get("task_name", "")
    keyword_filter = request.args.get("keyword", "")
    task_names_raw = request.args.get("task_names", "")
    task_name_list = []
    if task_names_raw:
        try:
            decoded_names = json.loads(task_names_raw)
            if isinstance(decoded_names, list):
                task_name_list = [
                    str(name).strip() for name in decoded_names
                    if isinstance(name, (str, bytes)) and str(name).strip()
                ]
        except Exception:
            task_name_list = []
    
    # æ˜¯å¦åªè¯·æ±‚æ‰€æœ‰ä»»åŠ¡åç§°
    get_all_task_names = request.args.get("get_all_task_names", "").lower() in ["true", "1", "yes"]
    
    # åˆå§‹åŒ–æ•°æ®åº“
    db = RecordDB()
    
    # å¦‚æœè¯·æ±‚æ‰€æœ‰ä»»åŠ¡åç§°ï¼Œå•ç‹¬æŸ¥è¯¢å¹¶è¿”å›
    if get_all_task_names:
        cursor = db.conn.cursor()
        cursor.execute("SELECT DISTINCT task_name FROM transfer_records WHERE task_name NOT IN ('rename', 'undo_rename') ORDER BY task_name")
        all_task_names = [row[0] for row in cursor.fetchall()]
        
        # å¦‚æœåŒæ—¶è¯·æ±‚åˆ†é¡µæ•°æ®ï¼Œç»§ç»­å¸¸è§„æŸ¥è¯¢
        if page > 0 and page_size > 0:
            result = db.get_records(
                page=page, 
                page_size=page_size, 
                sort_by=sort_by, 
                order=order,
                task_name_filter=task_name_filter,
                keyword_filter=keyword_filter,
                task_name_list=task_name_list,
                exclude_task_names=["rename", "undo_rename"]
            )
            # æ·»åŠ æ‰€æœ‰ä»»åŠ¡åç§°åˆ°ç»“æœä¸­
            result["all_task_names"] = all_task_names
            
            # å¤„ç†è®°å½•æ ¼å¼åŒ–
            format_records(result["records"])
            
            return jsonify({"success": True, "data": result})
        else:
            # åªè¿”å›ä»»åŠ¡åç§°
            return jsonify({"success": True, "data": {"all_task_names": all_task_names}})
    
    # å¸¸è§„æŸ¥è¯¢
    result = db.get_records(
        page=page, 
        page_size=page_size, 
        sort_by=sort_by, 
        order=order,
        task_name_filter=task_name_filter,
        keyword_filter=keyword_filter,
        task_name_list=task_name_list,
        exclude_task_names=["rename", "undo_rename"]
    )
    
    # å¤„ç†è®°å½•æ ¼å¼åŒ–
    format_records(result["records"])
    
    return jsonify({"success": True, "data": result})


# åˆ é™¤è½¬å­˜è®°å½•
@app.route("/delete_history_records", methods=["POST"])
def delete_history_records():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    # è·å–è¦åˆ é™¤çš„è®°å½•IDåˆ—è¡¨
    record_ids = request.json.get("record_ids", [])
    
    if not record_ids:
        return jsonify({"success": False, "message": "æœªæä¾›è¦åˆ é™¤çš„è®°å½•ID"})
    
    # åˆå§‹åŒ–æ•°æ®åº“
    db = RecordDB()
    
    # åˆ é™¤è®°å½•
    deleted_count = 0
    for record_id in record_ids:
        deleted_count += db.delete_record(record_id)

    # çƒ­æ›´æ–°ï¼šæŒ‰è®°å½• id åæŸ¥ä»»åŠ¡åå¹¶é‡ç®—è¿›åº¦
    try:
        if deleted_count > 0:
            cursor = db.conn.cursor()
            placeholders = ','.join(['?'] * len(record_ids)) if record_ids else ''
            if placeholders:
                cursor.execute(f"SELECT DISTINCT task_name FROM transfer_records WHERE id IN ({placeholders})", record_ids)
                task_names = [row[0] for row in (cursor.fetchall() or []) if row and row[0]]
                for tn in task_names:
                    recompute_task_metrics_and_notify(tn)
    except Exception:
        pass

    # å¹¿æ’­é€šçŸ¥ï¼šæœ‰è®°å½•è¢«åˆ é™¤ï¼Œè§¦å‘å‰ç«¯åˆ·æ–°ä»»åŠ¡/æ—¥å†
    try:
        if deleted_count > 0:
            notify_calendar_changed('delete_records')
    except Exception:
        pass

    return jsonify({
        "success": True,
        "message": f"æˆåŠŸåˆ é™¤ {deleted_count} æ¡è®°å½•",
        "deleted_count": deleted_count
    })


# è·å–ä»»åŠ¡æœ€æ–°è½¬å­˜ä¿¡æ¯ï¼ˆåŒ…æ‹¬æ—¥æœŸå’Œæ–‡ä»¶ï¼‰
@app.route("/task_latest_info")
def get_task_latest_info():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    try:
        # åˆå§‹åŒ–æ•°æ®åº“
        db = RecordDB()
        cursor = db.conn.cursor()

        # è·å–æ‰€æœ‰ä»»åŠ¡çš„æœ€æ–°è½¬å­˜æ—¶é—´
        query = """
        SELECT task_name, MAX(transfer_time) as latest_transfer_time
        FROM transfer_records
        WHERE task_name NOT IN ('rename', 'undo_rename')
        GROUP BY task_name
        """
        cursor.execute(query)
        latest_times = cursor.fetchall()

        task_latest_records = {}  # å­˜å‚¨æœ€æ–°è½¬å­˜æ—¥æœŸ
        task_latest_files = {}    # å­˜å‚¨æœ€æ–°è½¬å­˜æ–‡ä»¶

        for task_name, latest_time in latest_times:
            if latest_time:
                # 1. å¤„ç†æœ€æ–°è½¬å­˜æ—¥æœŸ
                try:
                    # ç¡®ä¿æ—¶é—´æˆ³åœ¨åˆç†èŒƒå›´å†…
                    timestamp = int(latest_time)
                    if timestamp > 9999999999:  # æ£€æµ‹æ˜¯å¦ä¸ºæ¯«ç§’çº§æ—¶é—´æˆ³ï¼ˆ13ä½ï¼‰
                        timestamp = timestamp / 1000  # è½¬æ¢ä¸ºç§’çº§æ—¶é—´æˆ³

                    if 0 < timestamp < 4102444800:  # ä»1970å¹´åˆ°2100å¹´çš„åˆç†æ—¶é—´æˆ³èŒƒå›´
                        # æ ¼å¼åŒ–ä¸ºæœˆ-æ—¥æ ¼å¼ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰å’Œå®Œæ•´æ—¥æœŸï¼ˆç”¨äºä»Šæ—¥åˆ¤æ–­ï¼‰
                        date_obj = datetime.fromtimestamp(timestamp)
                        formatted_date = date_obj.strftime("%m-%d")
                        full_date = date_obj.strftime("%Y-%m-%d")
                        task_latest_records[task_name] = {
                            "display": formatted_date,  # æ˜¾ç¤ºç”¨çš„ MM-DD æ ¼å¼
                            "full": full_date          # æ¯”è¾ƒç”¨çš„ YYYY-MM-DD æ ¼å¼
                        }
                except (ValueError, TypeError, OverflowError):
                    pass  # å¿½ç•¥æ— æ•ˆçš„æ—¶é—´æˆ³

                # 2. å¤„ç†æœ€æ–°è½¬å­˜æ–‡ä»¶
                # è·å–è¯¥ä»»åŠ¡åœ¨æœ€æ–°è½¬å­˜æ—¶é—´é™„è¿‘ï¼ˆåŒä¸€åˆ†é’Ÿå†…ï¼‰çš„æ‰€æœ‰æ–‡ä»¶
                # è¿™æ ·å¯ä»¥å¤„ç†åŒæ—¶è½¬å­˜å¤šä¸ªæ–‡ä»¶ä½†æ—¶é—´æˆ³ç•¥æœ‰å·®å¼‚çš„æƒ…å†µ
                time_window = 60000  # 60ç§’çš„æ—¶é—´çª—å£ï¼ˆæ¯«ç§’ï¼‰
                query = """
                SELECT renamed_to, original_name, transfer_time, modify_date
                FROM transfer_records
                WHERE task_name = ? AND transfer_time >= ? AND transfer_time <= ?
                ORDER BY id DESC
                """
                cursor.execute(query, (task_name, latest_time - time_window, latest_time + time_window))
                files = cursor.fetchall()

                if files:
                    if len(files) == 1:
                        # å¦‚æœåªæœ‰ä¸€ä¸ªæ–‡ä»¶ï¼Œç›´æ¥ä½¿ç”¨
                        best_file = files[0][0]  # renamed_to
                    else:
                        # å¦‚æœæœ‰å¤šä¸ªæ–‡ä»¶ï¼Œä½¿ç”¨å…¨å±€æ’åºå‡½æ•°è¿›è¡Œæ’åº
                        file_list = []
                        for renamed_to, original_name, transfer_time, modify_date in files:
                            # æ„é€ æ–‡ä»¶ä¿¡æ¯å­—å…¸ï¼Œæ¨¡æ‹Ÿå…¨å±€æ’åºå‡½æ•°éœ€è¦çš„æ ¼å¼
                            file_info = {
                                'file_name': renamed_to,
                                'original_name': original_name,
                                'updated_at': transfer_time  # ä½¿ç”¨è½¬å­˜æ—¶é—´è€Œä¸æ˜¯æ–‡ä»¶ä¿®æ”¹æ—¶é—´
                            }
                            file_list.append(file_info)

                        # ä½¿ç”¨å…¨å±€æ’åºå‡½æ•°è¿›è¡Œæ­£å‘æ’åºï¼Œæœ€åä¸€ä¸ªå°±æ˜¯æœ€æ–°çš„
                        try:
                            sorted_files = sorted(file_list, key=sort_file_by_name)
                            best_file = sorted_files[-1]['file_name']  # å–æ’åºåçš„æœ€åä¸€ä¸ªæ–‡ä»¶
                        except Exception as e:
                            # å¦‚æœæ’åºå¤±è´¥ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ–‡ä»¶ä½œä¸ºå¤‡é€‰
                            best_file = files[0][0]

                    # å»é™¤æ‰©å±•åå¹¶å¤„ç†å­£æ•°é›†æ•°ä¿¡æ¯
                    if best_file:
                        file_name_without_ext = os.path.splitext(best_file)[0]
                        processed_name = process_season_episode_info(file_name_without_ext, task_name)
                        task_latest_files[task_name] = processed_name

        # æ³¨å…¥"è¿½å‰§æ—¥å†"å±‚é¢çš„ç­¾åä¿¡æ¯ï¼Œä¾¿äºå‰ç«¯åœ¨æ— æ–°å¢è½¬å­˜æ–‡ä»¶æ—¶ä¹Ÿèƒ½æ£€æµ‹åˆ°æ–°å¢/åˆ é™¤å‰§ç›®
        try:
            caldb = CalendarDB()
            cur = caldb.conn.cursor()
            # shows æ•°é‡
            try:
                cur.execute('SELECT COUNT(*) FROM shows')
                shows_count = cur.fetchone()[0] if cur.fetchone is not None else 0
            except Exception:
                shows_count = 0
            # tmdb_id åˆ—è¡¨ï¼ˆæ’åºåæ‹¼æ¥ï¼Œå˜åŒ–å³è§¦å‘å‰ç«¯åˆ·æ–°ï¼‰
            tmdb_sig = ''
            try:
                cur.execute('SELECT tmdb_id FROM shows ORDER BY tmdb_id ASC')
                ids = [str(r[0]) for r in cur.fetchall()]
                tmdb_sig = ','.join(ids)
            except Exception:
                tmdb_sig = ''
            # å†™å…¥åˆ° latest_filesï¼Œä»¥å¤ç”¨å‰ç«¯ç°æœ‰ç­¾åè®¡ç®—é€»è¾‘
            task_latest_files['__calendar_shows__'] = str(shows_count)
            if tmdb_sig:
                task_latest_files['__calendar_tmdb_ids__'] = tmdb_sig
        except Exception:
            pass

        db.close()

        return jsonify({
            "success": True,
            "data": {
                "latest_records": task_latest_records,
                "latest_files": task_latest_files
            }
        })

    except Exception as e:
        return jsonify({
            "success": False,
            "message": f"è·å–ä»»åŠ¡æœ€æ–°ä¿¡æ¯å¤±è´¥: {str(e)}"
        })


# è·å–å½“æ—¥æ›´æ–°çš„å‰§é›†ï¼ˆæœ¬åœ°DBï¼ŒæŒ‰ transfer_records å½“å¤©è®°å½•èšåˆï¼‰
@app.route("/api/calendar/today_updates_local")
def get_calendar_today_updates_local():
    try:
        # è®¡ç®—ä»Šå¤© 00:00:00 ä¸ 23:59:59 çš„æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰èŒƒå›´
        now = datetime.now()
        start_of_day = datetime(now.year, now.month, now.day)
        end_of_day = datetime(now.year, now.month, now.day, 23, 59, 59)
        start_ms = int(start_of_day.timestamp() * 1000)
        end_ms = int(end_of_day.timestamp() * 1000)

        # è¯»å–ä»Šæ—¥çš„è½¬å­˜è®°å½•
        rdb = RecordDB()
        cur = rdb.conn.cursor()
        cur.execute(
            """
            SELECT task_name, renamed_to, original_name, transfer_time
            FROM transfer_records
            WHERE task_name NOT IN ('rename', 'undo_rename')
              AND transfer_time >= ? AND transfer_time <= ?
            ORDER BY id DESC
            """,
            (start_ms, end_ms)
        )
        rows = cur.fetchall() or []

        # å»ºç«‹ task_name -> (tmdb_id, show_name) çš„æ˜ å°„ï¼Œä¼˜å…ˆä½¿ç”¨å·²ç»‘å®šçš„ shows
        tmdb_map = {}
        try:
            cal_db = CalendarDB()
            # shows è¡¨æœ‰ bound_task_namesï¼Œé€æ¡è§£æç»‘å®š
            cur2 = cal_db.conn.cursor()
            cur2.execute('SELECT tmdb_id, name, bound_task_names FROM shows')
            for tmdb_id, name, bound in (cur2.fetchall() or []):
                try:
                    bound_list = []
                    if bound:
                        bound_list = [b.strip() for b in str(bound).split(',') if b and b.strip()]
                    for tname in bound_list:
                        if tname:
                            tmdb_map[tname] = { 'tmdb_id': int(tmdb_id), 'show_name': name or '' }
                except Exception:
                    continue
        except Exception:
            tmdb_map = {}

        # æå–å‰§é›†ç¼–å·/æ—¥æœŸ
        extractor = TaskExtractor()
        items = []
        for task_name, renamed_to, original_name, transfer_time in rows:
            # è§£æè¿›åº¦ä¿¡æ¯
            base_name = os.path.splitext(renamed_to or '')[0]
            parsed = extractor.extract_progress_from_latest_file(base_name)
            season = parsed.get('season_number')
            ep = parsed.get('episode_number')
            air_date = parsed.get('air_date')
            if not season and not ep and not air_date:
                # æ— æ³•è§£æåˆ°æœ‰æ•ˆä¿¡æ¯åˆ™è·³è¿‡
                continue
            bind = tmdb_map.get(task_name, {})
            items.append({
                'task_name': task_name or '',
                'tmdb_id': bind.get('tmdb_id'),
                'show_name': bind.get('show_name') or '',
                'season_number': season,
                'episode_number': ep,
                'air_date': air_date
            })

        return jsonify({ 'success': True, 'data': { 'items': items } })
    except Exception as e:
        return jsonify({ 'success': False, 'message': f'è¯»å–å½“æ—¥æ›´æ–°å¤±è´¥: {str(e)}', 'data': { 'items': [] } })


# åˆ é™¤å•æ¡è½¬å­˜è®°å½•
@app.route("/delete_history_record", methods=["POST"])
def delete_history_record():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    # è·å–è¦åˆ é™¤çš„è®°å½•ID
    record_id = request.json.get("id")
    
    if not record_id:
        return jsonify({"success": False, "message": "æœªæä¾›è¦åˆ é™¤çš„è®°å½•ID"})
    
    # åˆå§‹åŒ–æ•°æ®åº“
    db = RecordDB()
    
    # åˆ é™¤è®°å½•
    deleted = db.delete_record(record_id)
    # çƒ­æ›´æ–°ï¼šæ ¹æ®è®°å½• id åæŸ¥ä»»åŠ¡åå¹¶é‡ç®—è¿›åº¦
    try:
        if deleted:
            cursor = db.conn.cursor()
            cursor.execute('SELECT task_name FROM transfer_records WHERE id = ?', (record_id,))
            row = cursor.fetchone()
            if row and row[0]:
                recompute_task_metrics_and_notify(row[0])
    except Exception:
        pass

    # å¹¿æ’­é€šçŸ¥ï¼šæœ‰è®°å½•è¢«åˆ é™¤ï¼Œè§¦å‘å‰ç«¯åˆ·æ–°ä»»åŠ¡/æ—¥å†
    try:
        if deleted:
            notify_calendar_changed('delete_records')
    except Exception:
        pass

    if deleted:
        return jsonify({
            "success": True, 
            "message": "æˆåŠŸåˆ é™¤ 1 æ¡è®°å½•",
        })
    else:
        return jsonify({
            "success": False, 
            "message": "è®°å½•åˆ é™¤å¤±è´¥ï¼Œå¯èƒ½è®°å½•ä¸å­˜åœ¨",
        })


# è¾…åŠ©å‡½æ•°ï¼šæ ¼å¼åŒ–è®°å½•
def format_records(records):
    for record in records:
        # æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸ºå¯è¯»å½¢å¼
        if "transfer_time" in record:
            try:
                # ç¡®ä¿æ—¶é—´æˆ³åœ¨åˆç†èŒƒå›´å†…
                timestamp = int(record["transfer_time"])
                if timestamp > 9999999999:  # æ£€æµ‹æ˜¯å¦ä¸ºæ¯«ç§’çº§æ—¶é—´æˆ³ï¼ˆ13ä½ï¼‰
                    timestamp = timestamp / 1000  # è½¬æ¢ä¸ºç§’çº§æ—¶é—´æˆ³
                
                if 0 < timestamp < 4102444800:  # ä»1970å¹´åˆ°2100å¹´çš„åˆç†æ—¶é—´æˆ³èŒƒå›´
                    record["transfer_time_readable"] = datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d %H:%M:%S")
                else:
                    record["transfer_time_readable"] = "æ— æ•ˆæ—¥æœŸ"
            except (ValueError, TypeError, OverflowError):
                record["transfer_time_readable"] = "æ— æ•ˆæ—¥æœŸ"
                
        if "modify_date" in record:
            try:
                # ç¡®ä¿æ—¶é—´æˆ³åœ¨åˆç†èŒƒå›´å†…
                timestamp = int(record["modify_date"])
                if timestamp > 9999999999:  # æ£€æµ‹æ˜¯å¦ä¸ºæ¯«ç§’çº§æ—¶é—´æˆ³ï¼ˆ13ä½ï¼‰
                    timestamp = timestamp / 1000  # è½¬æ¢ä¸ºç§’çº§æ—¶é—´æˆ³
                    
                if 0 < timestamp < 4102444800:  # ä»1970å¹´åˆ°2100å¹´çš„åˆç†æ—¶é—´æˆ³èŒƒå›´
                    record["modify_date_readable"] = datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d %H:%M:%S")
                else:
                    record["modify_date_readable"] = "æ— æ•ˆæ—¥æœŸ"
            except (ValueError, TypeError, OverflowError):
                record["modify_date_readable"] = "æ— æ•ˆæ—¥æœŸ"
                
        # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
        if "file_size" in record:
            try:
                record["file_size_readable"] = format_bytes(int(record["file_size"]))
            except (ValueError, TypeError):
                record["file_size_readable"] = "æœªçŸ¥å¤§å°"


@app.route("/get_user_info")
def get_user_info():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    user_info_list = []
    for idx, cookie in enumerate(config_data["cookie"]):
        account = Quark(cookie, idx)
        account_info = account.init()
        if account_info:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç§»åŠ¨ç«¯å‚æ•°
            has_mparam = bool(account.mparam)
            user_info_list.append({
                "index": idx,
                "nickname": account_info["nickname"],
                "is_active": account.is_active,
                "has_mparam": has_mparam
            })
        else:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç§»åŠ¨ç«¯å‚æ•°
            has_mparam = bool(account.mparam)
            user_info_list.append({
                "index": idx,
                "nickname": "",
                "is_active": False,
                "has_mparam": has_mparam
            })

    return jsonify({"success": True, "data": user_info_list})


@app.route("/get_accounts_detail")
def get_accounts_detail():
    """è·å–æ‰€æœ‰è´¦å·çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ˜µç§°å’Œç©ºé—´ä½¿ç”¨æƒ…å†µ"""
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    accounts_detail = []
    for idx, cookie in enumerate(config_data["cookie"]):
        account = Quark(cookie, idx)
        account_info = account.init()

        # å¦‚æœæ— æ³•è·å–è´¦å·ä¿¡æ¯ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ç§»åŠ¨ç«¯å‚æ•°
        if not account_info:
            has_mparam = bool(account.mparam)
            # å¦‚æœåªæœ‰ç§»åŠ¨ç«¯å‚æ•°ï¼Œè·³è¿‡æ­¤è´¦å·ï¼ˆä¸æ˜¾ç¤ºåœ¨æ–‡ä»¶æ•´ç†é¡µé¢çš„è´¦å·é€‰æ‹©æ ä¸­ï¼‰
            if has_mparam:
                continue
            else:
                # å¦‚æœæ—¢æ²¡æœ‰è´¦å·ä¿¡æ¯ä¹Ÿæ²¡æœ‰ç§»åŠ¨ç«¯å‚æ•°ï¼Œæ˜¾ç¤ºä¸ºæœªç™»å½•
                account_detail = {
                    "index": idx,
                    "nickname": "",
                    "is_active": False,
                    "used_space": 0,
                    "total_space": 0,
                    "usage_rate": 0,
                    "display_text": f"è´¦å·{idx + 1}ï¼ˆæœªç™»å½•ï¼‰"
                }
                accounts_detail.append(account_detail)
                continue

        # æˆåŠŸè·å–è´¦å·ä¿¡æ¯çš„æƒ…å†µ
        account_detail = {
            "index": idx,
            "nickname": account_info["nickname"],
            "is_active": account.is_active,
            "used_space": 0,
            "total_space": 0,
            "usage_rate": 0,
            "display_text": ""
        }

        # æ£€æŸ¥æ˜¯å¦æœ‰ç§»åŠ¨ç«¯å‚æ•°
        has_mparam = bool(account.mparam)
        
        if has_mparam:
            # åŒæ—¶æœ‰cookieå’Œç§»åŠ¨ç«¯å‚æ•°ï¼Œå°è¯•è·å–ç©ºé—´ä¿¡æ¯
            try:
                growth_info = account.get_growth_info()
                if growth_info:
                    total_capacity = growth_info.get("total_capacity", 0)
                    account_detail["total_space"] = total_capacity
                    # æ˜¾ç¤ºæ˜µç§°å’Œæ€»å®¹é‡
                    total_str = format_bytes(total_capacity)
                    account_detail["display_text"] = f"{account_info['nickname']} Â· {total_str}"
                else:
                    # è·å–ç©ºé—´ä¿¡æ¯å¤±è´¥ï¼Œåªæ˜¾ç¤ºæ˜µç§°
                    account_detail["display_text"] = account_info["nickname"]
            except Exception as e:
                logging.error(f"è·å–è´¦å· {idx} ç©ºé—´ä¿¡æ¯å¤±è´¥: {str(e)}")
                # è·å–ç©ºé—´ä¿¡æ¯å¤±è´¥ï¼Œåªæ˜¾ç¤ºæ˜µç§°
                account_detail["display_text"] = account_info["nickname"]
        else:
            # åªæœ‰cookieï¼Œæ²¡æœ‰ç§»åŠ¨ç«¯å‚æ•°ï¼Œåªæ˜¾ç¤ºæ˜µç§°
            account_detail["display_text"] = account_info["nickname"]

        accounts_detail.append(account_detail)

    return jsonify({"success": True, "data": accounts_detail})


# é‡ç½®æ–‡ä»¶å¤¹ï¼ˆåˆ é™¤æ–‡ä»¶å¤¹å†…æ‰€æœ‰æ–‡ä»¶å’Œç›¸å…³è®°å½•ï¼‰
@app.route("/reset_folder", methods=["POST"])
def reset_folder():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    # è·å–è¯·æ±‚å‚æ•°
    save_path = request.json.get("save_path", "")
    account_index = int(request.json.get("account_index", 0))  # æ–°å¢è´¦å·ç´¢å¼•å‚æ•°

    if not save_path:
        return jsonify({"success": False, "message": "ä¿å­˜è·¯å¾„ä¸èƒ½ä¸ºç©º"})

    try:
        # éªŒè¯è´¦å·ç´¢å¼•
        if account_index < 0 or account_index >= len(config_data["cookie"]):
            return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

        # åˆå§‹åŒ–å¤¸å…‹ç½‘ç›˜å®¢æˆ·ç«¯
        account = Quark(config_data["cookie"][account_index], account_index)
        
        # 1. è·å–æ–‡ä»¶å¤¹ID
        # å…ˆæ£€æŸ¥æ˜¯å¦å·²æœ‰ç¼“å­˜çš„æ–‡ä»¶å¤¹ID
        folder_fid = account.savepath_fid.get(save_path)
        
        # å¦‚æœæ²¡æœ‰ç¼“å­˜çš„IDï¼Œåˆ™å°è¯•åˆ›å»ºæ–‡ä»¶å¤¹ä»¥è·å–ID
        if not folder_fid:
            mkdir_result = account.mkdir(save_path)
            if mkdir_result.get("code") == 0:
                folder_fid = mkdir_result["data"]["fid"]
                account.savepath_fid[save_path] = folder_fid
            else:
                return jsonify({"success": False, "message": f"è·å–æ–‡ä»¶å¤¹IDå¤±è´¥: {mkdir_result.get('message', 'æœªçŸ¥é”™è¯¯')}"})
        
        # 2. è·å–æ–‡ä»¶å¤¹å†…çš„æ‰€æœ‰æ–‡ä»¶
        file_list = account.ls_dir(folder_fid)
        if isinstance(file_list, dict) and file_list.get("error"):
            return jsonify({"success": False, "message": f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {file_list.get('error', 'æœªçŸ¥é”™è¯¯')}"})
        
        # æ”¶é›†æ‰€æœ‰æ–‡ä»¶ID
        file_ids = []
        for item in file_list:
            file_ids.append(item["fid"])
        
        # 3. åˆ é™¤æ‰€æœ‰æ–‡ä»¶
        deleted_files = 0
        if file_ids:
            delete_result = account.delete(file_ids)
            if delete_result.get("code") == 0:
                deleted_files = len(file_ids)
        
        # 4. åˆ é™¤ç›¸å…³çš„å†å²è®°å½•
        deleted_records = 0
        try:
            # åˆå§‹åŒ–æ•°æ®åº“
            db = RecordDB()
            
            # æŸ¥è¯¢ä¸è¯¥ä¿å­˜è·¯å¾„ç›¸å…³çš„æ‰€æœ‰è®°å½•
            cursor = db.conn.cursor()
            cursor.execute("SELECT id FROM transfer_records WHERE save_path = ?", (save_path,))
            record_ids = [row[0] for row in cursor.fetchall()]
            
            # åˆ é™¤æ‰¾åˆ°çš„æ‰€æœ‰è®°å½•
            for record_id in record_ids:
                deleted_records += db.delete_record(record_id)
            # çƒ­æ›´æ–°ï¼šæŒ‰ä¿å­˜è·¯å¾„æ¨æ–­ä»»åŠ¡åé›†åˆå¹¶è§¦å‘è¿›åº¦é‡ç®—
            try:
                if deleted_records > 0:
                    cursor.execute("SELECT DISTINCT task_name FROM transfer_records WHERE save_path = ?", (save_path,))
                    task_names = [row[0] for row in (cursor.fetchall() or []) if row and row[0]]
                    for tn in task_names:
                        recompute_task_metrics_and_notify(tn)
            except Exception:
                pass
                
        except Exception as e:
            logging.error(f">>> åˆ é™¤è®°å½•æ—¶å‡ºé”™: {str(e)}")
            # å³ä½¿åˆ é™¤è®°å½•å¤±è´¥ï¼Œä¹Ÿè¿”å›æ–‡ä»¶åˆ é™¤æˆåŠŸ
        
        # æˆåŠŸåé€šè¿‡ SSE é€šçŸ¥å‰ç«¯è¿›è¡Œçƒ­æ›´æ–°
        try:
            notify_calendar_changed('reset_folder')
        except Exception:
            pass

        return jsonify({
            "success": True, 
            "message": f"é‡ç½®æˆåŠŸï¼Œåˆ é™¤äº† {deleted_files} ä¸ªæ–‡ä»¶å’Œ {deleted_records} æ¡è®°å½•",
            "deleted_files": deleted_files,
            "deleted_records": deleted_records
        })
        
    except Exception as e:
        logging.error(f">>> é‡ç½®æ–‡ä»¶å¤¹æ—¶å‡ºé”™: {str(e)}")
        return jsonify({"success": False, "message": f"é‡ç½®æ–‡ä»¶å¤¹æ—¶å‡ºé”™: {str(e)}"})


# è·å–æ–‡ä»¶åˆ—è¡¨
@app.route("/file_list")
def get_file_list():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    # è·å–è¯·æ±‚å‚æ•°
    folder_id = request.args.get("folder_id", "root")
    sort_by = request.args.get("sort_by", "file_name")
    order = request.args.get("order", "asc")
    page = int(request.args.get("page", 1))
    page_size = int(request.args.get("page_size", 15))
    account_index = int(request.args.get("account_index", 0))
    force_refresh = request.args.get("force_refresh", "false").lower() == "true"  # æ–°å¢è´¦å·ç´¢å¼•å‚æ•°

    try:
        # éªŒè¯è´¦å·ç´¢å¼•
        if account_index < 0 or account_index >= len(config_data["cookie"]):
            return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

        # åˆå§‹åŒ–å¤¸å…‹ç½‘ç›˜å®¢æˆ·ç«¯
        account = Quark(config_data["cookie"][account_index], account_index)

        # è·å–æ–‡ä»¶åˆ—è¡¨
        if folder_id == "root":
            folder_id = "0"  # æ ¹ç›®å½•çš„IDä¸º0
            paths = []  # æ ¹ç›®å½•æ²¡æœ‰è·¯å¾„
        else:
            # è·å–å½“å‰æ–‡ä»¶å¤¹çš„è·¯å¾„
            paths = account.get_paths(folder_id)

        # è·å–æ€§èƒ½é…ç½®
        perf_config = get_performance_config()
        api_page_size = perf_config.get("api_page_size", 200)
        cache_expire_time = perf_config.get("cache_expire_time", 30)

        # ç¼“å­˜é”®
        cache_key = f"{account_index}_{folder_id}_{sort_by}_{order}"
        current_time = time.time()

        # æ£€æŸ¥ç¼“å­˜ï¼ˆé™¤éå¼ºåˆ¶åˆ·æ–°ï¼‰
        if not force_refresh:
            with cache_lock:
                if cache_key in file_list_cache:
                    cache_data, cache_time = file_list_cache[cache_key]
                    if current_time - cache_time < cache_expire_time:
                        # ä½¿ç”¨ç¼“å­˜æ•°æ®
                        cached_files = cache_data
                        total = len(cached_files)
                        start_idx = (page - 1) * page_size
                        end_idx = min(start_idx + page_size, total)
                        paginated_files = cached_files[start_idx:end_idx]

                        return jsonify({
                            "success": True,
                            "data": {
                                "list": paginated_files,
                                "total": total,
                                "paths": paths
                            }
                        })
        else:
            # å¼ºåˆ¶åˆ·æ–°æ—¶ï¼Œæ¸…é™¤å½“å‰ç›®å½•çš„ç¼“å­˜
            with cache_lock:
                if cache_key in file_list_cache:
                    del file_list_cache[cache_key]

        # æ— è®ºåˆ†é¡µè¿˜æ˜¯å…¨éƒ¨æ¨¡å¼ï¼Œéƒ½å¿…é¡»è·å–æ‰€æœ‰æ–‡ä»¶æ‰èƒ½è¿›è¡Œæ­£ç¡®çš„å…¨å±€æ’åº
        files = account.ls_dir(folder_id, page_size=api_page_size)

        if isinstance(files, dict) and files.get("error"):
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®å½•ä¸å­˜åœ¨çš„é”™è¯¯
            error_msg = files.get('error', 'æœªçŸ¥é”™è¯¯')
            if "ä¸å­˜åœ¨" in error_msg or "æ— æ•ˆ" in error_msg or "æ‰¾ä¸åˆ°" in error_msg:
                return jsonify({"success": False, "message": f"ç›®å½•ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®: {error_msg}"})
            else:
                return jsonify({"success": False, "message": f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {error_msg}"})

        # å¤„ç†æ–‡ä»¶å¤¹çš„include_itemså­—æ®µï¼Œç¡®ä¿ç©ºæ–‡ä»¶å¤¹æ˜¾ç¤ºä¸º0é¡¹è€Œä¸æ˜¯undefined
        for file_item in files:
            if file_item.get("dir", False):
                # å¦‚æœæ˜¯æ–‡ä»¶å¤¹ï¼Œç¡®ä¿include_itemså­—æ®µå­˜åœ¨ä¸”ä¸ºæ•°å­—
                if "include_items" not in file_item or file_item["include_items"] is None:
                    file_item["include_items"] = 0
                elif not isinstance(file_item["include_items"], (int, float)):
                    # å¦‚æœinclude_itemsä¸æ˜¯æ•°å­—ç±»å‹ï¼Œå°è¯•è½¬æ¢ä¸ºæ•´æ•°ï¼Œå¤±è´¥åˆ™è®¾ä¸º0
                    try:
                        file_item["include_items"] = int(file_item["include_items"])
                    except (ValueError, TypeError):
                        file_item["include_items"] = 0

        # è®¡ç®—æ€»æ•°
        total = len(files)

        # ä¼˜åŒ–æ’åºï¼šä½¿ç”¨æ›´é«˜æ•ˆçš„æ’åºæ–¹æ³•
        def get_sort_key(file_item):
            if sort_by == "file_name":
                # ä½¿ç”¨æ‹¼éŸ³æ’åº
                return get_filename_pinyin_sort_key(file_item["file_name"])
            elif sort_by == "file_size":
                # æ–‡ä»¶å¤¹æŒ‰é¡¹ç›®æ•°é‡æ’åºï¼Œæ–‡ä»¶æŒ‰å¤§å°æ’åº
                return file_item.get("include_items", 0) if file_item["dir"] else file_item["size"]
            else:  # updated_at
                return file_item["updated_at"]

        # åˆ†ç¦»æ–‡ä»¶å¤¹å’Œæ–‡ä»¶ä»¥ä¼˜åŒ–æ’åº
        if sort_by == "updated_at":
            # ä¿®æ”¹æ—¥æœŸæ’åºæ—¶ä¸¥æ ¼æŒ‰ç…§æ—¥æœŸæ’åºï¼Œä¸åŒºåˆ†æ–‡ä»¶å¤¹å’Œæ–‡ä»¶
            files.sort(key=get_sort_key, reverse=(order == "desc"))
            sorted_files = files
        else:
            # å…¶ä»–æ’åºæ—¶ç›®å½•å§‹ç»ˆåœ¨å‰é¢ï¼Œåˆ†åˆ«æ’åºä»¥æé«˜æ•ˆç‡
            directories = [f for f in files if f["dir"]]
            normal_files = [f for f in files if not f["dir"]]

            directories.sort(key=get_sort_key, reverse=(order == "desc"))
            normal_files.sort(key=get_sort_key, reverse=(order == "desc"))

            sorted_files = directories + normal_files

        # æ›´æ–°ç¼“å­˜
        with cache_lock:
            file_list_cache[cache_key] = (sorted_files, current_time)

        # åˆ†é¡µ
        start_idx = (page - 1) * page_size
        end_idx = min(start_idx + page_size, total)
        paginated_files = sorted_files[start_idx:end_idx]

        return jsonify({
            "success": True,
            "data": {
                "list": paginated_files,
                "total": total,
                "paths": paths
            }
        })
        
    except Exception as e:
        logging.error(f">>> è·å–æ–‡ä»¶åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}")
        return jsonify({"success": False, "message": f"è·å–æ–‡ä»¶åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}"})


# é¢„è§ˆé‡å‘½å
@app.route("/preview_rename")
def preview_rename():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    # è·å–è¯·æ±‚å‚æ•°
    folder_id = request.args.get("folder_id", "root")
    pattern = request.args.get("pattern", "")
    replace = request.args.get("replace", "")
    naming_mode = request.args.get("naming_mode", "regex")  # regex, sequence, episode
    include_folders = request.args.get("include_folders", "false") == "true"
    filterwords = request.args.get("filterwords", "")
    account_index = int(request.args.get("account_index", 0))  # æ–°å¢è´¦å·ç´¢å¼•å‚æ•°

    if not pattern:
        pattern = ".*"

    try:
        # éªŒè¯è´¦å·ç´¢å¼•
        if account_index < 0 or account_index >= len(config_data["cookie"]):
            return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

        # åˆå§‹åŒ–å¤¸å…‹ç½‘ç›˜å®¢æˆ·ç«¯
        account = Quark(config_data["cookie"][account_index], account_index)
        
        # è·å–æ–‡ä»¶åˆ—è¡¨
        if folder_id == "root":
            folder_id = "0"  # æ ¹ç›®å½•çš„IDä¸º0
        
        files = account.ls_dir(folder_id)
        if isinstance(files, dict) and files.get("error"):
            return jsonify({"success": False, "message": f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {files.get('error', 'æœªçŸ¥é”™è¯¯')}"})
        
        # ä½¿ç”¨é«˜çº§è¿‡æ»¤å‡½æ•°è¿‡æ»¤æ–‡ä»¶
        filtered_files = advanced_filter_files(files, filterwords)
        
        # å¦‚æœä¸åŒ…å«æ–‡ä»¶å¤¹ï¼Œè¿›ä¸€æ­¥è¿‡æ»¤æ‰æ–‡ä»¶å¤¹
        if not include_folders:
            filtered_files = [file for file in filtered_files if not file["dir"]]
        
        # æŒ‰ä¸åŒå‘½åæ¨¡å¼å¤„ç†
        preview_results = []
        
        if naming_mode == "sequence":
            # é¡ºåºå‘½åæ¨¡å¼
            # æ’åºæ–‡ä»¶ï¼ˆæŒ‰æ–‡ä»¶åæˆ–ä¿®æ”¹æ—¶é—´ï¼‰
            filtered_files.sort(key=lambda x: sort_file_by_name(x["file_name"]))
            
            sequence = 1
            for file in filtered_files:
                extension = os.path.splitext(file["file_name"])[1] if not file["dir"] else ""
                new_name = pattern.replace("{}", f"{sequence:02d}") + extension
                # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                new_name = apply_subtitle_naming_rule(new_name, config_data["task_settings"])
                preview_results.append({
                    "original_name": file["file_name"],
                    "new_name": new_name,
                    "file_id": file["fid"]
                })
                sequence += 1
                
        elif naming_mode == "episode":
            # å‰§é›†å‘½åæ¨¡å¼
            # è·å–ç”¨æˆ·è¡¥å……çš„å‰§é›†æ¨¡å¼ï¼ˆé»˜è®¤æ¨¡å¼ç”±åç«¯å†…éƒ¨æä¾›ï¼Œè¿™é‡Œåªå¤„ç†ç”¨æˆ·è¡¥å……ï¼‰
            episode_patterns = []
            raw_patterns = config_data.get("episode_patterns", [])
            for p in raw_patterns:
                if isinstance(p, dict) and p.get("regex"):
                    episode_patterns.append(p)
                elif isinstance(p, str):
                    episode_patterns.append({"regex": p})
                
            
            # åº”ç”¨é«˜çº§è¿‡æ»¤è¯è¿‡æ»¤ï¼ˆfilterwords å·²åœ¨å‡½æ•°å¼€å¤´è·å–ï¼‰
            if filterwords:
                # ä½¿ç”¨é«˜çº§è¿‡æ»¤å‡½æ•°
                filtered_files = advanced_filter_files(filtered_files, filterwords)
                # æ ‡è®°è¢«è¿‡æ»¤çš„æ–‡ä»¶
                for item in filtered_files:
                    if item not in filtered_files:
                        item["filtered"] = True
            
            # å¤„ç†æœªè¢«è¿‡æ»¤çš„æ–‡ä»¶
            for file in filtered_files:
                if not file["dir"] and not file.get("filtered"):  # åªå¤„ç†æœªè¢«è¿‡æ»¤çš„éç›®å½•æ–‡ä»¶
                    extension = os.path.splitext(file["file_name"])[1]
                    # ä»æ–‡ä»¶åä¸­æå–é›†å·
                    episode_num = extract_episode_number(file["file_name"], episode_patterns=episode_patterns)

                    if episode_num is not None:
                        new_name = pattern.replace("[]", f"{episode_num:02d}") + extension
                        # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                        new_name = apply_subtitle_naming_rule(new_name, config_data["task_settings"])
                        preview_results.append({
                            "original_name": file["file_name"],
                            "new_name": new_name,
                            "file_id": file["fid"]
                        })
                    else:
                        # æ²¡æœ‰æå–åˆ°é›†å·ï¼Œæ˜¾ç¤ºæ— æ³•è¯†åˆ«çš„æç¤º
                        preview_results.append({
                            "original_name": file["file_name"],
                            "new_name": "Ã— æ— æ³•è¯†åˆ«å‰§é›†ç¼–å·",
                            "file_id": file["fid"]
                        })
        else:
            # æ­£åˆ™å‘½åæ¨¡å¼
            for file in filtered_files:
                try:
                    # åº”ç”¨æ­£åˆ™è¡¨è¾¾å¼
                    if replace:
                        new_name = re.sub(pattern, replace, file["file_name"])
                        # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                        new_name = apply_subtitle_naming_rule(new_name, config_data["task_settings"])
                    else:
                        # å¦‚æœæ²¡æœ‰æä¾›æ›¿æ¢è¡¨è¾¾å¼ï¼Œåˆ™æ£€æŸ¥æ˜¯å¦åŒ¹é…
                        if re.search(pattern, file["file_name"]):
                            new_name = file["file_name"]  # åŒ¹é…ä½†ä¸æ›¿æ¢
                            # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                            new_name = apply_subtitle_naming_rule(new_name, config_data["task_settings"])
                        else:
                            new_name = ""  # è¡¨ç¤ºä¸åŒ¹é…
                            
                    preview_results.append({
                        "original_name": file["file_name"],
                        "new_name": new_name if new_name != file["file_name"] else "",  # å¦‚æœæ²¡æœ‰æ”¹å˜ï¼Œè¿”å›ç©ºè¡¨ç¤ºä¸é‡å‘½å
                        "file_id": file["fid"]
                    })
                except Exception as e:
                    # æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯
                    preview_results.append({
                        "original_name": file["file_name"],
                        "new_name": "",  # è¡¨ç¤ºæ— æ³•é‡å‘½å
                        "file_id": file["fid"],
                        "error": str(e)
                    })
        
        return jsonify({
            "success": True, 
            "data": preview_results
        })
        
    except Exception as e:
        logging.error(f">>> é¢„è§ˆé‡å‘½åæ—¶å‡ºé”™: {str(e)}")
        return jsonify({"success": False, "message": f"é¢„è§ˆé‡å‘½åæ—¶å‡ºé”™: {str(e)}"})


# æ‰¹é‡é‡å‘½å
@app.route("/batch_rename", methods=["POST"])
def batch_rename():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    # è·å–è¯·æ±‚å‚æ•°
    data = request.json
    files = data.get("files", [])
    account_index = int(data.get("account_index", 0))  # æ–°å¢è´¦å·ç´¢å¼•å‚æ•°

    if not files:
        return jsonify({"success": False, "message": "æ²¡æœ‰æ–‡ä»¶éœ€è¦é‡å‘½å"})

    try:
        # éªŒè¯è´¦å·ç´¢å¼•
        if account_index < 0 or account_index >= len(config_data["cookie"]):
            return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

        # åˆå§‹åŒ–å¤¸å…‹ç½‘ç›˜å®¢æˆ·ç«¯
        account = Quark(config_data["cookie"][account_index], account_index)
        
        # æ‰¹é‡é‡å‘½å
        success_count = 0
        failed_files = []
        save_path = data.get("save_path", "")
        batch_time = int(time.time() * 1000)  # æ‰¹æ¬¡æ—¶é—´æˆ³ï¼Œç¡®ä¿åŒä¸€æ‰¹transfer_timeä¸€è‡´
        for file_item in files:
            file_id = file_item.get("file_id")
            new_name = file_item.get("new_name")
            original_name = file_item.get("old_name") or ""
            if file_id and new_name:
                try:
                    result = account.rename(file_id, new_name)
                    if result.get("code") == 0:
                        success_count += 1
                        # è®°å½•é‡å‘½å
                        record_db.add_record(
                            task_name="rename",
                            original_name=original_name,
                            renamed_to=new_name,
                            file_size=0,
                            modify_date=int(time.time()),
                            file_id=file_id,
                            file_type="file",
                            save_path=save_path,
                            transfer_time=batch_time
                        )
                    else:
                        failed_files.append({
                            "file_id": file_id,
                            "new_name": new_name,
                            "error": result.get("message", "æœªçŸ¥é”™è¯¯")
                        })
                except Exception as e:
                    failed_files.append({
                        "file_id": file_id,
                        "new_name": new_name,
                        "error": str(e)
                    })
        
        # å¦‚æœæœ‰æˆåŠŸé‡å‘½åçš„æ–‡ä»¶ï¼Œè§¦å‘SSEé€šçŸ¥
        if success_count > 0:
            notify_calendar_changed('batch_rename_completed')
        
        return jsonify({
            "success": True, 
            "message": f"æˆåŠŸé‡å‘½å {success_count} ä¸ªæ–‡ä»¶ï¼Œå¤±è´¥ {len(failed_files)} ä¸ª",
            "success_count": success_count,
            "failed_files": failed_files
        })
        
    except Exception as e:
        logging.error(f">>> æ‰¹é‡é‡å‘½åæ—¶å‡ºé”™: {str(e)}")
        return jsonify({"success": False, "message": f"æ‰¹é‡é‡å‘½åæ—¶å‡ºé”™: {str(e)}"})


# æ’¤é”€é‡å‘½åæ¥å£
@app.route("/undo_rename", methods=["POST"])
def undo_rename():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    data = request.json
    save_path = data.get("save_path", "")
    account_index = int(data.get("account_index", 0))  # æ–°å¢è´¦å·ç´¢å¼•å‚æ•°

    if not save_path:
        return jsonify({"success": False, "message": "ç¼ºå°‘ç›®å½•å‚æ•°"})

    try:
        # éªŒè¯è´¦å·ç´¢å¼•
        if account_index < 0 or account_index >= len(config_data["cookie"]):
            return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

        account = Quark(config_data["cookie"][account_index], account_index)
        # æŸ¥è¯¢è¯¥ç›®å½•ä¸‹æœ€è¿‘ä¸€æ¬¡é‡å‘½åï¼ˆæŒ‰transfer_timeåˆ†ç»„ï¼Œtask_name=renameï¼‰
        records = record_db.get_records_by_save_path(save_path)
        rename_records = [r for r in records if r["task_name"] == "rename"]
        if not rename_records:
            return jsonify({"success": False, "message": "æ²¡æœ‰å¯æ’¤é”€çš„é‡å‘½åè®°å½•"})
        # æ‰¾åˆ°æœ€è¿‘ä¸€æ‰¹ï¼ˆtransfer_timeæœ€å¤§å€¼ï¼‰
        latest_time = max(r["transfer_time"] for r in rename_records)
        latest_batch = [r for r in rename_records if r["transfer_time"] == latest_time]
        success_count = 0
        failed_files = []
        deleted_ids = []
        for rec in latest_batch:
            file_id = rec["file_id"]
            old_name = rec["original_name"]
            try:
                result = account.rename(file_id, old_name)
                if result.get("code") == 0:
                    success_count += 1
                    deleted_ids.append(rec["id"])
                else:
                    failed_files.append({
                        "file_id": file_id,
                        "old_name": old_name,
                        "error": result.get("message", "æœªçŸ¥é”™è¯¯")
                    })
            except Exception as e:
                failed_files.append({
                    "file_id": file_id,
                    "old_name": old_name,
                    "error": str(e)
                })
        # æ’¤é”€æˆåŠŸçš„ï¼Œç›´æ¥åˆ é™¤å¯¹åº”renameè®°å½•
        for rid in deleted_ids:
            record_db.delete_record(rid)
        return jsonify({
            "success": True,
            "message": f"æˆåŠŸæ’¤é”€ {success_count} ä¸ªæ–‡ä»¶é‡å‘½åï¼Œå¤±è´¥ {len(failed_files)} ä¸ª",
            "success_count": success_count,
            "failed_files": failed_files
        })
    except Exception as e:
        logging.error(f">>> æ’¤é”€é‡å‘½åæ—¶å‡ºé”™: {str(e)}")
        return jsonify({"success": False, "message": f"æ’¤é”€é‡å‘½åæ—¶å‡ºé”™: {str(e)}"})


@app.route("/api/has_rename_record")
def has_rename_record():
    save_path = request.args.get("save_path", "")
    db = RecordDB()
    records = db.get_records_by_save_path(save_path)
    has_rename = any(r["task_name"] == "rename" for r in records)
    return jsonify({"has_rename": has_rename})


# æ‰‹åŠ¨åŒæ­¥ä»»åŠ¡é…ç½®ä¸æ•°æ®åº“ç»‘å®šå…³ç³»
@app.route("/api/calendar/sync_task_config", methods=["POST"])
def sync_task_config_api():
    """æ‰‹åŠ¨è§¦å‘ä»»åŠ¡é…ç½®ä¸æ•°æ®åº“ç»‘å®šå…³ç³»çš„åŒæ­¥"""
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    try:
        success = sync_task_config_with_database_bindings()
        if success:
            return jsonify({"success": True, "message": "åŒæ­¥å®Œæˆ"})
        else:
            return jsonify({"success": False, "message": "æ²¡æœ‰éœ€è¦åŒæ­¥çš„æ•°æ®"})
    except Exception as e:
        return jsonify({"success": False, "message": f"åŒæ­¥å¤±è´¥: {str(e)}"})

# æ‰‹åŠ¨åŒæ­¥å†…å®¹ç±»å‹æ•°æ®
# æ¸…é™¤ä»»åŠ¡åˆ—è¡¨ç¼“å­˜ï¼ˆåœ¨æ•°æ®æ›´æ–°æ—¶è°ƒç”¨ï¼‰
def clear_calendar_tasks_cache():
    """æ¸…é™¤ä»»åŠ¡åˆ—è¡¨ç¼“å­˜ï¼Œå¼ºåˆ¶ä¸‹æ¬¡è¯·æ±‚é‡æ–°åŠ è½½æ•°æ®"""
    global _calendar_tasks_cache
    with _calendar_tasks_cache_lock:
        _calendar_tasks_cache.clear()

# è¿½å‰§æ—¥å†å‰§é›†æ•°æ®ç¼“å­˜æœºåˆ¶
_calendar_episodes_cache = {}
_calendar_episodes_cache_lock = Lock()
_calendar_episodes_cache_ttl = 30  # ç¼“å­˜30ç§’

def clear_calendar_episodes_cache():
    """æ¸…é™¤å‰§é›†æ•°æ®ç¼“å­˜ï¼Œå¼ºåˆ¶ä¸‹æ¬¡è¯·æ±‚é‡æ–°åŠ è½½æ•°æ®"""
    global _calendar_episodes_cache
    with _calendar_episodes_cache_lock:
        _calendar_episodes_cache.clear()

def clear_all_calendar_cache():
    """æ¸…é™¤æ‰€æœ‰è¿½å‰§æ—¥å†ç›¸å…³ç¼“å­˜ï¼ˆä»»åŠ¡åˆ—è¡¨å’Œå‰§é›†æ•°æ®ï¼‰"""
    clear_calendar_tasks_cache()
    clear_calendar_episodes_cache()

@app.route("/api/calendar/sync_content_type", methods=["POST"])
def sync_content_type_api():
    """æ‰‹åŠ¨è§¦å‘å†…å®¹ç±»å‹æ•°æ®åŒæ­¥"""
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    try:
        success = sync_content_type_between_config_and_database()
        if success:
            return jsonify({"success": True, "message": "å†…å®¹ç±»å‹åŒæ­¥å®Œæˆ"})
        else:
            return jsonify({"success": False, "message": "æ²¡æœ‰éœ€è¦åŒæ­¥çš„å†…å®¹ç±»å‹æ•°æ®"})
    except Exception as e:
        return jsonify({"success": False, "message": f"å†…å®¹ç±»å‹åŒæ­¥å¤±è´¥: {str(e)}"})

# è¿½å‰§æ—¥å†APIè·¯ç”± - ç¼“å­˜æœºåˆ¶
_calendar_tasks_cache = {}
_calendar_tasks_cache_lock = Lock()
_calendar_tasks_cache_ttl = 30  # ç¼“å­˜30ç§’
_last_sync_time = 0
_sync_interval = 300  # åŒæ­¥æ“ä½œæ¯5åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡

@app.route("/api/calendar/tasks")
def get_calendar_tasks():
    """è·å–è¿½å‰§æ—¥å†ä»»åŠ¡ä¿¡æ¯ï¼ˆä¼˜åŒ–ç‰ˆï¼šæ·»åŠ ç¼“å­˜å’Œå‡å°‘åŒæ­¥é¢‘ç‡ï¼‰"""
    global _calendar_tasks_cache, _last_sync_time
    
    try:
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
        current_time = time.time()
        cache_key = 'tasks_data'
        
        with _calendar_tasks_cache_lock:
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨ä¸”æœªè¿‡æœŸ
            if cache_key in _calendar_tasks_cache:
                cache_data, cache_time = _calendar_tasks_cache[cache_key]
                if current_time - cache_time < _calendar_tasks_cache_ttl:
                    # ç¼“å­˜æœ‰æ•ˆï¼Œç›´æ¥è¿”å›
                    return jsonify(cache_data)
        
        # è·å–ä»»åŠ¡åˆ—è¡¨
        tasks = config_data.get('tasklist', [])
        
        # è·å–ä»»åŠ¡çš„æœ€è¿‘è½¬å­˜æ–‡ä»¶ä¿¡æ¯
        db = RecordDB()
        cursor = db.conn.cursor()
        
        # è·å–æ‰€æœ‰ä»»åŠ¡çš„æœ€æ–°è½¬å­˜æ—¶é—´ï¼ˆä¼˜åŒ–ï¼šä½¿ç”¨å•ä¸ªæŸ¥è¯¢ï¼‰
        query = """
        SELECT task_name, MAX(transfer_time) as latest_transfer_time
        FROM transfer_records
        WHERE task_name NOT IN ('rename', 'undo_rename')
        GROUP BY task_name
        """
        cursor.execute(query)
        latest_times = cursor.fetchall()
        
        task_latest_files = {}
        
        # æ‰¹é‡æŸ¥è¯¢æ–‡ä»¶ä¿¡æ¯ï¼Œå‡å°‘æ•°æ®åº“æŸ¥è¯¢æ¬¡æ•°
        for task_name, latest_time in latest_times:
            if latest_time:
                # è·å–è¯¥ä»»åŠ¡åœ¨æœ€æ–°è½¬å­˜æ—¶é—´é™„è¿‘çš„æ‰€æœ‰æ–‡ä»¶
                time_window = 60000  # 60ç§’çš„æ—¶é—´çª—å£ï¼ˆæ¯«ç§’ï¼‰
                query = """
                SELECT renamed_to, original_name, transfer_time, modify_date
                FROM transfer_records
                WHERE task_name = ? AND transfer_time >= ? AND transfer_time <= ?
                ORDER BY id DESC
                LIMIT 10
                """
                cursor.execute(query, (task_name, latest_time - time_window, latest_time + time_window))
                files = cursor.fetchall()
                
                if files:
                    if len(files) == 1:
                        best_file = files[0][0]  # renamed_to
                    else:
                        # å¦‚æœæœ‰å¤šä¸ªæ–‡ä»¶ï¼Œä½¿ç”¨å…¨å±€æ’åºå‡½æ•°è¿›è¡Œæ’åº
                        file_list = []
                        for renamed_to, original_name, transfer_time, modify_date in files:
                            file_info = {
                                'file_name': renamed_to,
                                'original_name': original_name,
                                'updated_at': transfer_time
                            }
                            file_list.append(file_info)
                        
                        try:
                            sorted_files = sorted(file_list, key=sort_file_by_name)
                            best_file = sorted_files[-1]['file_name']
                        except Exception:
                            best_file = files[0][0]
                    
                    # å»é™¤æ‰©å±•åå¹¶å¤„ç†å­£æ•°é›†æ•°ä¿¡æ¯
                    if best_file:
                        file_name_without_ext = os.path.splitext(best_file)[0]
                        processed_name = process_season_episode_info(file_name_without_ext, task_name)
                        task_latest_files[task_name] = processed_name
        
        db.close()
        
        try:
            extractor = TaskExtractor()
            tasks_info = extractor.extract_all_tasks_info(tasks, task_latest_files)
        except Exception as e:
            raise
        
        # ä¼˜åŒ–ï¼šå‡å°‘åŒæ­¥æ“ä½œé¢‘ç‡ï¼Œåªåœ¨å¿…è¦æ—¶æ‰§è¡Œï¼ˆæ¯5åˆ†é’Ÿæœ€å¤šæ‰§è¡Œä¸€æ¬¡ï¼‰
        # è¿™æ ·å¯ä»¥é¿å…æ¯æ¬¡è¯·æ±‚éƒ½æ‰§è¡Œè€—æ—¶çš„åŒæ­¥æ“ä½œ
        should_sync = (current_time - _last_sync_time) >= _sync_interval
        
        if should_sync:
            try:
                # é¦–å…ˆåŒæ­¥æ•°æ®åº“ç»‘å®šå…³ç³»åˆ°ä»»åŠ¡é…ç½®
                sync_task_config_with_database_bindings()
                
                # åŒæ­¥å†…å®¹ç±»å‹æ•°æ®
                sync_content_type_between_config_and_database()
                
                _last_sync_time = current_time
            except Exception as sync_error:
                # åŒæ­¥å¤±è´¥ä¸å½±å“æ•°æ®è¿”å›ï¼Œåªè®°å½•æ—¥å¿—
                logging.debug(f"åŒæ­¥æ“ä½œå¤±è´¥ï¼ˆä¸å½±å“æ•°æ®è¿”å›ï¼‰: {sync_error}")
        
        # åŸºäº tmdb ç»‘å®šè¡¥å……"å®é™…åŒ¹é…ç»“æœ"ï¼ˆshow åç§°/å¹´ä»½/æœ¬åœ°æµ·æŠ¥ï¼‰
        try:
            from app.sdk.db import CalendarDB
            cal_db = CalendarDB()
            enriched = []
            # å…ˆè·å–æ‰€æœ‰ shows æ•°æ®ï¼Œç”¨äºæŒ‰åç§°åŒ¹é…
            cursor = cal_db.conn.cursor()
            cursor.execute('SELECT tmdb_id, name, year, poster_local_path, bound_task_names FROM shows')
            all_shows = cursor.fetchall()
            shows_by_name = {s[1]: {'tmdb_id': s[0], 'name': s[1], 'year': s[2], 'poster_local_path': s[3], 'bound_task_names': s[4]} for s in all_shows}

            # è®¡ç®—æœ‰æ•ˆâ€œæœ€æ–°å­£â€ï¼šè‹¥ç¬¬ä¸€é›†æœªå®šæ¡£æˆ–åœ¨æœªæ¥ï¼Œåˆ™å›é€€åˆ°å·²æ’­å­£
            def determine_effective_latest_season(tmdb_id, fallback_latest):
                try:
                    cur = cal_db.conn.cursor()
                    cur.execute("""
                        SELECT season_number,
                               MIN(
                                   COALESCE(
                                       NULLIF(air_date_local, ''),
                                       NULLIF(air_date, '')
                                   )
                               ) as first_air
                        FROM episodes
                        WHERE tmdb_id=?
                        GROUP BY season_number
                        ORDER BY season_number DESC
                    """, (int(tmdb_id),))
                    rows = cur.fetchall() or []
                    from datetime import datetime as _dt
                    today = _dt.utcnow().strftime('%Y-%m-%d')
                    for sn, first_air in rows:
                        try:
                            if not sn:
                                continue
                            fa = (first_air or '').strip()
                            if not fa:
                                # æ— é¦–æ’­æ—¥æœŸè§†ä¸ºæœªå®šæ¡£å­£ï¼Œè·³è¿‡
                                continue
                            if fa > today:
                                # é¦–é›†åœ¨æœªæ¥ï¼Œè§†ä¸ºæœªå¼€æ’­å­£ï¼Œè·³è¿‡
                                continue
                            return int(sn)
                        except Exception:
                            continue
                except Exception:
                    pass
                try:
                    if fallback_latest and int(fallback_latest) > 0:
                        return int(fallback_latest)
                except Exception:
                    pass
                return None

            for idx, t in enumerate(tasks_info):
                # 1) ä¼˜å…ˆé€šè¿‡ calendar_info.match.tmdb_id æŸ¥æ‰¾
                raw = tasks[idx] if idx < len(tasks) else None
                cal = (raw or {}).get('calendar_info') or {}
                match = cal.get('match') or {}
                tmdb_id = match.get('tmdb_id') or (cal.get('tmdb_id') if isinstance(cal, dict) else None)
                legacy_match = raw.get('match') if isinstance(raw.get('match'), dict) else {}
                
                task_name = t.get('task_name', '').strip()
                matched_show = None
                
                # ä¼˜å…ˆé€šè¿‡ä»»åŠ¡çš„ TMDB åŒ¹é…ç»“æœæŸ¥æ‰¾èŠ‚ç›®
                if tmdb_id:
                    try:
                        show = cal_db.get_show(int(tmdb_id)) or {}
                        if show:
                            matched_show = show
                    except Exception as e:
                        pass
                
                # 2) å¦‚æœæ‰¾åˆ°åŒ¹é…çš„èŠ‚ç›®ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦å»ºç«‹ç»‘å®šå…³ç³»
                if matched_show:
                    # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²ç»ç»‘å®šåˆ°è¯¥èŠ‚ç›®ï¼Œé¿å…é‡å¤ç»‘å®š
                    bound_tasks = cal_db.get_bound_tasks_for_show(matched_show['tmdb_id'])
                    # æ¸…ç†ç©ºæ ¼ï¼Œç¡®ä¿æ¯”è¾ƒå‡†ç¡®
                    bound_tasks_clean = [task.strip() for task in bound_tasks if task.strip()]
                    needs_binding = task_name not in bound_tasks_clean
                                        
                    if needs_binding:
                        # å»ºç«‹ä»»åŠ¡ä¸èŠ‚ç›®çš„ç»‘å®šå…³ç³»ï¼ŒåŒæ—¶è®¾ç½®å†…å®¹ç±»å‹
                        task_content_type = t.get('content_type', '')
                        cal_db.bind_task_and_content_type(matched_show['tmdb_id'], task_name, task_content_type)
                    
                    t['match_tmdb_id'] = matched_show['tmdb_id']
                    t['matched_show_name'] = matched_show['name']
                    t['matched_year'] = matched_show['year']
                    t['matched_poster_local_path'] = matched_show['poster_local_path']
                    # æä¾›æœ€æ–°å­£æ•°ç”¨äºå‰ç«¯å±•ç¤ºï¼šä¼˜å…ˆä¿ç•™ç”¨æˆ·è®¾å®šçš„åŒ¹é…å­£ï¼Œå…¶æ¬¡ä¾æ®æœ‰æ•ˆæœ€æ–°å­£è§„åˆ™
                    try:
                        manual_season = (
                            match.get('latest_season_number')
                            or cal.get('latest_season_number')
                            or legacy_match.get('latest_season_number')
                            or t.get('matched_latest_season_number')
                        )
                        if manual_season:
                            t['matched_latest_season_number'] = int(manual_season)
                        else:
                            effective_latest = determine_effective_latest_season(
                                matched_show['tmdb_id'],
                                matched_show.get('latest_season_number')
                            )
                            if effective_latest:
                                t['matched_latest_season_number'] = effective_latest
                    except Exception:
                        pass
                    # ä»æ•°æ®åº“è·å–å®é™…çš„å†…å®¹ç±»å‹ï¼ˆå¦‚æœå·²è®¾ç½®ï¼‰
                    db_content_type = cal_db.get_show_content_type(matched_show['tmdb_id'])
                    t['matched_content_type'] = db_content_type if db_content_type else t.get('content_type', '')
                    # ä¼˜å…ˆä¿æŒä»»åŠ¡é…ç½®ä¸­çš„ç±»å‹ï¼›ä»…å½“ä»»åŠ¡æœªè®¾ç½®ä»»ä½•ç±»å‹æ—¶ï¼Œå›é€€ä¸ºæ•°æ®åº“ç±»å‹
                    extracted_ct = ((t.get('calendar_info') or {}).get('extracted') or {}).get('content_type')
                    config_ct = extracted_ct or t.get('content_type')
                    if not (config_ct and str(config_ct).strip()):
                        if t.get('matched_content_type'):
                            t['content_type'] = t['matched_content_type']
                    # ä»æ•°æ®åº“è·å– local_air_time å’Œ air_date_offset å¹¶æ·»åŠ åˆ° calendar_info ä¸­ä¾›å‰ç«¯è¯»å–
                    try:
                        schedule = cal_db.get_show_air_schedule(int(matched_show.get('tmdb_id'))) or {}
                        local_air_time = schedule.get('local_air_time') or ''
                        air_date_offset = schedule.get('air_date_offset') or 0
                        if not t.get('calendar_info'):
                            t['calendar_info'] = {}
                        t['calendar_info']['local_air_time'] = local_air_time
                        t['calendar_info']['air_date_offset'] = air_date_offset
                    except Exception:
                        pass
                else:
                    # å¦‚æœä»»åŠ¡é…ç½®ä¸­æ²¡æœ‰ TMDB åŒ¹é…ç»“æœï¼Œæ£€æŸ¥æ˜¯å¦å·²é€šè¿‡å…¶ä»–æ–¹å¼ç»‘å®šåˆ°èŠ‚ç›®
                    # é€šè¿‡ä»»åŠ¡åç§°åœ¨æ•°æ®åº“ä¸­æœç´¢å·²ç»‘å®šçš„èŠ‚ç›®
                    try:
                        cursor.execute('SELECT tmdb_id, name, year, poster_local_path FROM shows WHERE bound_task_names LIKE ?', (f'%{task_name}%',))
                        bound_show = cursor.fetchone()
                        if bound_show:
                            t['match_tmdb_id'] = bound_show[0]
                            t['matched_show_name'] = bound_show[1]
                            t['matched_year'] = bound_show[2]
                            t['matched_poster_local_path'] = bound_show[3]
                            # æŸ¥è¯¢å®Œæ•´ä¿¡æ¯ä»¥æä¾›æœ€æ–°å­£æ•°
                            try:
                                full_show = cal_db.get_show(int(bound_show[0]))
                                if full_show:
                                    manual_season = (
                                        match.get('latest_season_number')
                                        or cal.get('latest_season_number')
                                        or legacy_match.get('latest_season_number')
                                        or t.get('matched_latest_season_number')
                                    )
                                    if manual_season:
                                        t['matched_latest_season_number'] = int(manual_season)
                                    else:
                                        effective_latest = determine_effective_latest_season(
                                            int(bound_show[0]),
                                            full_show.get('latest_season_number')
                                        )
                                        if effective_latest:
                                            t['matched_latest_season_number'] = effective_latest
                                    # ä»å®Œæ•´ä¿¡æ¯ä¸­è·å– local_air_time å’Œ air_date_offset
                                    schedule = cal_db.get_show_air_schedule(int(bound_show[0])) or {}
                                    local_air_time = schedule.get('local_air_time') or ''
                                    air_date_offset = schedule.get('air_date_offset') or 0
                                    if not t.get('calendar_info'):
                                        t['calendar_info'] = {}
                                    t['calendar_info']['local_air_time'] = local_air_time
                                    t['calendar_info']['air_date_offset'] = air_date_offset
                            except Exception:
                                pass
                            # ä»æ•°æ®åº“è·å–å®é™…çš„å†…å®¹ç±»å‹ï¼ˆå¦‚æœå·²è®¾ç½®ï¼‰
                            db_content_type = cal_db.get_show_content_type(bound_show[0])
                            t['matched_content_type'] = db_content_type if db_content_type else t.get('content_type', '')
                            # ä¼˜å…ˆä»»åŠ¡é…ç½®ç±»å‹ï¼›ä»…åœ¨æœªé…ç½®ç±»å‹æ—¶ç”¨æ•°æ®åº“ç±»å‹
                            extracted_ct = ((t.get('calendar_info') or {}).get('extracted') or {}).get('content_type')
                            config_ct = extracted_ct or t.get('content_type')
                            if not (config_ct and str(config_ct).strip()):
                                if t.get('matched_content_type'):
                                    t['content_type'] = t['matched_content_type']
                            
                        else:
                            t['match_tmdb_id'] = None
                            t['matched_show_name'] = ''
                            t['matched_year'] = ''
                            t['matched_poster_local_path'] = ''
                            t['matched_content_type'] = t.get('content_type', '')
                    except Exception as e:
                        t['match_tmdb_id'] = None
                        t['matched_show_name'] = ''
                        t['matched_year'] = ''
                        t['matched_poster_local_path'] = ''
                        t['matched_content_type'] = t.get('content_type', '')
                enriched.append(t)
            tasks_info = enriched
        except Exception as _e:
            # è‹¥è¡¥å……å¤±è´¥ï¼Œä¸å½±å“ä¸»æµç¨‹
            pass

        # æ„å»ºè¿”å›æ•°æ®
        result_data = {
            'success': True,
            'data': {
                # è¿”å›å…¨éƒ¨ä»»åŠ¡ï¼ˆåŒ…æ‹¬æœªåŒ¹é…/æœªæå–å‰§åçš„ï¼‰ï¼Œç”¨äºå†…å®¹ç®¡ç†é¡µæ˜¾ç¤º
                'tasks': enrich_tasks_with_calendar_meta(tasks_info),
                'content_types': extractor.get_content_types_with_content([t for t in tasks_info if t.get('show_name')])
            }
        }
        
        # æ›´æ–°ç¼“å­˜
        with _calendar_tasks_cache_lock:
            _calendar_tasks_cache[cache_key] = (result_data, current_time)
        
        return jsonify(result_data)
    except Exception as e:
        # å¦‚æœå‡ºé”™ï¼Œå°è¯•è¿”å›ç¼“å­˜æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
        with _calendar_tasks_cache_lock:
            if cache_key in _calendar_tasks_cache:
                cache_data, _ = _calendar_tasks_cache[cache_key]
                logging.warning(f'è·å–è¿½å‰§æ—¥å†ä»»åŠ¡ä¿¡æ¯å¤±è´¥ï¼Œè¿”å›ç¼“å­˜æ•°æ®: {str(e)}')
                return jsonify(cache_data)
        
        # æ²¡æœ‰ç¼“å­˜ï¼Œè¿”å›é”™è¯¯
        return jsonify({
            'success': False,
            'message': f'è·å–è¿½å‰§æ—¥å†ä»»åŠ¡ä¿¡æ¯å¤±è´¥: {str(e)}',
            'data': {'tasks': [], 'content_types': []}
        })

@app.route("/api/calendar/episodes")
def get_calendar_episodes():
    """è·å–æŒ‡å®šæ—¥æœŸèŒƒå›´çš„å‰§é›†æ’­å‡ºä¿¡æ¯"""
    try:
        
        start_date = request.args.get('start_date')
        end_date = request.args.get('end_date')
        content_type = request.args.get('content_type', '')
        show_name = request.args.get('show_name', '')
        
        if not start_date or not end_date:
            return jsonify({
                'success': False,
                'message': 'è¯·æä¾›å¼€å§‹å’Œç»“æŸæ—¥æœŸ',
                'data': {'episodes': []}
            })
        
        # è·å–TMDBé…ç½®
        tmdb_api_key = config_data.get('tmdb_api_key', '')
        if not tmdb_api_key:
            return jsonify({
                'success': False,
                'message': 'TMDB APIæœªé…ç½®',
                'data': {'episodes': []}
            })
        
        # è·å–ä»»åŠ¡ä¿¡æ¯
        tasks = config_data.get('tasklist', [])
        extractor = TaskExtractor()
        tasks_info = extractor.extract_all_tasks_info(tasks, {})
        
        # è¿‡æ»¤ä»»åŠ¡
        if content_type:
            tasks_info = [task for task in tasks_info if task['content_type'] == content_type]
        if show_name:
            tasks_info = [task for task in tasks_info if show_name.lower() in task['show_name'].lower()]
        
        # è·å–å‰§é›†ä¿¡æ¯
        poster_language = get_poster_language_setting()
        tmdb_service = TMDBService(tmdb_api_key, poster_language)
        all_episodes = []
        
        for task_info in tasks_info:
            if task_info['show_name'] and task_info['year']:
                show_data = tmdb_service.search_and_get_episodes(
                    task_info['show_name'], 
                    task_info['year']
                )
                if show_data:
                    # è·å–å‰§é›†çš„æµ·æŠ¥ä¿¡æ¯
                    show_poster_path = show_data['show_info'].get('poster_path', '')
                    
                    # è¿‡æ»¤æ—¥æœŸèŒƒå›´å†…çš„å‰§é›†
                    for episode in show_data['episodes']:
                        # ç¡®ä¿episodeæœ‰air_dateå­—æ®µ
                        if episode.get('air_date') and start_date <= episode['air_date'] <= end_date:
                            episode['task_info'] = {
                                'task_name': task_info['task_name'],
                                'content_type': task_info['content_type'],
                                'progress': task_info
                            }
                            # æ·»åŠ æµ·æŠ¥è·¯å¾„ä¿¡æ¯
                            episode['poster_path'] = show_poster_path
                            all_episodes.append(episode)
        
        # æŒ‰æ’­å‡ºæ—¥æœŸæ’åº
        all_episodes.sort(key=lambda x: x.get('air_date', ''))
        
        return jsonify({
            'success': True,
            'data': {
                'episodes': all_episodes,
                'total': len(all_episodes)
            }
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–å‰§é›†æ’­å‡ºä¿¡æ¯å¤±è´¥: {str(e)}',
            'data': {'episodes': [], 'total': 0}
        })


# åˆå§‹åŒ–ï¼šä¸ºä»»åŠ¡å†™å…¥ shows/seasonsï¼Œä¸‹è½½æµ·æŠ¥æœ¬åœ°åŒ–
def process_new_tasks_async():
    """å¼‚æ­¥å¤„ç†æ–°ä»»åŠ¡çš„å…ƒæ•°æ®åŒ¹é…å’Œæµ·æŠ¥ä¸‹è½½ï¼Œä¸é˜»å¡å‰ç«¯å“åº”"""
    try:
        tmdb_api_key = config_data.get('tmdb_api_key', '')
        if not tmdb_api_key:
            return

        poster_language = get_poster_language_setting()
        tmdb_service = TMDBService(tmdb_api_key, poster_language)
        cal_db = CalendarDB()

        tasks = config_data.get('tasklist', [])
        # æ”¶é›†éœ€è¦å¤„ç†çš„ä»»åŠ¡
        tasks_to_process = []
        for task in tasks:
            # åªå¤„ç†æ²¡æœ‰å®Œæ•´å…ƒæ•°æ®çš„ä»»åŠ¡
            cal = (task or {}).get('calendar_info') or {}
            match = cal.get('match') or {}
            extracted = cal.get('extracted') or {}
            tmdb_id = match.get('tmdb_id')
            
            # å¦‚æœå·²ç»æœ‰å®Œæ•´çš„å…ƒæ•°æ®ï¼Œè·³è¿‡
            if tmdb_id and match.get('matched_show_name'):
                continue
                
            tasks_to_process.append(task)

        # å¦‚æœæ²¡æœ‰éœ€è¦å¤„ç†çš„ä»»åŠ¡ï¼Œç›´æ¥è¿”å›
        if not tasks_to_process:
            return

        # å¹¶è¡Œå¤„ç†ä»»åŠ¡
        import concurrent.futures
        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
            futures = []
            for task in tasks_to_process:
                future = executor.submit(process_single_task_async, task, tmdb_service, cal_db)
                futures.append(future)
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            for future in concurrent.futures.as_completed(futures):
                try:
                    future.result()
                except Exception as e:
                    logging.warning(f"å¤„ç†ä»»åŠ¡å¤±è´¥: {e}")

    except Exception as e:
        logging.warning(f"å¼‚æ­¥å¤„ç†æ–°ä»»åŠ¡å¤±è´¥: {e}")


def process_single_task_async(task, tmdb_service, cal_db):
    """å¤„ç†å•ä¸ªä»»åŠ¡çš„å…ƒæ•°æ®åŒ¹é…å’Œæµ·æŠ¥ä¸‹è½½"""
    try:
        cal = (task or {}).get('calendar_info') or {}
        match = cal.get('match') or {}
        extracted = cal.get('extracted') or {}
        tmdb_id = match.get('tmdb_id')
        
        # å¦‚æœè¿˜æ²¡æœ‰æå–ä¿¡æ¯ï¼Œå…ˆæå–
        if not extracted.get('show_name'):
            extractor = TaskExtractor()
            task_name = task.get('taskname') or task.get('task_name') or ''
            save_path = task.get('savepath', '')
            info = extractor.extract_show_info_from_path(save_path)
            extracted = {
                'show_name': info.get('show_name', ''),
                'year': info.get('year', ''),
                'content_type': info.get('type', 'other'),
            }
            cal['extracted'] = extracted
            task['calendar_info'] = cal

        # å¦‚æœè¿˜æ²¡æœ‰ TMDB åŒ¹é…ï¼Œè¿›è¡ŒåŒ¹é…
        if not tmdb_id and extracted.get('show_name'):
            try:
                show_name = extracted.get('show_name', '')
                year = extracted.get('year') or None
                search_result = None
                match_type = None  # 'exact' æˆ– 'name_only'
                
                # ä¼˜å…ˆçº§åŒ¹é…é€»è¾‘ï¼šå…ˆå°è¯•ç²¾å‡†åŒ¹é…ï¼ˆåç§°+å¹´ä»½ï¼‰ï¼Œæ— ç»“æœæ—¶å†æŒ‰åç§°åŒ¹é…
                if year:
                    # ç¬¬ä¸€æ­¥ï¼šå°è¯•ç²¾å‡†åŒ¹é…ï¼ˆåç§°+å¹´ä»½ï¼‰
                    search_results = tmdb_service.search_tv_show_all(show_name, year)
                    if search_results:
                        # ä»ç»“æœä¸­æ‰¾åˆ°å¹´ä»½å®Œå…¨åŒ¹é…çš„
                        for result in search_results:
                            result_year = None
                            first_air_date = result.get('first_air_date', '')
                            if first_air_date:
                                try:
                                    result_year = first_air_date[:4] if len(first_air_date) >= 4 else None
                                except Exception:
                                    pass
                            
                            if result_year == year and result.get('id'):
                                search_result = result
                                match_type = 'exact'
                                logging.debug(f"TMDB åŒ¹é…æˆåŠŸ: ä»»åŠ¡åç§°={task.get('taskname', '')}, èŠ‚ç›®åç§°={show_name}, å¹´ä»½={year}")
                                break
                
                # ç¬¬äºŒæ­¥ï¼šå¦‚æœç²¾å‡†åŒ¹é…æ²¡æœ‰ç»“æœï¼Œå°è¯•ä»…åç§°åŒ¹é…
                if not search_result:
                    search_results = tmdb_service.search_tv_show_all(show_name, None)
                    if search_results:
                        # å¦‚æœæœ‰å¹´ä»½ä¿¡æ¯ï¼Œé€‰æ‹©å¹´ä»½æœ€æ¥è¿‘çš„ç»“æœ
                        if year:
                            try:
                                target_year = int(year)
                                best_match = None
                                min_year_diff = float('inf')
                                
                                for result in search_results:
                                    if not result.get('id'):
                                        continue
                                    result_year = None
                                    first_air_date = result.get('first_air_date', '')
                                    if first_air_date:
                                        try:
                                            result_year = int(first_air_date[:4]) if len(first_air_date) >= 4 else None
                                        except Exception:
                                            pass
                                    
                                    if result_year:
                                        year_diff = abs(result_year - target_year)
                                        if year_diff < min_year_diff:
                                            min_year_diff = year_diff
                                            best_match = result
                                
                                if best_match:
                                    search_result = best_match
                                    match_type = 'name_only'
                                    matched_year = best_match.get('first_air_date', '')[:4] if best_match.get('first_air_date') else 'æœªçŸ¥'
                                    logging.debug(f"TMDB åŒ¹é…æˆåŠŸï¼ˆå¹´ä»½ä¸ä¸€è‡´ï¼‰: ä»»åŠ¡åç§°={task.get('taskname', '')}, èŠ‚ç›®åç§°={show_name}, æœŸæœ›å¹´ä»½={year}, åŒ¹é…å¹´ä»½={matched_year}, å¹´ä»½å·®å¼‚={min_year_diff}")
                            except (ValueError, TypeError) as e:
                                # å¹´ä»½è§£æå¤±è´¥ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªç»“æœ
                                search_result = search_results[0] if search_results else None
                                match_type = 'name_only'
                                logging.debug(f"TMDB åŒ¹é…æˆåŠŸï¼ˆå¹´ä»½è§£æå¤±è´¥ï¼‰: ä»»åŠ¡åç§°={task.get('taskname', '')}, èŠ‚ç›®åç§°={show_name}, é”™è¯¯={e}")
                        else:
                            # æ²¡æœ‰å¹´ä»½ä¿¡æ¯ï¼Œç›´æ¥ä½¿ç”¨ç¬¬ä¸€ä¸ªç»“æœ
                            search_result = search_results[0] if search_results else None
                            match_type = 'name_only'
                            logging.debug(f"TMDB åŒ¹é…æˆåŠŸï¼ˆæ— å¹´ä»½ä¿¡æ¯ï¼‰: ä»»åŠ¡åç§°={task.get('taskname', '')}, èŠ‚ç›®åç§°={show_name}")
                
                # å¦‚æœæ‰¾åˆ°äº†åŒ¹é…ç»“æœï¼Œç»§ç»­å¤„ç†
                if search_result and search_result.get('id'):
                    tmdb_id = search_result['id']
                    details = tmdb_service.get_tv_show_details(tmdb_id) or {}
                    seasons = details.get('seasons', [])
                    
                    # é€‰æ‹©å·²æ’­å‡ºçš„å­£ä¸­æœ€æ–°çš„ä¸€å­£
                    # ä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸåˆ¤æ–­å­£æ˜¯å¦å·²æ’­å‡ºï¼ˆç°åœ¨é›†çš„æ’­å‡ºæ—¥æœŸå·²ç»æ˜¯æœ¬åœ°æ—¥æœŸï¼Œä¸éœ€è¦é€šè¿‡æ’­å‡ºé›†æ•°åˆ·æ–°æ—¶é—´é™åˆ¶ï¼‰
                    from datetime import datetime as _dt
                    today_date = _dt.now().date()
                    latest_season_number = 0
                    latest_air_date = None
                    
                    for s in seasons:
                        sn = s.get('season_number', 0)
                        air_date = s.get('air_date')
                        
                        # åªè€ƒè™‘å·²æ’­å‡ºçš„å­£ï¼ˆæœ‰air_dateä¸”æ—©äºæˆ–ç­‰äºä»Šå¤©çš„æ—¥æœŸï¼‰
                        if sn and sn > 0 and air_date:  # æ’é™¤ç¬¬0å­£ï¼ˆç‰¹æ®Šå­£ï¼‰
                            try:
                                season_air_date = datetime.strptime(air_date, '%Y-%m-%d').date()
                                if season_air_date <= today_date:
                                    # é€‰æ‹©æ’­å‡ºæ—¥æœŸæœ€æ–°çš„å­£
                                    if latest_air_date is None or season_air_date > latest_air_date:
                                        latest_season_number = sn
                                        latest_air_date = season_air_date
                            except (ValueError, TypeError):
                                # æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè·³è¿‡
                                continue
                    
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å·²æ’­å‡ºçš„å­£ï¼Œå›é€€åˆ°ç¬¬1å­£
                    if latest_season_number == 0:
                        latest_season_number = 1

                    chinese_title = tmdb_service.get_chinese_title_with_fallback(tmdb_id, extracted.get('show_name', ''))
                    
                    cal['match'] = {
                        'matched_show_name': chinese_title,
                        'matched_year': (details.get('first_air_date') or '')[:4],
                        'tmdb_id': tmdb_id,
                        'latest_season_number': latest_season_number,
                        'latest_season_fetch_url': f"/tv/{tmdb_id}/season/{latest_season_number}",
                    }
                    task['calendar_info'] = cal
                    
                    # ç«‹å³é€šçŸ¥å‰ç«¯å…ƒæ•°æ®åŒ¹é…å®Œæˆ
                    try:
                        notify_calendar_changed('edit_metadata')
                    except Exception:
                        pass
                else:
                    # æ²¡æœ‰æ‰¾åˆ°ä»»ä½•åŒ¹é…ç»“æœ
                    year_info = f", å¹´ä»½={year}" if year else ""
                    logging.warning(f"TMDB åŒ¹é…å¤±è´¥ - ä»»åŠ¡åç§°: {task.get('taskname', '')}, æœç´¢çš„èŠ‚ç›®åç§°: {show_name}{year_info}, å¤±è´¥åŸå› : TMDB æœç´¢æ— ç»“æœï¼Œå¯èƒ½èŠ‚ç›®åç§°ä¸åŒ¹é…æˆ– TMDB ä¸­ä¸å­˜åœ¨è¯¥èŠ‚ç›®")
                        
            except Exception as e:
                # æ•è·å¼‚å¸¸å¹¶è¾“å‡ºè¯¦ç»†çš„å¤±è´¥åŸå› 
                task_name = task.get('taskname') or task.get('task_name') or ''
                show_name = extracted.get('show_name', '')
                year = extracted.get('year') or None
                year_info = f", å¹´ä»½={year}" if year else ""
                import traceback
                error_detail = str(e)
                error_type = type(e).__name__
                # è·å–å¼‚å¸¸å †æ ˆä¿¡æ¯çš„å‰å‡ è¡Œï¼Œç”¨äºè¯Šæ–­
                tb_lines = traceback.format_exc().split('\n')
                tb_summary = '; '.join([line.strip() for line in tb_lines[:3] if line.strip()][:2])
                logging.warning(f"TMDB åŒ¹é…å¤±è´¥ - ä»»åŠ¡åç§°: {task_name}, æœç´¢çš„èŠ‚ç›®åç§°: {show_name}{year_info}, å¤±è´¥åŸå› : å¼‚å¸¸ç±»å‹={error_type}, é”™è¯¯ä¿¡æ¯={error_detail}, å †æ ˆæ‘˜è¦={tb_summary}")

        # å¦‚æœç°åœ¨æœ‰ TMDB IDï¼Œä¸‹è½½æµ·æŠ¥å¹¶æ›´æ–°æ•°æ®åº“ï¼Œå¹¶åœ¨å¯èƒ½çš„æƒ…å†µä¸‹åŒæ­¥ Trakt æ’­å‡ºæ—¶é—´ä¿¡æ¯
        if tmdb_id:
            try:
                # é‡æ–°è·å–æ›´æ–°åçš„matchä¿¡æ¯
                updated_match = cal.get('match') or {}
                logging.debug(f"process_single_task_async - æ›´æ–°åçš„matchä¿¡æ¯: {updated_match}")
                details = tmdb_service.get_tv_show_details(tmdb_id) or {}
                name = tmdb_service.get_chinese_title_with_fallback(tmdb_id, extracted.get('show_name', ''))
                first_air = (details.get('first_air_date') or '')[:4]
                raw_status = (details.get('status') or '')
                try:
                    localized_status = tmdb_service.get_localized_show_status(int(tmdb_id), int(updated_match.get('latest_season_number') or 1), raw_status)
                    status = localized_status
                except Exception:
                    status = raw_status
                # ä½¿ç”¨æµ·æŠ¥è¯­è¨€è®¾ç½®è·å–æµ·æŠ¥è·¯å¾„
                poster_path = tmdb_service.get_poster_path_with_language(int(tmdb_id)) if tmdb_service else (details.get('poster_path') or '')
                latest_season_number = updated_match.get('latest_season_number') or 1
                logging.debug(f"process_single_task_async - æœ€ç»ˆä½¿ç”¨çš„å­£æ•°: {latest_season_number}")

                # è·å–ç°æœ‰çš„ç»‘å®šå…³ç³»å’Œå†…å®¹ç±»å‹ï¼Œé¿å…è¢«è¦†ç›–
                existing_show = cal_db.get_show(int(tmdb_id))
                existing_bound_tasks = existing_show.get('bound_task_names', '') if existing_show else ''
                existing_content_type = existing_show.get('content_type', '') if existing_show else ''
                existing_poster_path = existing_show.get('poster_local_path', '') if existing_show else ''
                is_custom_poster = bool(existing_show.get('is_custom_poster', 0)) if existing_show else False
                
                poster_local_path = ''
                if poster_path:
                    poster_local_path = download_poster_local(poster_path, int(tmdb_id), existing_poster_path, is_custom_poster)
                cal_db.upsert_show(int(tmdb_id), name, first_air, status, poster_local_path, int(latest_season_number), 0, existing_bound_tasks, existing_content_type)
                
                # å¦‚æœæµ·æŠ¥è·¯å¾„å‘ç”Ÿå˜åŒ–ï¼Œè§¦å‘å­¤ç«‹æ–‡ä»¶æ¸…ç†
                if poster_local_path and poster_local_path != existing_poster_path:
                    try:
                        cleanup_orphaned_posters()
                    except Exception as e:
                        logging.warning(f"æ¸…ç†å­¤ç«‹æµ·æŠ¥å¤±è´¥: {e}")
                
                # æ›´æ–° seasons è¡¨
                refresh_url = f"/tv/{tmdb_id}/season/{latest_season_number}"
                # å¤„ç†å­£åç§°
                season_name_raw = ''
                try:
                    for s in (details.get('seasons') or []):
                        if int(s.get('season_number') or 0) == int(latest_season_number):
                            season_name_raw = s.get('name') or ''
                            break
                except Exception:
                    season_name_raw = ''
                try:
                    from sdk.tmdb_service import TMDBService as _T
                    season_name_processed = tmdb_service.process_season_name(season_name_raw) if isinstance(tmdb_service, _T) else season_name_raw
                except Exception:
                    season_name_processed = season_name_raw
                cal_db.upsert_season(
                    int(tmdb_id),
                    int(latest_season_number),
                    details_of_season_episode_count(tmdb_service, tmdb_id, latest_season_number),
                    refresh_url,
                    season_name_processed
                )

                # ç«‹å³æ‹‰å–æœ€æ–°ä¸€å­£çš„æ‰€æœ‰é›†å¹¶å†™å…¥æœ¬åœ°ï¼Œä¿è¯å‰ç«¯å¯ç«‹å³è¯»å–
                try:
                    season = tmdb_service.get_tv_show_episodes(int(tmdb_id), int(latest_season_number)) or {}
                    episodes = season.get('episodes', []) or []
                    # æ ¹å› ä¿®å¤ï¼šæ¸…ç†æœ¬åœ°è¯¥å­£ä¸­ TMDB ä¸å­˜åœ¨çš„å¤šä½™é›†
                    try:
                        valid_eps = []
                        for _ep in episodes:
                            try:
                                n = int(_ep.get('episode_number') or 0)
                                if n > 0:
                                    valid_eps.append(n)
                            except Exception:
                                pass
                        cal_db.prune_season_episodes_not_in(int(tmdb_id), int(latest_season_number), valid_eps)
                    except Exception:
                        pass
                    from time import time as _now
                    now_ts = int(_now())
                    for ep in episodes:
                        cal_db.upsert_episode(
                            tmdb_id=int(tmdb_id),
                            season_number=int(latest_season_number),
                            episode_number=int(ep.get('episode_number') or 0),
                            name=ep.get('name') or '',
                            overview=ep.get('overview') or '',
                            air_date=ep.get('air_date') or '',
                            runtime=ep.get('runtime'),
                            ep_type=(ep.get('episode_type') or ep.get('type')),
                            updated_at=now_ts,
                        )

                    # ä½¿ç”¨ Trakt åŒæ­¥èŠ‚ç›®çº§æ’­å‡ºæ—¶é—´ï¼ˆå¦‚å·²é…ç½® Client IDï¼‰
                    try:
                        trakt_cfg = config_data.get("trakt", {}) if isinstance(config_data, dict) else {}
                        client_id = (trakt_cfg.get("client_id") or "").strip()
                        if client_id:
                            local_tz = config_data.get("local_timezone", "Asia/Shanghai")
                            tsvc = TraktService(client_id=client_id)
                            if tsvc.is_configured():
                                logging.debug(f"å¼€å§‹åŒæ­¥ Trakt æ’­å‡ºæ—¶é—´ tmdb_id={tmdb_id}")
                                show_info = tsvc.get_show_by_tmdb_id(int(tmdb_id))
                                if show_info and show_info.get("trakt_id"):
                                    trakt_id = show_info.get("trakt_id")
                                    logging.debug(f"æ‰¾åˆ° Trakt èŠ‚ç›® tmdb_id={tmdb_id}, trakt_id={trakt_id}")
                                    # 1) èŠ‚ç›®çº§æ’­å‡ºæ—¶é—´ -> æœ¬åœ°æ—¶åŒº HH:MMï¼Œå†™å…¥ shows.local_air_time
                                    airtime = tsvc.get_show_airtime(trakt_id)
                                    if airtime and airtime.get("aired_time") and airtime.get("timezone"):
                                        local_air_time = tsvc.convert_show_airtime_to_local(
                                            airtime.get("aired_time"), airtime.get("timezone"), local_tz
                                        ) or airtime.get("aired_time")
                                        logging.debug(f"è·å–åˆ°æ’­å‡ºæ—¶é—´ tmdb_id={tmdb_id}, aired_time={airtime.get('aired_time')}, timezone={airtime.get('timezone')}, local_air_time={local_air_time}")
                                        try:
                                            from sdk.db import CalendarDB as _CalDB
                                            _CalDB().update_show_air_schedule(
                                                int(tmdb_id),
                                                local_air_time=local_air_time or "",
                                                air_time_source=airtime.get("aired_time") or "",
                                                air_timezone=airtime.get("timezone") or "",
                                            )
                                            logging.debug(f"æˆåŠŸå†™å…¥æ’­å‡ºæ—¶é—´åˆ°æ•°æ®åº“ tmdb_id={tmdb_id}")
                                        except Exception as _db_err:
                                            logging.warning(f"å†™å…¥æ’­å‡ºæ—¶é—´åˆ°æ•°æ®åº“å¤±è´¥ tmdb_id={tmdb_id}: {_db_err}")
                                    else:
                                        logging.warning(f"æœªè·å–åˆ°å®Œæ•´çš„æ’­å‡ºæ—¶é—´ä¿¡æ¯ tmdb_id={tmdb_id}, airtime={airtime}")
                                else:
                                    logging.debug(f"æœªæ‰¾åˆ° Trakt èŠ‚ç›®æ˜ å°„ tmdb_id={tmdb_id}, show_info={show_info}")
                            else:
                                logging.debug(f"TraktService æœªé…ç½® tmdb_id={tmdb_id}")
                        else:
                            logging.debug(f"Trakt Client ID æœªé…ç½®ï¼Œè·³è¿‡åŒæ­¥ tmdb_id={tmdb_id}")
                    except Exception as _te_outer:
                        logging.warning(f"åŒæ­¥ Trakt æ’­å‡ºæ—¶é—´å¤±è´¥ tmdb_id={tmdb_id}: {_te_outer}")
                        import traceback
                        logging.debug(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
                    
                    # 2) å¦‚æœæœ‰ Trakt çš„æºæ—¶é—´/æ—¶åŒºï¼Œè®¡ç®—æ¯é›†çš„æœ¬åœ°æ’­å‡ºæ—¥æœŸå¹¶æ›´æ–° air_date_local
                    update_episodes_air_date_local(cal_db, int(tmdb_id), int(latest_season_number), episodes)
                except Exception as _e:
                    logging.warning(f"å†™å…¥å‰§é›†å¤±è´¥ tmdb_id={tmdb_id}: {_e}")
                
                # ç»‘å®šä»»åŠ¡åˆ°èŠ‚ç›®
                task_final_name = task.get('taskname') or task.get('task_name') or ''
                ct = extracted.get('content_type', '')
                try:
                    cal_db.bind_task_and_content_type(tmdb_id, task_final_name, ct)
                except Exception as e:
                    logging.warning(f"ç»‘å®šä»»åŠ¡å¤±è´¥: {e}")
                
                # ç«‹å³é€šçŸ¥å‰ç«¯æµ·æŠ¥ä¸‹è½½å®Œæˆ
                try:
                    notify_calendar_changed('edit_metadata')
                except Exception:
                    pass
                    
            except Exception as e:
                logging.warning(f"å¤„ç†ä»»åŠ¡æµ·æŠ¥å¤±è´¥: task={task.get('taskname', '')}, err={e}")

    except Exception as e:
        logging.warning(f"å¤„ç†å•ä¸ªä»»åŠ¡å¤±è´¥: task={task.get('taskname', '')}, err={e}")


def do_calendar_bootstrap() -> tuple:
    """å†…éƒ¨æ–¹æ³•ï¼šæ‰§è¡Œæ—¥å†åˆå§‹åŒ–ã€‚è¿”å› (success: bool, message: str)"""
    try:
        ensure_calendar_info_for_tasks()

        tmdb_api_key = config_data.get('tmdb_api_key', '')
        if not tmdb_api_key:
            return False, 'TMDB APIæœªé…ç½®'

        poster_language = get_poster_language_setting()
        tmdb_service = TMDBService(tmdb_api_key, poster_language)
        cal_db = CalendarDB()

        tasks = config_data.get('tasklist', [])
        any_written = False
        for task in tasks:
            cal = (task or {}).get('calendar_info') or {}
            match = cal.get('match') or {}
            extracted = cal.get('extracted') or {}
            tmdb_id = match.get('tmdb_id')
            if not tmdb_id:
                continue

            details = tmdb_service.get_tv_show_details(tmdb_id) or {}
            # ä½¿ç”¨æ–°çš„æ–¹æ³•è·å–ä¸­æ–‡æ ‡é¢˜ï¼Œæ”¯æŒä»åˆ«åä¸­è·å–ä¸­å›½åœ°åŒºçš„åˆ«å
            name = tmdb_service.get_chinese_title_with_fallback(tmdb_id, extracted.get('show_name', ''))
            first_air = (details.get('first_air_date') or '')[:4]
            # å°†åŸå§‹çŠ¶æ€è½¬æ¢ä¸ºæœ¬åœ°åŒ–ä¸­æ–‡ï¼Œä¸”å¯¹ returning_series åœºæ™¯åšæœ¬å­£ç»ˆ/æ’­å‡ºä¸­åˆ¤æ–­
            raw_status = (details.get('status') or '')
            try:
                localized_status = tmdb_service.get_localized_show_status(int(tmdb_id), int(match.get('latest_season_number') or 1), raw_status)
                status = localized_status
            except Exception:
                status = raw_status
            # ä½¿ç”¨æµ·æŠ¥è¯­è¨€è®¾ç½®è·å–æµ·æŠ¥è·¯å¾„
            poster_path = tmdb_service.get_poster_path_with_language(int(tmdb_id)) if tmdb_service else (details.get('poster_path') or '')
            latest_season_number = match.get('latest_season_number') or 1

            # è·å–ç°æœ‰çš„ç»‘å®šå…³ç³»å’Œå†…å®¹ç±»å‹ï¼Œé¿å…è¢«è¦†ç›–
            existing_show = cal_db.get_show(int(tmdb_id))
            existing_bound_tasks = existing_show.get('bound_task_names', '') if existing_show else ''
            existing_content_type = existing_show.get('content_type', '') if existing_show else ''
            existing_poster_path = existing_show.get('poster_local_path', '') if existing_show else ''
            is_custom_poster = bool(existing_show.get('is_custom_poster', 0)) if existing_show else False
            
            poster_local_path = ''
            if poster_path:
                poster_local_path = download_poster_local(poster_path, int(tmdb_id), existing_poster_path, is_custom_poster)
            cal_db.upsert_show(int(tmdb_id), name, first_air, status, poster_local_path, int(latest_season_number), 0, existing_bound_tasks, existing_content_type)
            refresh_url = f"/tv/{tmdb_id}/season/{latest_season_number}"
            # å¤„ç†å­£åç§°
            season_name_raw = ''
            try:
                for s in (details.get('seasons') or []):
                    if int(s.get('season_number') or 0) == int(latest_season_number):
                        season_name_raw = s.get('name') or ''
                        break
            except Exception:
                season_name_raw = ''
            try:
                from sdk.tmdb_service import TMDBService as _T
                season_name_processed = tmdb_service.process_season_name(season_name_raw) if isinstance(tmdb_service, _T) else season_name_raw
            except Exception:
                season_name_processed = season_name_raw
            cal_db.upsert_season(
                int(tmdb_id),
                int(latest_season_number),
                details_of_season_episode_count(tmdb_service, tmdb_id, latest_season_number),
                refresh_url,
                season_name_processed
            )

            # ç«‹å³æ‹‰å–æœ€æ–°ä¸€å­£çš„æ‰€æœ‰é›†å¹¶å†™å…¥æœ¬åœ°ï¼Œä¿è¯å‰ç«¯å¯ç«‹å³è¯»å–
            try:
                season = tmdb_service.get_tv_show_episodes(int(tmdb_id), int(latest_season_number)) or {}
                episodes = season.get('episodes', []) or []
                # æ ¹å› ä¿®å¤ï¼šæ¸…ç†æœ¬åœ°è¯¥å­£ä¸­ TMDB ä¸å­˜åœ¨çš„å¤šä½™é›†
                try:
                    valid_eps = []
                    for _ep in episodes:
                        try:
                            n = int(_ep.get('episode_number') or 0)
                            if n > 0:
                                valid_eps.append(n)
                        except Exception:
                            pass
                    cal_db.prune_season_episodes_not_in(int(tmdb_id), int(latest_season_number), valid_eps)
                except Exception:
                    pass
                from time import time as _now
                now_ts = int(_now())
                for ep in episodes:
                    cal_db.upsert_episode(
                        tmdb_id=int(tmdb_id),
                        season_number=int(latest_season_number),
                        episode_number=int(ep.get('episode_number') or 0),
                        name=ep.get('name') or '',
                        overview=ep.get('overview') or '',
                        air_date=ep.get('air_date') or '',
                        runtime=ep.get('runtime'),
                        ep_type=(ep.get('episode_type') or ep.get('type')),
                        updated_at=now_ts,
                    )
                # å¦‚æœæœ‰ Trakt çš„æºæ—¶é—´/æ—¶åŒºï¼Œè®¡ç®—æ¯é›†çš„æœ¬åœ°æ’­å‡ºæ—¥æœŸå¹¶æ›´æ–° air_date_local
                update_episodes_air_date_local(cal_db, int(tmdb_id), int(latest_season_number), episodes)
                any_written = True
            except Exception as _e:
                logging.warning(f"bootstrap å†™å…¥å‰§é›†å¤±è´¥ tmdb_id={tmdb_id}: {_e}")
        try:
            if any_written:
                notify_calendar_changed('bootstrap')
        except Exception:
            pass
        return True, 'OK'
    except Exception as e:
        return False, f'bootstrapå¤±è´¥: {str(e)}'


@app.route("/api/calendar/bootstrap", methods=["POST"])
def calendar_bootstrap():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    success, msg = do_calendar_bootstrap()
    return jsonify({"success": success, "message": msg})


def details_of_season_episode_count(tmdb_service: TMDBService, tmdb_id: int, season_number: int) -> int:
    try:
        season = tmdb_service.get_tv_show_episodes(tmdb_id, season_number) or {}
        return len(season.get('episodes', []) or [])
    except Exception:
        return 0


def update_episodes_air_date_local(cal_db: CalendarDB, tmdb_id: int, season_number: int, episodes: list):
    """
    è¾…åŠ©å‡½æ•°ï¼šå¦‚æœæœ‰ Trakt çš„æºæ—¶é—´/æ—¶åŒºï¼Œè®¡ç®—æ¯é›†çš„æœ¬åœ°æ’­å‡ºæ—¥æœŸå¹¶æ›´æ–° air_date_local
    å¦‚æœç”¨æˆ·æ‰‹åŠ¨è®¾ç½®äº† air_date_offsetï¼Œä¼˜å…ˆä½¿ç”¨è¯¥åç§»å€¼è€Œä¸æ˜¯é‡æ–°è®¡ç®—
    
    Args:
        cal_db: CalendarDB å®ä¾‹
        tmdb_id: èŠ‚ç›® TMDB ID
        season_number: å­£å·
        episodes: é›†åˆ—è¡¨ï¼ˆåŒ…å« air_date å­—æ®µï¼‰
    """
    try:
        # ä» shows è¡¨è¯»å– Trakt çš„æºæ—¶é—´/æ—¶åŒºå’Œç”¨æˆ·æ‰‹åŠ¨è®¾ç½®çš„åç§»å€¼
        show = cal_db.get_show(int(tmdb_id))
        if not show:
            return
        air_time_source = show.get('air_time_source') or ''
        air_timezone = show.get('air_timezone') or ''
        # è·å–ç”¨æˆ·æ‰‹åŠ¨è®¾ç½®çš„æ—¥æœŸåç§»å€¼ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        schedule = cal_db.get_show_air_schedule(int(tmdb_id)) or {}
        manual_air_date_offset = schedule.get('air_date_offset')
        local_air_time = schedule.get('local_air_time') or ''
        # è·å–æ˜¯å¦æ‰‹åŠ¨è®¾ç½®çš„æ ‡è®°ï¼ˆåªæœ‰ç”¨æˆ·åœ¨ WebUI ç¼–è¾‘å…ƒæ•°æ®é¡µé¢ä¿®æ”¹å¹¶ä¿å­˜åæ‰ä¸º Trueï¼‰
        air_date_offset_manually_set = schedule.get('air_date_offset_manually_set', False)
        
        # é‡è¦ï¼šåˆ¤æ–­æ˜¯å¦åº”è¯¥è‡ªåŠ¨è®¡ç®— air_date_offset
        # åˆ¤æ–­æ ‡å‡†ï¼š
        # 1. é»˜è®¤ is_manually_set ä¸º False
        # 2. åªæœ‰å½“ air_date_offset_manually_set ä¸º True æ—¶ï¼ˆç”¨æˆ·åœ¨ WebUI ç¼–è¾‘å…ƒæ•°æ®é¡µé¢ä¿®æ”¹å¹¶ä¿å­˜è¿‡ï¼‰ï¼Œæ‰è®¤ä¸ºæ˜¯æ‰‹åŠ¨è®¾ç½®çš„
        # 3. è¿™æ ·åˆå§‹åŒ–æ—¶å³ä½¿ air_date_offset æ˜¯ 0ï¼Œä¹Ÿä¼šè‡ªåŠ¨è®¡ç®—æ­£ç¡®çš„åç§»å€¼
        is_manually_set = bool(air_date_offset_manually_set)
        
        # å¦‚æœ manual_air_date_offset æ˜¯ Noneï¼Œè®¾ç½®ä¸º 0 ç”¨äºè®¡ç®—
        if manual_air_date_offset is None:
            manual_air_date_offset = 0
        
        # å¦‚æœç”¨æˆ·æ‰‹åŠ¨è®¾ç½®äº†åç§»å€¼ï¼ˆä¸”æ²¡æœ‰æ—¶åŒºä¿¡æ¯ï¼‰ï¼Œç›´æ¥ä½¿ç”¨åç§»å€¼è®¡ç®—
        if not air_time_source or not air_timezone:
            if is_manually_set:
                # ç”¨æˆ·æ‰‹åŠ¨è®¾ç½®äº†åç§»å€¼ï¼Œä½¿ç”¨åç§»å€¼è®¡ç®— air_date_local
                for ep in episodes:
                    ep_air_date = ep.get('air_date') or ''
                    ep_number = ep.get('episode_number') or 0
                    if not ep_number:
                        continue
                    if ep_air_date:
                        try:
                            from datetime import datetime as _dt, timedelta as _td
                            src_date = _dt.strptime(ep_air_date, '%Y-%m-%d').date()
                            adjusted_date = src_date + _td(days=manual_air_date_offset)
                            cal_db.update_episode_air_date_local(
                                int(tmdb_id),
                                int(season_number),
                                int(ep_number),
                                adjusted_date.strftime('%Y-%m-%d')
                            )
                        except Exception as _e_sync:
                            logging.debug(f"ä½¿ç”¨æ‰‹åŠ¨åç§»å€¼æ›´æ–° air_date_local å¤±è´¥ tmdb_id={tmdb_id}, season={season_number}, ep={ep_number}: {_e_sync}")
                    else:
                        # å¦‚æœ air_date ä¸ºç©ºï¼Œæ¸…ç©º air_date_local
                        try:
                            cal_db.update_episode_air_date_local(
                                int(tmdb_id),
                                int(season_number),
                                int(ep_number),
                                ''
                            )
                        except Exception as _e_clear:
                            logging.debug(f"æ¸…ç©º air_date_local å¤±è´¥ tmdb_id={tmdb_id}, season={season_number}, ep={ep_number}: {_e_clear}")
                return
            else:
                # æ²¡æœ‰æ—¶åŒºä¿¡æ¯ä¸”æ²¡æœ‰æ‰‹åŠ¨åç§»å€¼ï¼Œå°† air_date_local è®¾ç½®ä¸ºä¸ air_date ç›¸åŒçš„å€¼
                for ep in episodes:
                    ep_air_date = ep.get('air_date') or ''
                    ep_number = ep.get('episode_number') or 0
                    if not ep_number:
                        continue
                    if ep_air_date:
                        try:
                            cal_db.update_episode_air_date_local(
                                int(tmdb_id),
                                int(season_number),
                                int(ep_number),
                                ep_air_date
                            )
                        except Exception as _e_sync:
                            logging.debug(f"åŒæ­¥ air_date åˆ° air_date_local å¤±è´¥ tmdb_id={tmdb_id}, season={season_number}, ep={ep_number}: {_e_sync}")
                    else:
                        # å¦‚æœ air_date ä¸ºç©ºï¼Œæ¸…ç©º air_date_local
                        try:
                            cal_db.update_episode_air_date_local(
                                int(tmdb_id),
                                int(season_number),
                                int(ep_number),
                                ''
                            )
                        except Exception as _e_clear:
                            logging.debug(f"æ¸…ç©º air_date_local å¤±è´¥ tmdb_id={tmdb_id}, season={season_number}, ep={ep_number}: {_e_clear}")
                return
        
        # è·å–æœ¬åœ°æ—¶åŒºé…ç½®
        local_tz = config_data.get("local_timezone", "Asia/Shanghai")
        
        try:
            from zoneinfo import ZoneInfo as _ZoneInfo
            from datetime import datetime as _dt, time as _dtime, timedelta as _td
            date_offset = None  # ç”¨äºå­˜å‚¨è®¡ç®—å‡ºçš„æ—¥æœŸåç§»
            for ep in episodes:
                ep_air_date = ep.get('air_date') or ''
                ep_number = ep.get('episode_number') or 0
                if not ep_number:
                    continue
                if ep_air_date:
                    try:
                        # è§£æ TMDB air_date ä½œä¸ºæºæ—¶åŒºæ—¥æœŸ
                        src_date = _dt.strptime(ep_air_date, '%Y-%m-%d').date()
                        
                        # å¦‚æœç”¨æˆ·æ‰‹åŠ¨è®¾ç½®äº†åç§»å€¼ï¼ˆåŒ…æ‹¬æ‰‹åŠ¨è®¾ç½®ä¸º0ï¼‰ï¼Œä¼˜å…ˆä½¿ç”¨æ‰‹åŠ¨åç§»å€¼
                        if is_manually_set:
                            adjusted_date = src_date + _td(days=manual_air_date_offset)
                            air_date_local = adjusted_date.strftime('%Y-%m-%d')
                            date_offset = manual_air_date_offset
                        else:
                            # å¦åˆ™é€šè¿‡æ—¶åŒºè½¬æ¢è®¡ç®—
                            # è§£ææºæ—¶åŒºæ—¶é—´
                            hh, mm = [int(x) for x in air_time_source.split(':')]
                            src_time = _dtime(hour=hh, minute=mm)
                            # ç»„åˆæˆæºæ—¶åŒº datetime
                            src_dt = _dt.combine(src_date, src_time)
                            src_dt = src_dt.replace(tzinfo=_ZoneInfo(air_timezone))
                            # è½¬æ¢åˆ°æœ¬åœ°æ—¶åŒº
                            local_dt = src_dt.astimezone(_ZoneInfo(local_tz))
                            air_date_local = local_dt.strftime('%Y-%m-%d')
                            # è®¡ç®—æ—¥æœŸåç§»ï¼ˆå¦‚æœè¿˜æœªè®¡ç®—ï¼‰
                            if date_offset is None:
                                local_date = _dt.strptime(air_date_local, '%Y-%m-%d').date()
                                date_offset = (local_date - src_date).days
                        
                        # æ›´æ–°æ•°æ®åº“
                        cal_db.update_episode_air_date_local(
                            int(tmdb_id),
                            int(season_number),
                            int(ep_number),
                            air_date_local
                        )
                    except Exception as _e_local:
                        logging.debug(f"è®¡ç®—æœ¬åœ°æ’­å‡ºæ—¥æœŸå¤±è´¥ tmdb_id={tmdb_id}, season={season_number}, ep={ep_number}: {_e_local}")
                else:
                    # å¦‚æœ air_date ä¸ºç©ºï¼Œæ¸…ç©º air_date_local
                    try:
                        cal_db.update_episode_air_date_local(
                            int(tmdb_id),
                            int(season_number),
                            int(ep_number),
                            ''
                        )
                    except Exception as _e_clear:
                        logging.debug(f"æ¸…ç©º air_date_local å¤±è´¥ tmdb_id={tmdb_id}, season={season_number}, ep={ep_number}: {_e_clear}")
            
            # å¦‚æœè®¡ç®—å‡ºäº†æ—¥æœŸåç§»ä¸”ç”¨æˆ·æ²¡æœ‰æ‰‹åŠ¨è®¾ç½®ï¼Œå­˜å‚¨åˆ°æ•°æ®åº“
            # è¿™é‡Œçš„ date_offset æ˜¯é€šè¿‡æ—¶åŒºè½¬æ¢è®¡ç®—å‡ºçš„åç§»å€¼ï¼ˆä¾‹å¦‚ï¼šç¾ä¸œå‘¨æ—¥ 21:00 -> åŒ—äº¬æ—¶é—´å‘¨ä¸€ 10:00ï¼Œåç§» +1ï¼‰
            if date_offset is not None and not is_manually_set:
                try:
                    cal_db.update_show_air_schedule(
                        int(tmdb_id),
                        air_date_offset=date_offset
                    )
                except Exception as _offset_err:
                    logging.debug(f"å­˜å‚¨æ—¥æœŸåç§»å¤±è´¥ tmdb_id={tmdb_id}: {_offset_err}")
        except Exception as _e_batch:
            logging.debug(f"æ‰¹é‡æ›´æ–°æœ¬åœ°æ’­å‡ºæ—¥æœŸå¤±è´¥ tmdb_id={tmdb_id}, season={season_number}: {_e_batch}")
    except Exception as _e:
        logging.debug(f"æ›´æ–°æœ¬åœ°æ’­å‡ºæ—¥æœŸå¤±è´¥ tmdb_id={tmdb_id}: {_e}")


def sync_trakt_airtime_for_all_shows():
    """ä¸ºæ‰€æœ‰å·²æœ‰èŠ‚ç›®åŒæ­¥ä¸€æ¬¡ Trakt æ’­å‡ºæ—¶é—´ï¼ˆé¦–æ¬¡é…ç½® Client ID æ—¶ä½¿ç”¨ï¼‰"""
    try:
        trakt_cfg = config_data.get("trakt", {}) if isinstance(config_data, dict) else {}
        client_id = (trakt_cfg.get("client_id") or "").strip()
        if not client_id:
            logging.debug("Trakt Client ID æœªé…ç½®ï¼Œè·³è¿‡å…¨é‡æ’­å‡ºæ—¶é—´åŒæ­¥")
            return
        local_tz = config_data.get("local_timezone", "Asia/Shanghai")
        tsvc = TraktService(client_id=client_id)
        if not tsvc.is_configured():
            logging.debug("TraktService æœªé…ç½®ï¼Œè·³è¿‡å…¨é‡æ’­å‡ºæ—¶é—´åŒæ­¥")
            return

        cal_db = CalendarDB()
        shows = cal_db.get_all_shows() or []
        if not shows:
            logging.debug("å½“å‰æ— èŠ‚ç›®å¯åŒæ­¥ Trakt æ’­å‡ºæ—¶é—´")
            return

        total = len(shows)
        synced = 0
        for show in shows:
            tmdb_id = show.get("tmdb_id")
            if tmdb_id is None or tmdb_id == "":
                continue
            try:
                tmdb_id_int = int(tmdb_id)
            except Exception:
                continue

            try:
                show_info = tsvc.get_show_by_tmdb_id(tmdb_id_int)
                if not show_info or not show_info.get("trakt_id"):
                    logging.debug(f"æœªæ‰¾åˆ° Trakt èŠ‚ç›®æ˜ å°„ tmdb_id={tmdb_id_int}")
                    continue
                trakt_id = show_info.get("trakt_id")
                airtime = tsvc.get_show_airtime(trakt_id)
                if not airtime or not airtime.get("aired_time") or not airtime.get("timezone"):
                    logging.debug(f"Trakt æœªè¿”å›æ’­å‡ºæ—¶é—´ tmdb_id={tmdb_id_int}")
                    continue

                local_air_time = tsvc.convert_show_airtime_to_local(
                    airtime.get("aired_time"), airtime.get("timezone"), local_tz
                ) or airtime.get("aired_time")

                cal_db.update_show_air_schedule(
                    tmdb_id_int,
                    local_air_time=local_air_time or "",
                    air_time_source=airtime.get("aired_time") or "",
                    air_timezone=airtime.get("timezone") or "",
                )

                # åŒæ­¥å·²æœ‰é›†çš„æœ¬åœ°æ’­å‡ºæ—¥æœŸ
                try:
                    cursor = cal_db.conn.cursor()
                    cursor.execute(
                        "SELECT season_number, episode_number, air_date FROM episodes WHERE tmdb_id=?",
                        (tmdb_id_int,),
                    )
                    rows = cursor.fetchall()
                    episodes_by_season = {}
                    for season_number, ep_number, air_date in rows:
                        episodes_by_season.setdefault(season_number, []).append(
                            {"episode_number": ep_number, "air_date": air_date}
                        )
                    for season_number, eps in episodes_by_season.items():
                        update_episodes_air_date_local(cal_db, tmdb_id_int, int(season_number), eps)
                except Exception as _ep_err:
                    logging.debug(f"åŒæ­¥æœ¬åœ°æ’­å‡ºæ—¥æœŸå¤±è´¥ tmdb_id={tmdb_id_int}: {_ep_err}")

                synced += 1
            except Exception as _single_err:
                logging.debug(f"åŒæ­¥å•ä¸ªèŠ‚ç›® Trakt æ’­å‡ºæ—¶é—´å¤±è´¥ tmdb_id={tmdb_id_int}: {_single_err}")

        if synced > 0:
            try:
                notify_calendar_changed('trakt_airtime_synced')
            except Exception:
                pass
            try:
                _trigger_airtime_reschedule('trakt_airtime_synced')
            except Exception:
                pass
            # é¦–æ¬¡å…¨é‡åŒæ­¥åç«‹å³é‡ç®—æ’­å‡º/è½¬å­˜è¿›åº¦å¹¶çƒ­æ›´æ–°
            try:
                recompute_all_seasons_aired_daily()
            except Exception as _recalc_err:
                logging.debug(f"Trakt å…¨é‡åŒæ­¥åé‡ç®—è¿›åº¦å¤±è´¥: {_recalc_err}")

        logging.info(f"Trakt æ’­å‡ºæ—¶é—´å…¨é‡åŒæ­¥å®Œæˆï¼ŒæˆåŠŸ {synced}/{total}")
    except Exception as e:
        logging.warning(f"Trakt æ’­å‡ºæ—¶é—´å…¨é‡åŒæ­¥å¤±è´¥: {e}")


def get_poster_language_setting():
    """è·å–æµ·æŠ¥è¯­è¨€è®¾ç½®"""
    return config_data.get('poster_language', 'zh-CN')

def clear_all_posters():
    """æ¸…ç©ºæ‰€æœ‰æµ·æŠ¥æ–‡ä»¶"""
    try:
        import shutil
        if os.path.exists(CACHE_IMAGES_DIR):
            shutil.rmtree(CACHE_IMAGES_DIR)
            os.makedirs(CACHE_IMAGES_DIR, exist_ok=True)
        return True
    except Exception as e:
        logging.error(f"æ¸…ç©ºæµ·æŠ¥æ–‡ä»¶å¤±è´¥: {e}")
        return False

def cleanup_orphaned_posters():
    """æ¸…ç†å­¤ç«‹çš„æ—§æµ·æŠ¥æ–‡ä»¶ï¼ˆä¸åœ¨æ•°æ®åº“ä¸­çš„æµ·æŠ¥æ–‡ä»¶ï¼‰"""
    try:
        from app.sdk.db import CalendarDB
        cal_db = CalendarDB()
        
        # è·å–æ•°æ®åº“ä¸­æ‰€æœ‰æ­£åœ¨ä½¿ç”¨çš„æµ·æŠ¥è·¯å¾„
        shows = cal_db.get_all_shows()
        used_posters = set()
        for show in shows:
            poster_path = show.get('poster_local_path', '')
            if poster_path and poster_path.startswith('/cache/images/'):
                poster_name = poster_path.replace('/cache/images/', '')
                used_posters.add(poster_name)
        
        # æ‰«æç¼“å­˜ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
        if os.path.exists(CACHE_IMAGES_DIR):
            orphaned_files = []
            for filename in os.listdir(CACHE_IMAGES_DIR):
                if filename not in used_posters:
                    file_path = os.path.join(CACHE_IMAGES_DIR, filename)
                    if os.path.isfile(file_path):
                        orphaned_files.append(file_path)
            
            # åˆ é™¤å­¤ç«‹æ–‡ä»¶
            deleted_count = 0
            for file_path in orphaned_files:
                try:
                    os.remove(file_path)
                    deleted_count += 1
                except Exception as e:
                    logging.warning(f"åˆ é™¤å­¤ç«‹æµ·æŠ¥æ–‡ä»¶å¤±è´¥: {e}")
            
            # åªåœ¨åˆ é™¤äº†æ–‡ä»¶æ—¶æ‰è¾“å‡ºæ—¥å¿—
            if deleted_count > 0:
                logging.info(f"æµ·æŠ¥æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {deleted_count} ä¸ªå­¤ç«‹æ–‡ä»¶")
            return deleted_count > 0
        
        return False
    except Exception as e:
        logging.error(f"æ¸…ç†å­¤ç«‹æµ·æŠ¥å¤±è´¥: {e}")
        return False

def redownload_all_posters():
    """é‡æ–°ä¸‹è½½æ‰€æœ‰æµ·æŠ¥"""
    try:
        from app.sdk.db import CalendarDB
        cal_db = CalendarDB()
        
        # è·å–æ‰€æœ‰èŠ‚ç›®
        shows = cal_db.get_all_shows()
        if not shows:
            return True
            
        tmdb_api_key = config_data.get('tmdb_api_key', '')
        if not tmdb_api_key:
            logging.warning("TMDB APIæœªé…ç½®ï¼Œæ— æ³•é‡æ–°ä¸‹è½½æµ·æŠ¥")
            return False
            
        poster_language = get_poster_language_setting()
        tmdb_service = TMDBService(tmdb_api_key, poster_language)
        
        success_count = 0
        total_count = len(shows)
        
        for show in shows:
            try:
                tmdb_id = show.get('tmdb_id')
                if not tmdb_id:
                    continue
                    
                # è·å–æ–°çš„æµ·æŠ¥è·¯å¾„
                new_poster_path = tmdb_service.get_poster_path_with_language(int(tmdb_id))
                if new_poster_path:
                    # è·å–ç°æœ‰æµ·æŠ¥ä¿¡æ¯
                    existing_poster_path = show.get('poster_local_path', '')
                    is_custom_poster = bool(show.get('is_custom_poster', 0))
                    # ä¸‹è½½æ–°æµ·æŠ¥
                    poster_local_path = download_poster_local(new_poster_path, int(tmdb_id), existing_poster_path, is_custom_poster)
                    if poster_local_path:
                        # æ›´æ–°æ•°æ®åº“ä¸­çš„æµ·æŠ¥è·¯å¾„
                        cal_db.update_show_poster(int(tmdb_id), poster_local_path)
                        success_count += 1
                        # é€šçŸ¥å‰ç«¯è¯¥èŠ‚ç›®æµ·æŠ¥å·²æ›´æ–°
                        try:
                            notify_calendar_changed(f'poster_updated:{int(tmdb_id)}')
                        except Exception:
                            pass
                        
            except Exception as e:
                logging.error(f"é‡æ–°ä¸‹è½½æµ·æŠ¥å¤±è´¥ (TMDB ID: {show.get('tmdb_id')}): {e}")
                continue
                
        # é‡æ–°ä¸‹è½½å®Œæˆåï¼Œæ¸…ç†å­¤ç«‹çš„æ—§æµ·æŠ¥æ–‡ä»¶
        try:
            cleanup_orphaned_posters()
        except Exception as e:
            logging.warning(f"æ¸…ç†å­¤ç«‹æµ·æŠ¥å¤±è´¥: {e}")
        
        return success_count > 0
        
    except Exception as e:
        logging.error(f"é‡æ–°ä¸‹è½½æ‰€æœ‰æµ·æŠ¥å¤±è´¥: {e}")
        return False

def download_poster_local(poster_path: str, tmdb_id: int = None, existing_poster_path: str = None, is_custom_poster: bool = False) -> str:
    """ä¸‹è½½ TMDB æµ·æŠ¥åˆ°æœ¬åœ° static/cache/images ä¸‹ï¼Œç­‰æ¯”ç¼©æ”¾ä¸ºå®½400pxï¼Œè¿”å›ç›¸å¯¹è·¯å¾„ã€‚
    
    Args:
        poster_path: TMDBæµ·æŠ¥è·¯å¾„
        tmdb_id: TMDB IDï¼Œç”¨äºæ£€æŸ¥è‡ªå®šä¹‰æµ·æŠ¥æ ‡è®°
        existing_poster_path: ç°æœ‰çš„æµ·æŠ¥è·¯å¾„ï¼Œç”¨äºæ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        is_custom_poster: æ˜¯å¦ä¸ºè‡ªå®šä¹‰æµ·æŠ¥æ ‡è®°
    """
    try:
        if not poster_path:
            return ''
            
        folder = CACHE_IMAGES_DIR
        # åŸºäº poster_path ç”Ÿæˆæ–‡ä»¶å
        safe_name = poster_path.strip('/').replace('/', '_') or 'poster.jpg'
        file_path = os.path.join(folder, safe_name)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™ç›´æ¥è¿”å›è·¯å¾„
        if os.path.exists(file_path):
            return f"/cache/images/{safe_name}"
        
        # å¦‚æœæä¾›äº†ç°æœ‰æµ·æŠ¥è·¯å¾„ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        if existing_poster_path and tmdb_id is not None:
            existing_file_name = existing_poster_path.replace('/cache/images/', '')
            new_file_name = safe_name
            
            # å¦‚æœæ–‡ä»¶åä¸åŒï¼Œè¯´æ˜TMDBæµ·æŠ¥æœ‰å˜æ›´
            if existing_file_name != new_file_name:
                # æ£€æŸ¥æ˜¯å¦æœ‰è‡ªå®šä¹‰æµ·æŠ¥æ ‡è®°
                if is_custom_poster:
                    return existing_poster_path
                else:
                    # åˆ é™¤æ—§æ–‡ä»¶
                    try:
                        old_file_path = os.path.join(folder, existing_file_name)
                        if os.path.exists(old_file_path):
                            os.remove(old_file_path)
                    except Exception as e:
                        logging.warning(f"åˆ é™¤æ—§æµ·æŠ¥æ–‡ä»¶å¤±è´¥: {e}")
        
        # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œéœ€è¦ä¸‹è½½
        base = "https://image.tmdb.org/t/p/w400"
        url = f"{base}{poster_path}"
        r = requests.get(url, timeout=10)
        if r.status_code != 200:
            return ''
            
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(folder, exist_ok=True)
        
        with open(file_path, 'wb') as f:
            f.write(r.content)
        # è¿”å›ç”¨äºå‰ç«¯å¼•ç”¨çš„ç›¸å¯¹è·¯å¾„ï¼ˆé€šè¿‡ /cache/images æš´éœ²ï¼‰
        return f"/cache/images/{safe_name}"
    except Exception:
        return ''


def download_custom_poster(poster_url: str, tmdb_id: int, target_safe_name: str = None) -> str:
    """ä¸‹è½½è‡ªå®šä¹‰æµ·æŠ¥åˆ°æœ¬åœ°ï¼Œå°½é‡è¦†ç›–åŸæœ‰æµ·æŠ¥æ–‡ä»¶åï¼Œè¿”å›ç›¸å¯¹è·¯å¾„ã€‚

    æ³¨æ„ï¼šä¸å¼•å…¥ä»»ä½•é¢å¤–ä¾èµ–ï¼Œä¸è¿›è¡Œç­‰æ¯”ç¼©æ”¾ã€‚å¦‚éœ€ç¼©æ”¾åº”åœ¨å®¹å™¨å…·å¤‡å·¥å…·æ—¶å†æ‰©å±•ã€‚
    """
    try:
        if not poster_url or not tmdb_id:
            return ''

        folder = CACHE_IMAGES_DIR
        # ç›®æ ‡æ–‡ä»¶åï¼šè‹¥æä¾›åˆ™ä½¿ç”¨ç°æœ‰æ–‡ä»¶åè¦†ç›–ï¼›å¦åˆ™æ ¹æ®å†…å®¹ç±»å‹/URLæ¨æ–­æ‰©å±•å
        default_ext = 'jpg'
        safe_name = (target_safe_name or '').strip()
        if not safe_name:
            # å°è¯•ä» URL æ¨æ–­æ‰©å±•å
            guessed_ext = None
            try:
                from urllib.parse import urlparse
                path = urlparse(poster_url).path
                base = os.path.basename(path)
                if '.' in base:
                    guessed_ext = base.split('.')[-1].lower()
            except Exception:
                guessed_ext = None
            ext = guessed_ext or default_ext
            # ç®€å•æ ‡å‡†åŒ–
            if ext in ('jpeg',):
                ext = 'jpg'
            safe_name = f"poster_{tmdb_id}.{ext}"
        file_path = os.path.join(folder, safe_name)

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(folder, exist_ok=True)

        # å¤„ç† file:// å‰ç¼€
        if poster_url.lower().startswith('file://'):
            poster_url = poster_url[7:]

        # å¤„ç†æœ¬åœ°æ–‡ä»¶è·¯å¾„
        if poster_url.startswith('/') or poster_url.startswith('./'):
            # æœ¬åœ°æ–‡ä»¶è·¯å¾„
            if os.path.exists(poster_url):
                # è‹¥æä¾›äº†ç›®æ ‡åä½†å…¶æ‰©å±•åä¸æºæ–‡ä»¶æ˜æ˜¾ä¸ç¬¦ï¼ˆä¾‹å¦‚æºä¸º .avifï¼‰ï¼Œåˆ™æ”¹ç”¨åŸºäº tmdb_id çš„æ ‡å‡†æ–‡ä»¶åå¹¶åŒ¹é…æ‰©å±•
                try:
                    src_ext = os.path.splitext(poster_url)[1].lower().lstrip('.')
                except Exception:
                    src_ext = ''
                if src_ext in ('jpeg',):
                    src_ext = 'jpg'
                if src_ext in ('jpg', 'png', 'webp', 'avif'):
                    target_ext = os.path.splitext(safe_name)[1].lower().lstrip('.') if '.' in safe_name else ''
                    if target_ext != src_ext:
                        safe_name = f"poster_{tmdb_id}.{src_ext or default_ext}"
                        file_path = os.path.join(folder, safe_name)
                import shutil
                shutil.copy2(poster_url, file_path)
                return f"/cache/images/{safe_name}"
            else:
                logging.warning(f"æœ¬åœ°æµ·æŠ¥æ–‡ä»¶ä¸å­˜åœ¨: {poster_url}")
                return ''
        else:
            # ç½‘ç»œURL
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            r = requests.get(poster_url, timeout=15, headers=headers)
            if r.status_code != 200:
                logging.warning(f"ä¸‹è½½è‡ªå®šä¹‰æµ·æŠ¥å¤±è´¥: {poster_url}, çŠ¶æ€ç : {r.status_code}")
                return ''

            # æ£€æŸ¥å†…å®¹ç±»å‹æ˜¯å¦ä¸ºå›¾ç‰‡ï¼ˆæ— æ³•ä¸¥æ ¼åˆ¤æ–­æ‰©å±•åï¼Œè¿™é‡Œä»…åŸºäºå“åº”å¤´ï¼‰
            content_type = (r.headers.get('content-type') or '').lower()
            if not any(img_type in content_type for img_type in ['image/jpeg', 'image/jpg', 'image/png', 'image/webp', 'image/avif']):
                logging.warning(f"è‡ªå®šä¹‰æµ·æŠ¥URLä¸æ˜¯æœ‰æ•ˆçš„å›¾ç‰‡æ ¼å¼: {poster_url}, å†…å®¹ç±»å‹: {content_type}")
                # ä¸å¼ºåˆ¶å¤±è´¥ï¼Œæ”¾è¡Œä¿å­˜ï¼Œéƒ¨åˆ†æœåŠ¡ä¸è¿”å›æ ‡å‡†content-type
                # return ''

            # è‹¥æœªæŒ‡å®šç›®æ ‡æ–‡ä»¶åï¼Œæˆ–æŒ‡å®šçš„æ‰©å±•ä¸å†…å®¹ç±»å‹ä¸ä¸€è‡´ï¼Œåˆ™æ ¹æ® content-type ä¿®æ­£æ‰©å±•å
            need_fix_ext = False
            if (target_safe_name or '').strip():
                # æ ¡éªŒå·²æœ‰ç›®æ ‡åçš„æ‰©å±•
                current_ext = os.path.splitext(safe_name)[1].lower().lstrip('.') if '.' in safe_name else ''
                if ('image/avif' in content_type and current_ext != 'avif') or \
                   ('image/webp' in content_type and current_ext != 'webp') or \
                   (('image/jpeg' in content_type or 'image/jpg' in content_type) and current_ext not in ('jpg','jpeg')) or \
                   ('image/png' in content_type and current_ext != 'png'):
                    need_fix_ext = True
            if not (target_safe_name or '').strip() or need_fix_ext:
                ext_map = {
                    'image/jpeg': 'jpg',
                    'image/jpg': 'jpg',
                    'image/png': 'png',
                    'image/webp': 'webp',
                    'image/avif': 'avif',
                }
                chosen_ext = None
                for k, v in ext_map.items():
                    if k in content_type:
                        chosen_ext = v
                        break
                if chosen_ext:
                    base_no_ext = f"poster_{tmdb_id}"
                    safe_name = f"{base_no_ext}.{chosen_ext}"
                    file_path = os.path.join(folder, safe_name)

            with open(file_path, 'wb') as f:
                f.write(r.content)

            # è‡ªå®šä¹‰æµ·æŠ¥ä¿å­˜æˆåŠŸï¼ˆé™é»˜ï¼‰
            return f"/cache/images/{safe_name}"

    except Exception as e:
        logging.error(f"ä¸‹è½½è‡ªå®šä¹‰æµ·æŠ¥å¤±è´¥: {e}")
        return ''


# åˆ·æ–°ï¼šæ‹‰å–æœ€æ–°ä¸€å­£æ‰€æœ‰é›†ï¼ŒæŒ‰æœ‰æ—  runtime è¿›è¡Œå¢é‡æ›´æ–°
@app.route("/api/calendar/refresh_latest_season")
def calendar_refresh_latest_season():
    try:
        if not is_login():
            return jsonify({"success": False, "message": "æœªç™»å½•"})

        tmdb_id = request.args.get('tmdb_id', type=int)
        if not tmdb_id:
            return jsonify({"success": False, "message": "ç¼ºå°‘ tmdb_id"})

        tmdb_api_key = config_data.get('tmdb_api_key', '')
        if not tmdb_api_key:
            return jsonify({"success": False, "message": "TMDB API æœªé…ç½®"})

        poster_language = get_poster_language_setting()
        tmdb_service = TMDBService(tmdb_api_key, poster_language)
        cal_db = CalendarDB()
        show = cal_db.get_show(int(tmdb_id))
        if not show:
            return jsonify({"success": False, "message": "æœªåˆå§‹åŒ–è¯¥å‰§ï¼ˆè¯·å…ˆ bootstrapï¼‰"})

        try:
            show_name_for_log = show.get('name') or f"tmdb:{tmdb_id}"
            logging.info(f">>> å¼€å§‹æ‰§è¡Œåˆ·æ–°æœ€æ–°å­£å…ƒæ•°æ® [{show_name_for_log}]")
        except Exception:
            pass

        latest_season = int(show['latest_season_number'])
        season = tmdb_service.get_tv_show_episodes(tmdb_id, latest_season) or {}
        episodes = season.get('episodes', []) or []

        from time import time as _now
        now_ts = int(_now())

        any_written = False
        # æ ¹å› ä¿®å¤ï¼šæ¸…ç†æœ¬åœ°è¯¥å­£ä¸­ TMDB ä¸å­˜åœ¨çš„å¤šä½™é›†
        try:
            valid_eps = []
            for _ep in episodes:
                try:
                    n = int(_ep.get('episode_number') or 0)
                    if n > 0:
                        valid_eps.append(n)
                except Exception:
                    pass
            cal_db.prune_season_episodes_not_in(int(tmdb_id), int(latest_season), valid_eps)
        except Exception:
            pass
        for ep in episodes:
            cal_db.upsert_episode(
                tmdb_id=int(tmdb_id),
                season_number=latest_season,
                episode_number=int(ep.get('episode_number') or 0),
                name=ep.get('name') or '',
                overview=ep.get('overview') or '',
                air_date=ep.get('air_date') or '',
                runtime=ep.get('runtime'),
                ep_type=(ep.get('episode_type') or ep.get('type')),
                updated_at=now_ts,
            )
        # å¦‚æœæœ‰ Trakt çš„æºæ—¶é—´/æ—¶åŒºï¼Œè®¡ç®—æ¯é›†çš„æœ¬åœ°æ’­å‡ºæ—¥æœŸå¹¶æ›´æ–° air_date_local
        update_episodes_air_date_local(cal_db, int(tmdb_id), latest_season, episodes)
        any_written = True

        # åŒæ­¥æ›´æ–° seasons è¡¨çš„å­£åç§°ä¸æ€»é›†æ•°
        try:
            season_name_raw = season.get('name') or ''
            season_name_processed = tmdb_service.process_season_name(season_name_raw)
        except Exception:
            season_name_processed = season.get('name') or ''
        try:
            cal_db.upsert_season(
                int(tmdb_id),
                int(latest_season),
                len(episodes),
                f"/tv/{tmdb_id}/season/{latest_season}",
                season_name_processed
            )
            # å†™å› season_metricsï¼ˆair/totalï¼‰ï¼Œtransferred ç•™å¾…èšåˆæ›´æ–°
            try:
                # ä½¿ç”¨ is_episode_aired é€é›†åˆ¤æ–­è®¡ç®—å·²æ’­å‡ºé›†æ•°ï¼ˆè€ƒè™‘æ’­å‡ºæ—¶é—´ï¼‰
                # ä¿®å¤ï¼šä¸å†ä½¿ç”¨ç®€å•çš„æ—¥æœŸæ¯”è¾ƒï¼Œè€Œæ˜¯é€é›†è°ƒç”¨ is_episode_aired åˆ¤æ–­æ˜¯å¦å·²æ’­å‡º
                try:
                    from zoneinfo import ZoneInfo as _ZoneInfo
                    local_tz = _ZoneInfo(_get_local_timezone())
                    now_local_dt = datetime.now(local_tz)
                except Exception:
                    now_local_dt = datetime.now()
                aired_cnt = compute_aired_count_by_episode_check(int(tmdb_id), int(latest_season), now_local_dt)
                progress_pct = 0
                from time import time as _now
                cal_db.upsert_season_metrics(int(tmdb_id), int(latest_season), None, aired_cnt, int(len(episodes)), int(progress_pct), int(_now()))
            except Exception:
                pass
        except Exception:
            pass
        # å•èŠ‚ç›®æ‰‹åŠ¨åˆ·æ–°å®Œæˆåï¼Œç«‹å³é‡ç®—å·²æ’­å‡º/è¿›åº¦å¹¶åŒæ­¥å‰åç«¯
        try:
            recompute_show_aired_progress(int(tmdb_id))
        except Exception as _recalc_err:
            logging.debug(f"åˆ·æ–°åé‡ç®—æ’­å‡ºè¿›åº¦å¤±è´¥ tmdb_id={tmdb_id}: {_recalc_err}")

        try:
            if any_written:
                notify_calendar_changed('refresh_latest_season')
        except Exception:
            pass
        try:
            _trigger_airtime_reschedule('refresh_latest_season', tmdb_id)
        except Exception:
            pass
        try:
            logging.info(f">>> åˆ·æ–°æœ€æ–°å­£å…ƒæ•°æ® [{show_name_for_log}] æ‰§è¡ŒæˆåŠŸ")
        except Exception:
            pass
        return jsonify({"success": True, "updated": len(episodes)})
    except Exception as e:
        return jsonify({"success": False, "message": f"åˆ·æ–°å¤±è´¥: {str(e)}"})


# å·¥å…·å‡½æ•°ï¼šæ ¼å¼åŒ–é›†èŒƒå›´ç”¨äºæ—¥å¿—
def format_episode_range_for_log(episodes):
    try:
        eps = sorted(set(int(x) for x in episodes if x is not None))
    except Exception:
        return ''
    if not eps:
        return ''
    if len(eps) == 1:
        return f"ç¬¬ {eps[0]} é›†"
    # æ£€æµ‹è¿ç»­
    is_consecutive = all(eps[i] + 1 == eps[i + 1] for i in range(len(eps) - 1))
    if is_consecutive:
        return f"ç¬¬ {eps[0]} è‡³ {eps[-1]} é›†"
    return "ç¬¬ " + "ã€".join(str(e) for e in eps) + " é›†"


def _refresh_single_episode(cal_db, tmdb_id: int, season_number: int, episode_number: int, tmdb_service):
    season = tmdb_service.get_tv_show_episodes(tmdb_id, season_number) or {}
    episodes = season.get('episodes', []) or []
    target_episode = None
    for ep in episodes:
        if int(ep.get('episode_number') or 0) == episode_number:
            target_episode = ep
            break
    if not target_episode:
        raise ValueError(f"æœªæ‰¾åˆ°ç¬¬ {season_number} å­£ç¬¬ {episode_number} é›†")

    from time import time as _now
    now_ts = int(_now())
    cal_db.upsert_episode(
        tmdb_id=int(tmdb_id),
        season_number=season_number,
        episode_number=episode_number,
        name=target_episode.get('name') or '',
        overview=target_episode.get('overview') or '',
        air_date=target_episode.get('air_date') or '',
        runtime=target_episode.get('runtime'),
        ep_type=(target_episode.get('episode_type') or target_episode.get('type')),
        updated_at=now_ts,
    )
    update_episodes_air_date_local(cal_db, int(tmdb_id), season_number, [target_episode])
    return target_episode


# å¼ºåˆ¶åˆ·æ–°å•é›†å…ƒæ•°æ®
@app.route("/api/calendar/refresh_episode")
def calendar_refresh_episode():
    try:
        if not is_login():
            return jsonify({"success": False, "message": "æœªç™»å½•"})

        tmdb_id = request.args.get('tmdb_id', type=int)
        season_number = request.args.get('season_number', type=int)
        episode_number = request.args.get('episode_number', type=int)
        
        if not tmdb_id or not season_number or not episode_number:
            return jsonify({"success": False, "message": "ç¼ºå°‘å¿…è¦å‚æ•°"})

        tmdb_api_key = config_data.get('tmdb_api_key', '')
        if not tmdb_api_key:
            return jsonify({"success": False, "message": "TMDB API æœªé…ç½®"})

        poster_language = get_poster_language_setting()
        tmdb_service = TMDBService(tmdb_api_key, poster_language)
        cal_db = CalendarDB()
        
        show = cal_db.get_show(int(tmdb_id))
        if not show:
            return jsonify({"success": False, "message": "æœªåˆå§‹åŒ–è¯¥å‰§ï¼ˆè¯·å…ˆ bootstrapï¼‰"})

        show_name_for_log = show.get('name') or f"tmdb:{tmdb_id}"
        try:
            logging.info(f">>> å¼€å§‹æ‰§è¡Œåˆ·æ–°å…ƒæ•°æ® [{show_name_for_log} Â· ç¬¬ {season_number} å­£ Â· ç¬¬ {episode_number} é›†]")
        except Exception:
            pass

        target_episode = _refresh_single_episode(cal_db, int(tmdb_id), int(season_number), int(episode_number), tmdb_service)

        try:
            notify_calendar_changed('refresh_episode')
        except Exception:
            pass
        try:
            _trigger_airtime_reschedule('refresh_episode', tmdb_id)
        except Exception:
            pass
            
        show_name = show.get('name', 'æœªçŸ¥å‰§é›†')
        try:
            logging.info(f">>> åˆ·æ–°å…ƒæ•°æ® [{show_name_for_log} Â· ç¬¬ {season_number} å­£ Â· ç¬¬ {episode_number} é›†] æ‰§è¡ŒæˆåŠŸ")
        except Exception:
            pass
        return jsonify({"success": True, "message": f"ã€Š{show_name}ã€‹ç¬¬ {season_number} å­£ Â· ç¬¬ {episode_number} é›†åˆ·æ–°æˆåŠŸ"})
    except Exception as e:
        return jsonify({"success": False, "message": f"åˆ·æ–°å¤±è´¥: {str(e)}"})


# æ‰¹é‡åˆ·æ–°å¤šé›†ï¼ˆåˆå¹¶é›†ï¼‰
@app.route("/api/calendar/refresh_episodes_batch")
def calendar_refresh_episodes_batch():
    try:
        if not is_login():
            return jsonify({"success": False, "message": "æœªç™»å½•"})

        tmdb_id = request.args.get('tmdb_id', type=int)
        season_number = request.args.get('season_number', type=int)
        episode_numbers_raw = request.args.get('episode_numbers', '')

        if not tmdb_id or not season_number or not episode_numbers_raw:
            return jsonify({"success": False, "message": "ç¼ºå°‘å¿…è¦å‚æ•°"})

        try:
            episode_numbers = [int(x) for x in str(episode_numbers_raw).split(',') if str(x).strip()]
        except Exception:
            return jsonify({"success": False, "message": "episode_numbers å‚æ•°éæ³•"})
        if not episode_numbers:
            return jsonify({"success": False, "message": "ç¼ºå°‘æœ‰æ•ˆçš„é›†å·åˆ—è¡¨"})

        tmdb_api_key = config_data.get('tmdb_api_key', '')
        if not tmdb_api_key:
            return jsonify({"success": False, "message": "TMDB API æœªé…ç½®"})

        poster_language = get_poster_language_setting()
        tmdb_service = TMDBService(tmdb_api_key, poster_language)
        cal_db = CalendarDB()

        show = cal_db.get_show(int(tmdb_id))
        if not show:
            return jsonify({"success": False, "message": "æœªåˆå§‹åŒ–è¯¥å‰§ï¼ˆè¯·å…ˆ bootstrapï¼‰"})

        show_name_for_log = show.get('name') or f"tmdb:{tmdb_id}"
        ep_range = format_episode_range_for_log(episode_numbers)
        try:
            logging.info(f">>> å¼€å§‹æ‰§è¡Œåˆ·æ–°å…ƒæ•°æ® [{show_name_for_log} Â· ç¬¬ {season_number} å­£ Â· {ep_range}]")
        except Exception:
            pass

        failed = []
        for ep_num in episode_numbers:
            try:
                _refresh_single_episode(cal_db, int(tmdb_id), int(season_number), int(ep_num), tmdb_service)
            except Exception as e:
                failed.append((ep_num, str(e)))

        try:
            notify_calendar_changed('refresh_episode')
        except Exception:
            pass
        try:
            _trigger_airtime_reschedule('refresh_episodes_batch', tmdb_id)
        except Exception:
            pass

        show_name = show.get('name', 'æœªçŸ¥å‰§é›†')
        if failed:
            msg = f"ã€Š{show_name}ã€‹ç¬¬ {season_number} å­£ Â· {ep_range}éƒ¨åˆ†åˆ·æ–°å¤±è´¥: {failed}"
            return jsonify({"success": False, "message": msg})
        try:
            logging.info(f">>> åˆ·æ–°å…ƒæ•°æ® [{show_name_for_log} Â· ç¬¬ {season_number} å­£ Â· {ep_range}] æ‰§è¡ŒæˆåŠŸ")
        except Exception:
            pass
        return jsonify({"success": True, "message": f"ã€Š{show_name}ã€‹ç¬¬ {season_number} å­£ Â· {ep_range}åˆ·æ–°æˆåŠŸ"})
    except Exception as e:
        return jsonify({"success": False, "message": f"åˆ·æ–°å¤±è´¥: {str(e)}"})


# å¼ºåˆ¶åˆ·æ–°æ•´ä¸ªå­£çš„å…ƒæ•°æ®ï¼ˆå†…å®¹ç®¡ç†è§†å›¾ä½¿ç”¨ï¼‰
@app.route("/api/calendar/refresh_season")
def calendar_refresh_season():
    try:
        if not is_login():
            return jsonify({"success": False, "message": "æœªç™»å½•"})

        tmdb_id = request.args.get('tmdb_id', type=int)
        season_number = request.args.get('season_number', type=int)
        is_auto_refresh = request.args.get('is_auto_refresh', 'false').lower() == 'true'
        is_batch_refresh = request.args.get('is_batch_refresh', 'false').lower() == 'true'
        is_edit_metadata_refresh = request.args.get('is_edit_metadata_refresh', 'false').lower() == 'true'
        
        if not tmdb_id or not season_number:
            return jsonify({"success": False, "message": "ç¼ºå°‘å¿…è¦å‚æ•°"})

        tmdb_api_key = config_data.get('tmdb_api_key', '')
        if not tmdb_api_key:
            return jsonify({"success": False, "message": "TMDB API æœªé…ç½®"})

        poster_language = get_poster_language_setting()
        tmdb_service = TMDBService(tmdb_api_key, poster_language)
        cal_db = CalendarDB()
        
        # éªŒè¯èŠ‚ç›®æ˜¯å¦å­˜åœ¨
        show = cal_db.get_show(int(tmdb_id))
        if not show:
            return jsonify({"success": False, "message": "æœªåˆå§‹åŒ–è¯¥å‰§ï¼ˆè¯·å…ˆ bootstrapï¼‰"})

        # æ—¥å¿—ï¼šå­£çº§åˆ·æ–°ï¼ˆæ‰¹é‡åˆ·æ–°æ—¶ä¸è¾“å‡ºå•ä¸ªä»»åŠ¡æ—¥å¿—ï¼Œæ‰‹åŠ¨åˆ·æ–°ç”¨INFOï¼Œè‡ªåŠ¨åˆ·æ–°å’Œç¼–è¾‘å…ƒæ•°æ®è§¦å‘çš„åˆ·æ–°ç”¨DEBUGï¼‰
        if not is_batch_refresh:
            try:
                show_name_for_log = show.get('name') or f"tmdb:{tmdb_id}"
                log_msg = f">>> å¼€å§‹æ‰§è¡Œåˆ·æ–°å…ƒæ•°æ® [{show_name_for_log} Â· ç¬¬ {season_number} å­£]"
                if is_auto_refresh or is_edit_metadata_refresh:
                    logging.debug(log_msg)
                else:
                    logging.info(log_msg)
            except Exception:
                pass

        # è·å–æŒ‡å®šå­£çš„æ‰€æœ‰é›†æ•°æ®
        season = tmdb_service.get_tv_show_episodes(tmdb_id, season_number) or {}
        episodes = season.get('episodes', []) or []
        
        if not episodes:
            return jsonify({"success": False, "message": f"ç¬¬ {season_number} å­£æ²¡æœ‰é›†æ•°æ®"})

        # å¼ºåˆ¶æ›´æ–°è¯¥å­£æ‰€æœ‰é›†æ•°æ®ï¼ˆæ— è®ºæ˜¯å¦æœ‰ runtimeï¼‰
        from time import time as _now
        now_ts = int(_now())
        
        # æ ¹å› ä¿®å¤ï¼šæ¸…ç†æœ¬åœ°è¯¥å­£ä¸­ TMDB ä¸å­˜åœ¨çš„å¤šä½™é›†
        try:
            valid_eps = []
            for _ep in episodes:
                try:
                    n = int(_ep.get('episode_number') or 0)
                    if n > 0:
                        valid_eps.append(n)
                except Exception:
                    pass
            cal_db.prune_season_episodes_not_in(int(tmdb_id), int(season_number), valid_eps)
        except Exception:
            pass

        updated_count = 0
        for ep in episodes:
            cal_db.upsert_episode(
                tmdb_id=int(tmdb_id),
                season_number=season_number,
                episode_number=int(ep.get('episode_number') or 0),
                name=ep.get('name') or '',
                overview=ep.get('overview') or '',
                air_date=ep.get('air_date') or '',
                runtime=ep.get('runtime'),
                ep_type=(ep.get('episode_type') or ep.get('type')),
                updated_at=now_ts,
            )
            updated_count += 1
        
        # å¦‚æœæœ‰ Trakt çš„æºæ—¶é—´/æ—¶åŒºï¼Œè®¡ç®—æ¯é›†çš„æœ¬åœ°æ’­å‡ºæ—¥æœŸå¹¶æ›´æ–° air_date_local
        update_episodes_air_date_local(cal_db, int(tmdb_id), season_number, episodes)

        # åŒæ­¥æ›´æ–° seasons è¡¨çš„å­£åç§°ä¸æ€»é›†æ•°
        try:
            season_name_raw = season.get('name') or ''
            season_name_processed = tmdb_service.process_season_name(season_name_raw)
        except Exception:
            season_name_processed = season.get('name') or ''
        try:
            cal_db.upsert_season(
                int(tmdb_id),
                int(season_number),
                len(episodes),
                f"/tv/{tmdb_id}/season/{season_number}",
                season_name_processed
            )
            # å†™å› season_metricsï¼ˆä½¿ç”¨æ—¶åŒºæ„ŸçŸ¥çš„å·²æ’­å‡ºåˆ¤å®šï¼‰
            try:
                try:
                    from zoneinfo import ZoneInfo as _ZoneInfo
                    _local_tz = _ZoneInfo(_get_local_timezone())
                    _now_local_dt = datetime.now(_local_tz)
                except Exception:
                    _now_local_dt = datetime.now()
                aired_cnt = 0
                cur = cal_db.conn.cursor()
                cur.execute(
                    """
                    SELECT episode_number FROM episodes
                    WHERE tmdb_id=? AND season_number=?
                    """,
                    (int(tmdb_id), int(season_number)),
                )
                ep_list = cur.fetchall() or []
                for (_ep_no,) in ep_list:
                    try:
                        result = is_episode_aired(int(tmdb_id), int(season_number), int(_ep_no), _now_local_dt)
                        if result:
                            aired_cnt += 1
                    except Exception as _ep_err:
                        logging.debug(f"calendar_refresh_season è®¡ç®—å·²æ’­å‡ºé›†æ•°å¼‚å¸¸: tmdb_id={tmdb_id}, season={season_number}, ep={_ep_no}, error={_ep_err}")
                        import traceback
                        logging.debug(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
                        continue
                from time import time as _now
                logging.debug(f"calendar_refresh_season è®¡ç®—å®Œæˆ: tmdb_id={tmdb_id}, season={season_number}, aired_cnt={aired_cnt}, total={len(episodes)}")
                cal_db.upsert_season_metrics(int(tmdb_id), int(season_number), None, aired_cnt, int(len(episodes)), 0, int(_now()))
            except Exception as _metrics_err:
                logging.debug(f"calendar_refresh_season æ›´æ–° season_metrics å¼‚å¸¸: tmdb_id={tmdb_id}, season={season_number}, error={_metrics_err}")
                import traceback
                logging.debug(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
                pass
        except Exception:
            pass

        # é€šçŸ¥æ—¥å†æ•°æ®å˜æ›´
        try:
            notify_calendar_changed('refresh_season')
        except Exception:
            pass
        try:
            _trigger_airtime_reschedule('refresh_season', tmdb_id)
        except Exception:
            pass

        # è·å–å‰§åç”¨äºé€šçŸ¥
        show_name = show.get('name', 'æœªçŸ¥å‰§é›†')
        if not is_batch_refresh:
            try:
                log_msg = f">>> åˆ·æ–°å…ƒæ•°æ® [{show_name_for_log} Â· ç¬¬ {season_number} å­£] æ‰§è¡ŒæˆåŠŸ"
                if is_auto_refresh or is_edit_metadata_refresh:
                    logging.debug(log_msg)
                else:
                    logging.info(log_msg)
            except Exception:
                pass
        # åˆ·æ–°åå›å¡«ä»»åŠ¡è¿›åº¦ï¼ˆè‹¥æœ‰ç»‘å®šä¸”åŒ¹é…åˆ°åŒå­£ï¼‰
        try:
            tasks = (config_data or {}).get('tasklist', [])
            bound_tasks = []
            for _t in tasks:
                _name = _t.get('taskname') or _t.get('task_name') or ''
                _cal = (_t.get('calendar_info') or {})
                _match = (_cal.get('match') or {})
                _tid = _match.get('tmdb_id') or _cal.get('tmdb_id')
                _matched_sn = _t.get('matched_latest_season_number')
                if _name and _tid and int(_tid) == int(tmdb_id):
                    # ä»…å¯¹åŒ¹é…åˆ°åŒä¸€å­£çš„ä»»åŠ¡æ‰§è¡Œå›å¡«
                    if _matched_sn is None or int(_matched_sn) == int(season_number):
                        bound_tasks.append(_name)
            for _task_name in bound_tasks:
                try:
                    recompute_task_metrics_and_notify(_task_name)
                except Exception:
                    continue
        except Exception:
            pass

        return jsonify({"success": True, "message": f"ã€Š{show_name}ã€‹ç¬¬ {season_number} å­£åˆ·æ–°æˆåŠŸï¼Œå…± {updated_count} é›†"})
    except Exception as e:
        return jsonify({"success": False, "message": f"åˆ·æ–°å¤±è´¥: {str(e)}"})


# è®°å½•æ‰¹é‡åˆ·æ–°å¼€å§‹æ—¥å¿—
@app.route("/api/calendar/log_batch_refresh_start", methods=["POST"])
def log_batch_refresh_start():
    try:
        if not is_login():
            return jsonify({"success": False, "message": "æœªç™»å½•"})
        logging.info(">>> å¼€å§‹æ‰§è¡Œè¿½å‰§æ—¥å†æ‰‹åŠ¨åˆ·æ–°")
        return jsonify({"success": True})
    except Exception as e:
        return jsonify({"success": False, "message": f"è®°å½•æ—¥å¿—å¤±è´¥: {str(e)}"})


# è®°å½•æ‰¹é‡åˆ·æ–°ç»“æŸæ—¥å¿—
@app.route("/api/calendar/log_batch_refresh_end", methods=["POST"])
def log_batch_refresh_end():
    try:
        if not is_login():
            return jsonify({"success": False, "message": "æœªç™»å½•"})
        logging.info(">>> è¿½å‰§æ—¥å†æ‰‹åŠ¨åˆ·æ–°æ‰§è¡ŒæˆåŠŸ")
        return jsonify({"success": True})
    except Exception as e:
        return jsonify({"success": False, "message": f"è®°å½•æ—¥å¿—å¤±è´¥: {str(e)}"})


# åˆ·æ–°ï¼šæ‹‰å–å‰§çº§åˆ«çš„æœ€æ–°è¯¦æƒ…å¹¶æ›´æ–° shows è¡¨ï¼ˆç”¨äºæ›´æ–°èŠ‚ç›®çŠ¶æ€/ä¸­æ–‡å/é¦–æ’­å¹´/æµ·æŠ¥/æœ€æ–°å­£ï¼‰
@app.route("/api/calendar/refresh_show")
def calendar_refresh_show():
    try:
        if not is_login():
            return jsonify({"success": False, "message": "æœªç™»å½•"})

        tmdb_id = request.args.get('tmdb_id', type=int)
        if not tmdb_id:
            return jsonify({"success": False, "message": "ç¼ºå°‘ tmdb_id"})

        tmdb_api_key = config_data.get('tmdb_api_key', '')
        if not tmdb_api_key:
            return jsonify({"success": False, "message": "TMDB API æœªé…ç½®"})

        poster_language = get_poster_language_setting()
        tmdb_service = TMDBService(tmdb_api_key, poster_language)
        cal_db = CalendarDB()

        details = tmdb_service.get_tv_show_details(int(tmdb_id)) or {}
        if not details:
            return jsonify({"success": False, "message": "æœªè·å–åˆ°èŠ‚ç›®è¯¦æƒ…"})

        try:
            existing_show = cal_db.get_show(int(tmdb_id))
        except Exception:
            existing_show = None

        # æ ‡é¢˜ã€çŠ¶æ€ä¸æœ€æ–°å­£
        try:
            name = tmdb_service.get_chinese_title_with_fallback(int(tmdb_id), (existing_show or {}).get('name') or '')
        except Exception:
            name = (details.get('name') or details.get('original_name') or (existing_show or {}).get('name') or '')

        first_air = (details.get('first_air_date') or '')[:4]
        raw_status = (details.get('status') or '')
        try:
            latest_sn_for_status = int((existing_show or {}).get('latest_season_number') or 1)
            localized_status = tmdb_service.get_localized_show_status(int(tmdb_id), latest_sn_for_status, raw_status)
        except Exception:
            localized_status = raw_status

        latest_season_number = 0
        try:
            for s in (details.get('seasons') or []):
                sn = int(s.get('season_number') or 0)
                if sn > latest_season_number:
                    latest_season_number = sn
        except Exception:
            latest_season_number = 0
        if latest_season_number <= 0:
            try:
                latest_season_number = int((existing_show or {}).get('latest_season_number') or 1)
            except Exception:
                latest_season_number = 1

        # æµ·æŠ¥ - ä½¿ç”¨æµ·æŠ¥è¯­è¨€è®¾ç½®è·å–æµ·æŠ¥è·¯å¾„
        poster_path = tmdb_service.get_poster_path_with_language(int(tmdb_id)) if tmdb_service else (details.get('poster_path') or '')
        poster_local_path = ''
        try:
            if poster_path:
                existing_poster_path = existing_show.get('poster_local_path', '') if existing_show else ''
                is_custom_poster = bool(existing_show.get('is_custom_poster', 0)) if existing_show else False
                poster_local_path = download_poster_local(poster_path, int(tmdb_id), existing_poster_path, is_custom_poster)
            elif existing_show and existing_show.get('poster_local_path'):
                poster_local_path = existing_show.get('poster_local_path')
        except Exception:
            poster_local_path = (existing_show or {}).get('poster_local_path') or ''

        bound_task_names = (existing_show or {}).get('bound_task_names', '')
        content_type = (existing_show or {}).get('content_type', '')

        cal_db.upsert_show(
            int(tmdb_id),
            name,
            first_air,
            localized_status,
            poster_local_path,
            int(latest_season_number),
            0,
            bound_task_names,
            content_type
        )

        # å¦‚æœæµ·æŠ¥è·¯å¾„å‘ç”Ÿå˜åŒ–ï¼Œè§¦å‘å­¤ç«‹æ–‡ä»¶æ¸…ç†
        existing_poster_path = existing_show.get('poster_local_path', '') if existing_show else ''
        if poster_local_path and poster_local_path != existing_poster_path:
            try:
                cleanup_orphaned_posters()
            except Exception as e:
                logging.warning(f"æ¸…ç†å­¤ç«‹æµ·æŠ¥å¤±è´¥: {e}")

        try:
            notify_calendar_changed('refresh_show')
            # é€šçŸ¥å‰ç«¯æŒ‡å®šèŠ‚ç›®æµ·æŠ¥å¯èƒ½å·²æ›´æ–°ï¼Œç”¨äºè§¦å‘æŒ‰èŠ‚ç›®ç»´åº¦çš„ç¼“å­˜ç©¿é€
            try:
                if tmdb_id:
                    notify_calendar_changed(f'poster_updated:{int(tmdb_id)}')
            except Exception:
                pass
        except Exception:
            pass

        return jsonify({"success": True, "message": "å‰§ç›®è¯¦æƒ…å·²åˆ·æ–°"})
    except Exception as e:
        return jsonify({"success": False, "message": f"åˆ·æ–°å‰§å¤±è´¥: {str(e)}"})

# ç¼–è¾‘è¿½å‰§æ—¥å†å…ƒæ•°æ®ï¼šä¿®æ”¹ä»»åŠ¡åã€ä»»åŠ¡ç±»å‹ã€é‡ç»‘ TMDB
@app.route("/api/calendar/edit_metadata", methods=["POST"])
def calendar_edit_metadata():
    try:
        if not is_login():
            return jsonify({"success": False, "message": "æœªç™»å½•"})

        data = request.get_json(force=True) or {}
        task_name = (data.get('task_name') or '').strip()
        new_task_name = (data.get('new_task_name') or '').strip()
        new_content_type = (data.get('new_content_type') or '').strip()
        new_tmdb_id = data.get('new_tmdb_id')
        new_season_number = data.get('new_season_number')
        custom_poster_url = (data.get('custom_poster_url') or '').strip()
        local_air_time = (data.get('local_air_time') or '').strip()

        if not task_name:
            return jsonify({"success": False, "message": "ç¼ºå°‘ä»»åŠ¡åç§°"})

        global config_data
        tasks = config_data.get('tasklist', [])
        target = None
        for t in tasks:
            tn = t.get('taskname') or t.get('task_name') or ''
            if tn == task_name:
                target = t
                break
        if not target:
            return jsonify({"success": False, "message": "æœªæ‰¾åˆ°ä»»åŠ¡"})

        cal = (target.get('calendar_info') or {})
        match = (cal.get('match') or {})
        # å…¼å®¹æ—§å­—æ®µï¼Œé¿å…å› ç»“æ„å·®å¼‚æ— æ³•è¯»å–å·²åŒ¹é…çš„èŠ‚ç›®
        legacy_match = target.get('match') if isinstance(target.get('match'), dict) else {}
        old_tmdb_id = (
            match.get('tmdb_id')
            or cal.get('tmdb_id')
            or legacy_match.get('tmdb_id')
            or target.get('match_tmdb_id')
            or target.get('tmdb_id')
        )

        changed = False
        local_air_time_changed = False

        if new_task_name and new_task_name != task_name:
            target['taskname'] = new_task_name
            target['task_name'] = new_task_name
            changed = True

        # å¤„ç†èŠ‚ç›®çº§æœ¬åœ°æ’­å‡ºæ—¶é—´ï¼šå†™å…¥ä»»åŠ¡é…ç½®ï¼Œå¹¶åœ¨å­˜åœ¨ TMDB ID æ—¶åŒæ­¥åˆ°æ•°æ®åº“
        if 'calendar_info' not in target:
            target['calendar_info'] = {}
        if local_air_time or cal.get('local_air_time'):
            # å…è®¸ç”¨æˆ·æ¸…ç©ºæ’­å‡ºæ—¶é—´ï¼ˆå›é€€åˆ° Trakt è‡ªåŠ¨æ¨æ–­æˆ–å…¨å±€åˆ·æ–°æ—¶é—´ï¼‰
            # ä»æ•°æ®åº“è·å–å½“å‰çš„æ’­å‡ºæ—¶é—´å’Œåç§»å€¼ï¼Œè€Œä¸æ˜¯ä» cal ä¸­è·å–ï¼ˆå¯èƒ½ä¸å‡†ç¡®ï¼‰
            old_offset = 0
            old_air_time_only = ''
            if old_tmdb_id:
                try:
                    cal_db_for_offset = CalendarDB()
                    schedule_for_offset = cal_db_for_offset.get_show_air_schedule(int(old_tmdb_id)) or {}
                    old_air_time_only = schedule_for_offset.get('local_air_time') or ''
                    old_offset = schedule_for_offset.get('air_date_offset') or 0
                except Exception:
                    old_air_time_only = str(cal.get('local_air_time') or '').strip()
                    old_offset = cal.get('air_date_offset') or 0
            else:
                old_air_time_only = str(cal.get('local_air_time') or '').strip()
                old_offset = cal.get('air_date_offset') or 0
            
            norm_old = old_air_time_only  # åªä½¿ç”¨æ—¶é—´éƒ¨åˆ†ï¼Œä¸åŒ…å«åç§»å€¼
            norm_new = str(local_air_time or '').strip()
            
            # è§£ææ–°çš„æ’­å‡ºæ—¶é—´å­—ç¬¦ä¸²ï¼Œæå–æ—¶é—´å’Œæ—¥æœŸåç§»
            air_time_only_new = norm_new
            air_date_offset_new = 0
            offset_match = re.match(r'^([01]?[0-9]|2[0-3]):([0-5][0-9])\s+([+-])(\d+)d$', norm_new)
            if offset_match:
                air_time_only_new = offset_match.group(1) + ':' + offset_match.group(2)
                sign = offset_match.group(3)
                days = int(offset_match.group(4))
                air_date_offset_new = days if sign == '+' else -days
            
            # æ¯”è¾ƒæ—¶é—´éƒ¨åˆ†å’Œåç§»å€¼ï¼Œåªè¦æœ‰ä¸€ä¸ªä¸åŒå°±éœ€è¦æ›´æ–°
            time_changed = (air_time_only_new != norm_old) or (air_date_offset_new != old_offset)
            if time_changed:
                # ä½¿ç”¨å·²è§£æçš„å€¼
                air_time_only = air_time_only_new
                air_date_offset = air_date_offset_new
                
                target['calendar_info']['local_air_time'] = air_time_only
                target['calendar_info']['air_date_offset'] = air_date_offset
                changed = True
                local_air_time_changed = True
                # ç”¨æˆ·æ‰‹åŠ¨è®¾ç½®æ’­å‡ºæ—¶é—´ï¼šä»…ä»¥æœ¬åœ°æ—¶é—´ä¸ºå‡†ï¼ŒåŒæ—¶æ¸…ç©ºèŠ‚ç›®çº§æºæ—¶åŒºè®¾ç½®ï¼Œ
                # åç»­ä¸å†ä½¿ç”¨ Trakt çš„ airs.time / timezone åšæ—¥æœŸåç§»æ¨å¯¼
                try:
                    if old_tmdb_id:
                        cal_db_for_air = CalendarDB()
                        # ä¿ç•™åŸæœ‰çš„ air_time_source å’Œ air_timezoneï¼ˆä¸æ¸…ç©ºï¼‰ï¼Œä½†ä½¿ç”¨æ‰‹åŠ¨è®¾ç½®çš„åç§»å€¼
                        # è¿™æ · update_episodes_air_date_local å¯ä»¥ä¼˜å…ˆä½¿ç”¨æ‰‹åŠ¨åç§»å€¼
                        # å¦‚æœæ—¥æœŸåç§»å‘ç”Ÿå˜åŒ–ï¼Œæˆ–è€…æ—¶é—´éƒ¨åˆ†å‘ç”Ÿå˜åŒ–ï¼Œéƒ½æ ‡è®°ä¸ºæ‰‹åŠ¨è®¾ç½®
                        # å› ä¸ºç”¨æˆ·é€šè¿‡ WebUI ç¼–è¾‘å…ƒæ•°æ®é¡µé¢ä¿®æ”¹äº†æ’­å‡ºæ—¶é—´ï¼Œæ— è®ºæ˜¯å¦æ”¹å˜äº†åç§»å€¼ï¼Œéƒ½åº”è¯¥æ ‡è®°ä¸ºæ‰‹åŠ¨è®¾ç½®
                        should_mark_manually_set = (air_date_offset != old_offset) or (air_time_only_new != norm_old)
                        
                        cal_db_for_air.update_show_air_schedule(
                            int(old_tmdb_id),
                            local_air_time=air_time_only,
                            air_date_offset=air_date_offset,
                            air_date_offset_manually_set=True if should_mark_manually_set else None,
                        )
                        # å¦‚æœæ—¥æœŸåç§»å‘ç”Ÿå˜åŒ–ï¼Œé‡æ–°è®¡ç®—æ‰€æœ‰é›†çš„ air_date_local
                        if air_date_offset != old_offset:
                            try:
                                cursor = cal_db_for_air.conn.cursor()
                                cursor.execute(
                                    "SELECT season_number, episode_number, air_date FROM episodes WHERE tmdb_id=? AND air_date IS NOT NULL AND air_date != ''",
                                    (int(old_tmdb_id),),
                                )
                                rows = cursor.fetchall()
                                episodes_by_season = {}
                                for season_number, ep_number, air_date in rows:
                                    episodes_by_season.setdefault(season_number, []).append(
                                        {"episode_number": ep_number, "air_date": air_date}
                                    )
                                updated_count = 0
                                for season_number, eps in episodes_by_season.items():
                                    # ä½¿ç”¨æ–°çš„åç§»å€¼é‡æ–°è®¡ç®— air_date_local
                                    for ep in eps:
                                        try:
                                            from datetime import datetime as _dt, timedelta as _td
                                            src_date = _dt.strptime(ep['air_date'], '%Y-%m-%d').date()
                                            adjusted_date = src_date + _td(days=air_date_offset)
                                            cal_db_for_air.update_episode_air_date_local(
                                                int(old_tmdb_id),
                                                int(season_number),
                                                int(ep['episode_number']),
                                                adjusted_date.strftime('%Y-%m-%d')
                                            )
                                            updated_count += 1
                                        except Exception as _ep_err:
                                            logging.debug(f"æ›´æ–°é›†æ—¥æœŸå¤±è´¥ tmdb_id={old_tmdb_id}, season={season_number}, ep={ep['episode_number']}: {_ep_err}")
                            except Exception as _recalc_date_err:
                                logging.debug(f"é‡æ–°è®¡ç®—é›†æ—¥æœŸå¤±è´¥ tmdb_id={old_tmdb_id}: {_recalc_date_err}")
                        # å˜æ›´æ’­å‡ºæ—¶é—´åï¼Œç«‹å³é‡ç®—è¯¥èŠ‚ç›®çš„å·²æ’­/è¿›åº¦å¹¶é€šçŸ¥å‰ç«¯ï¼Œç¡®ä¿çƒ­æ›´æ–°
                        try:
                            recompute_show_aired_progress(int(old_tmdb_id))
                        except Exception as _recalc_err:
                            logging.debug(f"é‡ç®—èŠ‚ç›®è¿›åº¦å¤±è´¥ tmdb_id={old_tmdb_id}: {_recalc_err}")
                        try:
                            notify_calendar_changed('update_airtime')
                        except Exception:
                            pass
                        try:
                            _trigger_airtime_reschedule('update_airtime', old_tmdb_id)
                        except Exception as _sched_err:
                            logging.debug(f"é‡å»ºæ’­å‡ºæ—¶é—´è°ƒåº¦å¤±è´¥ tmdb_id={old_tmdb_id}: {_sched_err}")
                except Exception as e:
                    logging.warning(f"åŒæ­¥æœ¬åœ°æ’­å‡ºæ—¶é—´åˆ°æ•°æ®åº“å¤±è´¥: {e}")

        valid_types = {'tv', 'anime', 'variety', 'documentary', 'other', ''}
        if new_content_type in valid_types:
            extracted = (target.setdefault('calendar_info', {}).setdefault('extracted', {}))
            if extracted.get('content_type') != new_content_type:
                # åŒæ­¥åˆ°ä»»åŠ¡é…ç½®ä¸­çš„ extracted ä¸é¡¶å±‚ content_typeï¼Œä¿è¯å‰ç«¯ä¸å…¶ä»–é€»è¾‘å¯è§
                extracted['content_type'] = new_content_type
                target['content_type'] = new_content_type
                # æœªåŒ¹é…ä»»åŠ¡ï¼šæ²¡æœ‰ old_tmdb_id æ—¶ï¼Œä¸è®¿é—®æ•°æ®åº“ï¼Œä»…æ›´æ–°é…ç½®
                # å·²åŒ¹é…ä»»åŠ¡ï¼šè‹¥å·²æœ‰ç»‘å®šçš„ tmdb_idï¼Œåˆ™ç«‹å³åŒæ­¥åˆ°æ•°æ®åº“
                try:
                    if old_tmdb_id:
                        cal_db = CalendarDB()
                        cal_db.update_show_content_type(int(old_tmdb_id), new_content_type)
                        # åŒæ­¥ä»»åŠ¡åä¸å†…å®¹ç±»å‹ç»‘å®šå…³ç³»
                        task_final_name = target.get('taskname') or target.get('task_name') or task_name
                        cal_db.bind_task_and_content_type(int(old_tmdb_id), task_final_name, new_content_type)
                except Exception as e:
                    logging.warning(f"åŒæ­¥å†…å®¹ç±»å‹åˆ°æ•°æ®åº“å¤±è´¥: {e}")
                changed = True

        did_rematch = False
        new_tid = None
        season_no = None
        cal_db = CalendarDB()
        tmdb_api_key = config_data.get('tmdb_api_key', '')
        poster_language = get_poster_language_setting()
        tmdb_service = TMDBService(tmdb_api_key, poster_language) if tmdb_api_key else None
        # åœºæ™¯ä¸€ï¼šæä¾› new_tmdb_idï¼ˆé‡ç»‘èŠ‚ç›®ï¼Œå¯åŒæ—¶æŒ‡å®šå­£æ•°ï¼‰
        if new_tmdb_id:
            try:
                new_tid = int(str(new_tmdb_id).strip())
            except Exception:
                return jsonify({"success": False, "message": "TMDB ID éæ³•"})
            
            # ç‰¹æ®Šå¤„ç†ï¼štmdb_id ä¸º 0 è¡¨ç¤ºå–æ¶ˆåŒ¹é…
            if new_tid == 0:
                if old_tmdb_id:
                    # è§£ç»‘æ—§èŠ‚ç›®çš„ä»»åŠ¡å¼•ç”¨
                    try:
                        try:
                            _task_final_name = target.get('taskname') or target.get('task_name') or new_task_name or task_name
                        except Exception:
                            _task_final_name = task_name
                        cal_db.unbind_task_from_show(int(old_tmdb_id), _task_final_name)
                    except Exception as e:
                        logging.warning(f"è§£ç»‘æ—§èŠ‚ç›®ä»»åŠ¡å¤±è´¥: {e}")
                    
                    # æ¸…ç†æ—§èŠ‚ç›®çš„æ‰€æœ‰æ•°æ®ä¸æµ·æŠ¥ï¼ˆå¼ºåˆ¶æ¸…ç†ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»è§£ç»‘äº†ä»»åŠ¡ï¼‰
                    try:
                        purge_calendar_by_tmdb_id_internal(int(old_tmdb_id), force=True)
                    except Exception as e:
                        logging.warning(f"æ¸…ç†æ—§èŠ‚ç›®æ•°æ®å¤±è´¥: {e}")
                
                # æ¸…ç©ºä»»åŠ¡é…ç½®ä¸­çš„åŒ¹é…ä¿¡æ¯
                if 'calendar_info' not in target:
                    target['calendar_info'] = {}
                if 'match' in target['calendar_info']:
                    target['calendar_info']['match'] = {}
                
                changed = True
                msg = 'å·²å–æ¶ˆåŒ¹é…ï¼Œå¹¶æ¸…é™¤äº†åŸæœ‰çš„èŠ‚ç›®æ•°æ®'
                return jsonify({"success": True, "message": msg})
            
            try:
                season_no = int(new_season_number or 1)
            except Exception:
                season_no = 1

            # è‹¥ tmdb å‘ç”Ÿå˜æ›´ï¼Œå…ˆè§£ç»‘æ—§èŠ‚ç›®çš„ä»»åŠ¡å¼•ç”¨ï¼›å®é™…æ¸…ç†å»¶ååˆ°é…ç½®å†™ç›˜ä¹‹å
            old_to_purge_tmdb_id = None
            if old_tmdb_id and int(old_tmdb_id) != new_tid:
                # è§£ç»‘æ—§èŠ‚ç›®çš„ä»»åŠ¡å¼•ç”¨
                try:
                    try:
                        _task_final_name = target.get('taskname') or target.get('task_name') or new_task_name or task_name
                    except Exception:
                        _task_final_name = task_name
                    cal_db.unbind_task_from_show(int(old_tmdb_id), _task_final_name)
                except Exception as e:
                    logging.warning(f"è§£ç»‘æ—§èŠ‚ç›®ä»»åŠ¡å¤±è´¥: {e}")
                # è®°å½•å¾…æ¸…ç†çš„æ—§ tmdbï¼Œåœ¨é…ç½®æ›´æ–°å¹¶è½ç›˜åå†æ‰§è¡Œæ¸…ç†
                try:
                    old_to_purge_tmdb_id = int(old_tmdb_id)
                except Exception:
                    old_to_purge_tmdb_id = None

            show = cal_db.get_show(new_tid)
            if not show:
                if not tmdb_service:
                    return jsonify({"success": False, "message": "TMDB API æœªé…ç½®ï¼Œæ— æ³•åˆå§‹åŒ–æ–°èŠ‚ç›®"})
                # ç›´æ¥ä» TMDB è·å–è¯¦æƒ…å¹¶å†™å…¥æœ¬åœ°ï¼Œè€Œä¸æ˜¯è°ƒç”¨å…¨é‡ bootstrap
                details = tmdb_service.get_tv_show_details(new_tid) or {}
                if not details:
                    return jsonify({"success": False, "message": "æœªæ‰¾åˆ°æŒ‡å®š TMDB èŠ‚ç›®"})
                try:
                    chinese_title = tmdb_service.get_chinese_title_with_fallback(new_tid, details.get('name') or details.get('original_name') or '')
                except Exception:
                    chinese_title = details.get('name') or details.get('original_name') or ''
                poster_local_path = ''
                try:
                    poster_local_path = download_poster_local(details.get('poster_path') or '')
                except Exception:
                    poster_local_path = ''
                first_air = (details.get('first_air_date') or '')[:4]
                status = details.get('status') or ''
                # ä»¥ season_no ä½œä¸ºæœ€æ–°å­£å†™å…¥ shows
                cal_db.upsert_show(int(new_tid), chinese_title, first_air, status, poster_local_path, int(season_no), 0, '', (target.get('content_type') or ''))
                show = cal_db.get_show(new_tid)
                if not show:
                    return jsonify({"success": False, "message": "æœªæ‰¾åˆ°æŒ‡å®š TMDB èŠ‚ç›®"})

            task_final_name = target.get('taskname') or target.get('task_name') or new_task_name or task_name
            ct = (target.get('calendar_info') or {}).get('extracted', {}).get('content_type', '')
            try:
                cal_db.bind_task_and_content_type(new_tid, task_final_name, ct)
            except Exception as e:
                logging.warning(f"ç»‘å®šä»»åŠ¡å¤±è´¥: {e}")

            if 'calendar_info' not in target:
                target['calendar_info'] = {}
            if 'match' not in target['calendar_info']:
                target['calendar_info']['match'] = {}
            target['calendar_info']['match'].update({
                'tmdb_id': new_tid,
                'matched_show_name': show.get('name', ''),
                'matched_year': show.get('year', '')
            })
            target['calendar_info']['match']['latest_season_number'] = season_no

            try:
                season = tmdb_service.get_tv_show_episodes(new_tid, season_no) if tmdb_service else None
                eps = (season or {}).get('episodes', []) or []
                from time import time as _now
                now_ts = int(_now())
                # æ¸…ç†é™¤å½“å‰å­£å¤–çš„å…¶ä»–å­£æ•°æ®ï¼Œé¿å…æ®‹ç•™
                try:
                    cal_db.purge_other_seasons(int(new_tid), int(season_no))
                except Exception:
                    pass
                # æ ¹å› ä¿®å¤ï¼šæ¸…ç†æœ¬åœ°è¯¥å­£ä¸­ TMDB ä¸å­˜åœ¨çš„å¤šä½™é›†
                try:
                    valid_eps = []
                    for _ep in eps:
                        try:
                            n = int(_ep.get('episode_number') or 0)
                            if n > 0:
                                valid_eps.append(n)
                        except Exception:
                            pass
                    cal_db.prune_season_episodes_not_in(int(new_tid), int(season_no), valid_eps)
                except Exception:
                    pass
                for ep in eps:
                    cal_db.upsert_episode(
                        tmdb_id=int(new_tid),
                        season_number=int(season_no),
                        episode_number=int(ep.get('episode_number') or 0),
                        name=ep.get('name') or '',
                        overview=ep.get('overview') or '',
                        air_date=ep.get('air_date') or '',
                        runtime=ep.get('runtime'),
                        ep_type=(ep.get('episode_type') or ep.get('type')),
                        updated_at=now_ts,
                    )
                # å¦‚æœæœ‰ Trakt çš„æºæ—¶é—´/æ—¶åŒºï¼Œè®¡ç®—æ¯é›†çš„æœ¬åœ°æ’­å‡ºæ—¥æœŸå¹¶æ›´æ–° air_date_local
                update_episodes_air_date_local(cal_db, int(new_tid), int(season_no), eps)
                try:
                    sname_raw = (season or {}).get('name') or ''
                    sname = tmdb_service.process_season_name(sname_raw) if tmdb_service else sname_raw
                    cal_db.upsert_season(int(new_tid), int(season_no), len(eps), f"/tv/{new_tid}/season/{season_no}", sname)
                    cal_db.update_show_latest_season_number(int(new_tid), int(season_no))
                    # å†™å› season_metricsï¼ˆair/totalï¼‰ï¼Œtransferred ç•™ç»™èšåˆç¯èŠ‚è¡¥é½
                    try:
                        # ä½¿ç”¨ is_episode_aired é€é›†åˆ¤æ–­è®¡ç®—å·²æ’­å‡ºé›†æ•°ï¼ˆè€ƒè™‘æ’­å‡ºæ—¶é—´ï¼‰
                        # ä¿®å¤ï¼šä¸å†ä½¿ç”¨ç®€å•çš„æ—¥æœŸæ¯”è¾ƒï¼Œè€Œæ˜¯é€é›†è°ƒç”¨ is_episode_aired åˆ¤æ–­æ˜¯å¦å·²æ’­å‡º
                        try:
                            from zoneinfo import ZoneInfo as _ZoneInfo
                            local_tz = _ZoneInfo(_get_local_timezone())
                            now_local_dt = datetime.now(local_tz)
                        except Exception:
                            now_local_dt = datetime.now()
                        aired_cnt = compute_aired_count_by_episode_check(int(new_tid), int(season_no), now_local_dt)
                        progress_pct = 0  # æ­¤å¤„æ—  transferred_countï¼Œç™¾åˆ†æ¯”æš‚ç½® 0ï¼Œç”±èšåˆç¯èŠ‚è¡¥é½
                        from time import time as _now
                        cal_db.upsert_season_metrics(int(new_tid), int(season_no), None, aired_cnt, int(len(eps)), int(progress_pct), int(_now()))
                    except Exception:
                        pass
                except Exception:
                    pass
            except Exception as e:
                logging.warning(f"åˆ·æ–°æ–°å­£å¤±è´¥: {e}")

            did_rematch = True
            changed = True
            # å¦‚æœéœ€è¦ï¼Œå»¶åæ¸…ç†æ—§èŠ‚ç›®çš„æ•°æ®ï¼ˆæ­¤æ—¶ä»»åŠ¡é…ç½®å·²æŒ‡å‘æ–°èŠ‚ç›®ï¼Œé¿å…è¢«æ¸…ç†å‡½æ•°è¯¯åˆ¤ä»è¢«å¼•ç”¨ï¼‰
            if old_to_purge_tmdb_id is not None:
                try:
                    purge_calendar_by_tmdb_id_internal(int(old_to_purge_tmdb_id))
                except Exception as e:
                    logging.warning(f"æ¸…ç†æ—§ tmdb å¤±è´¥: {e}")
            # åŸºäºæœ€æ–°ä»»åŠ¡æ˜ å°„æ¸…ç†å­¤å„¿å­£ä¸æŒ‡æ ‡
            try:
                _tasks = config_data.get('tasklist', [])
                _valid_names = []
                _valid_pairs = []
                for _t in _tasks:
                    _n = _t.get('taskname') or _t.get('task_name') or ''
                    _cal = (_t.get('calendar_info') or {})
                    _match = (_cal.get('match') or {})
                    _tid = _match.get('tmdb_id') or _cal.get('tmdb_id')
                    _sn = _match.get('latest_season_number') or _cal.get('latest_season_number')
                    if _n:
                        _valid_names.append(_n)
                    if _tid and _sn:
                        try:
                            _valid_pairs.append((int(_tid), int(_sn)))
                        except Exception:
                            pass
                CalendarDB().cleanup_orphan_data(_valid_pairs, _valid_names)
                # æ¸…ç†å­¤ç«‹æ•°æ®åï¼Œä¹Ÿæ¸…ç†å¯èƒ½æ®‹ç•™çš„å­¤ç«‹æµ·æŠ¥æ–‡ä»¶
                try:
                    cleanup_orphaned_posters()
                except Exception:
                    pass
            except Exception:
                pass
        # åœºæ™¯äºŒï¼šæœªæä¾› new_tmdb_idï¼Œä½†æä¾›äº† new_season_numberï¼ˆä»…ä¿®æ”¹å­£æ•°ï¼‰
        elif (new_season_number is not None) and (str(new_season_number).strip() != '') and old_tmdb_id:
            try:
                season_no = int(new_season_number)
            except Exception:
                return jsonify({"success": False, "message": "å­£æ•°å¿…é¡»ä¸ºæ•°å­—"})

            # æ£€æŸ¥æ˜¯å¦ä¸å½“å‰åŒ¹é…çš„å­£æ•°ç›¸åŒï¼Œå¦‚æœç›¸åŒåˆ™è·³è¿‡å¤„ç†
            current_match_season = (
                match.get('latest_season_number')
                or legacy_match.get('latest_season_number')
                or target.get('matched_latest_season_number')
                or cal.get('latest_season_number')
            )
            if current_match_season and int(current_match_season) == season_no:
                # å­£æ•°æœªå˜åŒ–ï¼Œè·³è¿‡å¤„ç†
                pass
            else:
                if not tmdb_service:
                    return jsonify({"success": False, "message": "TMDB API æœªé…ç½®"})

                # æ›´æ–° shows è¡¨ä¸­çš„æœ€æ–°å­£ï¼Œæ¸…ç†å…¶ä»–å­£ï¼Œå¹¶æ‹‰å–æŒ‡å®šå­£æ•°æ®
                try:
                    cal_db.update_show_latest_season_number(int(old_tmdb_id), int(season_no))
                except Exception:
                    pass

                # æ‹‰å–è¯¥å­£æ•°æ®
                try:
                    season = tmdb_service.get_tv_show_episodes(int(old_tmdb_id), int(season_no)) or {}
                    eps = season.get('episodes', []) or []
                    from time import time as _now
                    now_ts = int(_now())
                    # æ¸…ç†é™¤å½“å‰å­£å¤–å…¶ä»–å­£ï¼Œé¿å…æ®‹ç•™
                    try:
                        cal_db.purge_other_seasons(int(old_tmdb_id), int(season_no))
                    except Exception:
                        pass
                    # æ ¹å› ä¿®å¤ï¼šæ¸…ç†æœ¬åœ°è¯¥å­£ä¸­ TMDB ä¸å­˜åœ¨çš„å¤šä½™é›†
                    try:
                        valid_eps = []
                        for _ep in eps:
                            try:
                                n = int(_ep.get('episode_number') or 0)
                                if n > 0:
                                    valid_eps.append(n)
                            except Exception:
                                pass
                        cal_db.prune_season_episodes_not_in(int(old_tmdb_id), int(season_no), valid_eps)
                    except Exception:
                        pass
                    for ep in eps:
                        cal_db.upsert_episode(
                            tmdb_id=int(old_tmdb_id),
                            season_number=int(season_no),
                            episode_number=int(ep.get('episode_number') or 0),
                            name=ep.get('name') or '',
                            overview=ep.get('overview') or '',
                            air_date=ep.get('air_date') or '',
                            runtime=ep.get('runtime'),
                            ep_type=(ep.get('episode_type') or ep.get('type')),
                            updated_at=now_ts,
                        )
                    # å¦‚æœæœ‰ Trakt çš„æºæ—¶é—´/æ—¶åŒºï¼Œè®¡ç®—æ¯é›†çš„æœ¬åœ°æ’­å‡ºæ—¥æœŸå¹¶æ›´æ–° air_date_local
                    update_episodes_air_date_local(cal_db, int(old_tmdb_id), int(season_no), eps)
                    try:
                        sname_raw = (season or {}).get('name') or ''
                        sname = tmdb_service.process_season_name(sname_raw)
                        cal_db.upsert_season(int(old_tmdb_id), int(season_no), len(eps), f"/tv/{old_tmdb_id}/season/{season_no}", sname)
                    except Exception:
                        pass
                except Exception as e:
                    return jsonify({"success": False, "message": f"åˆ·æ–°å­£æ•°æ®å¤±è´¥: {e}"})

                # æ›´æ–°ä»»åŠ¡é…ç½®ä¸­çš„ latest_season_number ä»¥ä¾¿å‰ç«¯å±•ç¤º
                try:
                    if 'calendar_info' not in target:
                        target['calendar_info'] = {}
                    if 'match' not in target['calendar_info']:
                        target['calendar_info']['match'] = {}
                    target['calendar_info']['match']['latest_season_number'] = int(season_no)
                except Exception:
                    pass

                changed = True
                # åŸºäºæœ€æ–°ä»»åŠ¡æ˜ å°„æ¸…ç†å­¤å„¿å­£ä¸æŒ‡æ ‡
                try:
                    _tasks = config_data.get('tasklist', [])
                    _valid_names = []
                    _valid_pairs = []
                    for _t in _tasks:
                        _n = _t.get('taskname') or _t.get('task_name') or ''
                        _cal = (_t.get('calendar_info') or {})
                        _match = (_cal.get('match') or {})
                        _tid = _match.get('tmdb_id') or _cal.get('tmdb_id')
                        _sn = _match.get('latest_season_number') or _cal.get('latest_season_number')
                        if _n:
                            _valid_names.append(_n)
                        if _tid and _sn:
                            try:
                                _valid_pairs.append((int(_tid), int(_sn)))
                            except Exception:
                                pass
                    CalendarDB().cleanup_orphan_data(_valid_pairs, _valid_names)
                    # æ¸…ç†å­¤ç«‹æ•°æ®åï¼Œä¹Ÿæ¸…ç†å¯èƒ½æ®‹ç•™çš„å­¤ç«‹æµ·æŠ¥æ–‡ä»¶
                    try:
                        cleanup_orphaned_posters()
                    except Exception:
                        pass
                except Exception:
                    pass

        # å¤„ç†è‡ªå®šä¹‰æµ·æŠ¥
        if custom_poster_url:
            # è·å–å½“å‰ä»»åŠ¡çš„TMDB ID
            current_tmdb_id = None
            if new_tmdb_id:
                current_tmdb_id = int(new_tmdb_id)
            elif old_tmdb_id:
                current_tmdb_id = int(old_tmdb_id)

            if current_tmdb_id:
                try:
                    # å°è¯•è¯»å–ç°æœ‰èŠ‚ç›®ï¼Œè‹¥æœ‰å·²æœ‰æµ·æŠ¥ï¼Œåˆ™è¦†ç›–åŒåæ–‡ä»¶ä»¥å®ç°åŸä½æ›¿æ¢
                    show_row = None
                    try:
                        show_row = cal_db.get_show(int(current_tmdb_id))
                    except Exception:
                        show_row = None

                    target_safe_name = None
                    if show_row and (show_row.get('poster_local_path') or '').strip():
                        try:
                            existing_path = (show_row.get('poster_local_path') or '').strip()
                            # æœŸæœ›æ ¼å¼ï¼š/cache/images/<filename>
                            target_safe_name = existing_path.split('/')[-1]
                        except Exception:
                            target_safe_name = None

                    # è¦†ç›–ä¿å­˜ï¼ˆä¸è¿›è¡Œç¼©æ”¾ï¼Œä¸æ–°å¢ä¾èµ–ï¼‰
                    saved_path = download_custom_poster(custom_poster_url, current_tmdb_id, target_safe_name)

                    if saved_path:
                        # æ›´æ–°æ•°æ®åº“è·¯å¾„ï¼Œæ ‡è®°ä¸ºè‡ªå®šä¹‰æµ·æŠ¥
                        try:
                            cal_db.update_show_poster(int(current_tmdb_id), saved_path, is_custom_poster=1)
                        except Exception as e:
                            logging.warning(f"æ›´æ–°æµ·æŠ¥è·¯å¾„å¤±è´¥: {e}")
                        
                        # è‹¥æ–‡ä»¶åå‘ç”Ÿå˜åŒ–åˆ™éœ€è¦åˆ é™¤æ—§æ–‡ä»¶
                        try:
                            existing_path = ''
                            if show_row:
                                existing_path = (show_row.get('poster_local_path') or '').strip()
                            if saved_path != existing_path:
                                # åˆ é™¤æ—§æ–‡ä»¶ï¼ˆè‹¥å­˜åœ¨ä¸”åœ¨ç¼“å­˜ç›®å½•ä¸‹ï¼‰
                                try:
                                    if existing_path and existing_path.startswith('/cache/images/'):
                                        old_name = existing_path.replace('/cache/images/', '')
                                        old_path = os.path.join(CACHE_IMAGES_DIR, old_name)
                                        if os.path.exists(old_path):
                                            os.remove(old_path)
                                except Exception as e:
                                    logging.warning(f"åˆ é™¤æ—§æµ·æŠ¥å¤±è´¥: {e}")
                        except Exception:
                            # å³ä½¿å¯¹æ¯”å¤±è´¥ä¹Ÿä¸å½±å“åŠŸèƒ½
                            pass
                        
                        # ç”¨æˆ·ä¸Šä¼ è‡ªå®šä¹‰æµ·æŠ¥åï¼Œæ€»æ˜¯è§¦å‘å­¤ç«‹æ–‡ä»¶æ¸…ç†
                        try:
                            cleanup_orphaned_posters()
                        except Exception as e:
                            logging.warning(f"æ¸…ç†å­¤ç«‹æµ·æŠ¥å¤±è´¥: {e}")

                        # æˆåŠŸæ›´æ–°è‡ªå®šä¹‰æµ·æŠ¥ï¼ˆé™é»˜ï¼‰
                        changed = True
                        # ä»…å½“è‡ªå®šä¹‰æµ·æŠ¥ä¿å­˜æˆåŠŸæ—¶ï¼Œé€šçŸ¥å‰ç«¯è¯¥èŠ‚ç›®æµ·æŠ¥å·²æ›´æ–°
                        try:
                            notify_calendar_changed(f'poster_updated:{int(current_tmdb_id)}')
                        except Exception:
                            pass
                    else:
                        logging.warning(f"è‡ªå®šä¹‰æµ·æŠ¥ä¿å­˜å¤±è´¥: {custom_poster_url}")
                except Exception as e:
                    logging.error(f"å¤„ç†è‡ªå®šä¹‰æµ·æŠ¥å¤±è´¥: {e}")
            else:
                logging.warning("æ— æ³•å¤„ç†è‡ªå®šä¹‰æµ·æŠ¥ï¼šç¼ºå°‘TMDB ID")

        if changed:
            Config.write_json(CONFIG_PATH, config_data)

        try:
            sync_task_config_with_database_bindings()
        except Exception as e:
            logging.warning(f"åŒæ­¥ç»‘å®šå¤±è´¥: {e}")

        try:
            notify_calendar_changed('edit_metadata')
        except Exception:
            pass

        if local_air_time_changed and old_tmdb_id:
            try:
                _trigger_airtime_reschedule('edit_metadata_local_air_time', old_tmdb_id)
            except Exception:
                pass

        # ç¡®å®šæœ€ç»ˆçš„ tmdb_id å’Œ season_numberï¼Œç”¨äºå‰ç«¯åˆ·æ–°
        # åªæœ‰åœ¨éœ€è¦åˆ·æ–°å…ƒæ•°æ®çš„æƒ…å†µä¸‹æ‰è¿”å›æœ‰æ•ˆçš„ tmdb_id å’Œ season_numberï¼š
        # 1. é‡æ–°åŒ¹é…äº† TMDBï¼ˆdid_rematchï¼‰
        # 2. ä¿®æ”¹äº†å­£æ•°ï¼ˆnew_season_numberï¼‰
        # 3. ä¿®æ”¹äº†è‡ªå®šä¹‰æµ·æŠ¥ï¼ˆcustom_poster_urlï¼‰- éœ€è¦åˆ·æ–°ä»¥æ›´æ–°æµ·æŠ¥
        # å…¶ä»–æƒ…å†µï¼ˆå¦‚åªä¿®æ”¹ä»»åŠ¡åã€å†…å®¹ç±»å‹ã€æœ¬åœ°æ’­å‡ºæ—¶é—´ï¼‰ä¸åº”è¯¥è§¦å‘åˆ·æ–°
        final_tmdb_id = None
        final_season_number = None
        if did_rematch and new_tid:
            # å¦‚æœé‡æ–°åŒ¹é…ï¼Œä½¿ç”¨æ–°çš„ tmdb_id å’Œ season_number
            final_tmdb_id = new_tid
            final_season_number = season_no
        elif (new_season_number is not None) and (str(new_season_number).strip() != '') and old_tmdb_id:
            # å¦‚æœåªä¿®æ”¹äº†å­£æ•°ï¼Œä½¿ç”¨å½“å‰çš„ tmdb_id å’Œæ–°çš„å­£æ•°
            try:
                final_tmdb_id = old_tmdb_id
                final_season_number = int(new_season_number)
            except Exception:
                pass
        elif custom_poster_url and old_tmdb_id:
            # å¦‚æœä¿®æ”¹äº†è‡ªå®šä¹‰æµ·æŠ¥ï¼Œéœ€è¦åˆ·æ–°ä»¥æ›´æ–°æµ·æŠ¥ï¼ˆä½†ä¸éœ€è¦åˆ·æ–°å…ƒæ•°æ®ï¼‰
            # è¿™é‡Œä¸è¿”å› tmdb_id å’Œ season_numberï¼Œå› ä¸ºæµ·æŠ¥æ›´æ–°ä¸éœ€è¦åˆ·æ–°å…ƒæ•°æ®
            # æµ·æŠ¥æ›´æ–°ä¼šé€šè¿‡ notify_calendar_changed('poster_updated:...') é€šçŸ¥å‰ç«¯
            pass

        msg = 'å…ƒæ•°æ®æ›´æ–°æˆåŠŸ'
        if did_rematch:
            msg = 'å…ƒæ•°æ®æ›´æ–°æˆåŠŸï¼Œå·²é‡æ–°åŒ¹é…å¹¶åˆ·æ–°å…ƒæ•°æ®'
        if custom_poster_url:
            if 'å·²é‡æ–°åŒ¹é…' in msg:
                msg = 'å…ƒæ•°æ®æ›´æ–°æˆåŠŸï¼Œå·²é‡æ–°åŒ¹é…å¹¶åˆ·æ–°å…ƒæ•°æ®ï¼Œè‡ªå®šä¹‰æµ·æŠ¥å·²æ›´æ–°'
            else:
                msg = 'å…ƒæ•°æ®æ›´æ–°æˆåŠŸï¼Œè‡ªå®šä¹‰æµ·æŠ¥å·²æ›´æ–°'
        
        # è¿”å›ä¿®æ”¹çŠ¶æ€å’Œéœ€è¦åˆ·æ–°çš„èŠ‚ç›®ä¿¡æ¯
        result = {
            "success": True,
            "message": msg,
            "changed": changed,
            "tmdb_id": final_tmdb_id,
            "season_number": final_season_number
        }
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "message": f"ä¿å­˜å¤±è´¥: {str(e)}"})

# è·å–èŠ‚ç›®ä¿¡æ¯ï¼ˆç”¨äºè·å–æœ€æ–°å­£æ•°ï¼‰
@app.route("/api/calendar/show_info")
def get_calendar_show_info():
    try:
        if not is_login():
            return jsonify({"success": False, "message": "æœªç™»å½•"})

        tmdb_id = request.args.get('tmdb_id', type=int)
        if not tmdb_id:
            return jsonify({"success": False, "message": "ç¼ºå°‘ tmdb_id"})

        cal_db = CalendarDB()
        show = cal_db.get_show(int(tmdb_id))
        if not show:
            return jsonify({"success": False, "message": "æœªæ‰¾åˆ°è¯¥èŠ‚ç›®"})

        return jsonify({
            "success": True,
            "data": {
                "tmdb_id": show['tmdb_id'],
                "name": show['name'],
                "year": show['year'],
                "status": show['status'],
                "latest_season_number": show['latest_season_number'],
                "poster_local_path": show['poster_local_path']
            }
        })
    except Exception as e:
        return jsonify({"success": False, "message": f"è·å–èŠ‚ç›®ä¿¡æ¯å¤±è´¥: {str(e)}"})


# --------- æ—¥å†åˆ·æ–°è°ƒåº¦ï¼šæŒ‰æ€§èƒ½è®¾ç½®çš„å‘¨æœŸè‡ªåŠ¨åˆ·æ–°æœ€æ–°å­£ ---------
def restart_calendar_refresh_job():
    try:
        global _calendar_refresh_last_interval
        # è¯»å–ç”¨æˆ·é…ç½®çš„åˆ·æ–°å‘¨æœŸï¼ˆç§’ï¼‰ï¼Œé»˜è®¤21600ç§’ï¼ˆ6å°æ—¶ï¼‰
        perf = config_data.get('performance', {}) if isinstance(config_data, dict) else {}
        interval_seconds = int(perf.get('calendar_refresh_interval_seconds', 21600))
        if interval_seconds <= 0:
            # éæ³•æˆ–å…³é—­åˆ™ç§»é™¤
            try:
                scheduler.remove_job('calendar_refresh_job')
            except Exception:
                pass
            # åªåœ¨çŠ¶æ€æ”¹å˜æ—¶è¾“å‡ºæ—¥å¿—
            if _calendar_refresh_last_interval is not None:
                logging.info("å·²å…³é—­è¿½å‰§æ—¥å†å…ƒæ•°æ®è‡ªåŠ¨åˆ·æ–°")
                _calendar_refresh_last_interval = None
            return

        # é‡ç½®ä»»åŠ¡
        try:
            scheduler.remove_job('calendar_refresh_job')
        except Exception:
            pass
        scheduler.add_job(
            run_calendar_refresh_all_internal_wrapper,
            IntervalTrigger(seconds=interval_seconds),
            id='calendar_refresh_job',
            replace_existing=True,
            misfire_grace_time=None,
            coalesce=True,
            max_instances=1,
        )
        if scheduler.state == 0:
            scheduler.start()
        # å‹å¥½æç¤ºï¼šä»…åœ¨å‘¨æœŸå˜åŒ–æ—¶è¾“å‡ºæ—¥å¿—ï¼ˆé¿å…é‡å¤è¾“å‡ºï¼‰
        try:
            if IS_FLASK_SERVER_PROCESS:
                if _calendar_refresh_last_interval != interval_seconds:
                    logging.info(f"å·²å¯åŠ¨è¿½å‰§æ—¥å†è‡ªåŠ¨åˆ·æ–°ï¼Œå‘¨æœŸ {interval_seconds} ç§’")
                    _calendar_refresh_last_interval = interval_seconds
        except Exception:
            pass
    except Exception as e:
        logging.warning(f"é…ç½®è‡ªåŠ¨åˆ·æ–°ä»»åŠ¡å¤±è´¥: {e}")


def run_calendar_refresh_all_internal_wrapper():
    """
    è¿½å‰§æ—¥å†è‡ªåŠ¨åˆ·æ–°çš„åŒ…è£…å‡½æ•°ï¼Œç”¨äºæ£€æŸ¥ä¸Šä¸€æ¬¡ä»»åŠ¡æ˜¯å¦è¿˜åœ¨è¿è¡Œ
    """
    global _calendar_refresh_thread
    
    logging.info(f">>> å¼€å§‹æ‰§è¡Œè¿½å‰§æ—¥å†è‡ªåŠ¨åˆ·æ–°")
    
    # æ£€æŸ¥ä¸Šä¸€æ¬¡ä»»åŠ¡æ˜¯å¦è¿˜åœ¨è¿è¡Œ
    if _calendar_refresh_thread is not None:
        try:
            if _calendar_refresh_thread.is_alive():  # çº¿ç¨‹è¿˜åœ¨è¿è¡Œ
                logging.warning(f">>> æ£€æµ‹åˆ°ä¸Šä¸€æ¬¡è¿½å‰§æ—¥å†è‡ªåŠ¨åˆ·æ–°ä»åœ¨è¿è¡Œï¼Œå°†å¿½ç•¥å¹¶ç»§ç»­æ‰§è¡Œæ–°ä»»åŠ¡")
                # æ³¨æ„ï¼šPython çº¿ç¨‹æ— æ³•å¼ºåˆ¶ç»ˆæ­¢ï¼Œåªèƒ½è®°å½•è­¦å‘Š
                # ä½†ç”±äºè°ƒåº¦å™¨ä¼šç»§ç»­æ‰§è¡Œï¼Œä¸ä¼šé˜»å¡åç»­ä»»åŠ¡
            else:  # çº¿ç¨‹å·²ç»“æŸï¼ˆæ­£å¸¸æˆ–å¼‚å¸¸é€€å‡ºï¼‰
                logging.debug(f">>> ä¸Šä¸€æ¬¡è¿½å‰§æ—¥å†è‡ªåŠ¨åˆ·æ–°å·²ç»“æŸ")
        except Exception as e:
            logging.warning(f">>> æ£€æŸ¥ä¸Šä¸€æ¬¡è¿½å‰§æ—¥å†è‡ªåŠ¨åˆ·æ–°ä»»åŠ¡çŠ¶æ€æ—¶å‡ºé”™: {e}")
        finally:
            # æ— è®ºä»€ä¹ˆæƒ…å†µï¼Œéƒ½æ¸…é™¤çº¿ç¨‹å¯¹è±¡ï¼Œç¡®ä¿ä¸‹æ¬¡èƒ½æ­£å¸¸è¿è¡Œ
            _calendar_refresh_thread = None
    
    # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œä»»åŠ¡ï¼Œè®°å½•çº¿ç¨‹å¯¹è±¡ä»¥ä¾¿ä¸‹æ¬¡æ£€æŸ¥
    def run_in_thread():
        global _calendar_refresh_thread
        try:
            run_calendar_refresh_all_internal()
            logging.info(f">>> è¿½å‰§æ—¥å†è‡ªåŠ¨åˆ·æ–°æ‰§è¡ŒæˆåŠŸ")
        except Exception as e:
            logging.error(f">>> è¿½å‰§æ—¥å†è‡ªåŠ¨åˆ·æ–°æ‰§è¡Œå¼‚å¸¸: {str(e)}")
            import traceback
            logging.error(f">>> å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
        finally:
            # ä»»åŠ¡å®Œæˆï¼Œæ¸…é™¤çº¿ç¨‹å¯¹è±¡
            _calendar_refresh_thread = None
    
    _calendar_refresh_thread = Thread(target=run_in_thread, daemon=True)
    _calendar_refresh_thread.start()
    # ä¸ç­‰å¾…çº¿ç¨‹å®Œæˆï¼Œè®©è°ƒåº¦å™¨è®¤ä¸ºä»»åŠ¡å·²å¯åŠ¨
    # è¿™æ ·å³ä½¿ä»»åŠ¡è¿è¡Œæ—¶é—´å¾ˆé•¿ï¼Œä¹Ÿä¸ä¼šé˜»å¡åç»­ä»»åŠ¡


def run_calendar_refresh_all_internal():
    try:
        tmdb_api_key = config_data.get('tmdb_api_key', '')
        if not tmdb_api_key:
            return
        poster_language = get_poster_language_setting()
        tmdb_service = TMDBService(tmdb_api_key, poster_language)
        db = CalendarDB()
        shows = []
        # ç®€å•è¯»å–æ‰€æœ‰å·²åˆå§‹åŒ–çš„å‰§ç›®
        try:
            cur = db.conn.cursor()
            cur.execute('SELECT tmdb_id FROM shows')
            shows = [r[0] for r in cur.fetchall()]
        except Exception:
            shows = []
        any_written = False
        status_changed_any = False
        for tmdb_id in shows:
            try:
                # ç›´æ¥é‡ç”¨å†…éƒ¨é€»è¾‘
                with app.app_context():
                    # è°ƒç”¨ä¸ endpoint ç›¸åŒçš„åˆ·æ–°æµç¨‹
                    season = tmdb_service.get_tv_show_episodes(int(tmdb_id), int(db.get_show(int(tmdb_id))['latest_season_number'])) or {}
                    episodes = season.get('episodes', []) or []
                    from time import time as _now
                    now_ts = int(_now())
                    for ep in episodes:
                        db.upsert_episode(
                            tmdb_id=int(tmdb_id),
                            season_number=int(db.get_show(int(tmdb_id))['latest_season_number']),
                            episode_number=int(ep.get('episode_number') or 0),
                            name=ep.get('name') or '',
                            overview=ep.get('overview') or '',
                            air_date=ep.get('air_date') or '',
                            runtime=ep.get('runtime'),
                            ep_type=(ep.get('episode_type') or ep.get('type')),
                            updated_at=now_ts,
                        )
                        any_written = True
                    
                    # å¦‚æœæœ‰ Trakt çš„æºæ—¶é—´/æ—¶åŒºï¼Œè®¡ç®—æ¯é›†çš„æœ¬åœ°æ’­å‡ºæ—¥æœŸå¹¶æ›´æ–° air_date_local
                    # å¦‚æœæ²¡æœ‰æ—¶åŒºä¿¡æ¯ï¼Œå°† air_date_local è®¾ç½®ä¸ºä¸ air_date ç›¸åŒçš„å€¼
                    update_episodes_air_date_local(db, int(tmdb_id), int(db.get_show(int(tmdb_id))['latest_season_number']), episodes)

                    # æ–°å¢ï¼šèŠ‚ç›®çŠ¶æ€å˜æ›´æ£€æµ‹ä¸æ›´æ–°ï¼ˆå¦‚ Returning â†’ æœ¬å­£ç»ˆ/å·²å®Œç»“ ç­‰ï¼‰
                    try:
                        existing_show = db.get_show(int(tmdb_id)) or {}
                        raw_details = tmdb_service.get_tv_show_details(int(tmdb_id)) or {}
                        raw_status = (raw_details.get('status') or '')
                        latest_sn_for_status = int((existing_show or {}).get('latest_season_number') or 1)
                        try:
                            localized_status = tmdb_service.get_localized_show_status(int(tmdb_id), latest_sn_for_status, raw_status)
                        except Exception:
                            localized_status = raw_status

                        old_status = (existing_show or {}).get('status') or ''
                        if localized_status and localized_status != old_status:
                            # ä»…æ›´æ–° status ç­‰å¿…è¦å­—æ®µï¼Œå…¶ä»–æ²¿ç”¨åŸå€¼
                            db.upsert_show(
                                tmdb_id=int(tmdb_id),
                                name=(existing_show or {}).get('name') or '',
                                year=(existing_show or {}).get('year') or '',
                                status=localized_status,
                                poster_local_path=(existing_show or {}).get('poster_local_path') or '',
                                latest_season_number=int((existing_show or {}).get('latest_season_number') or 1),
                                last_refreshed_at=now_ts,
                                bound_task_names=(existing_show or {}).get('bound_task_names') or '',
                                content_type=(existing_show or {}).get('content_type') or '',
                                is_custom_poster=int((existing_show or {}).get('is_custom_poster') or 0),
                            )
                            status_changed_any = True
                    except Exception:
                        # çŠ¶æ€æ›´æ–°å¤±è´¥ä¸å½±å“æ•´ä½“åˆ·æ–°
                        pass
            except Exception as e:
                logging.warning(f"è‡ªåŠ¨åˆ·æ–°å¤±è´¥ tmdb_id={tmdb_id}: {e}")
        try:
            if any_written:
                notify_calendar_changed('auto_refresh')
            if status_changed_any:
                notify_calendar_changed('status_updated')
        except Exception:
            pass
        try:
            _trigger_airtime_reschedule('auto_refresh')
        except Exception:
            pass
    except Exception as e:
        logging.warning(f"è‡ªåŠ¨åˆ·æ–°ä»»åŠ¡å¼‚å¸¸: {e}")
# æœ¬åœ°ç¼“å­˜è¯»å–ï¼šè·å–æœ€æ–°ä¸€å­£çš„æœ¬åœ°å‰§é›†æ•°æ®
@app.route("/api/calendar/episodes_local")
def get_calendar_episodes_local():
    """è·å–æœ¬åœ°å‰§é›†æ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼šæ·»åŠ ç¼“å­˜æœºåˆ¶ï¼‰"""
    global _calendar_episodes_cache
    
    try:
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
        current_time = time.time()
        tmdb_id = request.args.get('tmdb_id')
        cache_key = f'episodes_data_{tmdb_id or "all"}'
        
        with _calendar_episodes_cache_lock:
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨ä¸”æœªè¿‡æœŸ
            if cache_key in _calendar_episodes_cache:
                cache_data, cache_time = _calendar_episodes_cache[cache_key]
                if current_time - cache_time < _calendar_episodes_cache_ttl:
                    # ç¼“å­˜æœ‰æ•ˆï¼Œç›´æ¥è¿”å›
                    return jsonify(cache_data)
        
        db = CalendarDB()
        # å»ºç«‹ tmdb_id -> ä»»åŠ¡ä¿¡æ¯ æ˜ å°„ï¼Œç”¨äºå‰ç«¯ç­›é€‰ï¼ˆä»»åŠ¡å/ç±»å‹ï¼‰
        tmdb_to_taskinfo = {}
        try:
            tasks = config_data.get('tasklist', [])
            for t in tasks:
                cal = (t.get('calendar_info') or {})
                match = (cal.get('match') or {})
                extracted = (cal.get('extracted') or {})
                tid = match.get('tmdb_id')
                if tid:
                    tmdb_to_taskinfo[int(tid)] = {
                        'task_name': t.get('taskname') or t.get('task_name') or '',
                        'content_type': extracted.get('content_type') or extracted.get('type') or 'other',
                        'progress': {}
                    }
            # è‹¥æœªèƒ½å»ºç«‹å®Œæ•´æ˜ å°„ï¼Œå°è¯•åŸºäº shows è¡¨åç§°ä¸ä»»åŠ¡ extracted.show_name åšä¸€æ¬¡å…œåº•ç»‘å®š
            if not tmdb_to_taskinfo:
                try:
                    cur = db.conn.cursor()
                    cur.execute('SELECT tmdb_id, name FROM shows')
                    rows = cur.fetchall() or []
                    for tid, name in rows:
                        name = name or ''
                        # æ‰¾åˆ°åç§°ä¸€è‡´çš„ä»»åŠ¡
                        tgt = next((t for t in tasks if ((t.get('calendar_info') or {}).get('extracted') or {}).get('show_name') == name), None)
                        if tgt:
                            extracted = ((tgt.get('calendar_info') or {}).get('extracted') or {})
                            tmdb_to_taskinfo[int(tid)] = {
                                'task_name': tgt.get('taskname') or tgt.get('task_name') or '',
                                'content_type': extracted.get('content_type') or extracted.get('type') or 'other',
                                'progress': {}
                            }
                except Exception:
                    pass
        except Exception:
            tmdb_to_taskinfo = {}
        # è¯»å–ä»»åŠ¡æœ€æ–°è½¬å­˜æ–‡ä»¶ï¼Œæ„å»º task_name -> è§£æè¿›åº¦ æ˜ å°„
        progress_by_task = {}
        try:
            # ç›´æ¥è¯»å–æ•°æ®åº“ï¼Œé¿å…ä¾èµ–ç™»å½•æ ¡éªŒçš„æ¥å£è°ƒç”¨
            extractor = TaskExtractor()
            rdb = RecordDB()
            cursor = rdb.conn.cursor()
            cursor.execute("""
                SELECT task_name, MAX(transfer_time) as latest_transfer_time
                FROM transfer_records
                WHERE task_name NOT IN ('rename', 'undo_rename')
                GROUP BY task_name
            """)
            latest_times = cursor.fetchall() or []
            latest_files = {}
            for task_name, latest_time in latest_times:
                if latest_time:
                    time_window = 60000
                    cursor.execute(
                        """
                        SELECT renamed_to, original_name, transfer_time, modify_date
                        FROM transfer_records
                        WHERE task_name = ? AND transfer_time >= ? AND transfer_time <= ?
                        ORDER BY id DESC
                        """,
                        (task_name, latest_time - time_window, latest_time + time_window)
                    )
                    files = cursor.fetchall() or []
                    best_file = None
                    if files:
                        if len(files) == 1:
                            best_file = files[0][0]
                        else:
                            file_list = []
                            for renamed_to, original_name, transfer_time, modify_date in files:
                                file_list.append({'file_name': renamed_to, 'original_name': original_name, 'updated_at': transfer_time})
                            try:
                                sorted_files = sorted(file_list, key=sort_file_by_name)
                                best_file = sorted_files[-1]['file_name']
                            except Exception:
                                best_file = files[0][0]
                    if best_file:
                        file_name_without_ext = os.path.splitext(best_file)[0]
                        processed_name = process_season_episode_info(file_name_without_ext, task_name)
                        latest_files[task_name] = processed_name
            rdb.close()
            for tname, latest in (latest_files or {}).items():
                parsed = extractor.extract_progress_from_latest_file(latest)
                if parsed and (parsed.get('episode_number') or parsed.get('air_date')):
                    progress_by_task[tname] = parsed
        except Exception:
            progress_by_task = {}

        # è·å–æ—¥å†æ—¶åŒºæ¨¡å¼é…ç½®
        calendar_timezone_mode = config_data.get('calendar_timezone_mode', 'original')

        # ç»Ÿä¸€è·å–å½“å‰æœ¬åœ°æ—¶é—´ï¼Œç”¨äºæ‰¹é‡è®¡ç®— is_aired ä¿æŒä¸åç«¯ç»Ÿè®¡é€»è¾‘ä¸€è‡´
        try:
            from zoneinfo import ZoneInfo as _ZoneInfo
            local_tz = _ZoneInfo(_get_local_timezone())
            now_local_dt = datetime.now(local_tz)
        except Exception:
            now_local_dt = datetime.now()
        
        # æ‰¹é‡è®¡ç®— is_aired çš„è¾…åŠ©å‡½æ•°ï¼ˆé¿å…é‡å¤æ•°æ®åº“æŸ¥è¯¢ï¼‰
        def batch_compute_is_aired(episodes_list, db_instance):
            """æ‰¹é‡è®¡ç®—æ‰€æœ‰é›†çš„ is_airedï¼Œå¤ç”¨æ•°æ®åº“è¿æ¥å’Œæ‰¹é‡æŸ¥è¯¢ä¼˜åŒ–æ€§èƒ½"""
            if not episodes_list:
                return
            try:
                # æ”¶é›†æ‰€æœ‰éœ€è¦æŸ¥è¯¢çš„ (tmdb_id, season_number, episode_number) ä¸‰å…ƒç»„
                episode_keys = []
                for e in episodes_list:
                    try:
                        tmdb_id_i = int(e.get('tmdb_id'))
                        season_no_i = int(e.get('season_number'))
                        ep_no = int(e.get('episode_number'))
                        episode_keys.append((tmdb_id_i, season_no_i, ep_no, e))
                    except Exception:
                        continue
                
                if not episode_keys:
                    return
                
                # æ‰¹é‡æŸ¥è¯¢æ‰€æœ‰é›†çš„ air_date_localï¼ˆä¸€æ¬¡æ€§æŸ¥è¯¢ï¼‰
                cur = db_instance.conn.cursor()
                air_dates_map = {}
                try:
                    # SQLite ä¸æ”¯æŒå…ƒç»„ INï¼Œä½¿ç”¨ OR æ¡ä»¶ç»„åˆï¼ˆæ€§èƒ½ä»ç„¶æ¯”é€é›†æŸ¥è¯¢å¥½å¾ˆå¤šï¼‰
                    if len(episode_keys) <= 500:  # é™åˆ¶æ‰¹é‡å¤§å°ï¼Œé¿å… SQL è¿‡é•¿
                        conditions = []
                        params = []
                        for tmdb_id_i, season_no_i, ep_no, _ in episode_keys:
                            conditions.append("(tmdb_id=? AND season_number=? AND episode_number=?)")
                            params.extend([tmdb_id_i, season_no_i, ep_no])
                        sql = f"""
                            SELECT tmdb_id, season_number, episode_number, air_date_local
                            FROM episodes
                            WHERE {' OR '.join(conditions)}
                        """
                        cur.execute(sql, params)
                        for row in cur.fetchall():
                            tmdb_id_i, season_no_i, ep_no, air_date_local = row
                            air_dates_map[(int(tmdb_id_i), int(season_no_i), int(ep_no))] = air_date_local
                    else:
                        # å¦‚æœé›†æ•°å¤ªå¤šï¼Œåˆ†æ‰¹æŸ¥è¯¢ï¼ˆæ¯æ‰¹500ä¸ªï¼‰
                        batch_size = 500
                        for i in range(0, len(episode_keys), batch_size):
                            batch = episode_keys[i:i + batch_size]
                            conditions = []
                            params = []
                            for tmdb_id_i, season_no_i, ep_no, _ in batch:
                                conditions.append("(tmdb_id=? AND season_number=? AND episode_number=?)")
                                params.extend([tmdb_id_i, season_no_i, ep_no])
                            sql = f"""
                                SELECT tmdb_id, season_number, episode_number, air_date_local
                                FROM episodes
                                WHERE {' OR '.join(conditions)}
                            """
                            cur.execute(sql, params)
                            for row in cur.fetchall():
                                tmdb_id_i, season_no_i, ep_no, air_date_local = row
                                air_dates_map[(int(tmdb_id_i), int(season_no_i), int(ep_no))] = air_date_local
                except Exception:
                    # å¦‚æœæ‰¹é‡æŸ¥è¯¢å¤±è´¥ï¼Œå›é€€åˆ°é€é›†æŸ¥è¯¢ï¼ˆå…¼å®¹æ€§ï¼‰
                    for tmdb_id_i, season_no_i, ep_no, _ in episode_keys:
                        try:
                            cur.execute(
                                "SELECT air_date_local FROM episodes WHERE tmdb_id=? AND season_number=? AND episode_number=?",
                                (tmdb_id_i, season_no_i, ep_no)
                            )
                            row = cur.fetchone()
                            if row:
                                air_dates_map[(tmdb_id_i, season_no_i, ep_no)] = row[0]
                        except Exception:
                            pass
                
                # æ‰¹é‡æŸ¥è¯¢æ‰€æœ‰èŠ‚ç›®çš„æ’­å‡ºæ—¶é—´é…ç½®ï¼ˆä¸€æ¬¡æ€§æŸ¥è¯¢ï¼Œé¿å…é‡å¤ï¼‰
                unique_tmdb_ids = list(set([k[0] for k in episode_keys]))
                schedules_map = {}
                try:
                    if unique_tmdb_ids:
                        placeholders = ','.join(['?' for _ in unique_tmdb_ids])
                        cur.execute(
                            f"SELECT tmdb_id, local_air_time FROM shows WHERE tmdb_id IN ({placeholders})",
                            unique_tmdb_ids
                        )
                        for row in cur.fetchall():
                            schedules_map[int(row[0])] = (row[1] or '').strip() or None
                except Exception:
                    # å›é€€åˆ°é€èŠ‚ç›®æŸ¥è¯¢ï¼ˆä½¿ç”¨ get_show_air_schedule è·å–å®Œæ•´é…ç½®ï¼‰
                    for tmdb_id_i in unique_tmdb_ids:
                        try:
                            schedule = db_instance.get_show_air_schedule(tmdb_id_i) or {}
                            schedules_map[tmdb_id_i] = (schedule.get('local_air_time') or '').strip() or None
                        except Exception:
                            schedules_map[tmdb_id_i] = None
                
                # è·å–å…¨å±€æ’­å‡ºé›†æ•°åˆ·æ–°æ—¶é—´ï¼ˆåªéœ€è·å–ä¸€æ¬¡ï¼‰
                perf = config_data.get("performance", {}) if isinstance(config_data, dict) else {}
                refresh_time_str = perf.get("aired_refresh_time", "00:00")
                
                # åœ¨å†…å­˜ä¸­æ‰¹é‡è®¡ç®— is_airedï¼Œå¹¶åŒæ—¶ä¸ºå‰ç«¯æ³¨å…¥èŠ‚ç›®çº§æ’­å‡ºæ—¶é—´ï¼ˆlocal_air_timeï¼‰
                for tmdb_id_i, season_no_i, ep_no, episode_obj in episode_keys:
                    try:
                        air_date_local = air_dates_map.get((tmdb_id_i, season_no_i, ep_no))
                        if not air_date_local:
                            episode_obj['is_aired'] = False
                            continue
                        
                        # è·å–èŠ‚ç›®çº§æ’­å‡ºæ—¶é—´
                        local_air_time = schedules_map.get(tmdb_id_i)
                        # å°†èŠ‚ç›®çº§æ’­å‡ºæ—¶é—´åŸæ ·æ³¨å…¥åˆ°æ¯ä¸€é›†å¯¹è±¡ä¸­ï¼Œä¾›å‰ç«¯æ‚¬åœæç¤ºå±•ç¤º
                        # ä»…åœ¨å­˜åœ¨èŠ‚ç›®çº§é…ç½®æ—¶æ³¨å…¥ï¼›è‹¥é…ç½®ä¸ºç©ºåˆ™ä¿æŒè¯¥å­—æ®µç¼ºå¤±ï¼Œå‰ç«¯ä»æŒ‰åŸé€»è¾‘ä¸æ˜¾ç¤ºæ—¶é—´
                        if local_air_time:
                            episode_obj['local_air_time'] = local_air_time
                        time_to_use = local_air_time if local_air_time else refresh_time_str
                        
                        # è§£ææ—¶é—´ï¼ˆHH:MMï¼‰
                        hh, mm = 0, 0
                        try:
                            parts = str(time_to_use).split(":")
                            if len(parts) == 2:
                                hh = int(parts[0])
                                mm = int(parts[1])
                        except Exception:
                            hh, mm = 0, 0
                        
                        # ç»„åˆæ—¥æœŸå’Œæ—¶é—´ï¼Œä¸å½“å‰æ—¶é—´æ¯”è¾ƒ
                        dt_str = f"{air_date_local} {hh:02d}:{mm:02d}:00"
                        dt_ep_local = datetime.strptime(dt_str, "%Y-%m-%d %H:%M:%S")
                        if getattr(now_local_dt, "tzinfo", None) is not None:
                            dt_ep_local = dt_ep_local.replace(tzinfo=now_local_dt.tzinfo)
                        episode_obj['is_aired'] = dt_ep_local.timestamp() <= now_local_dt.timestamp()
                    except Exception:
                        episode_obj['is_aired'] = False
            except Exception:
                # å¦‚æœæ‰¹é‡è®¡ç®—å¤±è´¥ï¼Œå›é€€åˆ°é€é›†è°ƒç”¨ is_episode_airedï¼ˆå…¼å®¹æ€§ä¿è¯ï¼‰
                for e in episodes_list:
                    try:
                        tmdb_id_i = int(e.get('tmdb_id'))
                        season_no_i = int(e.get('season_number'))
                        ep_no = int(e.get('episode_number'))
                        e['is_aired'] = bool(is_episode_aired(tmdb_id_i, season_no_i, ep_no, now_local_dt))
                    except Exception:
                        e['is_aired'] = False
        
        if tmdb_id:
            show = db.get_show(int(tmdb_id))
            if not show:
                return jsonify({'success': True, 'data': {'episodes': [], 'total': 0}})
            eps = db.list_latest_season_episodes(int(tmdb_id), int(show['latest_season_number']))
            # æ ¹æ® calendar_timezone_mode é€‰æ‹©ä½¿ç”¨ air_date è¿˜æ˜¯ air_date_local
            # air_date_local åº”è¯¥å·²ç»åŒ…å«äº†åç§»å€¼ï¼Œç›´æ¥ä½¿ç”¨å³å¯
            for e in eps:
                if calendar_timezone_mode == 'local' and e.get('air_date_local'):
                    e['display_air_date'] = e['air_date_local']
                else:
                    e['display_air_date'] = e.get('air_date') or ''
                # è¡¥å…… tmdb_id å’Œ season_numberï¼ˆæ‰¹é‡è®¡ç®—éœ€è¦ï¼‰
                e['tmdb_id'] = int(tmdb_id)
                e['season_number'] = int(show['latest_season_number'])
            # æ‰¹é‡è®¡ç®— is_airedï¼ˆä¼˜åŒ–æ€§èƒ½ï¼‰
            batch_compute_is_aired(eps, db)
            # æ³¨å…¥ä»»åŠ¡ä¿¡æ¯ä¸æ ‡å‡†åŒ–è¿›åº¦
            info = tmdb_to_taskinfo.get(int(tmdb_id))
            if info:
                for e in eps:
                    e['task_info'] = info
                    # åˆå¹¶æ ‡å‡†åŒ–è¿›åº¦
                    tname = info.get('task_name') or ''
                    p = progress_by_task.get(tname)
                    if p:
                        e['task_info']['progress'] = p
            result_data = {'success': True, 'data': {'episodes': eps, 'total': len(eps), 'show': show}}
            
            # æ›´æ–°ç¼“å­˜
            with _calendar_episodes_cache_lock:
                _calendar_episodes_cache[cache_key] = (result_data, current_time)
            
            return jsonify(result_data)
        else:
            # è¿”å›å…¨éƒ¨æœ€æ–°å­£æ±‡æ€»ï¼ˆä¾›å‘¨è§†å›¾åˆå¹¶å±•ç¤ºï¼‰
            eps = db.list_all_latest_episodes()
            # æ ¹æ® calendar_timezone_mode é€‰æ‹©ä½¿ç”¨ air_date è¿˜æ˜¯ air_date_local
            # air_date_local åº”è¯¥å·²ç»åŒ…å«äº†åç§»å€¼ï¼Œç›´æ¥ä½¿ç”¨å³å¯
            for e in eps:
                if calendar_timezone_mode == 'local' and e.get('air_date_local'):
                    e['display_air_date'] = e['air_date_local']
                else:
                    e['display_air_date'] = e.get('air_date') or ''
            # æ‰¹é‡è®¡ç®— is_airedï¼ˆä¼˜åŒ–æ€§èƒ½ï¼‰
            batch_compute_is_aired(eps, db)
            for e in eps:
                info = tmdb_to_taskinfo.get(int(e.get('tmdb_id')))
                if info:
                    e['task_info'] = info
                    tname = info.get('task_name') or ''
                    p = progress_by_task.get(tname)
                    if p:
                        e['task_info']['progress'] = p
            result_data = {'success': True, 'data': {'episodes': eps, 'total': len(eps)}}
            
            # æ›´æ–°ç¼“å­˜
            with _calendar_episodes_cache_lock:
                _calendar_episodes_cache[cache_key] = (result_data, current_time)
            
            return jsonify(result_data)
    except Exception as e:
        # å¦‚æœå‡ºé”™ï¼Œå°è¯•è¿”å›ç¼“å­˜æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
        with _calendar_episodes_cache_lock:
            if cache_key in _calendar_episodes_cache:
                cache_data, _ = _calendar_episodes_cache[cache_key]
                logging.warning(f'è·å–æœ¬åœ°å‰§é›†æ•°æ®å¤±è´¥ï¼Œè¿”å›ç¼“å­˜æ•°æ®: {str(e)}')
                return jsonify(cache_data)
        
        # æ²¡æœ‰ç¼“å­˜ï¼Œè¿”å›é”™è¯¯
        return jsonify({'success': False, 'message': f'è¯»å–æœ¬åœ°å‰§é›†å¤±è´¥: {str(e)}', 'data': {'episodes': [], 'total': 0}})


# æ¸…ç†ç¼“å­˜ï¼šæŒ‰ tmdb_id åˆ é™¤å¯¹åº”å‰§ç›®çš„æ‰€æœ‰æœ¬åœ°ç¼“å­˜
@app.route("/api/calendar/purge_tmdb", methods=["POST"])
def purge_calendar_tmdb():
    try:
        tmdb_id = request.args.get('tmdb_id') or (request.json or {}).get('tmdb_id')
        if not tmdb_id:
            return jsonify({'success': False, 'message': 'ç¼ºå°‘ tmdb_id'})
        force = False
        try:
            fv = request.args.get('force') or (request.json or {}).get('force')
            force = True if str(fv).lower() in ('1', 'true', 'yes') else False
        except Exception:
            force = False
        ok = purge_calendar_by_tmdb_id_internal(int(tmdb_id), force=force)
        try:
            if ok:
                notify_calendar_changed('purge_tmdb')
        except Exception:
            pass
        return jsonify({'success': ok})
    except Exception as e:
        return jsonify({'success': False, 'message': f'æ¸…ç†å¤±è´¥: {str(e)}'})


# æ¸…ç†ç¼“å­˜ï¼šæŒ‰ä»»åŠ¡åæŸ¥æ‰¾ config ä¸­çš„ tmdb_id å¹¶æ¸…ç†
@app.route("/api/calendar/purge_by_task", methods=["POST"])
def purge_calendar_by_task():
    try:
        task_name = request.args.get('task_name') or (request.json or {}).get('task_name')
        if not task_name:
            return jsonify({'success': False, 'message': 'ç¼ºå°‘ task_name'})
        force = False
        try:
            fv = request.args.get('force') or (request.json or {}).get('force')
            force = True if str(fv).lower() in ('1', 'true', 'yes') else False
        except Exception:
            force = False
        # åœ¨é…ç½®ä¸­æŸ¥æ‰¾å¯¹åº”ä»»åŠ¡
        tasks = config_data.get('tasklist', [])
        target = next((t for t in tasks if t.get('taskname') == task_name or t.get('task_name') == task_name), None)
        if not target:
            # è‹¥ä»»åŠ¡ä¸å­˜åœ¨ï¼Œä½†ç”¨æˆ·å¸Œæœ›å¼ºåˆ¶æ¸…ç†ï¼šå°è¯•æŒ‰ tmdb_id åæŸ¥æ— å¼•ç”¨ show å¹¶æ¸…ç†ï¼ˆæ›´å®‰å…¨ï¼‰
            if force:
                # æ‰«æ shows è¡¨ï¼Œåˆ é™¤æœªè¢«ä»»ä½•ä»»åŠ¡å¼•ç”¨çš„è®°å½•ï¼ˆå­¤å„¿ï¼‰
                purged = purge_orphan_calendar_shows_internal()
                try:
                    if purged > 0:
                        notify_calendar_changed('purge_orphans')
                except Exception:
                    pass
                return jsonify({'success': True, 'message': f'ä»»åŠ¡ä¸å­˜åœ¨ï¼Œå·²å¼ºåˆ¶æ¸…ç†å­¤å„¿è®°å½• {purged} æ¡'})
            return jsonify({'success': True, 'message': 'ä»»åŠ¡ä¸å­˜åœ¨ï¼Œè§†ä¸ºå·²æ¸…ç†'})
        cal = (target or {}).get('calendar_info') or {}
        tmdb_id = cal.get('match', {}).get('tmdb_id') or cal.get('tmdb_id')
        if not tmdb_id:
            return jsonify({'success': True, 'message': 'ä»»åŠ¡æœªç»‘å®š tmdb_idï¼Œæ— éœ€æ¸…ç†'})
        ok = purge_calendar_by_tmdb_id_internal(int(tmdb_id), force=force)
        try:
            if ok:
                notify_calendar_changed('purge_by_task')
        except Exception:
            pass
        return jsonify({'success': ok})
    except Exception as e:
        return jsonify({'success': False, 'message': f'æ¸…ç†å¤±è´¥: {str(e)}'})
# è±†ç“£APIè·¯ç”±

# é€šç”¨ç”µå½±æ¥å£
@app.route("/api/douban/movie/recent_hot")
def get_movie_recent_hot():
    """è·å–ç”µå½±æ¦œå• - é€šç”¨æ¥å£"""
    try:
        category = request.args.get('category', 'çƒ­é—¨')
        type_param = request.args.get('type', 'å…¨éƒ¨')
        limit = int(request.args.get('limit', 20))
        start = int(request.args.get('start', 0))

        # æ˜ å°„categoryåˆ°main_category
        category_mapping = {
            'çƒ­é—¨': 'movie_hot',
            'æœ€æ–°': 'movie_latest',
            'è±†ç“£é«˜åˆ†': 'movie_top',
            'å†·é—¨ä½³ç‰‡': 'movie_underrated'
        }

        main_category = category_mapping.get(category, 'movie_hot')
        result = douban_service.get_list_data(main_category, type_param, limit, start)

        return jsonify(result)
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–ç”µå½±æ¦œå•å¤±è´¥: {str(e)}',
            'data': {'items': []}
        })

@app.route("/api/douban/movie/<movie_type>/<sub_category>")
def get_movie_list(movie_type, sub_category):
    """è·å–ç”µå½±æ¦œå•"""
    try:
        limit = int(request.args.get('limit', 20))
        start = int(request.args.get('start', 0))

        main_category = f"movie_{movie_type}"
        result = douban_service.get_list_data(main_category, sub_category, limit, start)

        return jsonify(result)
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–ç”µå½±æ¦œå•å¤±è´¥: {str(e)}',
            'data': {'items': []}
        })


# é€šç”¨ç”µè§†å‰§æ¥å£
@app.route("/api/douban/tv/recent_hot")
def get_tv_recent_hot():
    """è·å–ç”µè§†å‰§æ¦œå• - é€šç”¨æ¥å£"""
    try:
        category = request.args.get('category', 'tv')
        type_param = request.args.get('type', 'tv')
        limit = int(request.args.get('limit', 20))
        start = int(request.args.get('start', 0))

        # æ˜ å°„categoryåˆ°main_category
        if category == 'tv':
            main_category = 'tv_drama'
        elif category == 'show':
            main_category = 'tv_variety'
        elif category == 'tv_drama':
            main_category = 'tv_drama'
        elif category == 'tv_variety':
            main_category = 'tv_variety'
        else:
            main_category = 'tv_drama'

        result = douban_service.get_list_data(main_category, type_param, limit, start)

        return jsonify(result)
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–ç”µè§†å‰§æ¦œå•å¤±è´¥: {str(e)}',
            'data': {'items': []}
        })

@app.route("/api/douban/tv/<tv_type>/<sub_category>")
def get_tv_list(tv_type, sub_category):
    """è·å–ç”µè§†å‰§/ç»¼è‰ºæ¦œå•"""
    try:
        limit = int(request.args.get('limit', 20))
        start = int(request.args.get('start', 0))

        main_category = f"tv_{tv_type}"
        result = douban_service.get_list_data(main_category, sub_category, limit, start)

        return jsonify(result)
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–ç”µè§†å‰§æ¦œå•å¤±è´¥: {str(e)}',
            'data': {'items': []}
        })


@app.route("/api/proxy/douban-image")
def proxy_douban_image():
    """ä»£ç†è±†ç“£å›¾ç‰‡è¯·æ±‚ï¼Œè®¾ç½®æ­£ç¡®çš„ Referer å¤´ä»¥ç»•è¿‡é˜²ç›—é“¾é™åˆ¶"""
    try:
        image_url = request.args.get('url')
        if not image_url:
            return Response('ç¼ºå°‘å›¾ç‰‡URLå‚æ•°', status=400, mimetype='text/plain')
        
        # éªŒè¯URLæ˜¯å¦ä¸ºè±†ç“£å›¾ç‰‡åœ°å€
        if not (image_url.startswith('http://') or image_url.startswith('https://')):
            return Response('æ— æ•ˆçš„å›¾ç‰‡URL', status=400, mimetype='text/plain')
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºè±†ç“£å›¾ç‰‡åŸŸåï¼ˆdouban.com, doubanio.comç­‰ï¼‰
        douban_domains = ['douban.com', 'doubanio.com']
        is_douban_image = any(domain in image_url for domain in douban_domains)
        
        if not is_douban_image:
            # å¦‚æœä¸æ˜¯è±†ç“£å›¾ç‰‡ï¼Œå¯ä»¥é€‰æ‹©ç›´æ¥é‡å®šå‘æˆ–æ‹’ç»
            # è¿™é‡Œæˆ‘ä»¬é€‰æ‹©ç›´æ¥ä»£ç†ï¼Œä½†ä¸è®¾ç½®Referer
            headers = {
                'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1'
            }
        else:
            # è±†ç“£å›¾ç‰‡éœ€è¦è®¾ç½®Refererä¸ºè±†ç“£åŸŸå
            headers = {
                'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1',
                'Referer': 'https://movie.douban.com/'
            }
        
        # è¯·æ±‚å›¾ç‰‡
        response = requests.get(image_url, headers=headers, timeout=10, stream=True)
        
        if response.status_code != 200:
            return Response(f'å›¾ç‰‡åŠ è½½å¤±è´¥: {response.status_code}', 
                          status=response.status_code, 
                          mimetype='text/plain')
        
        # è·å–å›¾ç‰‡çš„Content-Type
        content_type = response.headers.get('Content-Type', 'image/jpeg')
        
        # è®¾ç½®å“åº”å¤´ï¼Œå…è®¸è·¨åŸŸï¼ˆå¦‚æœéœ€è¦ï¼‰
        resp = Response(
            stream_with_context(response.iter_content(chunk_size=8192)),
            content_type=content_type
        )
        resp.headers['Cache-Control'] = 'public, max-age=3600'
        
        return resp
        
    except Exception as e:
        logging.error(f"ä»£ç†è±†ç“£å›¾ç‰‡å¤±è´¥: {str(e)}")
        return Response(f'ä»£ç†å›¾ç‰‡å¤±è´¥: {str(e)}', status=500, mimetype='text/plain')

@app.route("/api/calendar/update_content_type", methods=["POST"])
def update_show_content_type():
    """æ›´æ–°èŠ‚ç›®çš„å†…å®¹ç±»å‹"""
    try:
        data = request.get_json()
        tmdb_id = data.get('tmdb_id')
        content_type = data.get('content_type')
        
        if not tmdb_id or not content_type:
            return jsonify({
                'success': False,
                'message': 'ç¼ºå°‘å¿…è¦å‚æ•°ï¼štmdb_id æˆ– content_type'
            })
        
        from app.sdk.db import CalendarDB
        cal_db = CalendarDB()
        
        # æ›´æ–°å†…å®¹ç±»å‹
        success = cal_db.update_show_content_type(int(tmdb_id), content_type)
        
        if success:
            return jsonify({
                'success': True,
                'message': 'å†…å®¹ç±»å‹æ›´æ–°æˆåŠŸ'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'èŠ‚ç›®ä¸å­˜åœ¨æˆ–æ›´æ–°å¤±è´¥'
            })
            
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'æ›´æ–°å†…å®¹ç±»å‹å¤±è´¥: {str(e)}'
        })

@app.route("/api/calendar/content_types")
def get_content_types():
    """è·å–æ‰€æœ‰èŠ‚ç›®å†…å®¹ç±»å‹"""
    try:
        from app.sdk.db import CalendarDB
        cal_db = CalendarDB()
        content_types = cal_db.get_all_content_types()
        return jsonify({
            'success': True,
            'data': content_types
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–èŠ‚ç›®å†…å®¹ç±»å‹å¤±è´¥: {str(e)}'
        })

def cleanup_episode_patterns_config(config_data):
    """æ¸…ç†å‰§é›†è¯†åˆ«è§„åˆ™é…ç½®"""
    try:
        # éœ€è¦æ¸…ç†çš„é»˜è®¤å‰§é›†è¯†åˆ«è§„åˆ™ï¼ˆæŒ‰éƒ¨åˆ†è§„åˆ™åŒ¹é…ï¼‰
        default_pattern_parts = [
            "ç¬¬(\\d+)é›†",
            "ç¬¬(\\d+)æœŸ", 
            "ç¬¬(\\d+)è¯",
            "(\\d+)é›†",
            "(\\d+)æœŸ",
            "(\\d+)è¯",
            "[Ee][Pp]?(\\d+)",
            "(\\d+)[-_\\s]*4[Kk]",
            "(\\d+)[-_\\\\s]*4[Kk]",
            "\\[(\\d+)\\]",
            "ã€(\\d+)ã€‘",
            "_?(\\d+)_?"
        ]
        
        cleaned_tasks = 0
        cleaned_global = False
        
        # 1. æ¸…ç†ä»»åŠ¡çº§åˆ«çš„ config_data.episode_patterns
        if 'tasklist' in config_data:
            for task in config_data['tasklist']:
                if 'config_data' in task and 'episode_patterns' in task['config_data']:
                    del task['config_data']['episode_patterns']
                    cleaned_tasks += 1
                    # å¦‚æœ config_data ä¸ºç©ºï¼Œåˆ é™¤æ•´ä¸ª config_data
                    if not task['config_data']:
                        del task['config_data']
        
        # 2. æ¸…ç†å…¨å±€é…ç½®ä¸­çš„é»˜è®¤è§„åˆ™
        if 'episode_patterns' in config_data:
            current_patterns = config_data['episode_patterns']
            if isinstance(current_patterns, list):
                # è¿‡æ»¤æ‰åŒ…å«é»˜è®¤è§„åˆ™çš„é…ç½®
                filtered_patterns = []
                for pattern in current_patterns:
                    if isinstance(pattern, dict) and 'regex' in pattern:
                        pattern_regex = pattern['regex']
                        # ç”¨ç«–çº¿åˆ†å‰²è§„åˆ™
                        pattern_parts = pattern_regex.split('|')
                        # è¿‡æ»¤æ‰é»˜è®¤è§„åˆ™éƒ¨åˆ†ï¼Œä¿ç•™è‡ªå®šä¹‰è§„åˆ™
                        custom_parts = [part.strip() for part in pattern_parts if part.strip() not in default_pattern_parts]
                        
                        if custom_parts:
                            # å¦‚æœæœ‰è‡ªå®šä¹‰è§„åˆ™ï¼Œä¿ç•™å¹¶é‡æ–°ç»„åˆ
                            filtered_patterns.append({
                                'regex': '|'.join(custom_parts)
                            })
                    elif isinstance(pattern, str):
                        pattern_regex = pattern
                        # ç”¨ç«–çº¿åˆ†å‰²è§„åˆ™
                        pattern_parts = pattern_regex.split('|')
                        # è¿‡æ»¤æ‰é»˜è®¤è§„åˆ™éƒ¨åˆ†ï¼Œä¿ç•™è‡ªå®šä¹‰è§„åˆ™
                        custom_parts = [part.strip() for part in pattern_parts if part.strip() not in default_pattern_parts]
                        
                        if custom_parts:
                            # å¦‚æœæœ‰è‡ªå®šä¹‰è§„åˆ™ï¼Œä¿ç•™å¹¶é‡æ–°ç»„åˆ
                            filtered_patterns.append('|'.join(custom_parts))
                
                # æ›´æ–°é…ç½®
                if filtered_patterns:
                    config_data['episode_patterns'] = filtered_patterns
                else:
                    # å¦‚æœæ²¡æœ‰å‰©ä½™è§„åˆ™ï¼Œæ¸…ç©ºé…ç½®
                    config_data['episode_patterns'] = []
                    cleaned_global = True
        
        # é™é»˜æ‰§è¡Œæ¸…ç†æ“ä½œï¼Œä¸è¾“å‡ºæ—¥å¿—
        
        return True
        
    except Exception as e:
        logging.error(f"æ¸…ç†å‰§é›†è¯†åˆ«è§„åˆ™é…ç½®å¤±è´¥: {str(e)}")
        return False

@app.route("/api/calendar/cleanup_orphaned_posters", methods=["POST"])
def cleanup_orphaned_posters_api():
    """æ‰‹åŠ¨æ¸…ç†å­¤ç«‹çš„æ—§æµ·æŠ¥æ–‡ä»¶"""
    try:
        if not is_login():
            return jsonify({"success": False, "message": "æœªç™»å½•"})
        
        success = cleanup_orphaned_posters()
        if success:
            return jsonify({"success": True, "message": "å­¤ç«‹æµ·æŠ¥æ–‡ä»¶æ¸…ç†å®Œæˆ"})
        else:
            return jsonify({"success": True, "message": "æ²¡æœ‰å‘ç°éœ€è¦æ¸…ç†çš„å­¤ç«‹æ–‡ä»¶"})
    except Exception as e:
        return jsonify({"success": False, "message": f"æ¸…ç†å­¤ç«‹æµ·æŠ¥å¤±è´¥: {str(e)}"})

if __name__ == "__main__":
    IS_FLASK_SERVER_PROCESS = True
    init()
    reload_tasks()
    # åœ¨ reload_tasks() ä¹‹åé‡æ–°æ³¨å†Œä¼šè¢«æ¸…ç©ºçš„åå°ä»»åŠ¡ï¼ˆé¿å… remove_all_jobs çš„å½±å“ï¼‰
    try:
        restart_calendar_refresh_job()
    except Exception:
        pass
    try:
        restart_daily_aired_update_job()
    except Exception:
        pass
    # åˆå§‹åŒ–å…¨å±€dbå¯¹è±¡ï¼Œç¡®ä¿æ‰€æœ‰æ¥å£å¯ç”¨
    record_db = RecordDB()
    app.run(debug=DEBUG, host="0.0.0.0", port=PORT)
