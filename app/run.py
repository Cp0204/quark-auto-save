# !/usr/bin/env python3
# -*- coding: utf-8 -*-
from flask import (
    json,
    Flask,
    url_for,
    session,
    jsonify,
    request,
    redirect,
    Response,
    render_template,
    send_from_directory,
    stream_with_context,
)
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.interval import IntervalTrigger
from apscheduler.triggers.date import DateTrigger
from queue import Queue
from sdk.cloudsaver import CloudSaver
try:
    from sdk.pansou import PanSou
except Exception:
    PanSou = None
from datetime import timedelta, datetime
import subprocess
import requests
import hashlib
import logging
import base64
import sys
import os
import re
import random
import time
import treelib
from functools import lru_cache
from threading import Lock, Thread

parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
sys.path.insert(0, parent_dir)
from quark_auto_save import Quark
from quark_auto_save import Config, format_bytes

# æ·»åŠ å¯¼å…¥å…¨å±€extract_episode_numberå’Œsort_file_by_nameå‡½æ•°
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from quark_auto_save import extract_episode_number, sort_file_by_name, chinese_to_arabic, is_date_format, apply_subtitle_naming_rule

# å¯¼å…¥è±†ç“£æœåŠ¡
from sdk.douban_service import douban_service

# å¯¼å…¥è¿½å‰§æ—¥å†ç›¸å…³æ¨¡å—
from utils.task_extractor import TaskExtractor
from sdk.tmdb_service import TMDBService
from sdk.db import CalendarDB
from sdk.db import RecordDB
from utils.task_extractor import TaskExtractor

def get_effective_date_for_aired_count():
    """
    æ ¹æ®ç”¨æˆ·è®¾ç½®çš„æ’­å‡ºé›†æ•°åˆ·æ–°æ—¶é—´ï¼Œè¿”å›åº”è¯¥ç”¨äºè®¡ç®—å·²æ’­å‡ºé›†æ•°çš„æ—¥æœŸã€‚
    å¦‚æœåœ¨åˆ·æ–°æ—¶é—´ä¹‹å‰ï¼Œè¿”å›æ˜¨å¤©çš„æ—¥æœŸï¼›å¦‚æœåœ¨åˆ·æ–°æ—¶é—´ä¹‹åï¼Œè¿”å›ä»Šå¤©çš„æ—¥æœŸã€‚
    è¿™æ ·å¯ä»¥ç¡®ä¿åœ¨åˆ·æ–°æ—¶é—´ä¹‹å‰ï¼Œå·²æ’­å‡ºé›†æ•°ä¸ä¼šè¢«æå‰æ›´æ–°ã€‚
    """
    from datetime import datetime as _dt, timedelta
    now = _dt.now()
    today = now.strftime('%Y-%m-%d')
    
    # è·å–ç”¨æˆ·é…ç½®çš„åˆ·æ–°æ—¶é—´ï¼Œé»˜è®¤ 00:00
    perf = config_data.get('performance', {}) if isinstance(config_data, dict) else {}
    refresh_time_str = perf.get('aired_refresh_time', '00:00')
    
    try:
        refresh_parts = refresh_time_str.split(':')
        if len(refresh_parts) == 2:
            refresh_hour = int(refresh_parts[0])
            refresh_minute = int(refresh_parts[1])
            current_hour = now.hour
            current_minute = now.minute
            
            # å½“å‰æ—¶é—´ >= åˆ·æ–°æ—¶é—´ï¼Œä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸ
            if current_hour > refresh_hour or (current_hour == refresh_hour and current_minute >= refresh_minute):
                return today
            else:
                # å½“å‰æ—¶é—´ < åˆ·æ–°æ—¶é—´ï¼Œä½¿ç”¨æ˜¨å¤©çš„æ—¥æœŸ
                yesterday = (now - timedelta(days=1)).strftime('%Y-%m-%d')
                return yesterday
        else:
            # è§£æå¤±è´¥æ—¶é»˜è®¤ä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸï¼ˆå‘åå…¼å®¹ï¼‰
            return today
    except Exception:
        # è§£æå¤±è´¥æ—¶é»˜è®¤ä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸï¼ˆå‘åå…¼å®¹ï¼‰
        return today

def enrich_tasks_with_calendar_meta(tasks_info: list) -> list:
    """ä¸ºä»»åŠ¡åˆ—è¡¨æ³¨å…¥æ—¥å†ç›¸å…³å…ƒæ•°æ®ï¼šèŠ‚ç›®çŠ¶æ€ã€æœ€æ–°å­£å¤„ç†ååç§°ã€å·²è½¬å­˜/å·²æ’­å‡º/æœ¬å­£æ€»é›†æ•°ã€‚
    è¿”å›æ–°çš„ä»»åŠ¡å­—å…¸åˆ—è¡¨ï¼Œå¢åŠ ä»¥ä¸‹å­—æ®µï¼š
    - matched_status: èŠ‚ç›®çŠ¶æ€ï¼ˆå¦‚ æ’­å‡ºä¸­ ç­‰ï¼‰
    - latest_season_name: æœ€æ–°å­£åç§°ï¼ˆå¤„ç†åï¼‰
    - season_counts: { transferred_count, aired_count, total_count }
    """
    try:
        if not tasks_info:
            return tasks_info
        db = CalendarDB()
        # é¢„å– shows ä¸ seasons æ•°æ®
        cur = db.conn.cursor()
        cur.execute('SELECT tmdb_id, status, latest_season_number FROM shows')
        rows = cur.fetchall() or []
        show_meta = {int(r[0]): {'status': r[1], 'latest_season_number': int(r[2])} for r in rows}

        cur.execute('SELECT tmdb_id, season_number, season_name, episode_count FROM seasons')
        rows = cur.fetchall() or []
        season_meta = {}
        for tid, sn, sname, ecount in rows:
            season_meta[(int(tid), int(sn))] = {'season_name': sname or '', 'episode_count': int(ecount or 0)}

        # ç»Ÿè®¡"å·²è½¬å­˜é›†æ•°"ï¼šåŸºäºè½¬å­˜è®°å½•æœ€æ–°è¿›åº¦æ„å»ºæ˜ å°„ï¼ˆæŒ‰ä»»åŠ¡åï¼‰
        transferred_by_task = {}
        try:
            rdb = RecordDB()
            cursor = rdb.conn.cursor()
            cursor.execute(
                """
                SELECT task_name, MAX(transfer_time) as latest_transfer_time
                FROM transfer_records
                WHERE task_name NOT IN ('rename', 'undo_rename')
                GROUP BY task_name
                """
            )
            latest_times = cursor.fetchall() or []
            extractor = TaskExtractor()
            for task_name, latest_time in latest_times:
                if latest_time:
                    cursor.execute(
                        """
                        SELECT renamed_to, original_name, transfer_time, modify_date
                        FROM transfer_records
                        WHERE task_name = ? AND transfer_time >= ? AND transfer_time <= ?
                        ORDER BY id DESC
                        """,
                        (task_name, latest_time - 60000, latest_time + 60000)
                    )
                    files = cursor.fetchall() or []
                    best = files[0][0] if files else ''
                    if len(files) > 1:
                        file_list = [{'file_name': f[0], 'original_name': f[1], 'updated_at': f[2]} for f in files]
                        try:
                            best = sorted(file_list, key=sort_file_by_name)[-1]['file_name']
                        except Exception:
                            best = files[0][0]
                    if best:
                        name_wo_ext = os.path.splitext(best)[0]
                        processed = process_season_episode_info(name_wo_ext, task_name)
                        parsed = extractor.extract_progress_from_latest_file(processed)
                        if parsed and parsed.get('episode_number'):
                            # åŒ…å«é›†æ•°çš„æƒ…å†µ
                            transferred_by_task[task_name] = int(parsed['episode_number'])
                        elif parsed and parsed.get('air_date'):
                            # åªæœ‰æ—¥æœŸçš„æƒ…å†µï¼šé€šè¿‡æŸ¥è¯¢æ•°æ®åº“è·å–å¯¹åº”æ—¥æœŸçš„æœ€å¤§é›†æ•°
                            air_date = parsed['air_date']
                            try:
                                # æŸ¥æ‰¾è¯¥ä»»åŠ¡å¯¹åº”çš„èŠ‚ç›®åç§°
                                task_info = next((t for t in tasks_info if (t.get('task_name') or t.get('taskname')) == task_name), None)
                                if task_info:
                                    show_name = (task_info.get('matched_show_name') or task_info.get('show_name') or '').strip()
                                    if show_name:
                                        # æŸ¥è¯¢è¯¥èŠ‚ç›®åœ¨è¯¥æ—¥æœŸæ’­å‡ºçš„æœ€å¤§é›†æ•°
                                        cur.execute(
                                            """
                                            SELECT MAX(CAST(episode_number AS INTEGER))
                                            FROM episodes
                                            WHERE show_name = ? AND air_date = ?
                                            """,
                                            (show_name, air_date)
                                        )
                                        result = cur.fetchone()
                                        if result and result[0] is not None:
                                            transferred_by_task[task_name] = int(result[0])
                            except Exception:
                                pass
            rdb.close()
        except Exception:
            transferred_by_task = {}

        # ç»Ÿè®¡"å·²æ’­å‡ºé›†æ•°"ï¼šè¯»å–æœ¬åœ° episodes è¡¨ä¸­æœ‰ air_date ä¸” <= æœ‰æ•ˆæ—¥æœŸçš„é›†æ•°
        # æœ‰æ•ˆæ—¥æœŸæ ¹æ®æ’­å‡ºé›†æ•°åˆ·æ–°æ—¶é—´ç¡®å®šï¼šåˆ·æ–°æ—¶é—´ä¹‹å‰ä½¿ç”¨æ˜¨å¤©çš„æ—¥æœŸï¼Œä¹‹åä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸ
        from datetime import datetime as _dt
        now = _dt.now()
        today = now.strftime('%Y-%m-%d')
        effective_date = get_effective_date_for_aired_count()  # è·å–åº”è¯¥ç”¨äºè®¡ç®—å·²æ’­å‡ºé›†æ•°çš„æœ‰æ•ˆæ—¥æœŸ
        current_time_str = now.strftime('%H:%M')
        # è·å–ç”¨æˆ·é…ç½®çš„åˆ·æ–°æ—¶é—´ï¼Œé»˜è®¤ 00:00
        perf = config_data.get('performance', {}) if isinstance(config_data, dict) else {}
        refresh_time_str = perf.get('aired_refresh_time', '00:00')
        # åˆ¤æ–­å½“å‰æ—¶é—´æ˜¯å¦å·²ç»è¿‡äº†ç”¨æˆ·è®¾ç½®çš„åˆ·æ–°æ—¶é—´
        allow_refresh = False
        try:
            refresh_parts = refresh_time_str.split(':')
            if len(refresh_parts) == 2:
                refresh_hour = int(refresh_parts[0])
                refresh_minute = int(refresh_parts[1])
                current_hour = now.hour
                current_minute = now.minute
                # å½“å‰æ—¶é—´ >= åˆ·æ–°æ—¶é—´ï¼Œå…è®¸åˆ·æ–°
                if current_hour > refresh_hour or (current_hour == refresh_hour and current_minute >= refresh_minute):
                    allow_refresh = True
        except Exception:
            # è§£æå¤±è´¥æ—¶é»˜è®¤å…è®¸åˆ·æ–°ï¼ˆå‘åå…¼å®¹ï¼‰
            allow_refresh = True
        aired_by_show_season = {}
        try:
            cur.execute(
                """
                SELECT tmdb_id, season_number, COUNT(1) FROM episodes
                WHERE air_date IS NOT NULL AND air_date != '' AND air_date <= ?
                GROUP BY tmdb_id, season_number
                """,
                (effective_date,)
            )
            for tid, sn, cnt in (cur.fetchall() or []):
                aired_by_show_season[(int(tid), int(sn))] = int(cnt or 0)
        except Exception:
            aired_by_show_season = {}

        # è¯»å– season_metrics ç¼“å­˜ï¼ˆä¼˜å…ˆä½¿ç”¨ç¼“å­˜å›å¡«å±•ç¤ºï¼›è‹¥ç¼“å­˜æ—¥æœŸæ—©äºä»Šå¤©ï¼Œåˆ™å¼ºåˆ¶ä½¿ç”¨ä»Šæ—¥å³æ—¶ç»Ÿè®¡è¦†ç›–å·²æ’­å‡ºé›†æ•°ï¼Œå¹¶åœ¨ä¸‹æ–¹å†™å›ï¼‰
        season_metrics_map = {}
        try:
            cur.execute('SELECT tmdb_id, season_number, transferred_count, aired_count, total_count, updated_at FROM season_metrics')
            for tid, sn, tc, ac, tc2, ua in (cur.fetchall() or []):
                season_metrics_map[(int(tid), int(sn))] = {
                    'transferred_count': 0 if tc is None else int(tc),
                    'aired_count': 0 if ac is None else int(ac),
                    'total_count': 0 if tc2 is None else int(tc2),
                    'updated_at': 0 if ua is None else int(ua),
                }
        except Exception:
            season_metrics_map = {}

        # æ³¨å…¥åˆ°ä»»åŠ¡
        enriched = []
        for t in tasks_info:
            tmdb_id = t.get('match_tmdb_id') or ((t.get('calendar_info') or {}).get('match') or {}).get('tmdb_id')
            task_name = t.get('task_name') or t.get('taskname') or ''
            status = ''
            latest_sn = None
            latest_season_name = ''
            total_count = None
            transferred_count = None
            aired_count = None

            try:
                if tmdb_id and int(tmdb_id) in show_meta:
                    meta = show_meta[int(tmdb_id)]
                    status = meta.get('status') or ''
                    # ä»…ä½¿ç”¨ä»»åŠ¡åŒ¹é…åˆ°çš„å­£å·ï¼›æ— åŒ¹é…åˆ™ä¸è®¡ç®—è¯¥ä»»åŠ¡çš„å­£çº§æ•°æ®
                    season_no_to_use = None
                    try:
                        if t.get('matched_latest_season_number') is not None:
                            v = int(t.get('matched_latest_season_number'))
                            if v > 0:
                                season_no_to_use = v
                    except Exception:
                        season_no_to_use = None
                    if season_no_to_use is not None:
                        latest_sn = season_no_to_use
                        sm = season_meta.get((int(tmdb_id), latest_sn)) or {}
                        latest_season_name = sm.get('season_name') or ''
                        # ä¼˜å…ˆç”¨ season_metrics ä¸­ç¼“å­˜çš„ total/airï¼ˆæŒ‰åŒ¹é…å­£ï¼‰
                        _metrics = season_metrics_map.get((int(tmdb_id), latest_sn)) or {}
                        total_count = _metrics.get('total_count')
                        aired_count = _metrics.get('aired_count')
                        _updated_at = _metrics.get('updated_at')
                        # fallbackï¼šæ— ç¼“å­˜åˆ™ç”¨å³æ—¶è®¡ç®—ï¼ˆæŒ‰åŒ¹é…å­£ï¼‰
                        if total_count in (None, 0):
                            total_count = sm.get('episode_count')
                        # ä¸€è‡´æ€§å¼ºåŒ–ï¼šåœ¨â€œæœªåˆ°åˆ·æ–°æ—¶é—´â€æ—¶ï¼Œå§‹ç»ˆä½¿ç”¨æŒ‰æœ‰æ•ˆæ—¥æœŸç»Ÿè®¡çš„å€¼è¦†ç›–/æ ¡æ­£ç¼“å­˜ï¼Œ
                        # é¿å…å‡ºç°æå‰è®¡å…¥å½“æ—¥é›†æ•°çš„å±•ç¤ºåå·®
                        try:
                            _aired_effective = aired_by_show_season.get((int(tmdb_id), latest_sn))
                            if _aired_effective is not None:
                                if not allow_refresh:
                                    # åˆ·æ–°æ—¶é—´ä¹‹å‰ï¼šæ— æ¡ä»¶é‡‡ç”¨æœ‰æ•ˆæ—¥æœŸå£å¾„
                                    aired_count = _aired_effective
                                else:
                                    # åˆ·æ–°æ—¶é—´ä¹‹åï¼šè‹¥ç¼“å­˜ä¸ºéå½“æ—¥æˆ–ç¼ºå¤±ï¼Œåˆ™é‡‡ç”¨æœ‰æ•ˆæ—¥æœŸå£å¾„å›å¡«
                                    _ua_date = None
                                    if _updated_at:
                                        _ua_date = _dt.fromtimestamp(int(_updated_at)).strftime('%Y-%m-%d')
                                    if ((_ua_date is None) or (_ua_date != today)):
                                        aired_count = _aired_effective
                        except Exception:
                            pass
                        if aired_count in (None, 0):
                            aired_count = aired_by_show_season.get((int(tmdb_id), latest_sn))
                    else:
                        # æœªåŒ¹é…åˆ°å­£ï¼šä¸è®¡ç®—è¯¥ä»»åŠ¡çš„å­£çº§æ•°æ®
                        latest_sn = None
                        latest_season_name = ''
                        total_count = 0
                        aired_count = 0
            except Exception:
                pass

            if task_name in transferred_by_task:
                transferred_count = transferred_by_task[task_name]

            # å°†çŠ¶æ€æœ¬åœ°åŒ–ï¼šreturning_series ç”¨æœ¬åœ°å·²æ’­/æ€»é›†æ•°åˆ¤æ–­ï¼›å…¶ä½™é€šè¿‡ TMDBService çš„å•è¡¨æ˜ å°„
            try:
                raw = (status or '').strip()
                key = raw.lower().replace(' ', '_')
                if key == 'returning_series':
                    # æ–°è§„åˆ™ï¼šå­˜åœ¨ finale ç±»å‹ ä¸” å·²æ’­å‡ºé›†æ•° â‰¥ æœ¬å­£æ€»é›†æ•° => æœ¬å­£ç»ˆï¼›å¦åˆ™ æ’­å‡ºä¸­
                    has_finale = False
                    try:
                        if tmdb_id and latest_sn:
                            cur.execute(
                                """
                                SELECT 1 FROM episodes
                                WHERE tmdb_id=? AND season_number=? AND LOWER(COALESCE(type, '')) LIKE '%finale%'
                                LIMIT 1
                                """,
                                (int(tmdb_id), int(latest_sn))
                            )
                            has_finale = cur.fetchone() is not None
                    except Exception:
                        has_finale = False

                    try:
                        aired = int(aired_count or 0)
                        total = int(total_count or 0)
                    except Exception:
                        aired, total = 0, 0

                    status = 'æœ¬å­£ç»ˆ' if (has_finale and total > 0 and aired >= total) else 'æ’­å‡ºä¸­'
                else:
                    try:
                        # ä»…ç”¨åˆ°é™æ€æ˜ å°„ï¼Œä¸è§¦å‘ç½‘ç»œè¯·æ±‚
                        _svc = TMDBService(config_data.get('tmdb_api_key', ''), get_poster_language_setting())
                        status = _svc.map_show_status_cn(raw)
                    except Exception:
                        status = raw
            except Exception:
                pass

            t['matched_status'] = status
            t['latest_season_name'] = latest_season_name

            # åç«¯å…œåº•ï¼šå½“æ–‡ä»¶åæ— é›†åºå·ä½†å«æ—¥æœŸæ—¶ï¼Œå°è¯•ç”¨ tmdb_id + season + air_date æ¨å¯¼å·²è½¬å­˜é›†æ•°
            # è¿™æ ·ä¸å‰ç«¯å±•ç¤ºå£å¾„ä¸€è‡´ï¼Œé¿å…æŠŠ transferred_count è¯¯å†™ä¸º 0
            try:
                _effective_transferred = int(transferred_count or 0)
            except Exception:
                _effective_transferred = 0

            if (not _effective_transferred) and task_name and tmdb_id and latest_sn:
                try:
                    # å–æœ€è¿‘ä¸€æ¡è½¬å­˜è®°å½•çš„æ–‡ä»¶åï¼Œè§£æå‡ºæ—¥æœŸ
                    rdb2 = RecordDB()
                    cur2 = rdb2.conn.cursor()
                    cur2.execute(
                        """
                        SELECT MAX(transfer_time) as latest_transfer_time
                        FROM transfer_records
                        WHERE task_name = ? AND task_name NOT IN ('rename', 'undo_rename')
                        """,
                        (task_name,)
                    )
                    _row = cur2.fetchone()
                    _lt = _row[0] if _row else None
                    _best = None
                    if _lt:
                        cur2.execute(
                            """
                            SELECT renamed_to, original_name, transfer_time, modify_date
                            FROM transfer_records
                            WHERE task_name = ? AND transfer_time >= ? AND transfer_time <= ?
                            ORDER BY id DESC
                            """,
                            (task_name, _lt - 60000, _lt + 60000)
                        )
                        _files = cur2.fetchall() or []
                        if _files:
                            _best = _files[0][0]
                    rdb2.close()

                    if _best:
                        _name_wo_ext = os.path.splitext(_best)[0]
                        _processed = process_season_episode_info(_name_wo_ext, task_name)
                        _parsed = TaskExtractor().extract_progress_from_latest_file(_processed)
                        if _parsed and (not _parsed.get('episode_number')) and _parsed.get('air_date'):
                            _air_date = _parsed.get('air_date')
                            # ç”¨ tmdb_id + season + air_date æŸ¥æ‰¾å½“å¤©å¯¹åº”çš„æœ€å¤§é›†å·
                            cur.execute(
                                """
                                SELECT MAX(CAST(episode_number AS INTEGER))
                                FROM episodes
                                WHERE tmdb_id = ? AND season_number = ? AND air_date = ?
                                """,
                                (int(tmdb_id), int(latest_sn), _air_date)
                            )
                            _res = cur.fetchone()
                            if _res and _res[0] is not None:
                                _effective_transferred = int(_res[0])
                except Exception:
                    pass

            t['season_counts'] = {
                'transferred_count': _effective_transferred,
                'aired_count': aired_count or 0,
                'total_count': total_count or 0,
            }
            # å†™å› season_metricsï¼ˆä»¥è¯¥ä»»åŠ¡è‡ªèº«åŒ¹é…åˆ°çš„å­£å·ä¸ºé”®ï¼›æ— åŒ¹é…åˆ™è·³è¿‡ï¼‰
            try:
                if tmdb_id and latest_sn:
                    from time import time as _now
                    # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”ï¼šä»¥ min(aired, total) ä¸ºåˆ†æ¯ï¼›åˆ†æ¯<=0 åˆ™ä¸º 0
                    try:
                        _trans = int(_effective_transferred or 0)
                        _aired = int(aired_count or 0)
                        _total = int(total_count or 0)
                        denom = min(_aired, _total)
                        progress_pct = (100 * min(_trans, denom) // denom) if denom > 0 else 0
                    except Exception:
                        progress_pct = 0
                    CalendarDB().upsert_season_metrics(int(tmdb_id), int(latest_sn), int(_effective_transferred or 0), int(aired_count or 0), int(total_count or 0), int(progress_pct), int(_now()))
            except Exception:
                pass
            # å†™å› task_metricsï¼ˆä»¥ä»»åŠ¡ä¸ºé”®ï¼‰
            try:
                if task_name and tmdb_id and latest_sn:
                    from time import time as _now
                    # åŒä¸€å¥—ç™¾åˆ†æ¯”å£å¾„
                    try:
                        _trans = int(_effective_transferred or 0)
                        _aired = int(aired_count or 0)
                        _total = int(total_count or 0)
                        denom = min(_aired, _total)
                        progress_pct = (100 * min(_trans, denom) // denom) if denom > 0 else 0
                    except Exception:
                        progress_pct = 0
                    CalendarDB().upsert_task_metrics(task_name, int(tmdb_id), int(latest_sn), int(_effective_transferred or 0), int(progress_pct), int(_now()))
            except Exception:
                pass
            enriched.append(t)
        return enriched
    except Exception:
        return tasks_info

# å†…éƒ¨ï¼šæ ¹æ® task_name é‡æ–°è®¡ç®—è½¬å­˜è¿›åº¦ï¼Œå¹¶å†™å› metrics ä¸æ¨é€å˜æ›´
def recompute_task_metrics_and_notify(task_name: str) -> bool:
    try:
        if not task_name:
            return False
        rdb = RecordDB()
        cursor = rdb.conn.cursor()
        cursor.execute(
            """
            SELECT MAX(transfer_time) as latest_transfer_time
            FROM transfer_records
            WHERE task_name = ? AND task_name NOT IN ('rename', 'undo_rename')
            """,
            (task_name,)
        )
        row = cursor.fetchone()
        latest_time = row[0] if row else None
        latest_file = None
        if latest_time:
            time_window = 60000
            cursor.execute(
                """
                SELECT renamed_to, original_name, transfer_time, modify_date
                FROM transfer_records
                WHERE task_name = ? AND transfer_time >= ? AND transfer_time <= ?
                ORDER BY id DESC
                """,
                (task_name, latest_time - time_window, latest_time + time_window)
            )
            files = cursor.fetchall() or []
            if files:
                if len(files) == 1:
                    latest_file = files[0][0]
                else:
                    # é€€åŒ–ï¼šæŒ‰ id DESC å·²è¿‘ä¼¼æœ€æ–°ï¼Œå–ç¬¬ä¸€æ¡ renamed_to
                    latest_file = files[0][0]
        rdb.close()

        ep_no = None
        parsed_air_date = None
        if latest_file:
            try:
                extractor = TaskExtractor()
                parsed = extractor.extract_progress_from_latest_file((latest_file or '').split('.')[0])
                if parsed and parsed.get('episode_number') is not None:
                    ep_no = int(parsed.get('episode_number'))
                elif parsed and parsed.get('air_date'):
                    # æš‚å­˜æ—¥æœŸï¼Œå¾…è§£æå‡º tmdb_id ä¸ season åæ®æ­¤æ¨å¯¼é›†å·
                    parsed_air_date = parsed.get('air_date')
            except Exception:
                ep_no = None

        cal_db = CalendarDB()
        cur = cal_db.conn.cursor()
        # ä»…ä»ä»»åŠ¡é…ç½®è§£æ tmdb ä¸å­£å·ï¼šå¼ºåˆ¶è¦æ±‚ matched_latest_season_number å­˜åœ¨ï¼Œå¦åˆ™è§†ä¸ºæœªåŒ¹é…
        tmdb_id = None
        season_no = None
        try:
            tasks = (config_data or {}).get('tasklist', [])
        except Exception:
            tasks = []
        try:
            tgt = next((t for t in tasks if (t.get('taskname') or t.get('task_name') or '') == task_name), None)
        except Exception:
            tgt = None
        if tgt:
            try:
                match = ((tgt.get('calendar_info') or {}).get('match') or {})
            except Exception:
                match = {}
            # tmdb_id å¿…é¡»æ¥è‡ªåŒ¹é…ä¿¡æ¯
            try:
                if match.get('tmdb_id'):
                    tmdb_id = int(match.get('tmdb_id'))
            except Exception:
                tmdb_id = None
            # season ä»…ä½¿ç”¨ matched_latest_season_number
            try:
                if tgt.get('matched_latest_season_number') is not None:
                    v = int(tgt.get('matched_latest_season_number'))
                    if v > 0:
                        season_no = v
            except Exception:
                season_no = None
        # æœªåŒ¹é…åˆ™è·³è¿‡
        if tmdb_id is None or season_no is None or int(season_no) <= 0:
            return False

        from time import time as _now
        now_ts = int(_now())
        # è‹¥ä»…æœ‰æ—¥æœŸä½†æ— é›†å·ï¼Œå°è¯•ç”¨ tmdb_id + season + air_date æ¨å¯¼é›†å·
        if ep_no is None and parsed_air_date:
            try:
                cur.execute(
                    """
                    SELECT MAX(CAST(episode_number AS INTEGER))
                    FROM episodes
                    WHERE tmdb_id = ? AND season_number = ? AND air_date = ?
                    """,
                    (int(tmdb_id), int(season_no), parsed_air_date)
                )
                _row = cur.fetchone()
                if _row and _row[0] is not None:
                    ep_no = int(_row[0])
            except Exception:
                pass

        # æ›´æ–° task_metrics çš„ transferred_count
        if ep_no is not None:
            cal_db.upsert_task_metrics(task_name, tmdb_id, season_no, ep_no, None, now_ts)

        # è¯»å– season_metrics/æˆ–åŠ¨æ€è®¡ç®—ï¼Œå†™å› progress_pct
        try:
            # è·å– aired/total
            metrics = cal_db.get_season_metrics(tmdb_id, season_no) or {}
            aired = metrics.get('aired_count')
            total = metrics.get('total_count')
            if aired in (None, 0) or total in (None, 0):
                # åŠ¨æ€å›é€€ï¼šä½¿ç”¨æœ‰æ•ˆæ—¥æœŸè®¡ç®—å·²æ’­å‡ºé›†æ•°
                effective_date = get_effective_date_for_aired_count()
                cur.execute(
                    """
                    SELECT COUNT(1) FROM episodes
                    WHERE tmdb_id=? AND season_number=? AND air_date IS NOT NULL AND air_date != '' AND air_date <= ?
                    """,
                    (tmdb_id, season_no, effective_date)
                )
                aired = int((cur.fetchone() or [0])[0])
                cur.execute('SELECT episode_count FROM seasons WHERE tmdb_id=? AND season_number=?', (tmdb_id, season_no))
                row2 = cur.fetchone()
                total = int((row2 or [0])[0]) if row2 else 0
            trans = int(ep_no or 0)
            denom = min(int(aired or 0), int(total or 0))
            progress_pct = (100 * min(trans, denom) // denom) if denom > 0 else 0
            cal_db.upsert_season_metrics(tmdb_id, season_no, None, aired, total, progress_pct, now_ts)
            cal_db.upsert_task_metrics(task_name, tmdb_id, season_no, trans, progress_pct, now_ts)
        except Exception:
            pass

        try:
            notify_calendar_changed('transfer_update')
        except Exception:
            pass
        return True
    except Exception:
        return False


def register_metrics_sync_routes(app):
    @app.route('/api/calendar/metrics/sync_task', methods=['POST'])
    def api_sync_task_metrics():
        try:
            data = request.get_json(silent=True) or {}
            task_name = data.get('task_name') or request.args.get('task_name')
            ok = recompute_task_metrics_and_notify(task_name)
            return jsonify({'success': bool(ok)})
        except Exception as e:
            return jsonify({'success': False, 'message': str(e)})

def advanced_filter_files(file_list, filterwords):
    """
    é«˜çº§è¿‡æ»¤å‡½æ•°ï¼Œæ”¯æŒä¿ç•™è¯å’Œè¿‡æ»¤è¯
    
    Args:
        file_list: æ–‡ä»¶åˆ—è¡¨
        filterwords: è¿‡æ»¤è§„åˆ™å­—ç¬¦ä¸²ï¼Œæ”¯æŒä»¥ä¸‹æ ¼å¼ï¼š
            - "åŠ æ›´ï¼Œä¼åˆ’ï¼Œè¶…å‰ï¼Œ(1)ï¼Œmkvï¼Œnfo"  # åªæœ‰è¿‡æ»¤è¯
            - "æœŸ|åŠ æ›´ï¼Œä¼åˆ’ï¼Œè¶…å‰ï¼Œ(1)ï¼Œmkvï¼Œnfo"  # ä¿ç•™è¯|è¿‡æ»¤è¯
            - "æœŸï¼Œ2160P|åŠ æ›´ï¼Œä¼åˆ’ï¼Œè¶…å‰ï¼Œ(1)ï¼Œmkvï¼Œnfo"  # å¤šä¸ªä¿ç•™è¯(æˆ–å…³ç³»)|è¿‡æ»¤è¯
            - "æœŸ|2160P|åŠ æ›´ï¼Œä¼åˆ’ï¼Œè¶…å‰ï¼Œ(1)ï¼Œmkvï¼Œnfo"  # å¤šä¸ªä¿ç•™è¯(å¹¶å…³ç³»)|è¿‡æ»¤è¯
            - "æœŸï¼Œ2160P|"  # åªæœ‰ä¿ç•™è¯ï¼Œæ— è¿‡æ»¤è¯
    
    Returns:
        è¿‡æ»¤åçš„æ–‡ä»¶åˆ—è¡¨
    """
    if not filterwords or not filterwords.strip():
        return file_list
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«åˆ†éš”ç¬¦ |
    if '|' not in filterwords:
        # åªæœ‰è¿‡æ»¤è¯çš„æƒ…å†µ
        filterwords = filterwords.replace("ï¼Œ", ",")
        filterwords_list = [word.strip().lower() for word in filterwords.split(',') if word.strip()]
        
        filtered_files = []
        for file in file_list:
            file_name = file['file_name'].lower()
            file_ext = os.path.splitext(file_name)[1].lower().lstrip('.')
            
            # æ£€æŸ¥è¿‡æ»¤è¯æ˜¯å¦å­˜åœ¨äºæ–‡ä»¶åä¸­ï¼Œæˆ–è€…è¿‡æ»¤è¯ç­‰äºæ‰©å±•å
            if not any(word in file_name for word in filterwords_list) and not any(word == file_ext for word in filterwords_list):
                filtered_files.append(file)
        
        return filtered_files
    
    # åŒ…å«åˆ†éš”ç¬¦çš„æƒ…å†µï¼Œéœ€è¦è§£æä¿ç•™è¯å’Œè¿‡æ»¤è¯
    parts = filterwords.split('|')
    if len(parts) < 2:
        # æ ¼å¼é”™è¯¯ï¼Œè¿”å›åŸåˆ—è¡¨
        return file_list
    
    # æœ€åä¸€ä¸ª|åé¢çš„æ˜¯è¿‡æ»¤è¯
    filter_part = parts[-1].strip()
    # å‰é¢çš„éƒ½æ˜¯ä¿ç•™è¯
    keep_parts = [part.strip() for part in parts[:-1] if part.strip()]
    
    # è§£æè¿‡æ»¤è¯
    filterwords_list = []
    if filter_part:
        filter_part = filter_part.replace("ï¼Œ", ",")
        filterwords_list = [word.strip().lower() for word in filter_part.split(',') if word.strip()]
    
    # è§£æä¿ç•™è¯ï¼šæ¯ä¸ª|åˆ†éš”çš„éƒ¨åˆ†éƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ç­›é€‰æ¡ä»¶
    # è¿™äº›æ¡ä»¶éœ€è¦æŒ‰é¡ºåºä¾æ¬¡åº”ç”¨ï¼Œå½¢æˆé“¾å¼ç­›é€‰
    keep_conditions = []
    for part in keep_parts:
        if part.strip():
            if ',' in part or 'ï¼Œ' in part:
                # åŒ…å«é€—å·ï¼Œè¡¨ç¤ºæˆ–å…³ç³»
                part = part.replace("ï¼Œ", ",")
                or_words = [word.strip().lower() for word in part.split(',') if word.strip()]
                keep_conditions.append(("or", or_words))
            else:
                # ä¸åŒ…å«é€—å·ï¼Œè¡¨ç¤ºå•ä¸ªè¯
                keep_conditions.append(("single", [part.strip().lower()]))
    
    # ç¬¬ä¸€æ­¥ï¼šåº”ç”¨ä¿ç•™è¯ç­›é€‰ï¼ˆé“¾å¼ç­›é€‰ï¼‰
    if keep_conditions:
        for condition_type, words in keep_conditions:
            filtered_by_keep = []
            for file in file_list:
                file_name = file['file_name'].lower()
                
                if condition_type == "or":
                    # æˆ–å…³ç³»ï¼šåŒ…å«ä»»æ„ä¸€ä¸ªè¯å³å¯
                    if any(word in file_name for word in words):
                        filtered_by_keep.append(file)
                elif condition_type == "single":
                    # å•ä¸ªè¯ï¼šå¿…é¡»åŒ…å«
                    if words[0] in file_name:
                        filtered_by_keep.append(file)
            
            file_list = filtered_by_keep
    
    # ç¬¬äºŒæ­¥ï¼šåº”ç”¨è¿‡æ»¤è¯è¿‡æ»¤
    if filterwords_list:
        filtered_files = []
        for file in file_list:
            file_name = file['file_name'].lower()
            file_ext = os.path.splitext(file_name)[1].lower().lstrip('.')
            
            # æ£€æŸ¥è¿‡æ»¤è¯æ˜¯å¦å­˜åœ¨äºæ–‡ä»¶åä¸­ï¼Œæˆ–è€…è¿‡æ»¤è¯ç­‰äºæ‰©å±•å
            if not any(word in file_name for word in filterwords_list) and not any(word == file_ext for word in filterwords_list):
                filtered_files.append(file)
        
        return filtered_files
    
    return file_list


def process_season_episode_info(filename, task_name=None):
    """
    å¤„ç†æ–‡ä»¶åä¸­çš„å­£æ•°å’Œé›†æ•°ä¿¡æ¯

    Args:
        filename: æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        task_name: å¯é€‰çš„ä»»åŠ¡åç§°ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦å·²åŒ…å«å­£æ•°ä¿¡æ¯

    Returns:
        å¤„ç†åçš„æ˜¾ç¤ºåç§°
    """

    def task_contains_season_info(task_name):
        """
        åˆ¤æ–­ä»»åŠ¡åç§°ä¸­æ˜¯å¦åŒ…å«å­£æ•°ä¿¡æ¯
        """
        if not task_name:
            return False

        # æ¸…ç†ä»»åŠ¡åç§°ä¸­çš„è¿ç»­ç©ºæ ¼å’Œç‰¹æ®Šç¬¦å·
        clean_name = task_name.replace('\u3000', ' ').replace('\t', ' ')
        clean_name = re.sub(r'\s+', ' ', clean_name).strip()

        # åŒ¹é…å¸¸è§çš„å­£æ•°æ ¼å¼
        season_patterns = [
            r'^(.*?)[\s\.\-_]+S\d+$',  # é»‘é•œ - S07ã€æŠ˜è…°.S01ã€éŸ³ä½ è€Œæ¥-S02
            r'^(.*?)[\s\.\-_]+Season\s*\d+$',  # é»‘é•œ - Season 1
            r'^(.*?)\s+S\d+$',  # å¿«ä¹çš„å¤§äºº S02
            r'^(.*?)[\s\.\-_]+S\d+E\d+$',  # å¤„ç† S01E01 æ ¼å¼
            r'^(.*?)\s+ç¬¬\s*\d+\s*å­£$',  # å¤„ç† ç¬¬Nå­£ æ ¼å¼
            r'^(.*?)[\s\.\-_]+ç¬¬\s*\d+\s*å­£$',  # å¤„ç† - ç¬¬Nå­£ æ ¼å¼
            r'^(.*?)\s+ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åé›¶]+å­£$',  # å¤„ç† ç¬¬ä¸€å­£ã€ç¬¬äºŒå­£ æ ¼å¼
            r'^(.*?)[\s\.\-_]+ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åé›¶]+å­£$',  # å¤„ç† - ç¬¬ä¸€å­£ã€- ç¬¬äºŒå­£ æ ¼å¼
        ]

        for pattern in season_patterns:
            if re.match(pattern, clean_name, re.IGNORECASE):
                return True

        return False

    # åŒ¹é… SxxExx æ ¼å¼ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    # æ”¯æŒ S1E1, S01E01, s13e10, S100E1000 ç­‰æ ¼å¼
    season_episode_match = re.search(r'[Ss](\d+)[Ee](\d+)', filename)
    if season_episode_match:
        season = season_episode_match.group(1).zfill(2)  # ç¡®ä¿ä¸¤ä½æ•°
        episode = season_episode_match.group(2).zfill(2)  # ç¡®ä¿ä¸¤ä½æ•°

        # å¦‚æœä»»åŠ¡åç§°ä¸­å·²åŒ…å«å­£æ•°ä¿¡æ¯ï¼Œåªæ˜¾ç¤ºé›†æ•°
        if task_contains_season_info(task_name):
            return f"E{episode}"
        else:
            return f"S{season}E{episode}"

    # åŒ¹é…åªæœ‰ Exx æˆ– EPxx æ ¼å¼ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    # æ”¯æŒ E1, E01, EP1, EP01, e10, ep10, E1000 ç­‰æ ¼å¼
    episode_only_match = re.search(r'[Ee][Pp]?(\d+)', filename)
    if episode_only_match:
        episode = episode_only_match.group(1).zfill(2)  # ç¡®ä¿ä¸¤ä½æ•°
        return f"E{episode}"

    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°å­£æ•°é›†æ•°ä¿¡æ¯ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦å»é™¤ä¸ä»»åŠ¡åç§°ç›¸åŒçš„å‰ç¼€
    if task_name:
        task_name_clean = task_name.strip()

        # é¦–å…ˆå°è¯•å®Œæ•´ä»»åŠ¡ååŒ¹é…
        if filename.startswith(task_name_clean):
            # å»é™¤ä»»åŠ¡åå‰ç¼€
            remaining = filename[len(task_name_clean):].strip()

            # å¦‚æœå‰©ä½™éƒ¨åˆ†ä»¥å¸¸è§åˆ†éš”ç¬¦å¼€å¤´ï¼Œä¹Ÿå»é™¤åˆ†éš”ç¬¦
            separators = [' - ', ' Â· ', '.', '_', '-', ' ']
            for sep in separators:
                if remaining.startswith(sep):
                    remaining = remaining[len(sep):].strip()
                    break

            # å¦‚æœå‰©ä½™éƒ¨åˆ†ä¸ä¸ºç©ºï¼Œè¿”å›å‰©ä½™éƒ¨åˆ†ï¼›å¦åˆ™è¿”å›åŸæ–‡ä»¶å
            return remaining if remaining else filename

        # å¦‚æœå®Œæ•´ä»»åŠ¡åä¸åŒ¹é…ï¼Œå°è¯•æå–å‰§åéƒ¨åˆ†è¿›è¡ŒåŒ¹é…
        # åŒ¹é…å¸¸è§çš„å­£æ•°æ ¼å¼ï¼Œæå–å‰§åéƒ¨åˆ†
        season_patterns = [
            r'^(.*?)[\s\.\-_]+S\d+$',  # ä½ å¥½ï¼Œæ˜ŸæœŸå…­ - S04
            r'^(.*?)[\s\.\-_]+Season\s*\d+$',  # é»‘é•œ - Season 1
            r'^(.*?)\s+S\d+$',  # å¿«ä¹çš„å¤§äºº S02
            r'^(.*?)[\s\.\-_]+S\d+E\d+$',  # å¤„ç† S01E01 æ ¼å¼
            r'^(.*?)\s+ç¬¬\s*\d+\s*å­£$',  # å¤„ç† ç¬¬Nå­£ æ ¼å¼
            r'^(.*?)[\s\.\-_]+ç¬¬\s*\d+\s*å­£$',  # å¤„ç† - ç¬¬Nå­£ æ ¼å¼
            r'^(.*?)\s+ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åé›¶]+å­£$',  # å¤„ç† ç¬¬ä¸€å­£ã€ç¬¬äºŒå­£ æ ¼å¼
            r'^(.*?)[\s\.\-_]+ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åé›¶]+å­£$',  # å¤„ç† - ç¬¬ä¸€å­£ã€- ç¬¬äºŒå­£ æ ¼å¼
        ]

        for pattern in season_patterns:
            match = re.match(pattern, task_name_clean, re.IGNORECASE)
            if match:
                show_name = match.group(1).strip()
                # å»é™¤æœ«å°¾å¯èƒ½æ®‹ç•™çš„åˆ†éš”ç¬¦
                show_name = re.sub(r'[\s\.\-_]+$', '', show_name)

                # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦ä»¥å‰§åå¼€å¤´
                if filename.startswith(show_name):
                    # å»é™¤å‰§åå‰ç¼€
                    remaining = filename[len(show_name):].strip()

                    # å¦‚æœå‰©ä½™éƒ¨åˆ†ä»¥å¸¸è§åˆ†éš”ç¬¦å¼€å¤´ï¼Œä¹Ÿå»é™¤åˆ†éš”ç¬¦
                    separators = [' - ', ' Â· ', '.', '_', '-', ' ']
                    for sep in separators:
                        if remaining.startswith(sep):
                            remaining = remaining[len(sep):].strip()
                            break

                    # å¦‚æœå‰©ä½™éƒ¨åˆ†ä¸ä¸ºç©ºï¼Œè¿”å›å‰©ä½™éƒ¨åˆ†ï¼›å¦åˆ™è¿”å›åŸæ–‡ä»¶å
                    return remaining if remaining else filename

    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°å­£æ•°é›†æ•°ä¿¡æ¯ï¼Œä¸”æ²¡æœ‰æ‰¾åˆ°ç›¸åŒå‰ç¼€ï¼Œè¿”å›åŸæ–‡ä»¶å
    return filename

# å¯¼å…¥æ‹¼éŸ³æ’åºå·¥å…·
try:
    from utils.pinyin_sort import get_filename_pinyin_sort_key
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„å°å†™æ’åºä½œä¸ºå¤‡ç”¨
    def get_filename_pinyin_sort_key(filename):
        return filename.lower()

# å¯¼å…¥æ•°æ®åº“æ¨¡å—
try:
    # å…ˆå°è¯•ç›¸å¯¹å¯¼å…¥
    from sdk.db import RecordDB
except ImportError:
    try:
        # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ä»appåŒ…å¯¼å…¥
        from app.sdk.db import RecordDB
    except ImportError:
        # å¦‚æœæ²¡æœ‰æ•°æ®åº“æ¨¡å—ï¼Œå®šä¹‰ä¸€ä¸ªç©ºç±»
        class RecordDB:
            def __init__(self, *args, **kwargs):
                pass
            
            def get_records(self, *args, **kwargs):
                return {"records": [], "pagination": {"total_records": 0, "total_pages": 0, "current_page": 1, "page_size": 20}}

# å¯¼å…¥å·¥å…·å‡½æ•°
try:
    # å…ˆå°è¯•ç›¸å¯¹å¯¼å…¥
    from sdk.utils import format_bytes, get_file_icon, format_file_display
except ImportError:
    try:
        # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ä»appåŒ…å¯¼å…¥
        from app.sdk.utils import format_bytes, get_file_icon, format_file_display
    except ImportError:
        # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å®ç°æˆ–ä»quark_auto_saveå¯¼å…¥
        # format_byteså·²ä»quark_auto_saveå¯¼å…¥
        def get_file_icon(file_name, is_dir=False):
            return "ğŸ“„" if not is_dir else "ğŸ“"
            
        def format_file_display(prefix, icon, name):
            return f"{prefix}{icon} {name}"


def get_app_ver():
    BUILD_SHA = os.environ.get("BUILD_SHA", "")
    BUILD_TAG = os.environ.get("BUILD_TAG", "")
    if BUILD_TAG[:1] == "v":
        return BUILD_TAG
    elif BUILD_SHA:
        return f"{BUILD_TAG}({BUILD_SHA[:7]})"
    else:
        return "dev"


# æ–‡ä»¶è·¯å¾„
PYTHON_PATH = "python3" if os.path.exists("/usr/bin/python3") else "python"
SCRIPT_PATH = os.environ.get("SCRIPT_PATH", "./quark_auto_save.py")
CONFIG_PATH = os.environ.get("CONFIG_PATH", "./config/quark_config.json")
PLUGIN_FLAGS = os.environ.get("PLUGIN_FLAGS", "")
DEBUG = os.environ.get("DEBUG", "false").lower() == "true"
# ä»ç¯å¢ƒå˜é‡è·å–ç«¯å£ï¼Œé»˜è®¤ä¸º5005
PORT = int(os.environ.get("PORT", "5005"))

config_data = {}
task_plugins_config_default = {}

# æ–‡ä»¶åˆ—è¡¨ç¼“å­˜
file_list_cache = {}
cache_lock = Lock()

# é»˜è®¤æ€§èƒ½å‚æ•°ï¼ˆå¦‚æœé…ç½®ä¸­æ²¡æœ‰è®¾ç½®ï¼‰
DEFAULT_PERFORMANCE_CONFIG = {
    "api_page_size": 200,
    "cache_expire_time": 30
}

def get_performance_config():
    """è·å–æ€§èƒ½é…ç½®å‚æ•°"""
    try:
        if config_data and "file_performance" in config_data:
            perf_config = config_data["file_performance"]
            # ç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯æ•´æ•°ç±»å‹
            result = {}
            for key, default_value in DEFAULT_PERFORMANCE_CONFIG.items():
                try:
                    result[key] = int(perf_config.get(key, default_value))
                except (ValueError, TypeError):
                    result[key] = default_value
            return result
    except Exception as e:
        print(f"è·å–æ€§èƒ½é…ç½®å¤±è´¥: {e}")
    return DEFAULT_PERFORMANCE_CONFIG

def cleanup_expired_cache():
    """æ¸…ç†æ‰€æœ‰è¿‡æœŸç¼“å­˜"""
    current_time = time.time()
    perf_config = get_performance_config()
    cache_expire_time = perf_config.get("cache_expire_time", 30)

    with cache_lock:
        expired_keys = [k for k, (_, t) in file_list_cache.items() if current_time - t > cache_expire_time]
        for k in expired_keys:
            del file_list_cache[k]
        return len(expired_keys)

app = Flask(__name__)
app.config["APP_VERSION"] = get_app_ver()
app.secret_key = "ca943f6db6dd34823d36ab08d8d6f65d"
try:
    register_metrics_sync_routes(app)
except Exception:
    pass
app.config["SESSION_COOKIE_NAME"] = "QUARK_AUTO_SAVE_X_SESSION"
app.config["PERMANENT_SESSION_LIFETIME"] = timedelta(days=31)
app.json.ensure_ascii = False
app.json.sort_keys = False
app.jinja_env.variable_start_string = "[["
app.jinja_env.variable_end_string = "]]"

# æ³¨å†Œ AVIF MIME ç±»å‹ï¼Œç¡®ä¿é™æ€è·¯ç”±èƒ½æ­£ç¡®è¿”å› Content-Type
try:
    import mimetypes
    mimetypes.add_type('image/avif', '.avif')
except Exception:
    pass

# ---- Aired count safeguard: æç®€æŒ‰éœ€æ ¡æ­£ ----
def _aired_stamp_path():
    try:
        return os.path.abspath(os.path.join(app.root_path, '..', 'config', '.aired_done'))
    except Exception:
        return '.aired_done'

def _read_aired_effective_stamp():
    try:
        p = _aired_stamp_path()
        if os.path.exists(p):
            with open(p, 'r', encoding='utf-8') as f:
                return (f.read() or '').strip()
    except Exception:
        pass
    return ''

def _write_aired_effective_stamp(effective_date_str: str):
    try:
        p = _aired_stamp_path()
        with open(p, 'w', encoding='utf-8') as f:
            f.write(str(effective_date_str or ''))
    except Exception:
        pass

def ensure_today_aired_done_if_due_once(trigger_reason: str = ''):
    """ä»…åœ¨éœ€è¦æ—¶ã€ä¸”è‡³å¤šæ¯æ—¥ä¸€æ¬¡æŒ‰éœ€è¡¥ç®—ã€‚æ— å®šæ—¶è½®è¯¢ï¼Œæ— é«˜é¢‘æ£€æŸ¥ã€‚"""
    global _aired_on_demand_checked_date
    try:
        # è®¡ç®—å½“å‰åº”ç”Ÿæ•ˆçš„æœ‰æ•ˆæ—¥æœŸ
        current_effective = str(get_effective_date_for_aired_count())
        # è¿›ç¨‹å†…å·²æ£€æŸ¥è¿‡æœ¬æœ‰æ•ˆæœŸï¼Œç›´æ¥è·³è¿‡
        if _aired_on_demand_checked_date == current_effective:
            return
        # ä»…å½“å·²è¿‡åˆ·æ–°æ—¶é—´æ—¶æ‰å…è®¸è¡¥ç®—ï¼ˆé¿å…æå‰ï¼‰
        from datetime import datetime as _dt
        now = _dt.now()
        perf = config_data.get('performance', {}) if isinstance(config_data, dict) else {}
        time_str = perf.get('aired_refresh_time', '00:00')
        try:
            hh, mm = [int(x) for x in time_str.split(':')]
            allow = (now.hour > hh) or (now.hour == hh and now.minute >= mm)
        except Exception:
            allow = True
        if not allow:
            # æœªåˆ°åˆ·æ–°ç‚¹ï¼Œä¸åšä»»ä½•äº‹
            return
        # å·²è®°å½•çš„ä¸Šæ¬¡å®Œæˆæ—¥æœŸ
        stamped = _read_aired_effective_stamp()
        if stamped != current_effective:
            # éœ€è¦è¡¥ç®—ä¸€æ¬¡
            logging.debug(f"æ£€æµ‹åˆ°å½“æ—¥å°šæœªç”Ÿæ•ˆï¼ˆè§¦å‘:{trigger_reason or 'on_demand'}ï¼‰ï¼Œæ‰§è¡Œä¸€æ¬¡è¡¥å¿åˆ·æ–°â€¦")
            recompute_all_seasons_aired_daily()
            # æˆåŠŸå recompute å†…éƒ¨ä¼šå†™ stampï¼›æ­¤å¤„å°†è¿›ç¨‹å†…è®°ä¸ºå·²æ£€æŸ¥ï¼Œé¿å…å¤šæ¬¡è§¦å‘
            _aired_on_demand_checked_date = current_effective
        else:
            # å·²å®Œæˆï¼Œæ ‡è®°ä»Šæ—¥å·²æ£€æŸ¥ï¼Œé¿å…é‡å¤
            _aired_on_demand_checked_date = current_effective
    except Exception:
        pass


def _is_after_refresh_time(now_dt):
    try:
        perf = config_data.get('performance', {}) if isinstance(config_data, dict) else {}
        time_str = perf.get('aired_refresh_time', '00:00')
        hh, mm = [int(x) for x in time_str.split(':')]
        return (now_dt.hour > hh) or (now_dt.hour == hh and now_dt.minute >= mm)
    except Exception:
        return True

def _is_today_aired_done() -> bool:
    try:
        from datetime import datetime as _dt
        now = _dt.now()
        if not _is_after_refresh_time(now):
            return False
        current_effective = str(get_effective_date_for_aired_count())
        stamped = _read_aired_effective_stamp()
        return stamped == current_effective
    except Exception:
        return False


def _schedule_aired_retry_in(minutes_delay: int = 10):
    try:
        from datetime import datetime as _dt, timedelta as _td
        # ç§»é™¤å·²æœ‰çš„é‡è¯•ä»»åŠ¡ï¼Œé¿å…é‡å¤å †ç§¯
        try:
            scheduler.remove_job('daily_aired_retry')
        except Exception:
            pass
        run_at = _dt.now() + _td(minutes=max(1, int(minutes_delay)))
        scheduler.add_job(
            func=lambda: recompute_all_seasons_aired_daily(),
            trigger=DateTrigger(run_date=run_at),
            id='daily_aired_retry',
            replace_existing=True,
            coalesce=True,
            max_instances=1,
        )
        if scheduler.state == 0:
            scheduler.start()
        logging.debug(f"å·²å®‰æ’æ’­å‡ºé›†æ•°è¡¥å¿é‡è¯•ä»»åŠ¡ï¼Œæ—¶é—´ {run_at.strftime('%Y-%m-%d %H:%M')}" )
    except Exception as e:
        logging.warning(f"å®‰æ’æ’­å‡ºé›†æ•°è¡¥å¿é‡è¯•ä»»åŠ¡å¤±è´¥: {e}")

# æ˜¯å¦ä¸º Flask ä¸»æœåŠ¡è¿›ç¨‹ï¼ˆä»…è¯¥è¿›ç¨‹è¾“å‡ºæŸäº›æç¤ºï¼‰
IS_FLASK_SERVER_PROCESS = False

scheduler = BackgroundScheduler(
    job_defaults={
        # å…è®¸åœ¨ç³»ç»Ÿå”¤é†’åè¡¥å¿æ‰§è¡Œå…¨éƒ¨é”™è¿‡çš„ä»»åŠ¡
        "misfire_grace_time": None,
        # ä¼‘çœ æœŸé—´å³ä¾¿é”™è¿‡å¤šæ¬¡è§¦å‘ï¼Œä¹Ÿä»…è¡¥å¿æ‰§è¡Œä¸€æ¬¡ï¼Œé¿å…å †ç§¯
        "coalesce": True,
    }
)

# å®šæ—¶ä»»åŠ¡è¿›ç¨‹/çº¿ç¨‹è·Ÿè¸ªï¼šç”¨äºæ£€æµ‹å’Œæ¸…ç†æœªå®Œæˆçš„ä»»åŠ¡
_crontab_task_process = None  # å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡çš„è¿›ç¨‹å¯¹è±¡
_calendar_refresh_thread = None  # è¿½å‰§æ—¥å†è‡ªåŠ¨åˆ·æ–°çš„çº¿ç¨‹å¯¹è±¡
# è®°å½•æ¯æ—¥ä»»åŠ¡ä¸Šæ¬¡ç”Ÿæ•ˆçš„æ—¶é—´ï¼Œé¿å…é‡å¤æ—¥å¿—
_daily_aired_last_time_str = None
_calendar_refresh_last_interval = None
_last_crontab = None
_last_crontab_delay = None
_aired_on_demand_checked_date = None  # æœ¬è¿›ç¨‹å†…ï¼Œå½“å¤©æ˜¯å¦å·²è¿›è¡Œè¿‡ä¸€æ¬¡æŒ‰éœ€æ£€æŸ¥
logging.basicConfig(
    level=logging.DEBUG if DEBUG else logging.INFO,
    format="[%(asctime)s][%(levelname)s] %(message)s",
    datefmt="%m-%d %H:%M:%S",
)
# é™ä½ç¬¬ä¸‰æ–¹ç½‘ç»œåº“çš„é‡è¯•å™ªéŸ³ï¼šå°† urllib3/requests çš„æ—¥å¿—è°ƒä¸º ERRORï¼Œå¹¶æŠŠ"Retrying ..."æ¶ˆæ¯é™çº§ä¸º DEBUG
try:
    logging.getLogger("urllib3").setLevel(logging.ERROR)
    logging.getLogger("requests").setLevel(logging.ERROR)

    class _RetryWarningToDebug(logging.Filter):
        def filter(self, record: logging.LogRecord) -> bool:
            try:
                msg = str(record.getMessage())
                if "Retrying (Retry(" in msg or "Retrying (" in msg:
                    # å°†æ­¤æ¡è®°å½•çš„ç­‰çº§é™åˆ° DEBUG
                    record.levelno = logging.DEBUG
                    record.levelname = "DEBUG"
            except Exception:
                pass
            return True

    _urllib3_logger = logging.getLogger("urllib3.connectionpool")
    _urllib3_logger.addFilter(_RetryWarningToDebug())
except Exception:
    pass
# è¿‡æ»¤werkzeugæ—¥å¿—è¾“å‡º
if not DEBUG:
    logging.getLogger("werkzeug").setLevel(logging.ERROR)
    # é™éŸ³ APScheduler çš„æ™®é€šä¿¡æ¯æ—¥å¿—ï¼Œé¿å… "Adding job tentatively" ç­‰å™ªéŸ³
    try:
        logging.getLogger("apscheduler").setLevel(logging.WARNING)
    except Exception:
        pass

# ç»Ÿä¸€æ‰€æœ‰å·²æœ‰å¤„ç†å™¨ï¼ˆåŒ…æ‹¬ werkzeugã€apschedulerï¼‰çš„æ—¥å¿—æ ¼å¼
_root_logger = logging.getLogger()
_standard_formatter = logging.Formatter(
    fmt="[%(asctime)s][%(levelname)s] %(message)s",
    datefmt="%m-%d %H:%M:%S",
)
for _handler in list(_root_logger.handlers):
    try:
        _handler.setFormatter(_standard_formatter)
    except Exception:
        pass

for _name in ("werkzeug", "apscheduler", "gunicorn.error", "gunicorn.access"):
    _logger = logging.getLogger(_name)
    for _handler in list(_logger.handlers):
        try:
            _handler.setFormatter(_standard_formatter)
        except Exception:
            pass


# --------- æ¯æ—¥ä»»åŠ¡ï¼šåœ¨ç”¨æˆ·è®¾ç½®çš„åˆ·æ–°æ—¶é—´é‡ç®—æ‰€æœ‰å­£çš„å·²æ’­å‡ºé›†æ•°å¹¶æ›´æ–°è¿›åº¦ ---------
def recompute_all_seasons_aired_daily():
    logging.info(f">>> å¼€å§‹æ‰§è¡Œæ’­å‡ºé›†æ•°è‡ªåŠ¨åˆ·æ–°")
    try:
        from datetime import datetime as _dt
        from time import time as _now
        now_ts = int(_now())
        # è·å–åº”è¯¥ç”¨äºè®¡ç®—å·²æ’­å‡ºé›†æ•°çš„æœ‰æ•ˆæ—¥æœŸï¼ˆæ ¹æ®æ’­å‡ºé›†æ•°åˆ·æ–°æ—¶é—´ç¡®å®šï¼‰
        effective_date = get_effective_date_for_aired_count()
        cal_db = CalendarDB()
        cur = cal_db.conn.cursor()
        # éå†æœ¬åœ°æ‰€æœ‰å­£
        cur.execute('SELECT tmdb_id, season_number, episode_count FROM seasons')
        rows = cur.fetchall() or []
        for tmdb_id, season_no, total in rows:
            try:
                tmdb_id_i = int(tmdb_id)
                season_no_i = int(season_no)
                total_i = int(total or 0)
                # ä½¿ç”¨æœ‰æ•ˆæ—¥æœŸè®¡ç®—å·²æ’­å‡ºé›†æ•°
                cur.execute(
                    """
                    SELECT COUNT(1) FROM episodes
                    WHERE tmdb_id=? AND season_number=? AND air_date IS NOT NULL AND air_date != '' AND air_date <= ?
                    """,
                    (tmdb_id_i, season_no_i, effective_date)
                )
                aired_i = int((cur.fetchone() or [0])[0])
                # å–å·²è½¬å­˜é›†æ•°ç”¨äºè®¡ç®—è¿›åº¦
                metrics = cal_db.get_season_metrics(tmdb_id_i, season_no_i) or {}
                transferred_i = int(metrics.get('transferred_count') or 0)
                denom = min(int(aired_i or 0), int(total_i or 0))
                progress_pct = (100 * min(transferred_i, denom) // denom) if denom > 0 else 0
                # å†™å›ç¼“å­˜ï¼šä»…æ›´æ–° aired/total/progress_pct ä¸æ—¶é—´æˆ³
                cal_db.upsert_season_metrics(tmdb_id_i, season_no_i, None, aired_i, total_i, progress_pct, now_ts)
            except Exception:
                continue
        # æˆåŠŸåå†™å…¥å½“æ—¥å®Œæˆæ ‡è®°ï¼ˆä½¿ç”¨ stamp æ–‡ä»¶ï¼Œé¿å…å¼•å…¥ DB ç»“æ„å˜æ›´ï¼‰
        try:
            _write_aired_effective_stamp(str(effective_date))
        except Exception:
            pass
        try:
            notify_calendar_changed('daily_aired_update')
        except Exception:
            pass
        # éªŒè¯å½“æ—¥æ˜¯å¦å·²ç”Ÿæ•ˆï¼ŒæˆåŠŸåˆ™æ¸…ç†é‡è¯•ä»»åŠ¡ï¼›å¦åˆ™å®‰æ’ä¸‹ä¸€æ¬¡è¡¥å¿é‡è¯•
        try:
            if _is_today_aired_done():
                try:
                    scheduler.remove_job('daily_aired_retry')
                except Exception:
                    pass
            else:
                _schedule_aired_retry_in(10)
        except Exception:
            pass
        logging.info(f">>> æ’­å‡ºé›†æ•°è‡ªåŠ¨åˆ·æ–°æ‰§è¡ŒæˆåŠŸ")
    except Exception as e:
        logging.warning(f">>> æ’­å‡ºé›†æ•°è‡ªåŠ¨åˆ·æ–°æ‰§è¡Œå¼‚å¸¸: {e}")
        # å‘ç”Ÿå¼‚å¸¸ä¹Ÿå®‰æ’ä¸€æ¬¡è¡¥å¿é‡è¯•
        try:
            _schedule_aired_retry_in(10)
        except Exception:
            pass


def restart_daily_aired_update_job():
    try:
        global _daily_aired_last_time_str
        try:
            scheduler.remove_job('daily_aired_update')
        except Exception:
            pass
        # ä»é…ç½®è¯»å–åˆ·æ–°æ—¶é—´ï¼Œé»˜è®¤ 00:00
        perf = config_data.get('performance', {}) if isinstance(config_data, dict) else {}
        time_str = perf.get('aired_refresh_time', '00:00')
        # è§£ææ—¶é—´æ ¼å¼ HH:MM
        try:
            parts = time_str.split(':')
            if len(parts) == 2:
                hour = int(parts[0])
                minute = int(parts[1])
                if 0 <= hour <= 23 and 0 <= minute <= 59:
                    trigger = CronTrigger(hour=hour, minute=minute)
                else:
                    trigger = CronTrigger(hour=0, minute=0)
                    hour, minute = 0, 0
            else:
                trigger = CronTrigger(hour=0, minute=0)
                hour, minute = 0, 0
        except Exception:
            trigger = CronTrigger(hour=0, minute=0)
            hour, minute = 0, 0
        scheduler.add_job(
            recompute_all_seasons_aired_daily,
            trigger=trigger,
            id='daily_aired_update',
            replace_existing=True,
            coalesce=True,
            max_instances=1,
            misfire_grace_time=None
        )
        if scheduler.state == 0:
            scheduler.start()
        # å‹å¥½æç¤ºï¼šæ¯æ—¥ä»»åŠ¡å·²å¯åŠ¨ï¼ˆä»…åœ¨æ—¶é—´å˜åŒ–æ—¶è¾“å‡ºï¼Œä¸”ä»…åœ¨ Flask ä¸»è¿›ç¨‹ä¸­æ‰“å°ï¼Œé¿å…å­è¿›ç¨‹å™ªéŸ³ï¼‰
        try:
            if IS_FLASK_SERVER_PROCESS:
                _time_str = f"{hour:02d}:{minute:02d}"
                if _daily_aired_last_time_str != _time_str:
                    logging.info(f"å·²å¯åŠ¨æ’­å‡ºé›†æ•°è‡ªåŠ¨åˆ·æ–°ï¼Œæ—¶é—´ {_time_str}")
                    _daily_aired_last_time_str = _time_str
        except Exception:
            pass
    except Exception as e:
        logging.warning(f"å¯åŠ¨æ’­å‡ºé›†æ•°è‡ªåŠ¨åˆ·æ–°å¤±è´¥: {e}")


# åº”ç”¨å¯åŠ¨æ—¶æ³¨å†Œæ¯æ—¥ä»»åŠ¡
try:
    restart_daily_aired_update_job()
    # å¯åŠ¨æ—¶åšä¸€æ¬¡æç®€æŒ‰éœ€è¡¥å¿æ£€æŸ¥ï¼ˆä»…ä¸€æ¬¡ï¼‰
    ensure_today_aired_done_if_due_once('startup')
    # å–æ¶ˆä½é¢‘å¥åº·æ£€æŸ¥æ–¹æ¡ˆï¼Œæ”¹ä¸ºå¤±è´¥åæŒ‰éœ€é‡è¯•è°ƒåº¦
except Exception:
    pass

# ç¼“å­˜ç›®å½•ï¼šæ”¾åœ¨ /app/config/cache ä¸‹ï¼Œç”¨æˆ·æ— éœ€æ–°å¢æ˜ å°„
CACHE_DIR = os.path.abspath(os.path.join(app.root_path, '..', 'config', 'cache'))
CACHE_IMAGES_DIR = os.path.join(CACHE_DIR, 'images')
os.makedirs(CACHE_IMAGES_DIR, exist_ok=True)


# --------- è¿½å‰§æ—¥å†ï¼šSSE äº‹ä»¶ä¸­å¿ƒï¼Œç”¨äºå®æ—¶é€šçŸ¥å‰ç«¯ DB å˜åŒ– ---------
calendar_subscribers = set()

def notify_calendar_changed(reason: str = ""):
    try:
        for q in list(calendar_subscribers):
            try:
                q.put_nowait({'type': 'calendar_changed', 'reason': reason})
            except Exception:
                pass
    except Exception:
        pass

@app.route('/api/calendar/stream')
def calendar_stream():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    # åœ¨é¦–ä¸ªå»ºç«‹ SSE çš„å…¥å£å¤„è§¦å‘ä¸€æ¬¡æç®€æŒ‰éœ€æ£€æŸ¥ï¼ˆæ— éœ€å…¨å±€æ¯è¯·æ±‚æ£€æŸ¥ï¼‰
    try:
        ensure_today_aired_done_if_due_once('calendar_stream')
    except Exception:
        pass

    def event_stream():
        q = Queue()
        calendar_subscribers.add(q)
        try:
            # è¿æ¥å»ºç«‹åç«‹å³å‘ä¸€æ¡å¿ƒè·³ï¼Œä¾¿äºå‰ç«¯ç«‹åˆ»è§¦å‘ä¸€æ¬¡æ£€æŸ¥
            yield f"event: ping\n" f"data: connected\n\n"
            import time as _t
            last_heartbeat = _t.time()
            while True:
                try:
                    item = q.get(timeout=15)
                    yield f"event: calendar_changed\n" f"data: {json.dumps(item, ensure_ascii=False)}\n\n"
                except Exception:
                    # å¿ƒè·³
                    now = _t.time()
                    if now - last_heartbeat >= 15:
                        last_heartbeat = now
                        yield f"event: ping\n" f"data: keepalive\n\n"
        except GeneratorExit:
            pass
        finally:
            try:
                calendar_subscribers.discard(q)
            except Exception:
                pass

    return Response(stream_with_context(event_stream()), content_type='text/event-stream;charset=utf-8')

def gen_md5(string):
    md5 = hashlib.md5()
    md5.update(string.encode("utf-8"))
    return md5.hexdigest()


def get_login_token():
    username = config_data["webui"]["username"]
    password = config_data["webui"]["password"]
    return gen_md5(f"token{username}{password}+-*/")[8:24]


def is_login():
    login_token = get_login_token()
    if session.get("token") == login_token or request.args.get("token") == login_token:
        return True
    else:
        return False
DEFAULT_REFRESH_SECONDS = 21600



# è®¾ç½®icon åŠç¼“å­˜é™æ€æ˜ å°„
@app.route("/favicon.ico")
def favicon():
    return send_from_directory(
        os.path.join(app.root_path, "static", "images"),
        "favicon.ico",
        mimetype="image/vnd.microsoft.icon",
    )

# å°† /cache/images/* æ˜ å°„åˆ°å®¿ä¸»ç¼“å­˜ç›®å½•ï¼Œä¾›å‰ç«¯è®¿é—®
@app.route('/cache/images/<path:filename>')
def serve_cache_images(filename):
    resp = send_from_directory(CACHE_IMAGES_DIR, filename)
    try:
        # å¯ç”¨é•¿æœŸç¼“å­˜ï¼šä¾èµ–å‰ç«¯é€šè¿‡ `?t=` ç©¿é€å‚æ•°åœ¨å˜æ›´æ—¶åˆ·æ–°
        # è¯´æ˜ï¼šå›¾ç‰‡æ–‡ä»¶åç¨³å®šä¸”å†…å®¹ç¨³å®šï¼Œæ­£å¸¸æƒ…å†µåº”å‘½ä¸­æµè§ˆå™¨ç¼“å­˜ï¼›
        # å½“ç”¨æˆ·ä¸»åŠ¨æ›´æ¢æµ·æŠ¥æ—¶ï¼Œå‰ç«¯ä¼šä¸ºè¯¥èŠ‚ç›®ç”Ÿæˆæ–°çš„æ—¶é—´æˆ³å‚æ•°ï¼Œå½¢æˆæ–°çš„ URLï¼Œä»è€Œè§¦å‘é‡æ–°ä¸‹è½½ã€‚
        resp.headers['Cache-Control'] = 'public, max-age=31536000, immutable'
        # æ¸…ç†å¯èƒ½çš„å†å²å­—æ®µï¼ˆéƒ¨åˆ†ä»£ç†å¯èƒ½ä¿ç•™ï¼‰
        resp.headers.pop('Pragma', None)
        resp.headers.pop('Expires', None)
    except Exception:
        pass
    return resp


# ç™»å½•é¡µé¢
@app.route("/login", methods=["GET", "POST"])
def login():
    if request.method == "POST":
        username = config_data["webui"]["username"]
        password = config_data["webui"]["password"]
        input_username = request.form.get("username")
        input_password = request.form.get("password")
        
        # éªŒè¯ç”¨æˆ·åå’Œå¯†ç 
        if not input_username or not input_password:
            logging.info(">>> ç™»å½•å¤±è´¥ï¼šç”¨æˆ·åæˆ–å¯†ç ä¸ºç©º")
            return render_template("login.html", message="ç”¨æˆ·åå’Œå¯†ç ä¸èƒ½ä¸ºç©º")
        elif username != input_username:
            logging.info(f">>> ç™»å½•å¤±è´¥ï¼šç”¨æˆ·åé”™è¯¯ {input_username}")
            return render_template("login.html", message="ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")
        elif password != input_password:
            logging.info(f">>> ç”¨æˆ· {input_username} ç™»å½•å¤±è´¥ï¼šå¯†ç é”™è¯¯")
            return render_template("login.html", message="ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")
        else:
            logging.info(f">>> ç”¨æˆ· {username} ç™»å½•æˆåŠŸ")
            session.permanent = True
            session["token"] = get_login_token()
            return redirect(url_for("index"))

    if is_login():
        return redirect(url_for("index"))
    return render_template("login.html", error=None)


# é€€å‡ºç™»å½•
@app.route("/logout")
def logout():
    session.pop("token", None)
    return redirect(url_for("login"))


# ç®¡ç†é¡µé¢
@app.route("/")
def index():
    if not is_login():
        return redirect(url_for("login"))
    return render_template(
        "index.html", version=app.config["APP_VERSION"], plugin_flags=PLUGIN_FLAGS
    )


# å·²ç§»é™¤å›¾ç‰‡ä»£ç†é€»è¾‘ï¼ˆæµ‹è¯•ç‰ˆä¸å†éœ€è¦è·¨åŸŸä»£ç†ï¼‰


# è·å–é…ç½®æ•°æ®
@app.route("/data")
def get_data():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    data = Config.read_json(CONFIG_PATH)
    # ç¡®ä¿æœ‰ç§’çº§åˆ·æ–°é»˜è®¤å€¼ï¼ˆä¸åšè¿ç§»é€»è¾‘ï¼‰
    perf = data.get('performance') if isinstance(data, dict) else None
    if not isinstance(perf, dict):
        data['performance'] = {'calendar_refresh_interval_seconds': DEFAULT_REFRESH_SECONDS, 'aired_refresh_time': '00:00'}
    else:
        if 'calendar_refresh_interval_seconds' not in perf:
            data['performance']['calendar_refresh_interval_seconds'] = DEFAULT_REFRESH_SECONDS
        if 'aired_refresh_time' not in perf:
            data['performance']['aired_refresh_time'] = '00:00'
    
    # ç¡®ä¿æµ·æŠ¥è¯­è¨€æœ‰é»˜è®¤å€¼
    if 'poster_language' not in data:
        data['poster_language'] = 'zh-CN'

    # å¤„ç†æ’ä»¶é…ç½®ä¸­çš„å¤šè´¦å·æ”¯æŒå­—æ®µï¼Œå°†æ•°ç»„æ ¼å¼è½¬æ¢ä¸ºé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²ç”¨äºæ˜¾ç¤º
    if "plugins" in data:
        # å¤„ç†Plexçš„quark_root_path
        if "plex" in data["plugins"] and "quark_root_path" in data["plugins"]["plex"]:
            data["plugins"]["plex"]["quark_root_path"] = format_array_config_for_display(
                data["plugins"]["plex"]["quark_root_path"]
            )

        # å¤„ç†AListçš„storage_id
        if "alist" in data["plugins"] and "storage_id" in data["plugins"]["alist"]:
            data["plugins"]["alist"]["storage_id"] = format_array_config_for_display(
                data["plugins"]["alist"]["storage_id"]
            )

    # åˆå§‹åŒ–æ’ä»¶é…ç½®æ¨¡å¼ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if "plugin_config_mode" not in data:
        data["plugin_config_mode"] = {
            "aria2": "independent",
            "alist_strm_gen": "independent",
            "emby": "independent"
        }
    
    # åˆå§‹åŒ–å…¨å±€æ’ä»¶é…ç½®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if "global_plugin_config" not in data:
        data["global_plugin_config"] = {
            "aria2": {
                "auto_download": True,
                "pause": False,
                "auto_delete_quark_files": False
            },
            "alist_strm_gen": {
                "auto_gen": True
            },
            "emby": {
                "try_match": True,
                "media_id": ""
            }
        }

    # åˆå§‹åŒ–æ¨é€é€šçŸ¥ç±»å‹é…ç½®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if "push_notify_type" not in data:
        data["push_notify_type"] = "full"

    # åˆå§‹åŒ–TMDBé…ç½®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if "tmdb_api_key" not in data:
        data["tmdb_api_key"] = ""

    # åˆå§‹åŒ–æœç´¢æ¥æºé»˜è®¤ç»“æ„
    if "source" not in data or not isinstance(data.get("source"), dict):
        data["source"] = {}
    # CloudSaver é»˜è®¤å­—æ®µ
    data["source"].setdefault("cloudsaver", {"server": "", "username": "", "password": "", "token": ""})
    # PanSou é»˜è®¤å­—æ®µ
    data["source"].setdefault("pansou", {"server": "https://so.252035.xyz"})

    # å‘é€webuiä¿¡æ¯ï¼Œä½†ä¸å‘é€å¯†ç åŸæ–‡
    data["webui"] = {
        "username": config_data["webui"]["username"],
        "password": config_data["webui"]["password"]
    }
    data["api_token"] = get_login_token()
    data["task_plugins_config_default"] = task_plugins_config_default
    return jsonify({"success": True, "data": data})


def sync_task_plugins_config():
    """åŒæ­¥æ›´æ–°æ‰€æœ‰ä»»åŠ¡çš„æ’ä»¶é…ç½®
    
    1. æ£€æŸ¥æ¯ä¸ªä»»åŠ¡çš„æ’ä»¶é…ç½®
    2. å¦‚æœæ’ä»¶é…ç½®ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
    3. å¦‚æœæ’ä»¶é…ç½®å­˜åœ¨ä½†ç¼ºå°‘æ–°çš„é…ç½®é¡¹ï¼Œæ·»åŠ é»˜è®¤å€¼
    4. ä¿ç•™åŸæœ‰çš„è‡ªå®šä¹‰é…ç½®
    5. åªå¤„ç†å·²å¯ç”¨çš„æ’ä»¶ï¼ˆé€šè¿‡PLUGIN_FLAGSæ£€æŸ¥ï¼‰
    6. æ¸…ç†è¢«ç¦ç”¨æ’ä»¶çš„é…ç½®
    7. åº”ç”¨å…¨å±€æ’ä»¶é…ç½®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    """
    global config_data, task_plugins_config_default
    
    # å¦‚æœæ²¡æœ‰ä»»åŠ¡åˆ—è¡¨ï¼Œç›´æ¥è¿”å›
    if not config_data.get("tasklist"):
        return
        
    # è·å–ç¦ç”¨çš„æ’ä»¶åˆ—è¡¨
    disabled_plugins = set()
    if PLUGIN_FLAGS:
        disabled_plugins = {name.lstrip('-') for name in PLUGIN_FLAGS.split(',')}
    
    # è·å–æ’ä»¶é…ç½®æ¨¡å¼
    plugin_config_mode = config_data.get("plugin_config_mode", {})
    global_plugin_config = config_data.get("global_plugin_config", {})
        
    # éå†æ‰€æœ‰ä»»åŠ¡
    for task in config_data["tasklist"]:
        # ç¡®ä¿ä»»åŠ¡æœ‰additionå­—æ®µ
        if "addition" not in task:
            task["addition"] = {}
            
        # æ¸…ç†è¢«ç¦ç”¨æ’ä»¶çš„é…ç½®
        for plugin_name in list(task["addition"].keys()):
            if plugin_name in disabled_plugins:
                del task["addition"][plugin_name]
            
        # éå†æ‰€æœ‰æ’ä»¶çš„é»˜è®¤é…ç½®
        for plugin_name, default_config in task_plugins_config_default.items():
            # è·³è¿‡è¢«ç¦ç”¨çš„æ’ä»¶
            if plugin_name in disabled_plugins:
                continue
            
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨å…¨å±€é…ç½®æ¨¡å¼
            if plugin_name in plugin_config_mode and plugin_config_mode[plugin_name] == "global":
                # ä½¿ç”¨å…¨å±€é…ç½®
                if plugin_name in global_plugin_config:
                    task["addition"][plugin_name] = global_plugin_config[plugin_name].copy()
                else:
                    task["addition"][plugin_name] = default_config.copy()
            else:
                # ä½¿ç”¨ç‹¬ç«‹é…ç½®
                if plugin_name not in task["addition"]:
                    task["addition"][plugin_name] = default_config.copy()
                else:
                    # å¦‚æœä»»åŠ¡ä¸­æœ‰è¯¥æ’ä»¶çš„é…ç½®ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„é…ç½®é¡¹
                    current_config = task["addition"][plugin_name]
                    # ç¡®ä¿current_configæ˜¯å­—å…¸ç±»å‹
                    if not isinstance(current_config, dict):
                        # å¦‚æœä¸æ˜¯å­—å…¸ç±»å‹ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
                        task["addition"][plugin_name] = default_config.copy()
                        continue
                        
                    # éå†é»˜è®¤é…ç½®çš„æ¯ä¸ªé”®å€¼å¯¹
                    for key, default_value in default_config.items():
                        if key not in current_config:
                            current_config[key] = default_value


def parse_comma_separated_config(value):
    """è§£æé€—å·åˆ†éš”çš„é…ç½®å­—ç¬¦ä¸²ä¸ºæ•°ç»„"""
    if isinstance(value, str) and value.strip():
        # åˆ†å‰²å­—ç¬¦ä¸²ï¼Œå»é™¤ç©ºç™½å­—ç¬¦
        items = [item.strip() for item in value.split(',') if item.strip()]
        # å¦‚æœåªæœ‰ä¸€ä¸ªé¡¹ç›®ï¼Œè¿”å›å­—ç¬¦ä¸²ï¼ˆå‘åå…¼å®¹ï¼‰
        return items[0] if len(items) == 1 else items
    return value

def format_array_config_for_display(value):
    """å°†æ•°ç»„é…ç½®æ ¼å¼åŒ–ä¸ºé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²ç”¨äºæ˜¾ç¤º"""
    if isinstance(value, list):
        return ', '.join(value)
    return value

# æ›´æ–°æ•°æ®
@app.route("/update", methods=["POST"])
def update():
    global config_data
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    # ä¿å­˜å‰å…ˆè®°å½•æ—§ä»»åŠ¡åä¸å…¶ tmdb ç»‘å®šï¼Œç”¨äºè‡ªåŠ¨æ¸…ç†
    old_tasks = config_data.get("tasklist", [])
    old_task_map = {}
    for t in old_tasks:
        name = t.get("taskname") or t.get("task_name") or ""
        cal = (t.get("calendar_info") or {})
        match = (cal.get("match") or {})
        if name:
            old_task_map[name] = {
                "tmdb_id": match.get("tmdb_id") or cal.get("tmdb_id")
            }
    
    # è®°å½•æ—§çš„æµ·æŠ¥è¯­è¨€è®¾ç½®
    old_poster_language = config_data.get('poster_language', 'zh-CN')
    # è®°å½•æ—§çš„æ’­å‡ºé›†æ•°åˆ·æ–°æ—¶é—´è®¾ç½®
    old_perf = config_data.get('performance', {}) if isinstance(config_data, dict) else {}
    old_aired_refresh_time = old_perf.get('aired_refresh_time', '00:00')
    dont_save_keys = ["task_plugins_config_default", "api_token"]
    for key, value in request.json.items():
        if key not in dont_save_keys:
            if key == "webui":
                # æ›´æ–°webuiå‡­æ®
                config_data["webui"]["username"] = value.get("username", config_data["webui"]["username"])
                config_data["webui"]["password"] = value.get("password", config_data["webui"]["password"])
            elif key == "plugins":
                # å¤„ç†æ’ä»¶é…ç½®ä¸­çš„å¤šè´¦å·æ”¯æŒå­—æ®µ
                if "plex" in value and "quark_root_path" in value["plex"]:
                    value["plex"]["quark_root_path"] = parse_comma_separated_config(
                        value["plex"]["quark_root_path"]
                    )

                if "alist" in value and "storage_id" in value["alist"]:
                    value["alist"]["storage_id"] = parse_comma_separated_config(
                        value["alist"]["storage_id"]
                    )

                config_data.update({key: value})
            elif key == "tmdb_api_key":
                # æ›´æ–°TMDB APIå¯†é’¥
                config_data[key] = value
            else:
                config_data.update({key: value})
    
    # åŒæ­¥æ›´æ–°ä»»åŠ¡çš„æ’ä»¶é…ç½®
    sync_task_plugins_config()
    
    # ä¿å­˜é…ç½®çš„æ‰§è¡Œæ­¥éª¤ï¼Œå¼‚æ­¥æ‰§è¡Œ
    try:
        prev_tmdb = (config_data.get('tmdb_api_key') or '').strip()
        new_tmdb = None
        for key, value in request.json.items():
            if key == 'tmdb_api_key':
                new_tmdb = (value or '').strip()
                break
    except Exception:
        prev_tmdb, new_tmdb = '', None

    import threading
    def _post_update_tasks(old_task_map_snapshot, prev_tmdb_value, new_tmdb_value, old_poster_lang, old_aired_refresh_time_value):
        # æ£€æŸ¥æµ·æŠ¥è¯­è¨€è®¾ç½®æ˜¯å¦æ”¹å˜
        new_poster_language = config_data.get('poster_language', 'zh-CN')
        if old_poster_lang != new_poster_language:
            try:
                # æ¸…ç©ºç°æœ‰æµ·æŠ¥
                clear_all_posters()
                # é‡æ–°ä¸‹è½½æ‰€æœ‰æµ·æŠ¥
                redownload_all_posters()
            except Exception as e:
                logging.error(f"é‡æ–°ä¸‹è½½æµ·æŠ¥å¤±è´¥: {e}")
        
        # æ£€æŸ¥æ’­å‡ºé›†æ•°åˆ·æ–°æ—¶é—´æ˜¯å¦æ”¹å˜
        new_perf = config_data.get('performance', {}) if isinstance(config_data, dict) else {}
        new_aired_refresh_time = new_perf.get('aired_refresh_time', '00:00')
        if old_aired_refresh_time_value != new_aired_refresh_time:
            try:
                # ç«‹å³é‡æ–°è®¡ç®—æ‰€æœ‰å·²æ’­å‡ºé›†æ•°ï¼Œä½¿ç”¨æ–°çš„åˆ·æ–°æ—¶é—´è®¾ç½®
                recompute_all_seasons_aired_daily()
                # é€šçŸ¥å‰ç«¯æ—¥å†æ•°æ®å·²æ›´æ–°
                notify_calendar_changed('aired_refresh_time_changed')
                logging.info(f"æ’­å‡ºé›†æ•°åˆ·æ–°æ—¶é—´å·²æ›´æ”¹ ({old_aired_refresh_time_value} -> {new_aired_refresh_time})ï¼Œå·²é‡æ–°è®¡ç®—å·²æ’­å‡ºé›†æ•°")
            except Exception as e:
                logging.warning(f"é‡æ–°è®¡ç®—å·²æ’­å‡ºé›†æ•°å¤±è´¥: {e}")
        
        # åœ¨ä¿å­˜é…ç½®æ—¶è‡ªåŠ¨è¿›è¡Œä»»åŠ¡ä¿¡æ¯æå–ä¸TMDBåŒ¹é…ï¼ˆè‹¥ç¼ºå¤±åˆ™è¡¥é½ï¼‰
        try:
            changed = ensure_calendar_info_for_tasks()
        except Exception as e:
            logging.warning(f"ensure_calendar_info_for_tasks å‘ç”Ÿå¼‚å¸¸: {e}")

        # åœ¨æ¸…ç†é€»è¾‘ä¹‹å‰ï¼Œå…ˆåŒæ­¥æ•°æ®åº“ç»‘å®šå…³ç³»åˆ°ä»»åŠ¡é…ç½®
        try:
            sync_task_config_with_database_bindings()
        except Exception as e:
            logging.warning(f"åŒæ­¥ä»»åŠ¡é…ç½®å¤±è´¥: {e}")
        
        # åŒæ­¥å†…å®¹ç±»å‹æ•°æ®
        try:
            sync_content_type_between_config_and_database()
        except Exception as e:
            logging.warning(f"åŒæ­¥å†…å®¹ç±»å‹å¤±è´¥: {e}")

        # åŸºäºä»»åŠ¡å˜æ›´è¿›è¡Œè‡ªåŠ¨æ¸…ç†ï¼šåˆ é™¤çš„ä»»åŠ¡ã€æˆ– tmdb ç»‘å®šå˜æ›´çš„æ—§ç»‘å®š
        try:
            current_tasks = config_data.get('tasklist', [])
            current_map = {}
            for t in current_tasks:
                name = t.get('taskname') or t.get('task_name') or ''
                cal = (t.get('calendar_info') or {})
                match = (cal.get('match') or {})
                if name:
                    current_map[name] = {
                        'tmdb_id': match.get('tmdb_id') or cal.get('tmdb_id')
                    }
            # è¢«åˆ é™¤çš„ä»»åŠ¡
            for name, info in (old_task_map_snapshot or {}).items():
                if name not in current_map:
                    tid = info.get('tmdb_id')
                    if tid:
                        purge_calendar_by_tmdb_id_internal(int(tid))
            # ç»‘å®šå˜æ›´ï¼šæ—§ä¸æ–° tmdb_id ä¸åŒï¼Œæ¸…ç†æ—§çš„
            for name, info in (old_task_map_snapshot or {}).items():
                if name in current_map:
                    old_tid = info.get('tmdb_id')
                    new_tid = current_map[name].get('tmdb_id')
                    if old_tid and old_tid != new_tid:
                        purge_calendar_by_tmdb_id_internal(int(old_tid))
        except Exception as e:
            logging.warning(f"è‡ªåŠ¨æ¸…ç†æœ¬åœ°æ—¥å†ç¼“å­˜å¤±è´¥: {e}")

        # åŸºäºæœ€æ–°ä»»åŠ¡æ˜ å°„æ¸…ç†å­¤å„¿ metrics/seasonsï¼ˆé¿å…æ®‹ç•™ï¼‰
        try:
            tasks = config_data.get('tasklist', [])
            valid_names = []
            valid_pairs = []
            for t in tasks:
                name = t.get('taskname') or t.get('task_name') or ''
                cal = (t.get('calendar_info') or {})
                match = (cal.get('match') or {})
                tid = match.get('tmdb_id') or cal.get('tmdb_id')
                sn = match.get('latest_season_number') or cal.get('latest_season_number')
                if name:
                    valid_names.append(name)
                if tid and sn:
                    try:
                        valid_pairs.append((int(tid), int(sn)))
                    except Exception:
                        pass
            try:
                from app.sdk.db import CalendarDB as _CalDB
                _CalDB().cleanup_orphan_data(valid_pairs, valid_names)
            except Exception:
                pass
        except Exception as e:
            logging.warning(f"è‡ªåŠ¨æ¸…ç†å­¤å„¿å­£ä¸æŒ‡æ ‡å¤±è´¥: {e}")


        # æ ¹æ®æœ€æ–°æ€§èƒ½é…ç½®é‡å¯è‡ªåŠ¨åˆ·æ–°ä»»åŠ¡
        try:
            restart_calendar_refresh_job()
        except Exception as e:
            logging.warning(f"é‡å¯è¿½å‰§æ—¥å†è‡ªåŠ¨åˆ·æ–°ä»»åŠ¡å¤±è´¥: {e}")
        
        # æ ¹æ®æœ€æ–°æ€§èƒ½é…ç½®é‡å¯å·²æ’­å‡ºé›†æ•°æ›´æ–°ä»»åŠ¡
        try:
            restart_daily_aired_update_job()
        except Exception as e:
            logging.warning(f"é‡å¯å·²æ’­å‡ºé›†æ•°æ›´æ–°ä»»åŠ¡å¤±è´¥: {e}")

        # å¦‚æœ TMDB API ä»æ— åˆ°æœ‰ï¼Œè‡ªåŠ¨æ‰§è¡Œä¸€æ¬¡ bootstrap
        try:
            if (prev_tmdb_value == '' or prev_tmdb_value is None) and new_tmdb_value and new_tmdb_value != '':
                success, msg = do_calendar_bootstrap()
                logging.info(f"é¦–æ¬¡é…ç½® TMDB APIï¼Œè‡ªåŠ¨åˆå§‹åŒ–: {success}, {msg}")
            else:
                # è‹¥æ­¤æ¬¡æ›´æ–°äº§ç”Ÿäº†æ–°çš„åŒ¹é…ç»‘å®šï¼Œä¹Ÿæ‰§è¡Œä¸€æ¬¡è½»é‡åˆå§‹åŒ–ï¼Œç¡®ä¿å‰ç«¯èƒ½ç«‹åˆ»è¯»åˆ°æœ¬åœ°æ•°æ®
                try:
                    if 'changed' in locals() and changed:
                        # åªå¤„ç†æ–°å¢çš„ä»»åŠ¡ï¼Œä¸å¤„ç†æ‰€æœ‰ä»»åŠ¡
                        process_new_tasks_async()
                except Exception as _e:
                    logging.warning(f"é…ç½®æ›´æ–°è§¦å‘æ—¥å†åˆå§‹åŒ–å¤±è´¥: {_e}")
        except Exception as e:
            logging.warning(f"è‡ªåŠ¨åˆå§‹åŒ– bootstrap å¤±è´¥: {e}")

    threading.Thread(target=_post_update_tasks, args=(old_task_map, prev_tmdb, new_tmdb, old_poster_language, old_aired_refresh_time), daemon=True).start()
    
    # ç¡®ä¿æ€§èƒ½é…ç½®åŒ…å«ç§’çº§å­—æ®µ
    if not isinstance(config_data.get('performance'), dict):
        config_data['performance'] = {'calendar_refresh_interval_seconds': DEFAULT_REFRESH_SECONDS, 'aired_refresh_time': '00:00'}
    else:
        config_data['performance'].setdefault('calendar_refresh_interval_seconds', DEFAULT_REFRESH_SECONDS)
        config_data['performance'].setdefault('aired_refresh_time', '00:00')
    Config.write_json(CONFIG_PATH, config_data)
    # æ›´æ–°session tokenï¼Œç¡®ä¿å½“å‰ä¼šè¯åœ¨ç”¨æˆ·åå¯†ç æ›´æ”¹åä»ç„¶æœ‰æ•ˆ
    session["token"] = get_login_token()
    # é‡æ–°åŠ è½½ä»»åŠ¡
    if reload_tasks():
        # é€šçŸ¥å‰ç«¯ä»»åŠ¡æ•°æ®å·²æ›´æ–°ï¼Œè§¦å‘å†…å®¹ç®¡ç†é¡µé¢çƒ­æ›´æ–°
        try:
            notify_calendar_changed('task_updated')
        except Exception:
            pass
        
        # ç«‹å³å¯åŠ¨æ–°ä»»åŠ¡çš„å¼‚æ­¥å¤„ç†ï¼Œä¸ç­‰å¾…
        threading.Thread(target=process_new_tasks_async, daemon=True).start()
        
        logging.info(f">>> é…ç½®æ›´æ–°æˆåŠŸ")
        return jsonify({"success": True, "message": "é…ç½®æ›´æ–°æˆåŠŸ"})
    else:
        logging.info(f">>> é…ç½®æ›´æ–°å¤±è´¥")
        return jsonify({"success": False, "message": "é…ç½®æ›´æ–°å¤±è´¥"})


# å¤„ç†è¿è¡Œè„šæœ¬è¯·æ±‚
@app.route("/run_script_now", methods=["POST"])
def run_script_now():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    tasklist = request.json.get("tasklist", [])
    command = [PYTHON_PATH, "-u", SCRIPT_PATH, CONFIG_PATH]
    logging.info(
        f">>> å¼€å§‹æ‰§è¡Œæ‰‹åŠ¨è¿è¡Œä»»åŠ¡ [{tasklist[0].get('taskname') if len(tasklist)>0 else 'ALL'}]"
    )

    def generate_output():
        # å…¨å±€å˜é‡ï¼šè·Ÿè¸ªä¸Šä¸€æ¬¡è¾“å‡ºæ˜¯å¦æ˜¯ç©ºè¡Œ
        last_was_empty = False
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        process_env = os.environ.copy()
        process_env["PYTHONIOENCODING"] = "utf-8"
        if tasklist:
            process_env["TASKLIST"] = json.dumps(tasklist, ensure_ascii=False)
            # æ·»åŠ åŸå§‹ä»»åŠ¡ç´¢å¼•çš„ç¯å¢ƒå˜é‡
            if len(tasklist) == 1 and 'original_index' in request.json:
                process_env["ORIGINAL_TASK_INDEX"] = str(request.json['original_index'])
        process = subprocess.Popen(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            encoding="utf-8",
            errors="replace",
            bufsize=1,
            env=process_env,
        )
        try:
            for line in iter(process.stdout.readline, ""):
                stripped_line = line.strip()
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç©ºè¡Œ
                is_empty = not stripped_line
                
                # å¦‚æœæ˜¯ç©ºè¡Œä¸”ä¸Šä¸€æ¬¡ä¹Ÿæ˜¯ç©ºè¡Œï¼Œè·³è¿‡æœ¬æ¬¡è¾“å‡º
                if is_empty and last_was_empty:
                    continue
                
                # è¾“å‡ºæ—¥å¿—ï¼ˆç©ºè¡Œä¹Ÿè¾“å‡ºï¼Œä½†é¿å…è¿ç»­ç©ºè¡Œï¼‰
                if is_empty:
                    logging.info("")
                    last_was_empty = True
                else:
                    logging.info(stripped_line)
                    last_was_empty = False
                
                yield f"data: {line}\n\n"
            yield "data: [DONE]\n\n"
        finally:
            process.stdout.close()
            process.wait()
            # ç»“æŸé€šçŸ¥ï¼šä»…åœ¨æ­£å¸¸é€€å‡ºæ—¶è®°å½•æˆåŠŸæ—¥å¿—ï¼Œéé›¶é€€å‡ºç è®°å½•è­¦å‘Š
            try:
                task_name = tasklist[0].get('taskname') if len(tasklist) > 0 else 'ALL'
            except Exception:
                task_name = 'ALL'
            if process.returncode == 0:
                logging.info(f">>> æ‰‹åŠ¨è¿è¡Œä»»åŠ¡ [{task_name}] æ‰§è¡ŒæˆåŠŸ")
            else:
                logging.warning(f">>> æ‰‹åŠ¨è¿è¡Œä»»åŠ¡ [{task_name}] æ‰§è¡Œå®Œæˆä½†è¿”å›éé›¶é€€å‡ºç : {process.returncode}")

    return Response(
        stream_with_context(generate_output()),
        content_type="text/event-stream;charset=utf-8",
    )


# -------------------- è¿½å‰§æ—¥å†ï¼šä»»åŠ¡æå–ä¸åŒ¹é…è¾…åŠ© --------------------
def purge_calendar_by_tmdb_id_internal(tmdb_id: int, force: bool = False) -> bool:
    """å†…éƒ¨å·¥å…·ï¼šæŒ‰ tmdb_id æ¸…ç† shows/seasons/episodesï¼Œå¹¶å°è¯•åˆ é™¤æœ¬åœ°æµ·æŠ¥æ–‡ä»¶
    :param force: True æ—¶æ— è§†æ˜¯å¦ä»è¢«å…¶ä»–ä»»åŠ¡å¼•ç”¨ï¼Œå¼ºåˆ¶åˆ é™¤
    """
    try:
        # è‹¥ä»æœ‰å…¶ä»–ä»»åŠ¡å¼•ç”¨åŒä¸€ tmdb_idï¼Œåˆ™ï¼ˆé»˜è®¤ï¼‰è·³è¿‡åˆ é™¤ä»¥é¿å…è¯¯åˆ å…±äº«èµ„æºï¼›å¸¦ force åˆ™ç»§ç»­
        if not force:
            try:
                tasks = config_data.get('tasklist', [])
                for t in tasks:
                    cal = (t.get('calendar_info') or {})
                    match = (cal.get('match') or {})
                    bound = match.get('tmdb_id') or cal.get('tmdb_id')
                    if bound and int(bound) == int(tmdb_id):
                        # è·å–æµ·æŠ¥æ–‡ä»¶åç”¨äºæ—¥å¿—æç¤º
                        try:
                            db = CalendarDB()
                            show = db.get_show(int(tmdb_id))
                            poster_path = show.get('poster_local_path', '') if show else ''
                            if poster_path and poster_path.startswith('/cache/images/'):
                                poster_filename = poster_path.replace('/cache/images/', '')
                            else:
                                poster_filename = f"poster_{tmdb_id}"
                        except Exception:
                            poster_filename = f"poster_{tmdb_id}"
                        logging.debug(f"è·³è¿‡æ¸…ç†æµ·æŠ¥æ–‡ä»¶ {poster_filename}ï¼ˆä»è¢«å…¶ä»–ä»»åŠ¡å¼•ç”¨ï¼‰")
                        return True
            except Exception:
                pass
        db = CalendarDB()
        # åˆ é™¤æ•°æ®åº“å‰ï¼Œå°è¯•åˆ é™¤æœ¬åœ°æµ·æŠ¥æ–‡ä»¶
        try:
            show = db.get_show(int(tmdb_id))
            poster_rel = (show or {}).get('poster_local_path') or ''
            if poster_rel and poster_rel.startswith('/cache/images/'):
                fname = poster_rel.replace('/cache/images/', '')
                fpath = os.path.join(CACHE_IMAGES_DIR, fname)
                if os.path.exists(fpath):
                    os.remove(fpath)
        except Exception as e:
            logging.warning(f"åˆ é™¤æµ·æŠ¥æ–‡ä»¶å¤±è´¥: {e}")
        db.delete_show(int(tmdb_id))
        return True
    except Exception as e:
        logging.warning(f"å†…éƒ¨æ¸…ç†å¤±è´¥ tmdb_id={tmdb_id}: {e}")
        return False


def purge_orphan_calendar_shows_internal() -> int:
    """åˆ é™¤æœªè¢«ä»»ä½•ä»»åŠ¡å¼•ç”¨çš„ showsï¼ˆè¿å¸¦ seasons/episodes ä¸æµ·æŠ¥ï¼‰ï¼Œè¿”å›æ¸…ç†æ•°é‡"""
    try:
        tasks = config_data.get('tasklist', [])
        referenced = set()
        for t in tasks:
            cal = (t.get('calendar_info') or {})
            match = (cal.get('match') or {})
            tid = match.get('tmdb_id') or cal.get('tmdb_id')
            if tid:
                try: referenced.add(int(tid))
                except Exception: pass
        db = CalendarDB()
        cur = db.conn.cursor()
        try:
            cur.execute('SELECT tmdb_id FROM shows')
            ids = [int(r[0]) for r in cur.fetchall()]
        except Exception:
            ids = []
        removed = 0
        for tid in ids:
            if tid not in referenced:
                if purge_calendar_by_tmdb_id_internal(int(tid), force=True):
                    removed += 1
        return removed
    except Exception:
        return 0
def sync_content_type_between_config_and_database() -> bool:
    """åŒæ­¥ä»»åŠ¡é…ç½®å’Œæ•°æ®åº“ä¹‹é—´çš„å†…å®¹ç±»å‹æ•°æ®ã€‚
    ç¡®ä¿ä¸¤ä¸ªæ•°æ®æºçš„ content_type ä¿æŒä¸€è‡´ã€‚
    """
    try:
        from app.sdk.db import CalendarDB
        cal_db = CalendarDB()
        
        tasks = config_data.get('tasklist', [])
        changed = False
        synced_count = 0
        
        for task in tasks:
            task_name = task.get('taskname') or task.get('task_name') or ''
            if not task_name:
                continue
                
            # è·å–ä»»åŠ¡é…ç½®ä¸­çš„å†…å®¹ç±»å‹
            cal = task.get('calendar_info') or {}
            extracted = cal.get('extracted') or {}
            config_content_type = extracted.get('content_type', '')
            
            # é€šè¿‡ä»»åŠ¡åç§°æŸ¥æ‰¾ç»‘å®šçš„èŠ‚ç›®
            bound_show = cal_db.get_show_by_task_name(task_name)
            
            if bound_show:
                # ä»»åŠ¡å·²ç»‘å®šåˆ°æ•°æ®åº“ä¸­çš„èŠ‚ç›®
                tmdb_id = bound_show['tmdb_id']
                db_content_type = bound_show.get('content_type', '')
                
                # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰å†…å®¹ç±»å‹ï¼Œä½†ä»»åŠ¡é…ç½®ä¸­æœ‰ï¼Œåˆ™åŒæ­¥åˆ°æ•°æ®åº“
                if not db_content_type and config_content_type:
                    cal_db.update_show_content_type(tmdb_id, config_content_type)
                    changed = True
                    synced_count += 1
                    logging.debug(f"åŒæ­¥å†…å®¹ç±»å‹åˆ°æ•°æ®åº“ - ä»»åŠ¡: '{task_name}', ç±»å‹: '{config_content_type}', tmdb_id: {tmdb_id}")
                
                # è‹¥ä¸¤è¾¹ä¸ä¸€è‡´ï¼šä»¥ä»»åŠ¡é…ç½®ä¼˜å…ˆï¼ŒåŒæ­¥åˆ°æ•°æ®åº“
                elif db_content_type and config_content_type and db_content_type != config_content_type:
                    cal_db.update_show_content_type(tmdb_id, config_content_type)
                    changed = True
                    synced_count += 1
                    logging.debug(f"è¦†ç›–æ•°æ®åº“å†…å®¹ç±»å‹ä¸ºä»»åŠ¡é…ç½®å€¼ - ä»»åŠ¡: '{task_name}', é…ç½®: '{config_content_type}', åŸDB: '{db_content_type}', tmdb_id: {tmdb_id}")
                # å¦‚æœæ•°æ®åº“æœ‰ç±»å‹ä½†ä»»åŠ¡é…ç½®æ²¡æœ‰ï¼Œåˆ™å›å¡«åˆ°é…ç½®
                elif db_content_type and not config_content_type:
                    if 'calendar_info' not in task:
                        task['calendar_info'] = {}
                    if 'extracted' not in task['calendar_info']:
                        task['calendar_info']['extracted'] = {}
                    task['calendar_info']['extracted']['content_type'] = db_content_type
                    changed = True
                    synced_count += 1
                    logging.debug(f"åŒæ­¥å†…å®¹ç±»å‹åˆ°ä»»åŠ¡é…ç½® - ä»»åŠ¡: '{task_name}', ç±»å‹: '{db_content_type}', tmdb_id: {tmdb_id}")
            else:
                # ä»»åŠ¡æ²¡æœ‰ç»‘å®šåˆ°æ•°æ®åº“ä¸­çš„èŠ‚ç›®ï¼Œä½†ä»»åŠ¡é…ç½®ä¸­æœ‰å†…å®¹ç±»å‹
                # è¿™ç§æƒ…å†µéœ€è¦å…ˆé€šè¿‡ TMDB åŒ¹é…å»ºç«‹ç»‘å®šå…³ç³»ï¼Œç„¶ååŒæ­¥å†…å®¹ç±»å‹
                if config_content_type:
                    # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦æœ‰ TMDB åŒ¹é…ä¿¡æ¯
                    match = cal.get('match') or {}
                    tmdb_id = match.get('tmdb_id')
                    
                    if tmdb_id:
                        # ä»»åŠ¡æœ‰ TMDB åŒ¹é…ä¿¡æ¯ï¼Œæ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦æœ‰å¯¹åº”çš„èŠ‚ç›®
                        show = cal_db.get_show(tmdb_id)
                        if show:
                            # èŠ‚ç›®å­˜åœ¨ï¼Œå»ºç«‹ç»‘å®šå…³ç³»å¹¶è®¾ç½®å†…å®¹ç±»å‹
                            cal_db.bind_task_to_show(tmdb_id, task_name)
                            cal_db.update_show_content_type(tmdb_id, config_content_type)
                            changed = True
                            synced_count += 1
                            logging.debug(f"å»ºç«‹ç»‘å®šå…³ç³»å¹¶åŒæ­¥å†…å®¹ç±»å‹ - ä»»åŠ¡: '{task_name}', ç±»å‹: '{config_content_type}', tmdb_id: {tmdb_id}")
                        else:
                            logging.debug(f"ä»»åŠ¡é…ç½®ä¸­çš„ TMDB ID åœ¨æ•°æ®åº“ä¸­ä¸å­˜åœ¨ - ä»»åŠ¡: '{task_name}', tmdb_id: {tmdb_id}")
                    else:
                        logging.debug(f"ä»»åŠ¡æ—  TMDB åŒ¹é…ä¿¡æ¯ï¼Œæ— æ³•å»ºç«‹ç»‘å®šå…³ç³» - ä»»åŠ¡: '{task_name}'")
        
        if changed:
            logging.debug(f"å†…å®¹ç±»å‹åŒæ­¥å®Œæˆï¼Œå…±åŒæ­¥äº† {synced_count} ä¸ªä»»åŠ¡")
            Config.write_json(CONFIG_PATH, config_data)
            
        return changed
        
    except Exception as e:
        logging.debug(f"å†…å®¹ç±»å‹åŒæ­¥å¤±è´¥: {e}")
        return False

def sync_task_config_with_database_bindings() -> bool:
    """åŒå‘åŒæ­¥ä»»åŠ¡é…ç½®å’Œæ•°æ®åº“ä¹‹é—´çš„ TMDB åŒ¹é…ä¿¡æ¯ã€‚
    ç¡®ä¿ä¸¤ä¸ªæ•°æ®æºçš„ TMDB ç»‘å®šå…³ç³»ä¿æŒä¸€è‡´ã€‚
    """
    try:
        from app.sdk.db import CalendarDB
        cal_db = CalendarDB()
        
        tasks = config_data.get('tasklist', [])
        changed = False
        synced_count = 0
        
        for task in tasks:
            task_name = task.get('taskname') or task.get('task_name') or ''
            if not task_name:
                continue
                
            # è·å–ä»»åŠ¡é…ç½®ä¸­çš„ TMDB åŒ¹é…ä¿¡æ¯
            cal = task.get('calendar_info') or {}
            match = cal.get('match') or {}
            config_tmdb_id = match.get('tmdb_id')
            
            # é€šè¿‡ä»»åŠ¡åç§°æŸ¥æ‰¾æ•°æ®åº“ä¸­çš„ç»‘å®šå…³ç³»
            bound_show = cal_db.get_show_by_task_name(task_name)
            db_tmdb_id = bound_show['tmdb_id'] if bound_show else None
            
            # åŒå‘åŒæ­¥é€»è¾‘
            if config_tmdb_id and not db_tmdb_id:
                # ä»»åŠ¡é…ç½®ä¸­æœ‰ TMDB IDï¼Œä½†æ•°æ®åº“ä¸­æ²¡æœ‰ç»‘å®šå…³ç³» â†’ åŒæ­¥åˆ°æ•°æ®åº“
                # é¦–å…ˆæ£€æŸ¥è¯¥ TMDB ID å¯¹åº”çš„èŠ‚ç›®æ˜¯å¦å­˜åœ¨
                show = cal_db.get_show(config_tmdb_id)
                if show:
                    # èŠ‚ç›®å­˜åœ¨ï¼Œå»ºç«‹ç»‘å®šå…³ç³»
                    cal_db.bind_task_to_show(config_tmdb_id, task_name)
                    changed = True
                    synced_count += 1
                    logging.debug(f"åŒæ­¥ç»‘å®šå…³ç³»åˆ°æ•°æ®åº“ - ä»»åŠ¡: '{task_name}', tmdb_id: {config_tmdb_id}, èŠ‚ç›®: '{show.get('name', '')}'")
                else:
                    logging.debug(f"ä»»åŠ¡é…ç½®ä¸­çš„ TMDB ID åœ¨æ•°æ®åº“ä¸­ä¸å­˜åœ¨ - ä»»åŠ¡: '{task_name}', tmdb_id: {config_tmdb_id}")
                    
            elif db_tmdb_id and not config_tmdb_id:
                # æ•°æ®åº“ä¸­æœ‰ç»‘å®šå…³ç³»ï¼Œä½†ä»»åŠ¡é…ç½®ä¸­æ²¡æœ‰ TMDB ID â†’ åŒæ­¥åˆ°ä»»åŠ¡é…ç½®
                show = cal_db.get_show(db_tmdb_id)
                if show:
                    # ç¡®ä¿ calendar_info ç»“æ„å­˜åœ¨
                    if 'calendar_info' not in task:
                        task['calendar_info'] = {}
                    if 'match' not in task['calendar_info']:
                        task['calendar_info']['match'] = {}
                    
                    # åŒæ­¥æ•°æ®åº“ä¿¡æ¯åˆ°ä»»åŠ¡é…ç½®
                    latest_season_number = show.get('latest_season_number', 1)  # ä½¿ç”¨æ•°æ®åº“ä¸­çš„å®é™…å­£æ•°
                    task['calendar_info']['match'].update({
                        'tmdb_id': db_tmdb_id,
                        'matched_show_name': show.get('name', ''),
                        'matched_year': show.get('year', ''),
                        'latest_season_fetch_url': f"/tv/{db_tmdb_id}/season/{latest_season_number}",
                        'latest_season_number': latest_season_number
                    })
                    
                    changed = True
                    synced_count += 1
                    logging.debug(f"åŒæ­¥ TMDB åŒ¹é…ä¿¡æ¯åˆ°ä»»åŠ¡é…ç½® - ä»»åŠ¡: '{task_name}', tmdb_id: {db_tmdb_id}, èŠ‚ç›®: '{show.get('name', '')}'")
                    
            elif config_tmdb_id and db_tmdb_id and config_tmdb_id != db_tmdb_id:
                # ä¸¤ä¸ªæ•°æ®æºéƒ½æœ‰ TMDB IDï¼Œä½†ä¸ä¸€è‡´ â†’ ä»¥æ•°æ®åº“ä¸ºå‡†ï¼ˆå› ä¸ºæ•°æ®åº“æ˜¯æƒå¨æ•°æ®æºï¼‰
                show = cal_db.get_show(db_tmdb_id)
                if show:
                    # ç¡®ä¿ calendar_info ç»“æ„å­˜åœ¨
                    if 'calendar_info' not in task:
                        task['calendar_info'] = {}
                    if 'match' not in task['calendar_info']:
                        task['calendar_info']['match'] = {}
                    
                    # ä»¥æ•°æ®åº“ä¸ºå‡†ï¼Œæ›´æ–°ä»»åŠ¡é…ç½®
                    latest_season_number = show.get('latest_season_number', 1)  # ä½¿ç”¨æ•°æ®åº“ä¸­çš„å®é™…å­£æ•°
                    task['calendar_info']['match'].update({
                        'tmdb_id': db_tmdb_id,
                        'matched_show_name': show.get('name', ''),
                        'matched_year': show.get('year', ''),
                        'latest_season_fetch_url': f"/tv/{db_tmdb_id}/season/{latest_season_number}",
                        'latest_season_number': latest_season_number
                    })
                    
                    changed = True
                    synced_count += 1
                    logging.debug(f"ç»Ÿä¸€ TMDB åŒ¹é…ä¿¡æ¯ï¼ˆä»¥æ•°æ®åº“ä¸ºå‡†ï¼‰ - ä»»åŠ¡: '{task_name}', åŸé…ç½®: {config_tmdb_id}, æ•°æ®åº“: {db_tmdb_id}, èŠ‚ç›®: '{show.get('name', '')}'")
        
        if changed:
            logging.debug(f"TMDB åŒ¹é…ä¿¡æ¯åŒå‘åŒæ­¥å®Œæˆï¼Œå…±åŒæ­¥äº† {synced_count} ä¸ªä»»åŠ¡")
            Config.write_json(CONFIG_PATH, config_data)
            
        return changed
        
    except Exception as e:
        logging.debug(f"TMDB åŒ¹é…ä¿¡æ¯åŒæ­¥å¤±è´¥: {e}")
        return False

def ensure_calendar_info_for_tasks() -> bool:
    """ä¸ºæ‰€æœ‰ä»»åŠ¡ç¡®ä¿å­˜åœ¨ calendar_info.extracted ä¸ calendar_info.match ä¿¡æ¯ã€‚
    - extracted: ä»ä»»åŠ¡ä¿å­˜è·¯å¾„/åç§°æå–çš„å‰§åã€å¹´ä»½ã€ç±»å‹ï¼ˆåªåœ¨ç¼ºå¤±æ—¶æå–ï¼‰
    - match: ä½¿ç”¨ TMDB è¿›è¡ŒåŒ¹é…ï¼ˆåªåœ¨ç¼ºå¤±æ—¶åŒ¹é…ï¼‰
    """
    tasks = config_data.get('tasklist', [])
    if not tasks:
        return

    extractor = TaskExtractor()
    tmdb_api_key = config_data.get('tmdb_api_key', '')
    poster_language = get_poster_language_setting()
    tmdb_service = TMDBService(tmdb_api_key, poster_language) if tmdb_api_key else None

    changed = False
    # ç®€å•å»é‡ç¼“å­˜ï¼Œé¿å…åŒä¸€åç§°/å¹´ä»½é‡å¤è¯·æ±‚ TMDB
    search_cache = {}
    details_cache = {}
    for task in tasks:
        # è·³è¿‡æ ‡è®°ä¸ºæ— éœ€å‚ä¸æ—¥å†åŒ¹é…çš„ä»»åŠ¡
        if task.get('skip_calendar') is True:
            continue
        task_name = task.get('taskname') or task.get('task_name') or ''
        save_path = task.get('savepath', '')

        cal = task.get('calendar_info') or {}
        extracted = cal.get('extracted') or {}

        # æå– extractedï¼ˆä»…åœ¨ç¼ºå¤±æ—¶ï¼‰
        need_extract = not extracted or not extracted.get('show_name')
        if need_extract:
            info = extractor.extract_show_info_from_path(save_path)
            extracted = {
                'show_name': info.get('show_name', ''),
                'year': info.get('year', ''),
                'content_type': info.get('type', 'other'),
            }
            cal['extracted'] = extracted
            changed = True

        # åŒ¹é… TMDBï¼ˆä»…åœ¨ç¼ºå¤±æ—¶ï¼‰
        match = cal.get('match') or {}
        if tmdb_service and not match.get('tmdb_id') and extracted.get('show_name'):
            try:
                key = (extracted.get('show_name') or '', extracted.get('year') or '')
                if key in search_cache:
                    search = search_cache[key]
                else:
                    search = tmdb_service.search_tv_show(extracted.get('show_name'), extracted.get('year') or None)
                    search_cache[key] = search
                if search and search.get('id'):
                    tmdb_id = search['id']
                    if tmdb_id in details_cache:
                        details = details_cache[tmdb_id]
                    else:
                        details = tmdb_service.get_tv_show_details(tmdb_id) or {}
                        details_cache[tmdb_id] = details
                    seasons = details.get('seasons', [])
                    logging.debug(f"TMDBå­£æ•°æ•°æ®: {seasons}")
                    
                    # é€‰æ‹©å·²æ’­å‡ºçš„å­£ä¸­æœ€æ–°çš„ä¸€å­£
                    # ä½¿ç”¨æœ‰æ•ˆæ—¥æœŸåˆ¤æ–­å­£æ˜¯å¦å·²æ’­å‡ºï¼ˆè€ƒè™‘æ’­å‡ºé›†æ•°åˆ·æ–°æ—¶é—´ï¼‰
                    effective_date_str = get_effective_date_for_aired_count()
                    effective_date = datetime.strptime(effective_date_str, '%Y-%m-%d').date()
                    latest_season_number = 0
                    latest_air_date = None
                    
                    for s in seasons:
                        sn = s.get('season_number', 0)
                        air_date = s.get('air_date')
                        logging.debug(f"å­£æ•°: {sn}, æ’­å‡ºæ—¥æœŸ: {air_date}, ç±»å‹: {type(sn)}")
                        
                        # åªè€ƒè™‘å·²æ’­å‡ºçš„å­£ï¼ˆæœ‰air_dateä¸”æ—©äºæˆ–ç­‰äºæœ‰æ•ˆæ—¥æœŸï¼‰
                        if sn and sn > 0 and air_date:  # æ’é™¤ç¬¬0å­£ï¼ˆç‰¹æ®Šå­£ï¼‰
                            try:
                                season_air_date = datetime.strptime(air_date, '%Y-%m-%d').date()
                                if season_air_date <= effective_date:
                                    # é€‰æ‹©æ’­å‡ºæ—¥æœŸæœ€æ–°çš„å­£
                                    if latest_air_date is None or season_air_date > latest_air_date:
                                        latest_season_number = sn
                                        latest_air_date = season_air_date
                            except (ValueError, TypeError):
                                # æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè·³è¿‡
                                continue
                    
                    logging.debug(f"è®¡ç®—å‡ºçš„æœ€æ–°å·²æ’­å­£æ•°: {latest_season_number}")
                    
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å·²æ’­å‡ºçš„å­£ï¼Œå›é€€åˆ°ç¬¬1å­£
                    if latest_season_number == 0:
                        latest_season_number = 1
                        logging.debug(f"æ²¡æœ‰æ‰¾åˆ°å·²æ’­å‡ºçš„å­£ï¼Œå›é€€åˆ°ç¬¬1å­£: {latest_season_number}")

                    # ä½¿ç”¨æ–°çš„æ–¹æ³•è·å–ä¸­æ–‡æ ‡é¢˜ï¼Œæ”¯æŒä»åˆ«åä¸­è·å–ä¸­å›½åœ°åŒºçš„åˆ«å
                    chinese_title = tmdb_service.get_chinese_title_with_fallback(tmdb_id, extracted.get('show_name', ''))
                    
                    cal['match'] = {
                        'matched_show_name': chinese_title,
                        'matched_year': (details.get('first_air_date') or '')[:4],
                        'tmdb_id': tmdb_id,
                        'latest_season_number': latest_season_number,
                        'latest_season_fetch_url': f"/tv/{tmdb_id}/season/{latest_season_number}",
                    }
                    changed = True
            except Exception as e:
                logging.warning(f"TMDB åŒ¹é…å¤±è´¥: task={task_name}, err={e}")

        if cal and task.get('calendar_info') != cal:
            task['calendar_info'] = cal

    if changed:
        config_data['tasklist'] = tasks
    return changed


# åˆ·æ–°Plexåª’ä½“åº“
@app.route("/refresh_plex_library", methods=["POST"])
def refresh_plex_library():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    task_index = request.json.get("task_index")
    if task_index is None:
        return jsonify({"success": False, "message": "ç¼ºå°‘ä»»åŠ¡ç´¢å¼•"})
        
    # è·å–ä»»åŠ¡ä¿¡æ¯
    task = config_data["tasklist"][task_index]
    if not task.get("savepath"):
        return jsonify({"success": False, "message": "ä»»åŠ¡æ²¡æœ‰ä¿å­˜è·¯å¾„"})
        
    # å¯¼å…¥Plexæ’ä»¶
    from plugins.plex import Plex
    
    # åˆå§‹åŒ–Plexæ’ä»¶
    plex = Plex(**config_data["plugins"]["plex"])
    if not plex.is_active:
        return jsonify({"success": False, "message": "Plex æ’ä»¶æœªæ­£ç¡®é…ç½®"})
        
    # æ‰§è¡Œåˆ·æ–°
    plex.run(task)
    
    return jsonify({"success": True, "message": "æˆåŠŸåˆ·æ–° Plex åª’ä½“åº“"})


# åˆ·æ–°AListç›®å½•
@app.route("/refresh_alist_directory", methods=["POST"])
def refresh_alist_directory():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    task_index = request.json.get("task_index")
    if task_index is None:
        return jsonify({"success": False, "message": "ç¼ºå°‘ä»»åŠ¡ç´¢å¼•"})
        
    # è·å–ä»»åŠ¡ä¿¡æ¯
    task = config_data["tasklist"][task_index]
    if not task.get("savepath"):
        return jsonify({"success": False, "message": "ä»»åŠ¡æ²¡æœ‰ä¿å­˜è·¯å¾„"})
        
    # å¯¼å…¥AListæ’ä»¶
    from plugins.alist import Alist
    
    # åˆå§‹åŒ–AListæ’ä»¶
    alist = Alist(**config_data["plugins"]["alist"])
    if not alist.is_active:
        return jsonify({"success": False, "message": "AList æ’ä»¶æœªæ­£ç¡®é…ç½®"})
        
    # æ‰§è¡Œåˆ·æ–°
    alist.run(task)
    
    return jsonify({"success": True, "message": "æˆåŠŸåˆ·æ–° AList ç›®å½•"})


# æ–‡ä»¶æ•´ç†é¡µé¢åˆ·æ–°Plexåª’ä½“åº“
@app.route("/refresh_filemanager_plex_library", methods=["POST"])
def refresh_filemanager_plex_library():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    folder_path = request.json.get("folder_path")
    account_index = request.json.get("account_index", 0)

    if not folder_path:
        return jsonify({"success": False, "message": "ç¼ºå°‘æ–‡ä»¶å¤¹è·¯å¾„"})

    # æ£€æŸ¥Plexæ’ä»¶é…ç½®
    if not config_data.get("plugins", {}).get("plex", {}).get("url"):
        return jsonify({"success": False, "message": "Plex æ’ä»¶æœªé…ç½®"})

    # å¯¼å…¥Plexæ’ä»¶
    from plugins.plex import Plex

    # åˆå§‹åŒ–Plexæ’ä»¶
    plex = Plex(**config_data["plugins"]["plex"])
    if not plex.is_active:
        return jsonify({"success": False, "message": "Plex æ’ä»¶æœªæ­£ç¡®é…ç½®"})

    # è·å–å¤¸å…‹è´¦å·ä¿¡æ¯
    try:
        account = Quark(config_data["cookie"][account_index], account_index)

        # å°†æ–‡ä»¶å¤¹è·¯å¾„è½¬æ¢ä¸ºå®é™…çš„ä¿å­˜è·¯å¾„
        # folder_pathæ˜¯ç›¸å¯¹äºå¤¸å…‹ç½‘ç›˜æ ¹ç›®å½•çš„è·¯å¾„
        # quark_root_pathæ˜¯å¤¸å…‹ç½‘ç›˜åœ¨æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿä¸­çš„æŒ‚è½½ç‚¹
        # æ ¹æ®è´¦å·ç´¢å¼•è·å–å¯¹åº”çš„å¤¸å…‹æ ¹è·¯å¾„
        quark_root_path = plex.get_quark_root_path(account_index)
        if not quark_root_path:
            return jsonify({"success": False, "message": f"Plex æ’ä»¶æœªé…ç½®è´¦å· {account_index} çš„å¤¸å…‹æ ¹è·¯å¾„"})

        if folder_path == "" or folder_path == "/":
            # ç©ºå­—ç¬¦ä¸²æˆ–æ ¹ç›®å½•è¡¨ç¤ºå¤¸å…‹ç½‘ç›˜æ ¹ç›®å½•
            full_path = quark_root_path
        else:
            # ç¡®ä¿è·¯å¾„æ ¼å¼æ­£ç¡®
            if not folder_path.startswith("/"):
                folder_path = "/" + folder_path

            # æ‹¼æ¥å®Œæ•´è·¯å¾„ï¼šå¤¸å…‹æ ¹è·¯å¾„ + ç›¸å¯¹è·¯å¾„
            import os
            full_path = os.path.normpath(os.path.join(quark_root_path, folder_path.lstrip("/"))).replace("\\", "/")

        # ç¡®ä¿åº“ä¿¡æ¯å·²åŠ è½½
        if plex._libraries is None:
            plex._libraries = plex._get_libraries()

        # æ‰§è¡Œåˆ·æ–°
        success = plex.refresh(full_path)

        if success:
            return jsonify({"success": True, "message": "æˆåŠŸåˆ·æ–° Plex åª’ä½“åº“"})
        else:
            return jsonify({"success": False, "message": "åˆ·æ–° Plex åª’ä½“åº“å¤±è´¥ï¼Œè¯·æ£€æŸ¥è·¯å¾„é…ç½®"})

    except Exception as e:
        return jsonify({"success": False, "message": f"åˆ·æ–° Plex åª’ä½“åº“å¤±è´¥: {str(e)}"})


# æ–‡ä»¶æ•´ç†é¡µé¢åˆ·æ–°AListç›®å½•
@app.route("/refresh_filemanager_alist_directory", methods=["POST"])
def refresh_filemanager_alist_directory():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    folder_path = request.json.get("folder_path")
    account_index = request.json.get("account_index", 0)

    if not folder_path:
        return jsonify({"success": False, "message": "ç¼ºå°‘æ–‡ä»¶å¤¹è·¯å¾„"})

    # æ£€æŸ¥AListæ’ä»¶é…ç½®
    if not config_data.get("plugins", {}).get("alist", {}).get("url"):
        return jsonify({"success": False, "message": "AList æ’ä»¶æœªé…ç½®"})

    # å¯¼å…¥AListæ’ä»¶
    from plugins.alist import Alist

    # åˆå§‹åŒ–AListæ’ä»¶
    alist = Alist(**config_data["plugins"]["alist"])
    if not alist.is_active:
        return jsonify({"success": False, "message": "AList æ’ä»¶æœªæ­£ç¡®é…ç½®"})

    # è·å–å¤¸å…‹è´¦å·ä¿¡æ¯
    try:
        account = Quark(config_data["cookie"][account_index], account_index)

        # å°†æ–‡ä»¶å¤¹è·¯å¾„è½¬æ¢ä¸ºå®é™…çš„ä¿å­˜è·¯å¾„
        # folder_pathæ˜¯ç›¸å¯¹äºå¤¸å…‹ç½‘ç›˜æ ¹ç›®å½•çš„è·¯å¾„ï¼Œå¦‚ "/" æˆ– "/æµ‹è¯•/æ–‡ä»¶å¤¹"
        # æ ¹æ®è´¦å·ç´¢å¼•è·å–å¯¹åº”çš„å­˜å‚¨é…ç½®
        storage_mount_path, quark_root_dir = alist.get_storage_config(account_index)

        if not storage_mount_path or not quark_root_dir:
            return jsonify({"success": False, "message": f"AList æ’ä»¶æœªé…ç½®è´¦å· {account_index} çš„å­˜å‚¨ä¿¡æ¯"})

        if folder_path == "/":
            # æ ¹ç›®å½•ï¼Œç›´æ¥ä½¿ç”¨å¤¸å…‹æ ¹è·¯å¾„
            full_path = quark_root_dir
        else:
            # å­ç›®å½•ï¼Œæ‹¼æ¥è·¯å¾„
            import os
            # ç§»é™¤folder_pathå¼€å¤´çš„/ï¼Œç„¶åæ‹¼æ¥
            relative_path = folder_path.lstrip("/")
            if quark_root_dir == "/":
                full_path = "/" + relative_path
            else:
                full_path = os.path.normpath(os.path.join(quark_root_dir, relative_path)).replace("\\", "/")

        # æ£€æŸ¥è·¯å¾„æ˜¯å¦åœ¨å¤¸å…‹æ ¹ç›®å½•å†…
        if quark_root_dir == "/" or full_path.startswith(quark_root_dir):
            # ä½¿ç”¨è´¦å·å¯¹åº”çš„å­˜å‚¨é…ç½®æ˜ å°„åˆ°AListè·¯å¾„
            # æ„å»ºAListè·¯å¾„
            if quark_root_dir == "/":
                relative_path = full_path.lstrip("/")
            else:
                relative_path = full_path.replace(quark_root_dir, "", 1).lstrip("/")

            alist_path = os.path.normpath(
                os.path.join(storage_mount_path, relative_path)
            ).replace("\\", "/")

            # æ‰§è¡Œåˆ·æ–°
            alist.refresh(alist_path)
            return jsonify({"success": True, "message": "æˆåŠŸåˆ·æ–° AList ç›®å½•"})
        else:
            return jsonify({"success": False, "message": "è·¯å¾„ä¸åœ¨AListé…ç½®çš„å¤¸å…‹æ ¹ç›®å½•å†…"})

    except Exception as e:
        return jsonify({"success": False, "message": f"åˆ·æ–° AList ç›®å½•å¤±è´¥: {str(e)}"})


@app.route("/task_suggestions")
def get_task_suggestions():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    query = request.args.get("q", "").lower()
    deep = request.args.get("d", "").lower()
    
    # æå–å‰§åï¼Œå»é™¤å­£æ•°ä¿¡æ¯
    def extract_show_name(task_name):
        # æ¸…ç†ä»»åŠ¡åç§°ä¸­çš„è¿ç»­ç©ºæ ¼å’Œç‰¹æ®Šç¬¦å·
        clean_name = task_name.replace('\u3000', ' ').replace('\t', ' ')
        clean_name = re.sub(r'\s+', ' ', clean_name).strip()
        
        # åŒ¹é…å¸¸è§çš„å­£æ•°æ ¼å¼
        # ä¾‹å¦‚ï¼šé»‘é•œ - S07ã€äººç”Ÿè‹¥å¦‚åˆè§ - S01ã€æŠ˜è…°.S01ã€éŸ³ä½ è€Œæ¥-S02ã€å¿«ä¹çš„å¤§äºº S02
        season_patterns = [
            r'^(.*?)[\s\.\-_]+S\d+$',  # é»‘é•œ - S07ã€æŠ˜è…°.S01ã€éŸ³ä½ è€Œæ¥-S02
            r'^(.*?)[\s\.\-_]+Season\s*\d+$',  # é»‘é•œ - Season 1
            r'^(.*?)\s+S\d+$',  # å¿«ä¹çš„å¤§äºº S02
            r'^(.*?)[\s\.\-_]+S\d+E\d+$',  # å¤„ç† S01E01 æ ¼å¼
            r'^(.*?)\s+ç¬¬\s*\d+\s*å­£$',  # å¤„ç† ç¬¬Nå­£ æ ¼å¼
            r'^(.*?)[\s\.\-_]+ç¬¬\s*\d+\s*å­£$',  # å¤„ç† - ç¬¬Nå­£ æ ¼å¼
            r'^(.*?)\s+ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åé›¶]+å­£$',  # å¤„ç† ç¬¬ä¸€å­£ã€ç¬¬äºŒå­£ æ ¼å¼
            r'^(.*?)[\s\.\-_]+ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åé›¶]+å­£$',  # å¤„ç† - ç¬¬ä¸€å­£ã€- ç¬¬äºŒå­£ æ ¼å¼
        ]
        
        for pattern in season_patterns:
            match = re.match(pattern, clean_name, re.IGNORECASE)
            if match:
                show_name = match.group(1).strip()
                # å»é™¤æœ«å°¾å¯èƒ½æ®‹ç•™çš„åˆ†éš”ç¬¦
                show_name = re.sub(r'[\s\.\-_]+$', '', show_name)
                return show_name
                
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°å­£æ•°æ ¼å¼ï¼Œè¿”å›åŸåç§°
        return clean_name
    
    # å¤„ç†æœç´¢å…³é”®è¯ï¼Œæå–å‰§å
    search_query = extract_show_name(query)
    
    try:
        sources_cfg = config_data.get("source", {}) or {}
        cs_data = sources_cfg.get("cloudsaver", {})
        ps_data = sources_cfg.get("pansou", {})

        merged = []
        providers = []

        # CloudSaver
        if (
            cs_data.get("server")
            and cs_data.get("username")
            and cs_data.get("password")
        ):
            cs = CloudSaver(cs_data.get("server"))
            cs.set_auth(
                cs_data.get("username", ""),
                cs_data.get("password", ""),
                cs_data.get("token", ""),
            )
            search = cs.auto_login_search(search_query)
            if search.get("success"):
                if search.get("new_token"):
                    cs_data["token"] = search.get("new_token")
                    Config.write_json(CONFIG_PATH, config_data)
                search_results = cs.clean_search_results(search.get("data"))
                if isinstance(search_results, list):
                    # ä¸º CloudSaver ç»“æœè¡¥é½æ¥æºå­—æ®µ
                    for it in search_results:
                        try:
                            if not it.get("source"):
                                it["source"] = "CloudSaver"
                        except Exception:
                            pass
                    merged.extend(search_results)
                    providers.append("CloudSaver")

        # PanSou
        if ps_data and ps_data.get("server") and PanSou is not None:
            try:
                ps = PanSou(ps_data.get("server"))
                result = ps.search(search_query)
                if result.get("success") and isinstance(result.get("data"), list):
                    # ä¸º PanSou ç»“æœè¡¥é½æ¥æºå­—æ®µ
                    for it in result.get("data"):
                        try:
                            if not it.get("source"):
                                it["source"] = "PanSou"
                        except Exception:
                            pass
                    merged.extend(result.get("data"))
                    providers.append("PanSou")
            except Exception as e:
                logging.warning(f"PanSou æœç´¢å¤±è´¥: {str(e)}")

        # å»é‡å¹¶ç»Ÿä¸€æ—¶é—´å­—æ®µä¸º publish_date
        # è§„åˆ™ï¼š
        # 1) é¦–è½®ä»…æŒ‰ shareurl å½’å¹¶ï¼šåŒä¸€é“¾æ¥ä¿ç•™å‘å¸ƒæ—¶é—´æœ€æ–°çš„ä¸€æ¡ï¼ˆå±•ç¤ºä»¥è¯¥æ¡ä¸ºå‡†ï¼‰
        # 2) å…œåº•ï¼ˆæå°‘ï¼‰ï¼šæ— é“¾æ¥æ—¶æŒ‰å®Œæ•´æŒ‡çº¹ï¼ˆshareurl|title|date|sourceï¼‰å½’å¹¶
        # 3) äºŒæ¬¡å½’å¹¶ï¼šå¯¹æ‰€æœ‰å€™é€‰ç»“æœå†æŒ‰ æ ‡é¢˜+å‘å¸ƒæ—¶é—´ åšä¸€æ¬¡å½’å¹¶ï¼ˆæ— è®º shareurl æ˜¯å¦ç›¸åŒï¼‰ï¼Œå–æœ€æ–°
        # æ³¨æ„ï¼šå½“å‘ç”Ÿå½’å¹¶å†²çªæ—¶ï¼Œå§‹ç»ˆä¿ç•™å‘å¸ƒæ—¶é—´æœ€æ–°çš„è®°å½•
        dedup_map = {}          # æŒ‰ shareurl å½’å¹¶ï¼Œå€¼ä¸º {item, _sources:set}
        fingerprint_map = {}    # å…œåº•ï¼šå®Œæ•´æŒ‡çº¹å½’å¹¶ï¼ˆä»…å½“ç¼ºå¤±é“¾æ¥æ—¶ï¼‰ï¼ŒåŒä¸Š
        # è§„èŒƒåŒ–å·¥å…·
        def normalize_shareurl(url: str) -> str:
            try:
                if not url:
                    return ""
                u = url.strip()
                # ä»…å–å¤¸å…‹åˆ†äº«ID: pan.quark.cn/s/<id>[?...]
                # åŒæ—¶æ”¯æŒç›´æ¥ä¼ å…¥IDçš„æƒ…å†µ
                match = re.search(r"/s/([^\?/#\s]+)", u)
                if match:
                    return match.group(1)
                # å¦‚æœæ²¡æœ‰åŸŸåè·¯å¾„ï¼Œå°è¯•å»æ‰æŸ¥è¯¢å‚æ•°
                return u.split('?')[0]
            except Exception:
                return url or ""
        def normalize_title(title: str) -> str:
            try:
                if not title:
                    return ""
                import unicodedata
                t = unicodedata.normalize('NFKC', title)
                t = t.replace('\u3000', ' ').replace('\t', ' ')
                t = re.sub(r"\s+", " ", t).strip()
                return t
            except Exception:
                return title or ""
        def normalize_date(date_str: str) -> str:
            try:
                if not date_str:
                    return ""
                import unicodedata
                ds = unicodedata.normalize('NFKC', date_str).strip()
                return ds
            except Exception:
                return (date_str or "").strip()
        # è§£ææ—¶é—´ä¾›æ¯”è¾ƒ
        def to_ts(datetime_str):
            if not datetime_str:
                return 0
            try:
                s = str(datetime_str).strip()
                from datetime import datetime
                try:
                    return datetime.strptime(s, "%Y-%m-%d %H:%M:%S").timestamp()
                except Exception:
                    pass
                try:
                    return datetime.strptime(s, "%Y-%m-%d").timestamp()
                except Exception:
                    pass
                try:
                    s2 = s.replace('Z', '+00:00')
                    return datetime.fromisoformat(s2).timestamp()
                except Exception:
                    return 0
            except Exception:
                return 0

        for item in merged:
            if not isinstance(item, dict):
                continue
            # ç»Ÿä¸€æ—¶é—´å­—æ®µï¼šä¼˜å…ˆä½¿ç”¨å·²å­˜åœ¨çš„ publish_dateï¼Œå¦åˆ™ä½¿ç”¨ datetimeï¼Œå¹¶å†™å› publish_date
            try:
                if not item.get("publish_date") and item.get("datetime"):
                    item["publish_date"] = item.get("datetime")
            except Exception:
                pass

            shareurl = normalize_shareurl(item.get("shareurl") or "")
            title = normalize_title(item.get("taskname") or "")
            pubdate = normalize_date(item.get("publish_date") or "")
            source = (item.get("source") or "").strip()

            timestamp = to_ts(pubdate)

            # æ¡ä»¶1ï¼šæŒ‰ shareurl å½’å¹¶ï¼Œå–æœ€æ–°
            if shareurl:
                existed = dedup_map.get(shareurl)
                if not existed or to_ts(existed["item"].get("publish_date")) < timestamp:
                    dedup_map[shareurl] = {"item": item, "_sources": set([src for src in [source] if src])}
                else:
                    # æ›´æ–°æ—¶é—´è¾ƒæ—§ä½†æ¥æºéœ€è¦åˆå¹¶
                    try:
                        if source:
                            existed["_sources"].add(source)
                    except Exception:
                        pass
            else:
                # æ¡ä»¶2ï¼ˆå…œåº•ï¼‰ï¼šå®Œæ•´æŒ‡çº¹å½’å¹¶ï¼ˆæå°‘å‘ç”Ÿï¼‰ï¼Œä¾ç„¶å–æœ€æ–°
                fingerprint = f"{shareurl}|{title}|{pubdate}|{source}"
                existed = fingerprint_map.get(fingerprint)
                if not existed or to_ts(existed["item"].get("publish_date")) < timestamp:
                    fingerprint_map[fingerprint] = {"item": item, "_sources": set([src for src in [source] if src])}
                else:
                    try:
                        if source:
                            existed["_sources"].add(source)
                    except Exception:
                        pass

        # ç¬¬ä¸€è½®ï¼šæ±‡æ€»å½’å¹¶åçš„å€™é€‰ç»“æœ
        candidates = list(dedup_map.values()) + list(fingerprint_map.values())

        # ç¬¬äºŒè½®ï¼šæ— è®º shareurl æ˜¯å¦ç›¸åŒï¼Œå†æŒ‰ æ ‡é¢˜+å‘å¸ƒæ—¶é—´ å½’å¹¶ä¸€æ¬¡ï¼ˆä½¿ç”¨æ—¶é—´æˆ³ä½œä¸ºé”®ï¼Œå…¼å®¹ä¸åŒæ—¶é—´æ ¼å¼ï¼‰ï¼Œä¿ç•™æœ€æ–°
        final_map = {}
        for pack in candidates:
            try:
                item = pack.get("item") if isinstance(pack, dict) else pack
                src_set = pack.get("_sources") if isinstance(pack, dict) else set([ (item.get("source") or "").strip() ])
                t = normalize_title(item.get("taskname") or "")
                d = normalize_date(item.get("publish_date") or "")
                s = normalize_shareurl(item.get("shareurl") or "")
                src = (item.get("source") or "").strip()
                # ä¼˜å…ˆé‡‡ç”¨ æ ‡é¢˜+æ—¶é—´ ä½œä¸ºå½’å¹¶é”®
                ts_val = to_ts(d)
                if t and ts_val:
                    key = f"TD::{t}||{int(ts_val)}"
                elif s:
                    key = f"URL::{s}"
                else:
                    key = f"FP::{s}|{t}|{d}|{src}"
                existed = final_map.get(key)
                current_ts = to_ts(item.get("publish_date"))
                if not existed:
                    # åˆæ¬¡æ”¾å…¥æ—¶å¸¦ä¸Šæ¥æºé›†åˆ
                    item_copy = dict(item)
                    item_copy["_sources"] = set([*list(src_set)])
                    final_map[key] = item_copy
                else:
                    existed_ts = to_ts(existed.get("publish_date"))
                    if current_ts > existed_ts:
                        item_copy = dict(item)
                        # ç»§æ‰¿æ—§æ¥æºå¹¶åˆå¹¶æ–°æ¥æº
                        merged_sources = set(list(existed.get("_sources") or set()))
                        for ssrc in list(src_set):
                            if ssrc:
                                merged_sources.add(ssrc)
                        item_copy["_sources"] = merged_sources
                        final_map[key] = item_copy
                    elif current_ts == existed_ts:
                        # æ—¶é—´å®Œå…¨ç›¸åŒï¼Œä½¿ç”¨ç¡®å®šæ€§ä¼˜å…ˆçº§æ‰“ç ´å¹³æ‰‹
                        source_priority = {"CloudSaver": 2, "PanSou": 1}
                        existed_pri = source_priority.get((existed.get("source") or "").strip(), 0)
                        current_pri = source_priority.get(src, 0)
                        # æ— è®ºè°èƒœå‡ºï¼Œéƒ½è¦åˆå¹¶æ¥æºé›†åˆ
                        if current_pri > existed_pri:
                            item_copy = dict(item)
                            merged_sources = set(list(existed.get("_sources") or set()))
                            for ssrc in list(src_set):
                                if ssrc:
                                    merged_sources.add(ssrc)
                            item_copy["_sources"] = merged_sources
                            final_map[key] = item_copy
                        elif current_pri == existed_pri:
                            # è¿›ä¸€æ­¥æ¯”è¾ƒä¿¡æ¯ä¸°å¯Œåº¦ï¼ˆcontent é•¿åº¦ï¼‰
                            if len(str(item.get("content") or "")) > len(str(existed.get("content") or "")):
                                item_copy = dict(item)
                                # åˆå¹¶æ¥æº
                                merged_sources = set(list(existed.get("_sources") or set()))
                                for ssrc in list(src_set):
                                    if ssrc:
                                        merged_sources.add(ssrc)
                                item_copy["_sources"] = merged_sources
                                final_map[key] = item_copy
                            else:
                                # å³ä¾¿ä¸æ›¿æ¢ä¸»ä½“ï¼Œä¹Ÿåˆå¹¶æ¥æº
                                try:
                                    merged_sources = set(list(existed.get("_sources") or set()))
                                    for ssrc in list(src_set):
                                        if ssrc:
                                            merged_sources.add(ssrc)
                                    existed["_sources"] = merged_sources
                                except Exception:
                                    pass
            except Exception:
                # å‡ºç°å¼‚å¸¸åˆ™è·³è¿‡è¯¥é¡¹
                continue

        # è¾“å‡ºå‰ï¼šå°†æ¥æºé›†åˆå‹ç¼©ä¸ºå±•ç¤ºå­—ç¬¦ä¸²
        dedup = []
        for v in final_map.values():
            try:
                srcs = sorted([s for s in list(v.get("_sources") or []) if s])
                v.pop("_sources", None)
                if srcs:
                    v["source"] = " Â· ".join(srcs)
                dedup.append(v)
            except Exception:
                dedup.append(v)

        # ä»…åœ¨æ’åºæ—¶å¯¹å¤šç§æ ¼å¼è¿›è¡Œè§£æï¼ˆä¼˜å…ˆè§£æ YYYY-MM-DD HH:mm:ssï¼Œå…¶æ¬¡ ISOï¼‰
        if dedup:
            def parse_datetime_for_sort(item):
                """è§£ææ—¶é—´å­—æ®µï¼Œè¿”å›å¯æ¯”è¾ƒçš„æ—¶é—´æˆ³ï¼ˆç»Ÿä¸€ä»¥ publish_date ä¸ºå‡†ï¼‰"""
                datetime_str = item.get("publish_date")
                if not datetime_str:
                    return 0  # æ²¡æœ‰æ—¶é—´çš„æ’åœ¨æœ€å
                from datetime import datetime
                s = str(datetime_str).strip()
                # ä¼˜å…ˆè§£ææ ‡å‡†æ˜¾ç¤ºæ ¼å¼
                try:
                    dt = datetime.strptime(s, "%Y-%m-%d %H:%M:%S")
                    return dt.timestamp()
                except Exception:
                    pass
                # è¡¥å……è§£æä»…æ—¥æœŸæ ¼å¼
                try:
                    dt = datetime.strptime(s, "%Y-%m-%d")
                    return dt.timestamp()
                except Exception:
                    pass
                # å…¶æ¬¡å°è¯• ISOï¼ˆæ”¯æŒ Z/åç§»ï¼‰
                try:
                    s2 = s.replace('Z', '+00:00')
                    dt = datetime.fromisoformat(s2)
                    return dt.timestamp()
                except Exception:
                    return 0  # è§£æå¤±è´¥æ’åœ¨æœ€å
            
            # æŒ‰æ—¶é—´å€’åºæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            dedup.sort(key=parse_datetime_for_sort, reverse=True)
            
            return jsonify({
                "success": True,
                "source": ", ".join(providers) if providers else "èšåˆ",
                "data": dedup
            })

        # è‹¥æ— æœ¬åœ°å¯ç”¨æ¥æºï¼Œå›é€€åˆ°å…¬å¼€ç½‘ç»œ
        base_url = base64.b64decode("aHR0cHM6Ly9zLjkxNzc4OC54eXo=").decode()
        url = f"{base_url}/task_suggestions?q={search_query}&d={deep}"
        response = requests.get(url)
        return jsonify({
            "success": True,
            "source": "ç½‘ç»œå…¬å¼€",
            "data": response.json()
        })

    except Exception as e:
        return jsonify({"success": True, "message": f"error: {str(e)}"})


# è·å–åˆ†äº«è¯¦æƒ…æ¥å£
@app.route("/get_share_detail", methods=["GET", "POST"])
def get_share_detail():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    # æ”¯æŒGETå’ŒPOSTè¯·æ±‚
    if request.method == "GET":
        shareurl = request.args.get("shareurl", "")
        stoken = request.args.get("stoken", "")
    else:
        shareurl = request.json.get("shareurl", "")
        stoken = request.json.get("stoken", "")
        
    account = Quark("", 0)
    # è®¾ç½®accountçš„å¿…è¦å±æ€§
    account.episode_patterns = request.json.get("regex", {}).get("episode_patterns", []) if request.method == "POST" else []
    
    pwd_id, passcode, pdir_fid, paths = account.extract_url(shareurl)
    if not stoken:
        is_sharing, stoken = account.get_stoken(pwd_id, passcode)
        if not is_sharing:
            return jsonify({"success": False, "data": {"error": stoken}})
    share_detail = account.get_detail(pwd_id, stoken, pdir_fid, _fetch_share=1)
    # ç»Ÿä¸€é”™è¯¯è¿”å›ï¼Œé¿å…å‰ç«¯å´©æºƒ
    if isinstance(share_detail, dict) and share_detail.get("error"):
        return jsonify({"success": False, "data": {"error": share_detail.get("error")}})

    share_detail["paths"] = paths
    share_detail["stoken"] = stoken

    # å¤„ç†æ–‡ä»¶å¤¹çš„include_itemså­—æ®µï¼Œç¡®ä¿ç©ºæ–‡ä»¶å¤¹æ˜¾ç¤ºä¸º0é¡¹è€Œä¸æ˜¯undefined
    if "list" in share_detail and isinstance(share_detail["list"], list):
        for file_item in share_detail["list"]:
            if file_item.get("dir", False):
                # å¦‚æœæ˜¯æ–‡ä»¶å¤¹ï¼Œç¡®ä¿include_itemså­—æ®µå­˜åœ¨ä¸”ä¸ºæ•°å­—
                if "include_items" not in file_item or file_item["include_items"] is None:
                    file_item["include_items"] = 0
                elif not isinstance(file_item["include_items"], (int, float)):
                    # å¦‚æœinclude_itemsä¸æ˜¯æ•°å­—ç±»å‹ï¼Œå°è¯•è½¬æ¢ä¸ºæ•´æ•°ï¼Œå¤±è´¥åˆ™è®¾ä¸º0
                    try:
                        file_item["include_items"] = int(file_item["include_items"])
                    except (ValueError, TypeError):
                        file_item["include_items"] = 0

    # å¦‚æœæ˜¯GETè¯·æ±‚æˆ–è€…ä¸éœ€è¦é¢„è§ˆæ­£åˆ™ï¼Œç›´æ¥è¿”å›åˆ†äº«è¯¦æƒ…
    if request.method == "GET" or not request.json.get("regex"):
        return jsonify({"success": True, "data": share_detail})
        
    # æ­£åˆ™å‘½åé¢„è§ˆ
    def preview_regex(share_detail):
        regex = request.json.get("regex")
        # æ£€æŸ¥æ˜¯å¦ä¸ºé¡ºåºå‘½åæ¨¡å¼
        if regex.get("use_sequence_naming") and regex.get("sequence_naming"):
            # é¡ºåºå‘½åæ¨¡å¼é¢„è§ˆ
            sequence_pattern = regex.get("sequence_naming")
            current_sequence = 1
            
            # æ„å»ºé¡ºåºå‘½åçš„æ­£åˆ™è¡¨è¾¾å¼
            if sequence_pattern == "{}":
                # å¯¹äºå•ç‹¬çš„{}ï¼Œä½¿ç”¨ç‰¹æ®ŠåŒ¹é…
                regex_pattern = "(\\d+)"
            else:
                regex_pattern = re.escape(sequence_pattern).replace('\\{\\}', '(\\d+)')
            
            # å®ç°ä¸å®é™…é‡å‘½åç›¸åŒçš„æ’åºç®—æ³•
            def extract_sort_value(file):
                return sort_file_by_name(file)
            
            # è¿‡æ»¤å‡ºéç›®å½•æ–‡ä»¶ï¼Œå¹¶ä¸”æ’é™¤å·²ç»ç¬¦åˆå‘½åè§„åˆ™çš„æ–‡ä»¶
            files_to_process = []
            for f in share_detail["list"]:
                if f["dir"]:
                    continue  # è·³è¿‡ç›®å½•
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç¬¦åˆå‘½åè§„åˆ™
                if sequence_pattern == "{}":
                    # å¯¹äºå•ç‹¬çš„{}ï¼Œæ£€æŸ¥æ–‡ä»¶åæ˜¯å¦ä¸ºçº¯æ•°å­—
                    file_name_without_ext = os.path.splitext(f["file_name"])[0]
                    if file_name_without_ext.isdigit():
                        # å¢åŠ åˆ¤æ–­ï¼šå¦‚æœæ˜¯æ—¥æœŸæ ¼å¼çš„çº¯æ•°å­—ï¼Œä¸è§†ä¸ºå·²å‘½å
                        if not is_date_format(file_name_without_ext):
                            continue  # è·³è¿‡å·²ç¬¦åˆå‘½åè§„åˆ™çš„æ–‡ä»¶
                elif re.match(regex_pattern, f["file_name"]):
                    continue  # è·³è¿‡å·²ç¬¦åˆå‘½åè§„åˆ™çš„æ–‡ä»¶
                
                # æ·»åŠ åˆ°å¾…å¤„ç†æ–‡ä»¶åˆ—è¡¨
                files_to_process.append(f)
            
            # æ ¹æ®æå–çš„æ’åºå€¼è¿›è¡Œæ’åº
            sorted_files = sorted(files_to_process, key=extract_sort_value)
            
            # åº”ç”¨é«˜çº§è¿‡æ»¤è¯è¿‡æ»¤
            filterwords = regex.get("filterwords", "")
            if filterwords:
                # ä½¿ç”¨é«˜çº§è¿‡æ»¤å‡½æ•°
                filtered_files = advanced_filter_files(sorted_files, filterwords)
                # æ ‡è®°è¢«è¿‡æ»¤çš„æ–‡ä»¶
                for item in sorted_files:
                    if item not in filtered_files:
                        item["filtered"] = True
            
            # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ†é…åºå·
            for file in sorted_files:
                if not file.get("filtered"):
                    # è·å–æ–‡ä»¶æ‰©å±•å
                    file_ext = os.path.splitext(file["file_name"])[1]
                    # ç”Ÿæˆé¢„è§ˆæ–‡ä»¶å
                    if sequence_pattern == "{}":
                        # å¯¹äºå•ç‹¬çš„{}ï¼Œç›´æ¥ä½¿ç”¨æ•°å­—åºå·ä½œä¸ºæ–‡ä»¶å
                        file["file_name_re"] = f"{current_sequence:02d}{file_ext}"
                    else:
                        # æ›¿æ¢æ‰€æœ‰çš„{}ä¸ºå½“å‰åºå·
                        file["file_name_re"] = sequence_pattern.replace("{}", f"{current_sequence:02d}") + file_ext
                    
                    # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                    file["file_name_re"] = apply_subtitle_naming_rule(file["file_name_re"], config_data["task_settings"])
                    current_sequence += 1
            
            return share_detail
        elif regex.get("use_episode_naming") and regex.get("episode_naming"):
            # å‰§é›†å‘½åæ¨¡å¼é¢„è§ˆ
            episode_pattern = regex.get("episode_naming")
            episode_patterns = regex.get("episode_patterns", [])
            
            # è·å–ç”¨æˆ·è¡¥å……çš„å‰§é›†æ¨¡å¼ï¼ˆé»˜è®¤æ¨¡å¼ç”±åç«¯å†…éƒ¨æä¾›ï¼Œè¿™é‡Œåªå¤„ç†ç”¨æˆ·è¡¥å……ï¼‰
            episode_patterns = []
            raw_patterns = config_data.get("episode_patterns", [])
            for p in raw_patterns:
                if isinstance(p, dict) and p.get("regex"):
                    episode_patterns.append(p)
                elif isinstance(p, str):
                    episode_patterns.append({"regex": p})
                
            
            # åº”ç”¨é«˜çº§è¿‡æ»¤è¯è¿‡æ»¤
            filterwords = regex.get("filterwords", "")
            if filterwords:
                # ä½¿ç”¨é«˜çº§è¿‡æ»¤å‡½æ•°
                filtered_files = advanced_filter_files(share_detail["list"], filterwords)
                # æ ‡è®°è¢«è¿‡æ»¤çš„æ–‡ä»¶
                for item in share_detail["list"]:
                    if item not in filtered_files:
                        item["filtered"] = True
                        item["file_name_re"] = "Ã—"
            
            # å¤„ç†æœªè¢«è¿‡æ»¤çš„æ–‡ä»¶
            for file in share_detail["list"]:
                if not file["dir"] and not file.get("filtered"):  # åªå¤„ç†æœªè¢«è¿‡æ»¤çš„éç›®å½•æ–‡ä»¶
                    extension = os.path.splitext(file["file_name"])[1]
                    # ä»æ–‡ä»¶åä¸­æå–é›†å·
                    episode_num = extract_episode_number(file["file_name"], episode_patterns=episode_patterns)

                    if episode_num is not None:
                        file["file_name_re"] = episode_pattern.replace("[]", f"{episode_num:02d}") + extension
                        # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                        file["file_name_re"] = apply_subtitle_naming_rule(file["file_name_re"], config_data["task_settings"])
                        # æ·»åŠ episode_numberå­—æ®µç”¨äºå‰ç«¯æ’åº
                        file["episode_number"] = episode_num
                    else:
                        # æ²¡æœ‰æå–åˆ°é›†å·ï¼Œæ˜¾ç¤ºæ— æ³•è¯†åˆ«çš„æç¤º
                        file["file_name_re"] = "Ã— æ— æ³•è¯†åˆ«å‰§é›†ç¼–å·"
            
            return share_detail
        else:
            # æ™®é€šæ­£åˆ™å‘½åé¢„è§ˆ
            pattern, replace = account.magic_regex_func(
                regex.get("pattern", ""),
                regex.get("replace", ""),
                regex.get("taskname", ""),
                regex.get("magic_regex", {}),
            )
            
            # åº”ç”¨é«˜çº§è¿‡æ»¤è¯è¿‡æ»¤
            filterwords = regex.get("filterwords", "")
            if filterwords:
                # ä½¿ç”¨é«˜çº§è¿‡æ»¤å‡½æ•°
                filtered_files = advanced_filter_files(share_detail["list"], filterwords)
                # æ ‡è®°è¢«è¿‡æ»¤çš„æ–‡ä»¶
                for item in share_detail["list"]:
                    if item not in filtered_files:
                        item["filtered"] = True
                
            # åº”ç”¨æ­£åˆ™å‘½å
            for item in share_detail["list"]:
                # åªå¯¹æœªè¢«è¿‡æ»¤çš„æ–‡ä»¶åº”ç”¨æ­£åˆ™å‘½å
                if not item.get("filtered") and re.search(pattern, item["file_name"]):
                    file_name = item["file_name"]
                    item["file_name_re"] = (
                        re.sub(pattern, replace, file_name) if replace != "" else file_name
                    )
                    # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                    item["file_name_re"] = apply_subtitle_naming_rule(item["file_name_re"], config_data["task_settings"])
            return share_detail

    share_detail = preview_regex(share_detail)

    # å†æ¬¡å¤„ç†æ–‡ä»¶å¤¹çš„include_itemså­—æ®µï¼Œç¡®ä¿é¢„è§ˆåçš„æ•°æ®ä¹Ÿæ­£ç¡®
    if "list" in share_detail and isinstance(share_detail["list"], list):
        for file_item in share_detail["list"]:
            if file_item.get("dir", False):
                # å¦‚æœæ˜¯æ–‡ä»¶å¤¹ï¼Œç¡®ä¿include_itemså­—æ®µå­˜åœ¨ä¸”ä¸ºæ•°å­—
                if "include_items" not in file_item or file_item["include_items"] is None:
                    file_item["include_items"] = 0
                elif not isinstance(file_item["include_items"], (int, float)):
                    # å¦‚æœinclude_itemsä¸æ˜¯æ•°å­—ç±»å‹ï¼Œå°è¯•è½¬æ¢ä¸ºæ•´æ•°ï¼Œå¤±è´¥åˆ™è®¾ä¸º0
                    try:
                        file_item["include_items"] = int(file_item["include_items"])
                    except (ValueError, TypeError):
                        file_item["include_items"] = 0

    return jsonify({"success": True, "data": share_detail})


@app.route("/get_savepath_detail")
def get_savepath_detail():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    # è·å–è´¦å·ç´¢å¼•å‚æ•°
    account_index = int(request.args.get("account_index", 0))

    # éªŒè¯è´¦å·ç´¢å¼•
    if account_index < 0 or account_index >= len(config_data["cookie"]):
        return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

    account = Quark(config_data["cookie"][account_index], account_index)
    paths = []
    if path := request.args.get("path"):
        if path == "/":
            fid = 0
        else:
            dir_names = path.split("/")
            if dir_names[0] == "":
                dir_names.pop(0)
            path_fids = []
            current_path = ""
            for dir_name in dir_names:
                current_path += "/" + dir_name
                path_fids.append(current_path)
            if get_fids := account.get_fids(path_fids):
                fid = get_fids[-1]["fid"]
                paths = [
                    {"fid": get_fid["fid"], "name": dir_name}
                    for get_fid, dir_name in zip(get_fids, dir_names)
                ]
            else:
                return jsonify({"success": False, "data": {"error": "è·å–fidå¤±è´¥"}})
    else:
        fid = request.args.get("fid", "0")

    # è·å–æ–‡ä»¶åˆ—è¡¨
    files = account.ls_dir(fid)

    # å¤„ç†æ–‡ä»¶å¤¹çš„include_itemså­—æ®µï¼Œç¡®ä¿ç©ºæ–‡ä»¶å¤¹æ˜¾ç¤ºä¸º0é¡¹è€Œä¸æ˜¯undefined
    if isinstance(files, list):
        for file_item in files:
            if file_item.get("dir", False):
                # å¦‚æœæ˜¯æ–‡ä»¶å¤¹ï¼Œç¡®ä¿include_itemså­—æ®µå­˜åœ¨ä¸”ä¸ºæ•°å­—
                if "include_items" not in file_item or file_item["include_items"] is None:
                    file_item["include_items"] = 0
                elif not isinstance(file_item["include_items"], (int, float)):
                    # å¦‚æœinclude_itemsä¸æ˜¯æ•°å­—ç±»å‹ï¼Œå°è¯•è½¬æ¢ä¸ºæ•´æ•°ï¼Œå¤±è´¥åˆ™è®¾ä¸º0
                    try:
                        file_item["include_items"] = int(file_item["include_items"])
                    except (ValueError, TypeError):
                        file_item["include_items"] = 0

    file_list = {
        "list": files,
        "paths": paths,
    }
    return jsonify({"success": True, "data": file_list})


@app.route("/delete_file", methods=["POST"])
def delete_file():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    # è·å–è´¦å·ç´¢å¼•å‚æ•°
    account_index = int(request.json.get("account_index", 0))

    # éªŒè¯è´¦å·ç´¢å¼•
    if account_index < 0 or account_index >= len(config_data["cookie"]):
        return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

    account = Quark(config_data["cookie"][account_index], account_index)
    if fid := request.json.get("fid"):
        response = account.delete([fid])
        
        # å¤„ç†delete_recordså‚æ•°
        if request.json.get("delete_records") and response.get("code") == 0:
            try:
                # åˆå§‹åŒ–æ•°æ®åº“
                db = RecordDB()
                
                # è·å–save_pathå‚æ•°
                save_path = request.json.get("save_path", "")
                
                # å¦‚æœæ²¡æœ‰æä¾›save_pathï¼Œåˆ™ä¸åˆ é™¤ä»»ä½•è®°å½•
                if not save_path:
                    response["deleted_records"] = 0
                    # logging.info(f">>> åˆ é™¤æ–‡ä»¶ {fid} ä½†æœªæä¾›save_pathï¼Œä¸åˆ é™¤ä»»ä½•è®°å½•")
                    return jsonify(response)
                
                # æŸ¥è¯¢ä¸è¯¥æ–‡ä»¶IDå’Œsave_pathç›¸å…³çš„æ‰€æœ‰è®°å½•
                cursor = db.conn.cursor()
                
                # ä½¿ç”¨file_idå’Œsave_pathè¿›è¡Œç²¾ç¡®åŒ¹é…
                cursor.execute("SELECT id FROM transfer_records WHERE file_id = ? AND save_path = ?", (fid, save_path))
                record_ids = [row[0] for row in cursor.fetchall()]
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„file_idè®°å½•ï¼Œå°è¯•é€šè¿‡æ–‡ä»¶åæŸ¥æ‰¾
                if not record_ids:
                    # è·å–æ–‡ä»¶åï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                    file_name = request.json.get("file_name", "")
                    if file_name:
                        # ä½¿ç”¨æ–‡ä»¶åå’Œsave_pathè¿›è¡Œç²¾ç¡®åŒ¹é…
                        cursor.execute("""
                            SELECT id FROM transfer_records 
                            WHERE (original_name = ? OR renamed_to = ?) 
                            AND save_path = ?
                        """, (file_name, file_name, save_path))
                        
                        record_ids = [row[0] for row in cursor.fetchall()]
                
                # åˆ é™¤æ‰¾åˆ°çš„æ‰€æœ‰è®°å½•
                deleted_count = 0
                for record_id in record_ids:
                    deleted_count += db.delete_record(record_id)
                # çƒ­æ›´æ–°ï¼šæŒ‰ä¿å­˜è·¯å¾„æ¨æ–­ä»»åŠ¡åé›†åˆå¹¶è§¦å‘è¿›åº¦é‡ç®—
                try:
                    if deleted_count > 0:
                        cursor.execute("SELECT DISTINCT task_name FROM transfer_records WHERE save_path = ?", (save_path,))
                        task_names = [row[0] for row in (cursor.fetchall() or []) if row and row[0]]
                        for tn in task_names:
                            recompute_task_metrics_and_notify(tn)
                except Exception:
                    pass
                
                # æ·»åŠ åˆ é™¤è®°å½•çš„ä¿¡æ¯åˆ°å“åº”ä¸­
                response["deleted_records"] = deleted_count
                # logging.info(f">>> åˆ é™¤æ–‡ä»¶ {fid} åŒæ—¶åˆ é™¤äº† {deleted_count} æ¡ç›¸å…³è®°å½•")
                # è‹¥å­˜åœ¨è®°å½•åˆ é™¤ï¼Œé€šçŸ¥å‰ç«¯åˆ·æ–°ï¼ˆå½±å“ï¼šæœ€è¿‘è½¬å­˜ã€è¿›åº¦ã€ä»Šæ—¥æ›´æ–°ç­‰ï¼‰
                try:
                    if deleted_count > 0:
                        notify_calendar_changed('delete_records')
                except Exception:
                    pass
                
            except Exception as e:
                logging.error(f">>> åˆ é™¤è®°å½•æ—¶å‡ºé”™: {str(e)}")
                # ä¸å½±å“ä¸»æµç¨‹ï¼Œå³ä½¿åˆ é™¤è®°å½•å¤±è´¥ä¹Ÿè¿”å›æ–‡ä»¶åˆ é™¤æˆåŠŸ
    else:
        response = {"success": False, "message": "ç¼ºå¤±å¿…è¦å­—æ®µ: fid"}
    return jsonify(response)


@app.route("/move_file", methods=["POST"])
def move_file():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    # è·å–è´¦å·ç´¢å¼•å‚æ•°
    account_index = int(request.json.get("account_index", 0))

    # éªŒè¯è´¦å·ç´¢å¼•
    if account_index < 0 or account_index >= len(config_data["cookie"]):
        return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

    account = Quark(config_data["cookie"][account_index], account_index)

    # è·å–å‚æ•°
    file_ids = request.json.get("file_ids", [])
    target_folder_id = request.json.get("target_folder_id")

    if not file_ids:
        return jsonify({"success": False, "message": "ç¼ºå°‘æ–‡ä»¶IDåˆ—è¡¨"})

    if not target_folder_id:
        return jsonify({"success": False, "message": "ç¼ºå°‘ç›®æ ‡æ–‡ä»¶å¤¹ID"})

    try:
        # è°ƒç”¨å¤¸å…‹ç½‘ç›˜çš„ç§»åŠ¨API
        response = account.move(file_ids, target_folder_id)

        if response["code"] == 0:
            return jsonify({
                "success": True,
                "message": f"æˆåŠŸç§»åŠ¨ {len(file_ids)} ä¸ªæ–‡ä»¶",
                "moved_count": len(file_ids)
            })
        else:
            return jsonify({
                "success": False,
                "message": response.get("message", "ç§»åŠ¨å¤±è´¥")
            })
    except Exception as e:
        return jsonify({
            "success": False,
            "message": f"ç§»åŠ¨æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"
        })


@app.route("/create_folder", methods=["POST"])
def create_folder():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    # è·å–è¯·æ±‚å‚æ•°
    data = request.json
    parent_folder_id = data.get("parent_folder_id")
    folder_name = data.get("folder_name", "æ–°å»ºæ–‡ä»¶å¤¹")
    account_index = int(data.get("account_index", 0))

    # éªŒè¯å‚æ•°
    if not parent_folder_id:
        return jsonify({"success": False, "message": "ç¼ºå°‘çˆ¶ç›®å½•ID"})

    # éªŒè¯è´¦å·ç´¢å¼•
    if account_index < 0 or account_index >= len(config_data["cookie"]):
        return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

    try:
        # åˆå§‹åŒ–å¤¸å…‹ç½‘ç›˜å®¢æˆ·ç«¯
        account = Quark(config_data["cookie"][account_index], account_index)

        # è°ƒç”¨æ–°å»ºæ–‡ä»¶å¤¹API
        response = account.mkdir_in_folder(parent_folder_id, folder_name)

        if response.get("code") == 0:
            # åˆ›å»ºæˆåŠŸï¼Œè¿”å›æ–°æ–‡ä»¶å¤¹ä¿¡æ¯
            new_folder = response.get("data", {})
            return jsonify({
                "success": True,
                "message": "æ–‡ä»¶å¤¹åˆ›å»ºæˆåŠŸ",
                "data": {
                    "fid": new_folder.get("fid"),
                    "file_name": new_folder.get("file_name", folder_name),
                    "dir": True,
                    "size": 0,
                    "updated_at": new_folder.get("updated_at"),
                    "include_items": 0
                }
            })
        else:
            # å¤„ç†ç‰¹å®šçš„é”™è¯¯ä¿¡æ¯
            error_message = response.get("message", "åˆ›å»ºæ–‡ä»¶å¤¹å¤±è´¥")

            # æ£€æŸ¥æ˜¯å¦æ˜¯åŒåæ–‡ä»¶å¤¹å†²çª
            if "åŒå" in error_message or "å·²å­˜åœ¨" in error_message or "é‡å¤" in error_message or "doloading" in error_message:
                error_message = "å·²å­˜åœ¨åŒåæ–‡ä»¶å¤¹ï¼Œè¯·ä¿®æ”¹åç§°åå†è¯•"

            return jsonify({
                "success": False,
                "message": error_message
            })

    except Exception as e:
        logging.error(f">>> åˆ›å»ºæ–‡ä»¶å¤¹æ—¶å‡ºé”™: {str(e)}")
        return jsonify({
            "success": False,
            "message": f"åˆ›å»ºæ–‡ä»¶å¤¹æ—¶å‡ºé”™: {str(e)}"
        })


# æ·»åŠ ä»»åŠ¡æ¥å£
@app.route("/api/add_task", methods=["POST"])
def add_task():
    global config_data
    # éªŒè¯token
    if not is_login():
        return jsonify({"success": False, "code": 1, "message": "æœªç™»å½•"}), 401
    # å¿…é€‰å­—æ®µ
    request_data = request.json
    required_fields = ["taskname", "shareurl", "savepath"]
    for field in required_fields:
        if field not in request_data or not request_data[field]:
            return (
                jsonify(
                    {"success": False, "code": 2, "message": f"ç¼ºå°‘å¿…è¦å­—æ®µ: {field}"}
                ),
                400,
            )
    # æ·»åŠ ä»»åŠ¡
    config_data["tasklist"].append(request_data)
    Config.write_json(CONFIG_PATH, config_data)
    logging.info(f">>> é€šè¿‡APIæ·»åŠ ä»»åŠ¡: {request_data['taskname']}")
    return jsonify(
        {"success": True, "code": 0, "message": "ä»»åŠ¡æ·»åŠ æˆåŠŸ", "data": request_data}
    )


# å®šæ—¶ä»»åŠ¡æ‰§è¡Œçš„å‡½æ•°
def run_python(args):
    global _crontab_task_process
    
    logging.info(f">>> å¼€å§‹æ‰§è¡Œå®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡")
    
    # æ£€æŸ¥ä¸Šä¸€æ¬¡ä»»åŠ¡æ˜¯å¦è¿˜åœ¨è¿è¡Œï¼Œå¦‚æœæ˜¯åˆ™å¼ºåˆ¶ç»ˆæ­¢
    if _crontab_task_process is not None:
        try:
            # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œï¼ˆpoll() è¿”å› None è¡¨ç¤ºè¿˜åœ¨è¿è¡Œï¼Œè¿”å›é€€å‡ºç è¡¨ç¤ºå·²ç»“æŸï¼‰
            poll_result = _crontab_task_process.poll()
            if poll_result is None:  # è¿›ç¨‹è¿˜åœ¨è¿è¡Œ
                logging.warning(f">>> æ£€æµ‹åˆ°ä¸Šä¸€æ¬¡å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡ä»åœ¨è¿è¡Œï¼Œæ­£åœ¨å¼ºåˆ¶ç»ˆæ­¢...")
                _crontab_task_process.kill()
                _crontab_task_process.wait(timeout=10)
                logging.warning(f">>> å·²å¼ºåˆ¶ç»ˆæ­¢ä¸Šä¸€æ¬¡å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡")
            else:  # è¿›ç¨‹å·²ç»“æŸï¼ˆæ­£å¸¸æˆ–å¼‚å¸¸é€€å‡ºï¼‰
                logging.debug(f">>> ä¸Šä¸€æ¬¡å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡å·²ç»“æŸï¼ˆé€€å‡ºç : {poll_result}ï¼‰")
        except ProcessLookupError:
            # è¿›ç¨‹ä¸å­˜åœ¨ï¼ˆå¯èƒ½å·²è¢«ç³»ç»Ÿæ¸…ç†ï¼‰
            logging.debug(f">>> ä¸Šä¸€æ¬¡å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡è¿›ç¨‹å·²ä¸å­˜åœ¨/å·²è‡ªåŠ¨æ¸…ç†")
        except Exception as e:
            logging.warning(f">>> æ£€æŸ¥/ç»ˆæ­¢ä¸Šä¸€æ¬¡å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡æ—¶å‡ºé”™: {e}")
        finally:
            # æ— è®ºä»€ä¹ˆæƒ…å†µï¼Œéƒ½æ¸…é™¤è¿›ç¨‹å¯¹è±¡ï¼Œç¡®ä¿ä¸‹æ¬¡èƒ½æ­£å¸¸è¿è¡Œ
            _crontab_task_process = None

    # åœ¨å®šæ—¶ä»»åŠ¡å¼€å§‹å‰æ¸…ç†è¿‡æœŸç¼“å­˜
    try:
        cleaned_count = cleanup_expired_cache()
        if cleaned_count > 0:
            logging.info(f">>> æ¸…ç†äº† {cleaned_count} ä¸ªè¿‡æœŸç¼“å­˜é¡¹")
    except Exception as e:
        logging.warning(f">>> æ¸…ç†ç¼“å­˜æ—¶å‡ºé”™: {e}")

    # æ£€æŸ¥æ˜¯å¦éœ€è¦éšæœºå»¶è¿Ÿæ‰§è¡Œ
    if delay := config_data.get("crontab_delay"):
        try:
            delay_seconds = int(delay)
            if delay_seconds > 0:
                # åœ¨0åˆ°è®¾å®šå€¼ä¹‹é—´éšæœºé€‰æ‹©ä¸€ä¸ªå»¶è¿Ÿæ—¶é—´
                random_delay = random.randint(0, delay_seconds)
                logging.info(f">>> éšæœºå»¶è¿Ÿæ‰§è¡Œ {random_delay} ç§’")
                time.sleep(random_delay)
        except (ValueError, TypeError):
            logging.warning(f">>> å»¶è¿Ÿæ‰§è¡Œè®¾ç½®æ— æ•ˆ: {delay}")

    # ä½¿ç”¨ subprocess æ‰§è¡Œä»»åŠ¡ï¼Œè®°å½•è¿›ç¨‹å¯¹è±¡ä»¥ä¾¿ä¸‹æ¬¡æ£€æŸ¥
    try:
        process_env = os.environ.copy()
        process_env["PYTHONIOENCODING"] = "utf-8"
        
        # æ„å»ºå‘½ä»¤
        if isinstance(args, str):
            import shlex
            args_list = shlex.split(args)
            command = [PYTHON_PATH] + args_list
        else:
            command = [PYTHON_PATH] + list(args)
        
        # å¯åŠ¨è¿›ç¨‹å¹¶è®°å½•ï¼Œå®æ—¶è¾“å‡ºæ—¥å¿—
        _crontab_task_process = subprocess.Popen(
            command,
            env=process_env,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            encoding="utf-8",
            errors="replace",
            bufsize=1,  # è¡Œç¼“å†²ï¼Œç¡®ä¿å®æ—¶è¾“å‡º
        )
        
        # å®æ—¶è¯»å–è¾“å‡ºå¹¶å†™å…¥æ—¥å¿—ï¼Œä¿ç•™å®Œæ•´æ—¥å¿—åŠŸèƒ½
        # å…¨å±€å˜é‡ï¼šè·Ÿè¸ªä¸Šä¸€æ¬¡è¾“å‡ºæ˜¯å¦æ˜¯ç©ºè¡Œ
        last_was_empty = False
        
        try:
            for line in iter(_crontab_task_process.stdout.readline, ""):
                stripped_line = line.rstrip()
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç©ºè¡Œï¼ˆå»é™¤æ¢è¡Œç¬¦åæ˜¯å¦ä¸ºç©ºï¼‰
                is_empty = not stripped_line
                
                # å¦‚æœæ˜¯ç©ºè¡Œä¸”ä¸Šä¸€æ¬¡ä¹Ÿæ˜¯ç©ºè¡Œï¼Œè·³è¿‡æœ¬æ¬¡è¾“å‡º
                if is_empty and last_was_empty:
                    continue
                
                # è¾“å‡ºæ—¥å¿—ï¼ˆç©ºè¡Œä¹Ÿè¾“å‡ºï¼Œä½†é¿å…è¿ç»­ç©ºè¡Œï¼‰
                if is_empty:
                    logging.info("")
                    last_was_empty = True
                else:
                    logging.info(stripped_line)
                    last_was_empty = False
        finally:
            _crontab_task_process.stdout.close()
        
        # ç­‰å¾…è¿›ç¨‹å®Œæˆ
        returncode = _crontab_task_process.wait()
        
        if returncode == 0:
            logging.info(f">>> å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ")
        else:
            logging.warning(f">>> å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡æ‰§è¡Œå®Œæˆä½†è¿”å›éé›¶é€€å‡ºç : {returncode}")
    except Exception as e:
        logging.error(f">>> å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {str(e)}")
        import traceback
        logging.error(f">>> å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
    finally:
        # ä»»åŠ¡å®Œæˆï¼Œæ¸…é™¤è¿›ç¨‹å¯¹è±¡
        _crontab_task_process = None


# é‡æ–°åŠ è½½ä»»åŠ¡
def reload_tasks():
    global _last_crontab, _last_crontab_delay
    # è¯»å–å®šæ—¶è§„åˆ™
    if crontab := config_data.get("crontab"):
        if scheduler.state == 1:
            scheduler.pause()  # æš‚åœè°ƒåº¦å™¨
        trigger = CronTrigger.from_crontab(crontab)
        scheduler.remove_all_jobs()
        scheduler.add_job(
            run_python,
            trigger=trigger,
            args=[f"{SCRIPT_PATH} {CONFIG_PATH}"],
            id=SCRIPT_PATH,
            misfire_grace_time=None,
            coalesce=True,
            max_instances=1,
        )
        if scheduler.state == 0:
            scheduler.start()
        elif scheduler.state == 2:
            scheduler.resume()
        
        # è¯»å–å»¶è¿Ÿæ‰§è¡Œè®¾ç½®
        delay = config_data.get("crontab_delay")
        delay_str = str(delay) if delay is not None else None
        
        # ä»…åœ¨é…ç½®çœŸæ­£æ”¹å˜æ—¶è¾“å‡ºæ—¥å¿—ï¼ˆé¿å…é‡å¤è¾“å‡ºï¼‰
        crontab_changed = (_last_crontab != crontab)
        delay_changed = (_last_crontab_delay != delay_str)
        
        if crontab_changed or delay_changed:
            scheduler_state_map = {0: "åœæ­¢", 1: "è¿è¡Œ", 2: "æš‚åœ"}
            logging.info(">>> é‡è½½è°ƒåº¦å™¨")
            logging.info(f"è°ƒåº¦çŠ¶æ€: {scheduler_state_map[scheduler.state]}")
            # åˆå¹¶è¾“å‡ºï¼šå®šæ—¶è§„åˆ™ + ä»»åŠ¡è¯´æ˜
            logging.info(f"å·²å¯åŠ¨å®šæ—¶è¿è¡Œå…¨éƒ¨ä»»åŠ¡ï¼Œå®šæ—¶è§„åˆ™ {crontab}")
            # è®°å½•å»¶è¿Ÿæ‰§è¡Œè®¾ç½®
            if delay:
                logging.info(f"å»¶è¿Ÿæ‰§è¡Œ: 0-{delay}ç§’")
            # æ›´æ–°è®°å½•çš„å€¼
            _last_crontab = crontab
            _last_crontab_delay = delay_str
        # ä¸å†å†—ä½™è¾“å‡ºç°æœ‰ä»»åŠ¡åˆ—è¡¨
        return True
    else:
        # crontab è¢«ç§»é™¤çš„æƒ…å†µ
        if _last_crontab is not None:
            logging.info(">>> no crontab")
            _last_crontab = None
            _last_crontab_delay = None
        return False


def init():
    global config_data, task_plugins_config_default
    logging.info(f">>> åˆå§‹åŒ–é…ç½®")
    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(CONFIG_PATH):
        if not os.path.exists(os.path.dirname(CONFIG_PATH)):
            os.makedirs(os.path.dirname(CONFIG_PATH))
        with open("quark_config.json", "rb") as src, open(CONFIG_PATH, "wb") as dest:
            dest.write(src.read())

    # è¯»å–é…ç½®
    config_data = Config.read_json(CONFIG_PATH)
    Config.breaking_change_update(config_data)
    
    # è‡ªåŠ¨æ¸…ç†å‰§é›†è¯†åˆ«è§„åˆ™é…ç½®
    cleanup_episode_patterns_config(config_data)

    # é»˜è®¤ç®¡ç†è´¦å·
    config_data["webui"] = {
        "username": os.environ.get("WEBUI_USERNAME")
        or config_data.get("webui", {}).get("username", "admin"),
        "password": os.environ.get("WEBUI_PASSWORD")
        or config_data.get("webui", {}).get("password", "admin"),
    }

    # é»˜è®¤å®šæ—¶è§„åˆ™
    if not config_data.get("crontab"):
        config_data["crontab"] = "0 8,18,20 * * *"
    
    # é»˜è®¤å»¶è¿Ÿæ‰§è¡Œè®¾ç½®
    if "crontab_delay" not in config_data:
        config_data["crontab_delay"] = 0

    # åˆå§‹åŒ–æ’ä»¶é…ç½®
    _, plugins_config_default, task_plugins_config_default = Config.load_plugins()
    plugins_config_default.update(config_data.get("plugins", {}))
    config_data["plugins"] = plugins_config_default
    
    # è·å–ç¦ç”¨çš„æ’ä»¶åˆ—è¡¨
    disabled_plugins = set()
    if PLUGIN_FLAGS:
        disabled_plugins = {name.lstrip('-') for name in PLUGIN_FLAGS.split(',')}
    
    # æ¸…ç†æ‰€æœ‰ä»»åŠ¡ä¸­è¢«ç¦ç”¨æ’ä»¶çš„é…ç½®
    if config_data.get("tasklist"):
        for task in config_data["tasklist"]:
            if "addition" in task:
                for plugin_name in list(task["addition"].keys()):
                    if plugin_name in disabled_plugins:
                        del task["addition"][plugin_name]
    
    # åˆå§‹åŒ–æ’ä»¶é…ç½®æ¨¡å¼ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if "plugin_config_mode" not in config_data:
        config_data["plugin_config_mode"] = {
            "aria2": "independent",
            "alist_strm_gen": "independent",
            "emby": "independent"
        }
    
    # åˆå§‹åŒ–å…¨å±€æ’ä»¶é…ç½®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if "global_plugin_config" not in config_data:
        config_data["global_plugin_config"] = {
            "aria2": {
                "auto_download": True,
                "pause": False,
                "auto_delete_quark_files": False
            },
            "alist_strm_gen": {
                "auto_gen": True
            },
            "emby": {
                "try_match": True,
                "media_id": ""
            }
        }

    # åˆå§‹åŒ–æ¨é€é€šçŸ¥ç±»å‹é…ç½®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if "push_notify_type" not in config_data:
        config_data["push_notify_type"] = "full"

    # åŒæ­¥æ›´æ–°ä»»åŠ¡çš„æ’ä»¶é…ç½®
    sync_task_plugins_config()

    # æ›´æ–°é…ç½®
    Config.write_json(CONFIG_PATH, config_data)


# è·å–å†å²è½¬å­˜è®°å½•
@app.route("/history_records")
def get_history_records():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
        
    # è·å–è¯·æ±‚å‚æ•°
    page = int(request.args.get("page", 1))
    page_size = int(request.args.get("page_size", 20))
    sort_by = request.args.get("sort_by", "transfer_time")
    order = request.args.get("order", "desc")
    
    # è·å–ç­›é€‰å‚æ•°
    task_name_filter = request.args.get("task_name", "")
    keyword_filter = request.args.get("keyword", "")
    
    # æ˜¯å¦åªè¯·æ±‚æ‰€æœ‰ä»»åŠ¡åç§°
    get_all_task_names = request.args.get("get_all_task_names", "").lower() in ["true", "1", "yes"]
    
    # åˆå§‹åŒ–æ•°æ®åº“
    db = RecordDB()
    
    # å¦‚æœè¯·æ±‚æ‰€æœ‰ä»»åŠ¡åç§°ï¼Œå•ç‹¬æŸ¥è¯¢å¹¶è¿”å›
    if get_all_task_names:
        cursor = db.conn.cursor()
        cursor.execute("SELECT DISTINCT task_name FROM transfer_records WHERE task_name NOT IN ('rename', 'undo_rename') ORDER BY task_name")
        all_task_names = [row[0] for row in cursor.fetchall()]
        
        # å¦‚æœåŒæ—¶è¯·æ±‚åˆ†é¡µæ•°æ®ï¼Œç»§ç»­å¸¸è§„æŸ¥è¯¢
        if page > 0 and page_size > 0:
            result = db.get_records(
                page=page, 
                page_size=page_size, 
                sort_by=sort_by, 
                order=order,
                task_name_filter=task_name_filter,
                keyword_filter=keyword_filter,
                exclude_task_names=["rename", "undo_rename"]
            )
            # æ·»åŠ æ‰€æœ‰ä»»åŠ¡åç§°åˆ°ç»“æœä¸­
            result["all_task_names"] = all_task_names
            
            # å¤„ç†è®°å½•æ ¼å¼åŒ–
            format_records(result["records"])
            
            return jsonify({"success": True, "data": result})
        else:
            # åªè¿”å›ä»»åŠ¡åç§°
            return jsonify({"success": True, "data": {"all_task_names": all_task_names}})
    
    # å¸¸è§„æŸ¥è¯¢
    result = db.get_records(
        page=page, 
        page_size=page_size, 
        sort_by=sort_by, 
        order=order,
        task_name_filter=task_name_filter,
        keyword_filter=keyword_filter,
        exclude_task_names=["rename", "undo_rename"]
    )
    
    # å¤„ç†è®°å½•æ ¼å¼åŒ–
    format_records(result["records"])
    
    return jsonify({"success": True, "data": result})


# åˆ é™¤è½¬å­˜è®°å½•
@app.route("/delete_history_records", methods=["POST"])
def delete_history_records():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    # è·å–è¦åˆ é™¤çš„è®°å½•IDåˆ—è¡¨
    record_ids = request.json.get("record_ids", [])
    
    if not record_ids:
        return jsonify({"success": False, "message": "æœªæä¾›è¦åˆ é™¤çš„è®°å½•ID"})
    
    # åˆå§‹åŒ–æ•°æ®åº“
    db = RecordDB()
    
    # åˆ é™¤è®°å½•
    deleted_count = 0
    for record_id in record_ids:
        deleted_count += db.delete_record(record_id)

    # çƒ­æ›´æ–°ï¼šæŒ‰è®°å½• id åæŸ¥ä»»åŠ¡åå¹¶é‡ç®—è¿›åº¦
    try:
        if deleted_count > 0:
            cursor = db.conn.cursor()
            placeholders = ','.join(['?'] * len(record_ids)) if record_ids else ''
            if placeholders:
                cursor.execute(f"SELECT DISTINCT task_name FROM transfer_records WHERE id IN ({placeholders})", record_ids)
                task_names = [row[0] for row in (cursor.fetchall() or []) if row and row[0]]
                for tn in task_names:
                    recompute_task_metrics_and_notify(tn)
    except Exception:
        pass

    # å¹¿æ’­é€šçŸ¥ï¼šæœ‰è®°å½•è¢«åˆ é™¤ï¼Œè§¦å‘å‰ç«¯åˆ·æ–°ä»»åŠ¡/æ—¥å†
    try:
        if deleted_count > 0:
            notify_calendar_changed('delete_records')
    except Exception:
        pass

    return jsonify({
        "success": True,
        "message": f"æˆåŠŸåˆ é™¤ {deleted_count} æ¡è®°å½•",
        "deleted_count": deleted_count
    })


# è·å–ä»»åŠ¡æœ€æ–°è½¬å­˜ä¿¡æ¯ï¼ˆåŒ…æ‹¬æ—¥æœŸå’Œæ–‡ä»¶ï¼‰
@app.route("/task_latest_info")
def get_task_latest_info():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    try:
        # åˆå§‹åŒ–æ•°æ®åº“
        db = RecordDB()
        cursor = db.conn.cursor()

        # è·å–æ‰€æœ‰ä»»åŠ¡çš„æœ€æ–°è½¬å­˜æ—¶é—´
        query = """
        SELECT task_name, MAX(transfer_time) as latest_transfer_time
        FROM transfer_records
        WHERE task_name NOT IN ('rename', 'undo_rename')
        GROUP BY task_name
        """
        cursor.execute(query)
        latest_times = cursor.fetchall()

        task_latest_records = {}  # å­˜å‚¨æœ€æ–°è½¬å­˜æ—¥æœŸ
        task_latest_files = {}    # å­˜å‚¨æœ€æ–°è½¬å­˜æ–‡ä»¶

        for task_name, latest_time in latest_times:
            if latest_time:
                # 1. å¤„ç†æœ€æ–°è½¬å­˜æ—¥æœŸ
                try:
                    # ç¡®ä¿æ—¶é—´æˆ³åœ¨åˆç†èŒƒå›´å†…
                    timestamp = int(latest_time)
                    if timestamp > 9999999999:  # æ£€æµ‹æ˜¯å¦ä¸ºæ¯«ç§’çº§æ—¶é—´æˆ³ï¼ˆ13ä½ï¼‰
                        timestamp = timestamp / 1000  # è½¬æ¢ä¸ºç§’çº§æ—¶é—´æˆ³

                    if 0 < timestamp < 4102444800:  # ä»1970å¹´åˆ°2100å¹´çš„åˆç†æ—¶é—´æˆ³èŒƒå›´
                        # æ ¼å¼åŒ–ä¸ºæœˆ-æ—¥æ ¼å¼ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰å’Œå®Œæ•´æ—¥æœŸï¼ˆç”¨äºä»Šæ—¥åˆ¤æ–­ï¼‰
                        date_obj = datetime.fromtimestamp(timestamp)
                        formatted_date = date_obj.strftime("%m-%d")
                        full_date = date_obj.strftime("%Y-%m-%d")
                        task_latest_records[task_name] = {
                            "display": formatted_date,  # æ˜¾ç¤ºç”¨çš„ MM-DD æ ¼å¼
                            "full": full_date          # æ¯”è¾ƒç”¨çš„ YYYY-MM-DD æ ¼å¼
                        }
                except (ValueError, TypeError, OverflowError):
                    pass  # å¿½ç•¥æ— æ•ˆçš„æ—¶é—´æˆ³

                # 2. å¤„ç†æœ€æ–°è½¬å­˜æ–‡ä»¶
                # è·å–è¯¥ä»»åŠ¡åœ¨æœ€æ–°è½¬å­˜æ—¶é—´é™„è¿‘ï¼ˆåŒä¸€åˆ†é’Ÿå†…ï¼‰çš„æ‰€æœ‰æ–‡ä»¶
                # è¿™æ ·å¯ä»¥å¤„ç†åŒæ—¶è½¬å­˜å¤šä¸ªæ–‡ä»¶ä½†æ—¶é—´æˆ³ç•¥æœ‰å·®å¼‚çš„æƒ…å†µ
                time_window = 60000  # 60ç§’çš„æ—¶é—´çª—å£ï¼ˆæ¯«ç§’ï¼‰
                query = """
                SELECT renamed_to, original_name, transfer_time, modify_date
                FROM transfer_records
                WHERE task_name = ? AND transfer_time >= ? AND transfer_time <= ?
                ORDER BY id DESC
                """
                cursor.execute(query, (task_name, latest_time - time_window, latest_time + time_window))
                files = cursor.fetchall()

                if files:
                    if len(files) == 1:
                        # å¦‚æœåªæœ‰ä¸€ä¸ªæ–‡ä»¶ï¼Œç›´æ¥ä½¿ç”¨
                        best_file = files[0][0]  # renamed_to
                    else:
                        # å¦‚æœæœ‰å¤šä¸ªæ–‡ä»¶ï¼Œä½¿ç”¨å…¨å±€æ’åºå‡½æ•°è¿›è¡Œæ’åº
                        file_list = []
                        for renamed_to, original_name, transfer_time, modify_date in files:
                            # æ„é€ æ–‡ä»¶ä¿¡æ¯å­—å…¸ï¼Œæ¨¡æ‹Ÿå…¨å±€æ’åºå‡½æ•°éœ€è¦çš„æ ¼å¼
                            file_info = {
                                'file_name': renamed_to,
                                'original_name': original_name,
                                'updated_at': transfer_time  # ä½¿ç”¨è½¬å­˜æ—¶é—´è€Œä¸æ˜¯æ–‡ä»¶ä¿®æ”¹æ—¶é—´
                            }
                            file_list.append(file_info)

                        # ä½¿ç”¨å…¨å±€æ’åºå‡½æ•°è¿›è¡Œæ­£å‘æ’åºï¼Œæœ€åä¸€ä¸ªå°±æ˜¯æœ€æ–°çš„
                        try:
                            sorted_files = sorted(file_list, key=sort_file_by_name)
                            best_file = sorted_files[-1]['file_name']  # å–æ’åºåçš„æœ€åä¸€ä¸ªæ–‡ä»¶
                        except Exception as e:
                            # å¦‚æœæ’åºå¤±è´¥ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ–‡ä»¶ä½œä¸ºå¤‡é€‰
                            best_file = files[0][0]

                    # å»é™¤æ‰©å±•åå¹¶å¤„ç†å­£æ•°é›†æ•°ä¿¡æ¯
                    if best_file:
                        file_name_without_ext = os.path.splitext(best_file)[0]
                        processed_name = process_season_episode_info(file_name_without_ext, task_name)
                        task_latest_files[task_name] = processed_name

        # æ³¨å…¥"è¿½å‰§æ—¥å†"å±‚é¢çš„ç­¾åä¿¡æ¯ï¼Œä¾¿äºå‰ç«¯åœ¨æ— æ–°å¢è½¬å­˜æ–‡ä»¶æ—¶ä¹Ÿèƒ½æ£€æµ‹åˆ°æ–°å¢/åˆ é™¤å‰§ç›®
        try:
            caldb = CalendarDB()
            cur = caldb.conn.cursor()
            # shows æ•°é‡
            try:
                cur.execute('SELECT COUNT(*) FROM shows')
                shows_count = cur.fetchone()[0] if cur.fetchone is not None else 0
            except Exception:
                shows_count = 0
            # tmdb_id åˆ—è¡¨ï¼ˆæ’åºåæ‹¼æ¥ï¼Œå˜åŒ–å³è§¦å‘å‰ç«¯åˆ·æ–°ï¼‰
            tmdb_sig = ''
            try:
                cur.execute('SELECT tmdb_id FROM shows ORDER BY tmdb_id ASC')
                ids = [str(r[0]) for r in cur.fetchall()]
                tmdb_sig = ','.join(ids)
            except Exception:
                tmdb_sig = ''
            # å†™å…¥åˆ° latest_filesï¼Œä»¥å¤ç”¨å‰ç«¯ç°æœ‰ç­¾åè®¡ç®—é€»è¾‘
            task_latest_files['__calendar_shows__'] = str(shows_count)
            if tmdb_sig:
                task_latest_files['__calendar_tmdb_ids__'] = tmdb_sig
        except Exception:
            pass

        db.close()

        return jsonify({
            "success": True,
            "data": {
                "latest_records": task_latest_records,
                "latest_files": task_latest_files
            }
        })

    except Exception as e:
        return jsonify({
            "success": False,
            "message": f"è·å–ä»»åŠ¡æœ€æ–°ä¿¡æ¯å¤±è´¥: {str(e)}"
        })


# è·å–å½“æ—¥æ›´æ–°çš„å‰§é›†ï¼ˆæœ¬åœ°DBï¼ŒæŒ‰ transfer_records å½“å¤©è®°å½•èšåˆï¼‰
@app.route("/api/calendar/today_updates_local")
def get_calendar_today_updates_local():
    try:
        # è®¡ç®—ä»Šå¤© 00:00:00 ä¸ 23:59:59 çš„æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰èŒƒå›´
        now = datetime.now()
        start_of_day = datetime(now.year, now.month, now.day)
        end_of_day = datetime(now.year, now.month, now.day, 23, 59, 59)
        start_ms = int(start_of_day.timestamp() * 1000)
        end_ms = int(end_of_day.timestamp() * 1000)

        # è¯»å–ä»Šæ—¥çš„è½¬å­˜è®°å½•
        rdb = RecordDB()
        cur = rdb.conn.cursor()
        cur.execute(
            """
            SELECT task_name, renamed_to, original_name, transfer_time
            FROM transfer_records
            WHERE task_name NOT IN ('rename', 'undo_rename')
              AND transfer_time >= ? AND transfer_time <= ?
            ORDER BY id DESC
            """,
            (start_ms, end_ms)
        )
        rows = cur.fetchall() or []

        # å»ºç«‹ task_name -> (tmdb_id, show_name) çš„æ˜ å°„ï¼Œä¼˜å…ˆä½¿ç”¨å·²ç»‘å®šçš„ shows
        tmdb_map = {}
        try:
            cal_db = CalendarDB()
            # shows è¡¨æœ‰ bound_task_namesï¼Œé€æ¡è§£æç»‘å®š
            cur2 = cal_db.conn.cursor()
            cur2.execute('SELECT tmdb_id, name, bound_task_names FROM shows')
            for tmdb_id, name, bound in (cur2.fetchall() or []):
                try:
                    bound_list = []
                    if bound:
                        bound_list = [b.strip() for b in str(bound).split(',') if b and b.strip()]
                    for tname in bound_list:
                        if tname:
                            tmdb_map[tname] = { 'tmdb_id': int(tmdb_id), 'show_name': name or '' }
                except Exception:
                    continue
        except Exception:
            tmdb_map = {}

        # æå–å‰§é›†ç¼–å·/æ—¥æœŸ
        extractor = TaskExtractor()
        items = []
        for task_name, renamed_to, original_name, transfer_time in rows:
            # è§£æè¿›åº¦ä¿¡æ¯
            base_name = os.path.splitext(renamed_to or '')[0]
            parsed = extractor.extract_progress_from_latest_file(base_name)
            season = parsed.get('season_number')
            ep = parsed.get('episode_number')
            air_date = parsed.get('air_date')
            if not season and not ep and not air_date:
                # æ— æ³•è§£æåˆ°æœ‰æ•ˆä¿¡æ¯åˆ™è·³è¿‡
                continue
            bind = tmdb_map.get(task_name, {})
            items.append({
                'task_name': task_name or '',
                'tmdb_id': bind.get('tmdb_id'),
                'show_name': bind.get('show_name') or '',
                'season_number': season,
                'episode_number': ep,
                'air_date': air_date
            })

        return jsonify({ 'success': True, 'data': { 'items': items } })
    except Exception as e:
        return jsonify({ 'success': False, 'message': f'è¯»å–å½“æ—¥æ›´æ–°å¤±è´¥: {str(e)}', 'data': { 'items': [] } })


# åˆ é™¤å•æ¡è½¬å­˜è®°å½•
@app.route("/delete_history_record", methods=["POST"])
def delete_history_record():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    # è·å–è¦åˆ é™¤çš„è®°å½•ID
    record_id = request.json.get("id")
    
    if not record_id:
        return jsonify({"success": False, "message": "æœªæä¾›è¦åˆ é™¤çš„è®°å½•ID"})
    
    # åˆå§‹åŒ–æ•°æ®åº“
    db = RecordDB()
    
    # åˆ é™¤è®°å½•
    deleted = db.delete_record(record_id)
    # çƒ­æ›´æ–°ï¼šæ ¹æ®è®°å½• id åæŸ¥ä»»åŠ¡åå¹¶é‡ç®—è¿›åº¦
    try:
        if deleted:
            cursor = db.conn.cursor()
            cursor.execute('SELECT task_name FROM transfer_records WHERE id = ?', (record_id,))
            row = cursor.fetchone()
            if row and row[0]:
                recompute_task_metrics_and_notify(row[0])
    except Exception:
        pass

    # å¹¿æ’­é€šçŸ¥ï¼šæœ‰è®°å½•è¢«åˆ é™¤ï¼Œè§¦å‘å‰ç«¯åˆ·æ–°ä»»åŠ¡/æ—¥å†
    try:
        if deleted:
            notify_calendar_changed('delete_records')
    except Exception:
        pass

    if deleted:
        return jsonify({
            "success": True, 
            "message": "æˆåŠŸåˆ é™¤ 1 æ¡è®°å½•",
        })
    else:
        return jsonify({
            "success": False, 
            "message": "è®°å½•åˆ é™¤å¤±è´¥ï¼Œå¯èƒ½è®°å½•ä¸å­˜åœ¨",
        })


# è¾…åŠ©å‡½æ•°ï¼šæ ¼å¼åŒ–è®°å½•
def format_records(records):
    for record in records:
        # æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸ºå¯è¯»å½¢å¼
        if "transfer_time" in record:
            try:
                # ç¡®ä¿æ—¶é—´æˆ³åœ¨åˆç†èŒƒå›´å†…
                timestamp = int(record["transfer_time"])
                if timestamp > 9999999999:  # æ£€æµ‹æ˜¯å¦ä¸ºæ¯«ç§’çº§æ—¶é—´æˆ³ï¼ˆ13ä½ï¼‰
                    timestamp = timestamp / 1000  # è½¬æ¢ä¸ºç§’çº§æ—¶é—´æˆ³
                
                if 0 < timestamp < 4102444800:  # ä»1970å¹´åˆ°2100å¹´çš„åˆç†æ—¶é—´æˆ³èŒƒå›´
                    record["transfer_time_readable"] = datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d %H:%M:%S")
                else:
                    record["transfer_time_readable"] = "æ— æ•ˆæ—¥æœŸ"
            except (ValueError, TypeError, OverflowError):
                record["transfer_time_readable"] = "æ— æ•ˆæ—¥æœŸ"
                
        if "modify_date" in record:
            try:
                # ç¡®ä¿æ—¶é—´æˆ³åœ¨åˆç†èŒƒå›´å†…
                timestamp = int(record["modify_date"])
                if timestamp > 9999999999:  # æ£€æµ‹æ˜¯å¦ä¸ºæ¯«ç§’çº§æ—¶é—´æˆ³ï¼ˆ13ä½ï¼‰
                    timestamp = timestamp / 1000  # è½¬æ¢ä¸ºç§’çº§æ—¶é—´æˆ³
                    
                if 0 < timestamp < 4102444800:  # ä»1970å¹´åˆ°2100å¹´çš„åˆç†æ—¶é—´æˆ³èŒƒå›´
                    record["modify_date_readable"] = datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d %H:%M:%S")
                else:
                    record["modify_date_readable"] = "æ— æ•ˆæ—¥æœŸ"
            except (ValueError, TypeError, OverflowError):
                record["modify_date_readable"] = "æ— æ•ˆæ—¥æœŸ"
                
        # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
        if "file_size" in record:
            try:
                record["file_size_readable"] = format_bytes(int(record["file_size"]))
            except (ValueError, TypeError):
                record["file_size_readable"] = "æœªçŸ¥å¤§å°"


@app.route("/get_user_info")
def get_user_info():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    user_info_list = []
    for idx, cookie in enumerate(config_data["cookie"]):
        account = Quark(cookie, idx)
        account_info = account.init()
        if account_info:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç§»åŠ¨ç«¯å‚æ•°
            has_mparam = bool(account.mparam)
            user_info_list.append({
                "index": idx,
                "nickname": account_info["nickname"],
                "is_active": account.is_active,
                "has_mparam": has_mparam
            })
        else:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç§»åŠ¨ç«¯å‚æ•°
            has_mparam = bool(account.mparam)
            user_info_list.append({
                "index": idx,
                "nickname": "",
                "is_active": False,
                "has_mparam": has_mparam
            })

    return jsonify({"success": True, "data": user_info_list})


@app.route("/get_accounts_detail")
def get_accounts_detail():
    """è·å–æ‰€æœ‰è´¦å·çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ˜µç§°å’Œç©ºé—´ä½¿ç”¨æƒ…å†µ"""
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    accounts_detail = []
    for idx, cookie in enumerate(config_data["cookie"]):
        account = Quark(cookie, idx)
        account_info = account.init()

        # å¦‚æœæ— æ³•è·å–è´¦å·ä¿¡æ¯ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ç§»åŠ¨ç«¯å‚æ•°
        if not account_info:
            has_mparam = bool(account.mparam)
            # å¦‚æœåªæœ‰ç§»åŠ¨ç«¯å‚æ•°ï¼Œè·³è¿‡æ­¤è´¦å·ï¼ˆä¸æ˜¾ç¤ºåœ¨æ–‡ä»¶æ•´ç†é¡µé¢çš„è´¦å·é€‰æ‹©æ ä¸­ï¼‰
            if has_mparam:
                continue
            else:
                # å¦‚æœæ—¢æ²¡æœ‰è´¦å·ä¿¡æ¯ä¹Ÿæ²¡æœ‰ç§»åŠ¨ç«¯å‚æ•°ï¼Œæ˜¾ç¤ºä¸ºæœªç™»å½•
                account_detail = {
                    "index": idx,
                    "nickname": "",
                    "is_active": False,
                    "used_space": 0,
                    "total_space": 0,
                    "usage_rate": 0,
                    "display_text": f"è´¦å·{idx + 1}ï¼ˆæœªç™»å½•ï¼‰"
                }
                accounts_detail.append(account_detail)
                continue

        # æˆåŠŸè·å–è´¦å·ä¿¡æ¯çš„æƒ…å†µ
        account_detail = {
            "index": idx,
            "nickname": account_info["nickname"],
            "is_active": account.is_active,
            "used_space": 0,
            "total_space": 0,
            "usage_rate": 0,
            "display_text": ""
        }

        # æ£€æŸ¥æ˜¯å¦æœ‰ç§»åŠ¨ç«¯å‚æ•°
        has_mparam = bool(account.mparam)
        
        if has_mparam:
            # åŒæ—¶æœ‰cookieå’Œç§»åŠ¨ç«¯å‚æ•°ï¼Œå°è¯•è·å–ç©ºé—´ä¿¡æ¯
            try:
                growth_info = account.get_growth_info()
                if growth_info:
                    total_capacity = growth_info.get("total_capacity", 0)
                    account_detail["total_space"] = total_capacity
                    # æ˜¾ç¤ºæ˜µç§°å’Œæ€»å®¹é‡
                    total_str = format_bytes(total_capacity)
                    account_detail["display_text"] = f"{account_info['nickname']} Â· {total_str}"
                else:
                    # è·å–ç©ºé—´ä¿¡æ¯å¤±è´¥ï¼Œåªæ˜¾ç¤ºæ˜µç§°
                    account_detail["display_text"] = account_info["nickname"]
            except Exception as e:
                logging.error(f"è·å–è´¦å· {idx} ç©ºé—´ä¿¡æ¯å¤±è´¥: {str(e)}")
                # è·å–ç©ºé—´ä¿¡æ¯å¤±è´¥ï¼Œåªæ˜¾ç¤ºæ˜µç§°
                account_detail["display_text"] = account_info["nickname"]
        else:
            # åªæœ‰cookieï¼Œæ²¡æœ‰ç§»åŠ¨ç«¯å‚æ•°ï¼Œåªæ˜¾ç¤ºæ˜µç§°
            account_detail["display_text"] = account_info["nickname"]

        accounts_detail.append(account_detail)

    return jsonify({"success": True, "data": accounts_detail})


# é‡ç½®æ–‡ä»¶å¤¹ï¼ˆåˆ é™¤æ–‡ä»¶å¤¹å†…æ‰€æœ‰æ–‡ä»¶å’Œç›¸å…³è®°å½•ï¼‰
@app.route("/reset_folder", methods=["POST"])
def reset_folder():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    # è·å–è¯·æ±‚å‚æ•°
    save_path = request.json.get("save_path", "")
    account_index = int(request.json.get("account_index", 0))  # æ–°å¢è´¦å·ç´¢å¼•å‚æ•°

    if not save_path:
        return jsonify({"success": False, "message": "ä¿å­˜è·¯å¾„ä¸èƒ½ä¸ºç©º"})

    try:
        # éªŒè¯è´¦å·ç´¢å¼•
        if account_index < 0 or account_index >= len(config_data["cookie"]):
            return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

        # åˆå§‹åŒ–å¤¸å…‹ç½‘ç›˜å®¢æˆ·ç«¯
        account = Quark(config_data["cookie"][account_index], account_index)
        
        # 1. è·å–æ–‡ä»¶å¤¹ID
        # å…ˆæ£€æŸ¥æ˜¯å¦å·²æœ‰ç¼“å­˜çš„æ–‡ä»¶å¤¹ID
        folder_fid = account.savepath_fid.get(save_path)
        
        # å¦‚æœæ²¡æœ‰ç¼“å­˜çš„IDï¼Œåˆ™å°è¯•åˆ›å»ºæ–‡ä»¶å¤¹ä»¥è·å–ID
        if not folder_fid:
            mkdir_result = account.mkdir(save_path)
            if mkdir_result.get("code") == 0:
                folder_fid = mkdir_result["data"]["fid"]
                account.savepath_fid[save_path] = folder_fid
            else:
                return jsonify({"success": False, "message": f"è·å–æ–‡ä»¶å¤¹IDå¤±è´¥: {mkdir_result.get('message', 'æœªçŸ¥é”™è¯¯')}"})
        
        # 2. è·å–æ–‡ä»¶å¤¹å†…çš„æ‰€æœ‰æ–‡ä»¶
        file_list = account.ls_dir(folder_fid)
        if isinstance(file_list, dict) and file_list.get("error"):
            return jsonify({"success": False, "message": f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {file_list.get('error', 'æœªçŸ¥é”™è¯¯')}"})
        
        # æ”¶é›†æ‰€æœ‰æ–‡ä»¶ID
        file_ids = []
        for item in file_list:
            file_ids.append(item["fid"])
        
        # 3. åˆ é™¤æ‰€æœ‰æ–‡ä»¶
        deleted_files = 0
        if file_ids:
            delete_result = account.delete(file_ids)
            if delete_result.get("code") == 0:
                deleted_files = len(file_ids)
        
        # 4. åˆ é™¤ç›¸å…³çš„å†å²è®°å½•
        deleted_records = 0
        try:
            # åˆå§‹åŒ–æ•°æ®åº“
            db = RecordDB()
            
            # æŸ¥è¯¢ä¸è¯¥ä¿å­˜è·¯å¾„ç›¸å…³çš„æ‰€æœ‰è®°å½•
            cursor = db.conn.cursor()
            cursor.execute("SELECT id FROM transfer_records WHERE save_path = ?", (save_path,))
            record_ids = [row[0] for row in cursor.fetchall()]
            
            # åˆ é™¤æ‰¾åˆ°çš„æ‰€æœ‰è®°å½•
            for record_id in record_ids:
                deleted_records += db.delete_record(record_id)
            # çƒ­æ›´æ–°ï¼šæŒ‰ä¿å­˜è·¯å¾„æ¨æ–­ä»»åŠ¡åé›†åˆå¹¶è§¦å‘è¿›åº¦é‡ç®—
            try:
                if deleted_records > 0:
                    cursor.execute("SELECT DISTINCT task_name FROM transfer_records WHERE save_path = ?", (save_path,))
                    task_names = [row[0] for row in (cursor.fetchall() or []) if row and row[0]]
                    for tn in task_names:
                        recompute_task_metrics_and_notify(tn)
            except Exception:
                pass
                
        except Exception as e:
            logging.error(f">>> åˆ é™¤è®°å½•æ—¶å‡ºé”™: {str(e)}")
            # å³ä½¿åˆ é™¤è®°å½•å¤±è´¥ï¼Œä¹Ÿè¿”å›æ–‡ä»¶åˆ é™¤æˆåŠŸ
        
        # æˆåŠŸåé€šè¿‡ SSE é€šçŸ¥å‰ç«¯è¿›è¡Œçƒ­æ›´æ–°
        try:
            notify_calendar_changed('reset_folder')
        except Exception:
            pass

        return jsonify({
            "success": True, 
            "message": f"é‡ç½®æˆåŠŸï¼Œåˆ é™¤äº† {deleted_files} ä¸ªæ–‡ä»¶å’Œ {deleted_records} æ¡è®°å½•",
            "deleted_files": deleted_files,
            "deleted_records": deleted_records
        })
        
    except Exception as e:
        logging.error(f">>> é‡ç½®æ–‡ä»¶å¤¹æ—¶å‡ºé”™: {str(e)}")
        return jsonify({"success": False, "message": f"é‡ç½®æ–‡ä»¶å¤¹æ—¶å‡ºé”™: {str(e)}"})


# è·å–æ–‡ä»¶åˆ—è¡¨
@app.route("/file_list")
def get_file_list():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})

    # è·å–è¯·æ±‚å‚æ•°
    folder_id = request.args.get("folder_id", "root")
    sort_by = request.args.get("sort_by", "file_name")
    order = request.args.get("order", "asc")
    page = int(request.args.get("page", 1))
    page_size = int(request.args.get("page_size", 15))
    account_index = int(request.args.get("account_index", 0))
    force_refresh = request.args.get("force_refresh", "false").lower() == "true"  # æ–°å¢è´¦å·ç´¢å¼•å‚æ•°

    try:
        # éªŒè¯è´¦å·ç´¢å¼•
        if account_index < 0 or account_index >= len(config_data["cookie"]):
            return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

        # åˆå§‹åŒ–å¤¸å…‹ç½‘ç›˜å®¢æˆ·ç«¯
        account = Quark(config_data["cookie"][account_index], account_index)

        # è·å–æ–‡ä»¶åˆ—è¡¨
        if folder_id == "root":
            folder_id = "0"  # æ ¹ç›®å½•çš„IDä¸º0
            paths = []  # æ ¹ç›®å½•æ²¡æœ‰è·¯å¾„
        else:
            # è·å–å½“å‰æ–‡ä»¶å¤¹çš„è·¯å¾„
            paths = account.get_paths(folder_id)

        # è·å–æ€§èƒ½é…ç½®
        perf_config = get_performance_config()
        api_page_size = perf_config.get("api_page_size", 200)
        cache_expire_time = perf_config.get("cache_expire_time", 30)

        # ç¼“å­˜é”®
        cache_key = f"{account_index}_{folder_id}_{sort_by}_{order}"
        current_time = time.time()

        # æ£€æŸ¥ç¼“å­˜ï¼ˆé™¤éå¼ºåˆ¶åˆ·æ–°ï¼‰
        if not force_refresh:
            with cache_lock:
                if cache_key in file_list_cache:
                    cache_data, cache_time = file_list_cache[cache_key]
                    if current_time - cache_time < cache_expire_time:
                        # ä½¿ç”¨ç¼“å­˜æ•°æ®
                        cached_files = cache_data
                        total = len(cached_files)
                        start_idx = (page - 1) * page_size
                        end_idx = min(start_idx + page_size, total)
                        paginated_files = cached_files[start_idx:end_idx]

                        return jsonify({
                            "success": True,
                            "data": {
                                "list": paginated_files,
                                "total": total,
                                "paths": paths
                            }
                        })
        else:
            # å¼ºåˆ¶åˆ·æ–°æ—¶ï¼Œæ¸…é™¤å½“å‰ç›®å½•çš„ç¼“å­˜
            with cache_lock:
                if cache_key in file_list_cache:
                    del file_list_cache[cache_key]

        # æ— è®ºåˆ†é¡µè¿˜æ˜¯å…¨éƒ¨æ¨¡å¼ï¼Œéƒ½å¿…é¡»è·å–æ‰€æœ‰æ–‡ä»¶æ‰èƒ½è¿›è¡Œæ­£ç¡®çš„å…¨å±€æ’åº
        files = account.ls_dir(folder_id, page_size=api_page_size)

        if isinstance(files, dict) and files.get("error"):
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®å½•ä¸å­˜åœ¨çš„é”™è¯¯
            error_msg = files.get('error', 'æœªçŸ¥é”™è¯¯')
            if "ä¸å­˜åœ¨" in error_msg or "æ— æ•ˆ" in error_msg or "æ‰¾ä¸åˆ°" in error_msg:
                return jsonify({"success": False, "message": f"ç›®å½•ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®: {error_msg}"})
            else:
                return jsonify({"success": False, "message": f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {error_msg}"})

        # å¤„ç†æ–‡ä»¶å¤¹çš„include_itemså­—æ®µï¼Œç¡®ä¿ç©ºæ–‡ä»¶å¤¹æ˜¾ç¤ºä¸º0é¡¹è€Œä¸æ˜¯undefined
        for file_item in files:
            if file_item.get("dir", False):
                # å¦‚æœæ˜¯æ–‡ä»¶å¤¹ï¼Œç¡®ä¿include_itemså­—æ®µå­˜åœ¨ä¸”ä¸ºæ•°å­—
                if "include_items" not in file_item or file_item["include_items"] is None:
                    file_item["include_items"] = 0
                elif not isinstance(file_item["include_items"], (int, float)):
                    # å¦‚æœinclude_itemsä¸æ˜¯æ•°å­—ç±»å‹ï¼Œå°è¯•è½¬æ¢ä¸ºæ•´æ•°ï¼Œå¤±è´¥åˆ™è®¾ä¸º0
                    try:
                        file_item["include_items"] = int(file_item["include_items"])
                    except (ValueError, TypeError):
                        file_item["include_items"] = 0

        # è®¡ç®—æ€»æ•°
        total = len(files)

        # ä¼˜åŒ–æ’åºï¼šä½¿ç”¨æ›´é«˜æ•ˆçš„æ’åºæ–¹æ³•
        def get_sort_key(file_item):
            if sort_by == "file_name":
                # ä½¿ç”¨æ‹¼éŸ³æ’åº
                return get_filename_pinyin_sort_key(file_item["file_name"])
            elif sort_by == "file_size":
                # æ–‡ä»¶å¤¹æŒ‰é¡¹ç›®æ•°é‡æ’åºï¼Œæ–‡ä»¶æŒ‰å¤§å°æ’åº
                return file_item.get("include_items", 0) if file_item["dir"] else file_item["size"]
            else:  # updated_at
                return file_item["updated_at"]

        # åˆ†ç¦»æ–‡ä»¶å¤¹å’Œæ–‡ä»¶ä»¥ä¼˜åŒ–æ’åº
        if sort_by == "updated_at":
            # ä¿®æ”¹æ—¥æœŸæ’åºæ—¶ä¸¥æ ¼æŒ‰ç…§æ—¥æœŸæ’åºï¼Œä¸åŒºåˆ†æ–‡ä»¶å¤¹å’Œæ–‡ä»¶
            files.sort(key=get_sort_key, reverse=(order == "desc"))
            sorted_files = files
        else:
            # å…¶ä»–æ’åºæ—¶ç›®å½•å§‹ç»ˆåœ¨å‰é¢ï¼Œåˆ†åˆ«æ’åºä»¥æé«˜æ•ˆç‡
            directories = [f for f in files if f["dir"]]
            normal_files = [f for f in files if not f["dir"]]

            directories.sort(key=get_sort_key, reverse=(order == "desc"))
            normal_files.sort(key=get_sort_key, reverse=(order == "desc"))

            sorted_files = directories + normal_files

        # æ›´æ–°ç¼“å­˜
        with cache_lock:
            file_list_cache[cache_key] = (sorted_files, current_time)

        # åˆ†é¡µ
        start_idx = (page - 1) * page_size
        end_idx = min(start_idx + page_size, total)
        paginated_files = sorted_files[start_idx:end_idx]

        return jsonify({
            "success": True,
            "data": {
                "list": paginated_files,
                "total": total,
                "paths": paths
            }
        })
        
    except Exception as e:
        logging.error(f">>> è·å–æ–‡ä»¶åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}")
        return jsonify({"success": False, "message": f"è·å–æ–‡ä»¶åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}"})


# é¢„è§ˆé‡å‘½å
@app.route("/preview_rename")
def preview_rename():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    # è·å–è¯·æ±‚å‚æ•°
    folder_id = request.args.get("folder_id", "root")
    pattern = request.args.get("pattern", "")
    replace = request.args.get("replace", "")
    naming_mode = request.args.get("naming_mode", "regex")  # regex, sequence, episode
    include_folders = request.args.get("include_folders", "false") == "true"
    filterwords = request.args.get("filterwords", "")
    account_index = int(request.args.get("account_index", 0))  # æ–°å¢è´¦å·ç´¢å¼•å‚æ•°

    if not pattern:
        pattern = ".*"

    try:
        # éªŒè¯è´¦å·ç´¢å¼•
        if account_index < 0 or account_index >= len(config_data["cookie"]):
            return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

        # åˆå§‹åŒ–å¤¸å…‹ç½‘ç›˜å®¢æˆ·ç«¯
        account = Quark(config_data["cookie"][account_index], account_index)
        
        # è·å–æ–‡ä»¶åˆ—è¡¨
        if folder_id == "root":
            folder_id = "0"  # æ ¹ç›®å½•çš„IDä¸º0
        
        files = account.ls_dir(folder_id)
        if isinstance(files, dict) and files.get("error"):
            return jsonify({"success": False, "message": f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {files.get('error', 'æœªçŸ¥é”™è¯¯')}"})
        
        # ä½¿ç”¨é«˜çº§è¿‡æ»¤å‡½æ•°è¿‡æ»¤æ–‡ä»¶
        filtered_files = advanced_filter_files(files, filterwords)
        
        # å¦‚æœä¸åŒ…å«æ–‡ä»¶å¤¹ï¼Œè¿›ä¸€æ­¥è¿‡æ»¤æ‰æ–‡ä»¶å¤¹
        if not include_folders:
            filtered_files = [file for file in filtered_files if not file["dir"]]
        
        # æŒ‰ä¸åŒå‘½åæ¨¡å¼å¤„ç†
        preview_results = []
        
        if naming_mode == "sequence":
            # é¡ºåºå‘½åæ¨¡å¼
            # æ’åºæ–‡ä»¶ï¼ˆæŒ‰æ–‡ä»¶åæˆ–ä¿®æ”¹æ—¶é—´ï¼‰
            filtered_files.sort(key=lambda x: sort_file_by_name(x["file_name"]))
            
            sequence = 1
            for file in filtered_files:
                extension = os.path.splitext(file["file_name"])[1] if not file["dir"] else ""
                new_name = pattern.replace("{}", f"{sequence:02d}") + extension
                # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                new_name = apply_subtitle_naming_rule(new_name, config_data["task_settings"])
                preview_results.append({
                    "original_name": file["file_name"],
                    "new_name": new_name,
                    "file_id": file["fid"]
                })
                sequence += 1
                
        elif naming_mode == "episode":
            # å‰§é›†å‘½åæ¨¡å¼
            # è·å–ç”¨æˆ·è¡¥å……çš„å‰§é›†æ¨¡å¼ï¼ˆé»˜è®¤æ¨¡å¼ç”±åç«¯å†…éƒ¨æä¾›ï¼Œè¿™é‡Œåªå¤„ç†ç”¨æˆ·è¡¥å……ï¼‰
            episode_patterns = []
            raw_patterns = config_data.get("episode_patterns", [])
            for p in raw_patterns:
                if isinstance(p, dict) and p.get("regex"):
                    episode_patterns.append(p)
                elif isinstance(p, str):
                    episode_patterns.append({"regex": p})
                
            
            # åº”ç”¨é«˜çº§è¿‡æ»¤è¯è¿‡æ»¤ï¼ˆfilterwords å·²åœ¨å‡½æ•°å¼€å¤´è·å–ï¼‰
            if filterwords:
                # ä½¿ç”¨é«˜çº§è¿‡æ»¤å‡½æ•°
                filtered_files = advanced_filter_files(filtered_files, filterwords)
                # æ ‡è®°è¢«è¿‡æ»¤çš„æ–‡ä»¶
                for item in filtered_files:
                    if item not in filtered_files:
                        item["filtered"] = True
            
            # å¤„ç†æœªè¢«è¿‡æ»¤çš„æ–‡ä»¶
            for file in filtered_files:
                if not file["dir"] and not file.get("filtered"):  # åªå¤„ç†æœªè¢«è¿‡æ»¤çš„éç›®å½•æ–‡ä»¶
                    extension = os.path.splitext(file["file_name"])[1]
                    # ä»æ–‡ä»¶åä¸­æå–é›†å·
                    episode_num = extract_episode_number(file["file_name"], episode_patterns=episode_patterns)

                    if episode_num is not None:
                        new_name = pattern.replace("[]", f"{episode_num:02d}") + extension
                        # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                        new_name = apply_subtitle_naming_rule(new_name, config_data["task_settings"])
                        preview_results.append({
                            "original_name": file["file_name"],
                            "new_name": new_name,
                            "file_id": file["fid"]
                        })
                    else:
                        # æ²¡æœ‰æå–åˆ°é›†å·ï¼Œæ˜¾ç¤ºæ— æ³•è¯†åˆ«çš„æç¤º
                        preview_results.append({
                            "original_name": file["file_name"],
                            "new_name": "Ã— æ— æ³•è¯†åˆ«å‰§é›†ç¼–å·",
                            "file_id": file["fid"]
                        })
        else:
            # æ­£åˆ™å‘½åæ¨¡å¼
            for file in filtered_files:
                try:
                    # åº”ç”¨æ­£åˆ™è¡¨è¾¾å¼
                    if replace:
                        new_name = re.sub(pattern, replace, file["file_name"])
                        # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                        new_name = apply_subtitle_naming_rule(new_name, config_data["task_settings"])
                    else:
                        # å¦‚æœæ²¡æœ‰æä¾›æ›¿æ¢è¡¨è¾¾å¼ï¼Œåˆ™æ£€æŸ¥æ˜¯å¦åŒ¹é…
                        if re.search(pattern, file["file_name"]):
                            new_name = file["file_name"]  # åŒ¹é…ä½†ä¸æ›¿æ¢
                            # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                            new_name = apply_subtitle_naming_rule(new_name, config_data["task_settings"])
                        else:
                            new_name = ""  # è¡¨ç¤ºä¸åŒ¹é…
                            
                    preview_results.append({
                        "original_name": file["file_name"],
                        "new_name": new_name if new_name != file["file_name"] else "",  # å¦‚æœæ²¡æœ‰æ”¹å˜ï¼Œè¿”å›ç©ºè¡¨ç¤ºä¸é‡å‘½å
                        "file_id": file["fid"]
                    })
                except Exception as e:
                    # æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯
                    preview_results.append({
                        "original_name": file["file_name"],
                        "new_name": "",  # è¡¨ç¤ºæ— æ³•é‡å‘½å
                        "file_id": file["fid"],
                        "error": str(e)
                    })
        
        return jsonify({
            "success": True, 
            "data": preview_results
        })
        
    except Exception as e:
        logging.error(f">>> é¢„è§ˆé‡å‘½åæ—¶å‡ºé”™: {str(e)}")
        return jsonify({"success": False, "message": f"é¢„è§ˆé‡å‘½åæ—¶å‡ºé”™: {str(e)}"})


# æ‰¹é‡é‡å‘½å
@app.route("/batch_rename", methods=["POST"])
def batch_rename():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    # è·å–è¯·æ±‚å‚æ•°
    data = request.json
    files = data.get("files", [])
    account_index = int(data.get("account_index", 0))  # æ–°å¢è´¦å·ç´¢å¼•å‚æ•°

    if not files:
        return jsonify({"success": False, "message": "æ²¡æœ‰æ–‡ä»¶éœ€è¦é‡å‘½å"})

    try:
        # éªŒè¯è´¦å·ç´¢å¼•
        if account_index < 0 or account_index >= len(config_data["cookie"]):
            return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

        # åˆå§‹åŒ–å¤¸å…‹ç½‘ç›˜å®¢æˆ·ç«¯
        account = Quark(config_data["cookie"][account_index], account_index)
        
        # æ‰¹é‡é‡å‘½å
        success_count = 0
        failed_files = []
        save_path = data.get("save_path", "")
        batch_time = int(time.time() * 1000)  # æ‰¹æ¬¡æ—¶é—´æˆ³ï¼Œç¡®ä¿åŒä¸€æ‰¹transfer_timeä¸€è‡´
        for file_item in files:
            file_id = file_item.get("file_id")
            new_name = file_item.get("new_name")
            original_name = file_item.get("old_name") or ""
            if file_id and new_name:
                try:
                    result = account.rename(file_id, new_name)
                    if result.get("code") == 0:
                        success_count += 1
                        # è®°å½•é‡å‘½å
                        record_db.add_record(
                            task_name="rename",
                            original_name=original_name,
                            renamed_to=new_name,
                            file_size=0,
                            modify_date=int(time.time()),
                            file_id=file_id,
                            file_type="file",
                            save_path=save_path,
                            transfer_time=batch_time
                        )
                    else:
                        failed_files.append({
                            "file_id": file_id,
                            "new_name": new_name,
                            "error": result.get("message", "æœªçŸ¥é”™è¯¯")
                        })
                except Exception as e:
                    failed_files.append({
                        "file_id": file_id,
                        "new_name": new_name,
                        "error": str(e)
                    })
        
        # å¦‚æœæœ‰æˆåŠŸé‡å‘½åçš„æ–‡ä»¶ï¼Œè§¦å‘SSEé€šçŸ¥
        if success_count > 0:
            notify_calendar_changed('batch_rename_completed')
        
        return jsonify({
            "success": True, 
            "message": f"æˆåŠŸé‡å‘½å {success_count} ä¸ªæ–‡ä»¶ï¼Œå¤±è´¥ {len(failed_files)} ä¸ª",
            "success_count": success_count,
            "failed_files": failed_files
        })
        
    except Exception as e:
        logging.error(f">>> æ‰¹é‡é‡å‘½åæ—¶å‡ºé”™: {str(e)}")
        return jsonify({"success": False, "message": f"æ‰¹é‡é‡å‘½åæ—¶å‡ºé”™: {str(e)}"})


# æ’¤é”€é‡å‘½åæ¥å£
@app.route("/undo_rename", methods=["POST"])
def undo_rename():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    data = request.json
    save_path = data.get("save_path", "")
    account_index = int(data.get("account_index", 0))  # æ–°å¢è´¦å·ç´¢å¼•å‚æ•°

    if not save_path:
        return jsonify({"success": False, "message": "ç¼ºå°‘ç›®å½•å‚æ•°"})

    try:
        # éªŒè¯è´¦å·ç´¢å¼•
        if account_index < 0 or account_index >= len(config_data["cookie"]):
            return jsonify({"success": False, "message": "è´¦å·ç´¢å¼•æ— æ•ˆ"})

        account = Quark(config_data["cookie"][account_index], account_index)
        # æŸ¥è¯¢è¯¥ç›®å½•ä¸‹æœ€è¿‘ä¸€æ¬¡é‡å‘½åï¼ˆæŒ‰transfer_timeåˆ†ç»„ï¼Œtask_name=renameï¼‰
        records = record_db.get_records_by_save_path(save_path)
        rename_records = [r for r in records if r["task_name"] == "rename"]
        if not rename_records:
            return jsonify({"success": False, "message": "æ²¡æœ‰å¯æ’¤é”€çš„é‡å‘½åè®°å½•"})
        # æ‰¾åˆ°æœ€è¿‘ä¸€æ‰¹ï¼ˆtransfer_timeæœ€å¤§å€¼ï¼‰
        latest_time = max(r["transfer_time"] for r in rename_records)
        latest_batch = [r for r in rename_records if r["transfer_time"] == latest_time]
        success_count = 0
        failed_files = []
        deleted_ids = []
        for rec in latest_batch:
            file_id = rec["file_id"]
            old_name = rec["original_name"]
            try:
                result = account.rename(file_id, old_name)
                if result.get("code") == 0:
                    success_count += 1
                    deleted_ids.append(rec["id"])
                else:
                    failed_files.append({
                        "file_id": file_id,
                        "old_name": old_name,
                        "error": result.get("message", "æœªçŸ¥é”™è¯¯")
                    })
            except Exception as e:
                failed_files.append({
                    "file_id": file_id,
                    "old_name": old_name,
                    "error": str(e)
                })
        # æ’¤é”€æˆåŠŸçš„ï¼Œç›´æ¥åˆ é™¤å¯¹åº”renameè®°å½•
        for rid in deleted_ids:
            record_db.delete_record(rid)
        return jsonify({
            "success": True,
            "message": f"æˆåŠŸæ’¤é”€ {success_count} ä¸ªæ–‡ä»¶é‡å‘½åï¼Œå¤±è´¥ {len(failed_files)} ä¸ª",
            "success_count": success_count,
            "failed_files": failed_files
        })
    except Exception as e:
        logging.error(f">>> æ’¤é”€é‡å‘½åæ—¶å‡ºé”™: {str(e)}")
        return jsonify({"success": False, "message": f"æ’¤é”€é‡å‘½åæ—¶å‡ºé”™: {str(e)}"})


@app.route("/api/has_rename_record")
def has_rename_record():
    save_path = request.args.get("save_path", "")
    db = RecordDB()
    records = db.get_records_by_save_path(save_path)
    has_rename = any(r["task_name"] == "rename" for r in records)
    return jsonify({"has_rename": has_rename})


# æ‰‹åŠ¨åŒæ­¥ä»»åŠ¡é…ç½®ä¸æ•°æ®åº“ç»‘å®šå…³ç³»
@app.route("/api/calendar/sync_task_config", methods=["POST"])
def sync_task_config_api():
    """æ‰‹åŠ¨è§¦å‘ä»»åŠ¡é…ç½®ä¸æ•°æ®åº“ç»‘å®šå…³ç³»çš„åŒæ­¥"""
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    try:
        success = sync_task_config_with_database_bindings()
        if success:
            return jsonify({"success": True, "message": "åŒæ­¥å®Œæˆ"})
        else:
            return jsonify({"success": False, "message": "æ²¡æœ‰éœ€è¦åŒæ­¥çš„æ•°æ®"})
    except Exception as e:
        return jsonify({"success": False, "message": f"åŒæ­¥å¤±è´¥: {str(e)}"})

# æ‰‹åŠ¨åŒæ­¥å†…å®¹ç±»å‹æ•°æ®
@app.route("/api/calendar/sync_content_type", methods=["POST"])
def sync_content_type_api():
    """æ‰‹åŠ¨è§¦å‘å†…å®¹ç±»å‹æ•°æ®åŒæ­¥"""
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    
    try:
        success = sync_content_type_between_config_and_database()
        if success:
            return jsonify({"success": True, "message": "å†…å®¹ç±»å‹åŒæ­¥å®Œæˆ"})
        else:
            return jsonify({"success": False, "message": "æ²¡æœ‰éœ€è¦åŒæ­¥çš„å†…å®¹ç±»å‹æ•°æ®"})
    except Exception as e:
        return jsonify({"success": False, "message": f"å†…å®¹ç±»å‹åŒæ­¥å¤±è´¥: {str(e)}"})

# è¿½å‰§æ—¥å†APIè·¯ç”±
@app.route("/api/calendar/tasks")
def get_calendar_tasks():
    """è·å–è¿½å‰§æ—¥å†ä»»åŠ¡ä¿¡æ¯"""
    try:
        logging.debug("è¿›å…¥get_calendar_taskså‡½æ•°")
        logging.debug(f"config_dataç±»å‹: {type(config_data)}")
        logging.debug(f"config_dataå†…å®¹: {config_data}")
        
        # è·å–ä»»åŠ¡åˆ—è¡¨
        tasks = config_data.get('tasklist', [])
        
        # è·å–ä»»åŠ¡çš„æœ€è¿‘è½¬å­˜æ–‡ä»¶ä¿¡æ¯
        db = RecordDB()
        cursor = db.conn.cursor()
        
        # è·å–æ‰€æœ‰ä»»åŠ¡çš„æœ€æ–°è½¬å­˜æ—¶é—´
        query = """
        SELECT task_name, MAX(transfer_time) as latest_transfer_time
        FROM transfer_records
        WHERE task_name NOT IN ('rename', 'undo_rename')
        GROUP BY task_name
        """
        cursor.execute(query)
        latest_times = cursor.fetchall()
        
        task_latest_files = {}
        
        for task_name, latest_time in latest_times:
            if latest_time:
                # è·å–è¯¥ä»»åŠ¡åœ¨æœ€æ–°è½¬å­˜æ—¶é—´é™„è¿‘çš„æ‰€æœ‰æ–‡ä»¶
                time_window = 60000  # 60ç§’çš„æ—¶é—´çª—å£ï¼ˆæ¯«ç§’ï¼‰
                query = """
                SELECT renamed_to, original_name, transfer_time, modify_date
                FROM transfer_records
                WHERE task_name = ? AND transfer_time >= ? AND transfer_time <= ?
                ORDER BY id DESC
                """
                cursor.execute(query, (task_name, latest_time - time_window, latest_time + time_window))
                files = cursor.fetchall()
                
                if files:
                    if len(files) == 1:
                        best_file = files[0][0]  # renamed_to
                    else:
                        # å¦‚æœæœ‰å¤šä¸ªæ–‡ä»¶ï¼Œä½¿ç”¨å…¨å±€æ’åºå‡½æ•°è¿›è¡Œæ’åº
                        file_list = []
                        for renamed_to, original_name, transfer_time, modify_date in files:
                            file_info = {
                                'file_name': renamed_to,
                                'original_name': original_name,
                                'updated_at': transfer_time
                            }
                            file_list.append(file_info)
                        
                        try:
                            sorted_files = sorted(file_list, key=sort_file_by_name)
                            best_file = sorted_files[-1]['file_name']
                        except Exception:
                            best_file = files[0][0]
                    
                    # å»é™¤æ‰©å±•åå¹¶å¤„ç†å­£æ•°é›†æ•°ä¿¡æ¯
                    if best_file:
                        file_name_without_ext = os.path.splitext(best_file)[0]
                        processed_name = process_season_episode_info(file_name_without_ext, task_name)
                        task_latest_files[task_name] = processed_name
        
        db.close()
        
        # æå–ä»»åŠ¡ä¿¡æ¯
        logging.debug("å¼€å§‹æå–ä»»åŠ¡ä¿¡æ¯")
        logging.debug(f"tasksæ•°é‡: {len(tasks)}")
        logging.debug(f"task_latest_filesæ•°é‡: {len(task_latest_files)}")
        
        try:
            extractor = TaskExtractor()
            logging.debug("TaskExtractoråˆ›å»ºæˆåŠŸ")
            tasks_info = extractor.extract_all_tasks_info(tasks, task_latest_files)
            logging.debug("extract_all_tasks_infoè°ƒç”¨æˆåŠŸ")
        except Exception as e:
            logging.debug(f"TaskExtractorç›¸å…³æ“ä½œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
        
        logging.debug(f"æå–çš„ä»»åŠ¡ä¿¡æ¯æ•°é‡: {len(tasks_info)}")
        if tasks_info:
            logging.debug(f"ç¬¬ä¸€ä¸ªä»»åŠ¡ä¿¡æ¯: {tasks_info[0]}")

        # é¦–å…ˆåŒæ­¥æ•°æ®åº“ç»‘å®šå…³ç³»åˆ°ä»»åŠ¡é…ç½®
        sync_task_config_with_database_bindings()
        
        # åŒæ­¥å†…å®¹ç±»å‹æ•°æ®
        sync_content_type_between_config_and_database()
        
        # åŸºäº tmdb ç»‘å®šè¡¥å……"å®é™…åŒ¹é…ç»“æœ"ï¼ˆshow åç§°/å¹´ä»½/æœ¬åœ°æµ·æŠ¥ï¼‰
        try:
            from app.sdk.db import CalendarDB
            cal_db = CalendarDB()
            enriched = []
            # å…ˆè·å–æ‰€æœ‰ shows æ•°æ®ï¼Œç”¨äºæŒ‰åç§°åŒ¹é…
            cursor = cal_db.conn.cursor()
            cursor.execute('SELECT tmdb_id, name, year, poster_local_path, bound_task_names FROM shows')
            all_shows = cursor.fetchall()
            shows_by_name = {s[1]: {'tmdb_id': s[0], 'name': s[1], 'year': s[2], 'poster_local_path': s[3], 'bound_task_names': s[4]} for s in all_shows}
            
            for idx, t in enumerate(tasks_info):
                # 1) ä¼˜å…ˆé€šè¿‡ calendar_info.match.tmdb_id æŸ¥æ‰¾
                raw = tasks[idx] if idx < len(tasks) else None
                cal = (raw or {}).get('calendar_info') or {}
                match = cal.get('match') or {}
                tmdb_id = match.get('tmdb_id')
                
                task_name = t.get('task_name', '').strip()
                matched_show = None
                
                # ä¼˜å…ˆé€šè¿‡ä»»åŠ¡çš„ TMDB åŒ¹é…ç»“æœæŸ¥æ‰¾èŠ‚ç›®
                if tmdb_id:
                    try:
                        show = cal_db.get_show(int(tmdb_id)) or {}
                        if show:
                            matched_show = show
                            logging.debug(f"é€šè¿‡ä»»åŠ¡ TMDB åŒ¹é…ç»“æœæ‰¾åˆ°èŠ‚ç›® - ä»»åŠ¡: '{task_name}', tmdb_id: {tmdb_id}, èŠ‚ç›®: '{show.get('name', '')}'")
                    except Exception as e:
                        logging.debug(f"é€šè¿‡ä»»åŠ¡ TMDB åŒ¹é…ç»“æœæŸ¥æ‰¾å¤±è´¥ - ä»»åŠ¡: '{task_name}', tmdb_id: {tmdb_id}, é”™è¯¯: {e}")
                        pass
                else:
                    logging.debug(f"ä»»åŠ¡é…ç½®ä¸­æ—  TMDB åŒ¹é…ç»“æœï¼Œå°è¯•é€šè¿‡å·²ç»‘å®šå…³ç³»æŸ¥æ‰¾ - ä»»åŠ¡: '{task_name}'")
                
                # 2) å¦‚æœæ‰¾åˆ°åŒ¹é…çš„èŠ‚ç›®ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦å»ºç«‹ç»‘å®šå…³ç³»
                if matched_show:
                    # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²ç»ç»‘å®šåˆ°è¯¥èŠ‚ç›®ï¼Œé¿å…é‡å¤ç»‘å®š
                    bound_tasks = cal_db.get_bound_tasks_for_show(matched_show['tmdb_id'])
                    # æ¸…ç†ç©ºæ ¼ï¼Œç¡®ä¿æ¯”è¾ƒå‡†ç¡®
                    bound_tasks_clean = [task.strip() for task in bound_tasks if task.strip()]
                    needs_binding = task_name not in bound_tasks_clean
                    
                    logging.debug(f"æ£€æŸ¥ç»‘å®šçŠ¶æ€ - ä»»åŠ¡: '{task_name}', å·²ç»‘å®šä»»åŠ¡: {bound_tasks_clean}, éœ€è¦ç»‘å®š: {needs_binding}")
                    
                    if needs_binding:
                        # å»ºç«‹ä»»åŠ¡ä¸èŠ‚ç›®çš„ç»‘å®šå…³ç³»ï¼ŒåŒæ—¶è®¾ç½®å†…å®¹ç±»å‹
                        task_content_type = t.get('content_type', '')
                        cal_db.bind_task_and_content_type(matched_show['tmdb_id'], task_name, task_content_type)
                        logging.debug(f"æˆåŠŸç»‘å®šä»»åŠ¡åˆ°èŠ‚ç›® - ä»»åŠ¡: '{task_name}', èŠ‚ç›®: '{matched_show['name']}', tmdb_id: {matched_show['tmdb_id']}")
                    else:
                        logging.debug(f"ä»»åŠ¡å·²ç»‘å®šåˆ°èŠ‚ç›®ï¼Œè·³è¿‡é‡å¤ç»‘å®š - ä»»åŠ¡: '{task_name}', èŠ‚ç›®: '{matched_show['name']}', tmdb_id: {matched_show['tmdb_id']}")
                    
                    t['match_tmdb_id'] = matched_show['tmdb_id']
                    t['matched_show_name'] = matched_show['name']
                    t['matched_year'] = matched_show['year']
                    t['matched_poster_local_path'] = matched_show['poster_local_path']
                    # æä¾›æœ€æ–°å­£æ•°ç”¨äºå‰ç«¯å±•ç¤º
                    try:
                        t['matched_latest_season_number'] = matched_show.get('latest_season_number')
                    except Exception:
                        pass
                    # ä»æ•°æ®åº“è·å–å®é™…çš„å†…å®¹ç±»å‹ï¼ˆå¦‚æœå·²è®¾ç½®ï¼‰
                    db_content_type = cal_db.get_show_content_type(matched_show['tmdb_id'])
                    t['matched_content_type'] = db_content_type if db_content_type else t.get('content_type', '')
                    # ä¼˜å…ˆä¿æŒä»»åŠ¡é…ç½®ä¸­çš„ç±»å‹ï¼›ä»…å½“ä»»åŠ¡æœªè®¾ç½®ä»»ä½•ç±»å‹æ—¶ï¼Œå›é€€ä¸ºæ•°æ®åº“ç±»å‹
                    extracted_ct = ((t.get('calendar_info') or {}).get('extracted') or {}).get('content_type')
                    config_ct = extracted_ct or t.get('content_type')
                    if not (config_ct and str(config_ct).strip()):
                        if t.get('matched_content_type'):
                            t['content_type'] = t['matched_content_type']
                else:
                    # å¦‚æœä»»åŠ¡é…ç½®ä¸­æ²¡æœ‰ TMDB åŒ¹é…ç»“æœï¼Œæ£€æŸ¥æ˜¯å¦å·²é€šè¿‡å…¶ä»–æ–¹å¼ç»‘å®šåˆ°èŠ‚ç›®
                    # é€šè¿‡ä»»åŠ¡åç§°åœ¨æ•°æ®åº“ä¸­æœç´¢å·²ç»‘å®šçš„èŠ‚ç›®
                    try:
                        cursor.execute('SELECT tmdb_id, name, year, poster_local_path FROM shows WHERE bound_task_names LIKE ?', (f'%{task_name}%',))
                        bound_show = cursor.fetchone()
                        if bound_show:
                            t['match_tmdb_id'] = bound_show[0]
                            t['matched_show_name'] = bound_show[1]
                            t['matched_year'] = bound_show[2]
                            t['matched_poster_local_path'] = bound_show[3]
                            # æŸ¥è¯¢å®Œæ•´ä¿¡æ¯ä»¥æä¾›æœ€æ–°å­£æ•°
                            try:
                                full_show = cal_db.get_show(int(bound_show[0]))
                                if full_show and 'latest_season_number' in full_show:
                                    t['matched_latest_season_number'] = full_show['latest_season_number']
                            except Exception:
                                pass
                            # ä»æ•°æ®åº“è·å–å®é™…çš„å†…å®¹ç±»å‹ï¼ˆå¦‚æœå·²è®¾ç½®ï¼‰
                            db_content_type = cal_db.get_show_content_type(bound_show[0])
                            t['matched_content_type'] = db_content_type if db_content_type else t.get('content_type', '')
                            # ä¼˜å…ˆä»»åŠ¡é…ç½®ç±»å‹ï¼›ä»…åœ¨æœªé…ç½®ç±»å‹æ—¶ç”¨æ•°æ®åº“ç±»å‹
                            extracted_ct = ((t.get('calendar_info') or {}).get('extracted') or {}).get('content_type')
                            config_ct = extracted_ct or t.get('content_type')
                            if not (config_ct and str(config_ct).strip()):
                                if t.get('matched_content_type'):
                                    t['content_type'] = t['matched_content_type']
                            
                            logging.debug(f"é€šè¿‡å·²ç»‘å®šå…³ç³»æ‰¾åˆ°èŠ‚ç›® - ä»»åŠ¡: '{task_name}', èŠ‚ç›®: '{bound_show[1]}', tmdb_id: {bound_show[0]}")
                        else:
                            t['match_tmdb_id'] = None
                            t['matched_show_name'] = ''
                            t['matched_year'] = ''
                            t['matched_poster_local_path'] = ''
                            t['matched_content_type'] = t.get('content_type', '')
                            
                            logging.debug(f"ä»»åŠ¡æœªç»‘å®šåˆ°ä»»ä½•èŠ‚ç›® - ä»»åŠ¡: '{task_name}'")
                    except Exception as e:
                        logging.debug(f"æœç´¢å·²ç»‘å®šèŠ‚ç›®å¤±è´¥ - ä»»åŠ¡: '{task_name}', é”™è¯¯: {e}")
                        t['match_tmdb_id'] = None
                        t['matched_show_name'] = ''
                        t['matched_year'] = ''
                        t['matched_poster_local_path'] = ''
                        t['matched_content_type'] = t.get('content_type', '')
                enriched.append(t)
            tasks_info = enriched
        except Exception as _e:
            # è‹¥è¡¥å……å¤±è´¥ï¼Œä¸å½±å“ä¸»æµç¨‹
            print(f"è¡¥å……åŒ¹é…ç»“æœå¤±è´¥: {_e}")
            pass

        return jsonify({
            'success': True,
            'data': {
                # è¿”å›å…¨éƒ¨ä»»åŠ¡ï¼ˆåŒ…æ‹¬æœªåŒ¹é…/æœªæå–å‰§åçš„ï¼‰ï¼Œç”¨äºå†…å®¹ç®¡ç†é¡µæ˜¾ç¤º
                'tasks': enrich_tasks_with_calendar_meta(tasks_info),
                'content_types': extractor.get_content_types_with_content([t for t in tasks_info if t.get('show_name')])
            }
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–è¿½å‰§æ—¥å†ä»»åŠ¡ä¿¡æ¯å¤±è´¥: {str(e)}',
            'data': {'tasks': [], 'content_types': []}
        })

@app.route("/api/calendar/episodes")
def get_calendar_episodes():
    """è·å–æŒ‡å®šæ—¥æœŸèŒƒå›´çš„å‰§é›†æ’­å‡ºä¿¡æ¯"""
    try:
        
        start_date = request.args.get('start_date')
        end_date = request.args.get('end_date')
        content_type = request.args.get('content_type', '')
        show_name = request.args.get('show_name', '')
        
        if not start_date or not end_date:
            return jsonify({
                'success': False,
                'message': 'è¯·æä¾›å¼€å§‹å’Œç»“æŸæ—¥æœŸ',
                'data': {'episodes': []}
            })
        
        # è·å–TMDBé…ç½®
        tmdb_api_key = config_data.get('tmdb_api_key', '')
        if not tmdb_api_key:
            return jsonify({
                'success': False,
                'message': 'TMDB APIæœªé…ç½®',
                'data': {'episodes': []}
            })
        
        # è·å–ä»»åŠ¡ä¿¡æ¯
        tasks = config_data.get('tasklist', [])
        extractor = TaskExtractor()
        tasks_info = extractor.extract_all_tasks_info(tasks, {})
        
        # è¿‡æ»¤ä»»åŠ¡
        if content_type:
            tasks_info = [task for task in tasks_info if task['content_type'] == content_type]
        if show_name:
            tasks_info = [task for task in tasks_info if show_name.lower() in task['show_name'].lower()]
        
        # è·å–å‰§é›†ä¿¡æ¯
        poster_language = get_poster_language_setting()
        tmdb_service = TMDBService(tmdb_api_key, poster_language)
        all_episodes = []
        
        for task_info in tasks_info:
            if task_info['show_name'] and task_info['year']:
                show_data = tmdb_service.search_and_get_episodes(
                    task_info['show_name'], 
                    task_info['year']
                )
                if show_data:
                    # è·å–å‰§é›†çš„æµ·æŠ¥ä¿¡æ¯
                    show_poster_path = show_data['show_info'].get('poster_path', '')
                    
                    # è¿‡æ»¤æ—¥æœŸèŒƒå›´å†…çš„å‰§é›†
                    for episode in show_data['episodes']:
                        # ç¡®ä¿episodeæœ‰air_dateå­—æ®µ
                        if episode.get('air_date') and start_date <= episode['air_date'] <= end_date:
                            episode['task_info'] = {
                                'task_name': task_info['task_name'],
                                'content_type': task_info['content_type'],
                                'progress': task_info
                            }
                            # æ·»åŠ æµ·æŠ¥è·¯å¾„ä¿¡æ¯
                            episode['poster_path'] = show_poster_path
                            all_episodes.append(episode)
        
        # æŒ‰æ’­å‡ºæ—¥æœŸæ’åº
        all_episodes.sort(key=lambda x: x.get('air_date', ''))
        
        return jsonify({
            'success': True,
            'data': {
                'episodes': all_episodes,
                'total': len(all_episodes)
            }
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–å‰§é›†æ’­å‡ºä¿¡æ¯å¤±è´¥: {str(e)}',
            'data': {'episodes': [], 'total': 0}
        })


# åˆå§‹åŒ–ï¼šä¸ºä»»åŠ¡å†™å…¥ shows/seasonsï¼Œä¸‹è½½æµ·æŠ¥æœ¬åœ°åŒ–
def process_new_tasks_async():
    """å¼‚æ­¥å¤„ç†æ–°ä»»åŠ¡çš„å…ƒæ•°æ®åŒ¹é…å’Œæµ·æŠ¥ä¸‹è½½ï¼Œä¸é˜»å¡å‰ç«¯å“åº”"""
    try:
        tmdb_api_key = config_data.get('tmdb_api_key', '')
        if not tmdb_api_key:
            return

        poster_language = get_poster_language_setting()
        tmdb_service = TMDBService(tmdb_api_key, poster_language)
        cal_db = CalendarDB()

        tasks = config_data.get('tasklist', [])
        # æ”¶é›†éœ€è¦å¤„ç†çš„ä»»åŠ¡
        tasks_to_process = []
        for task in tasks:
            # åªå¤„ç†æ²¡æœ‰å®Œæ•´å…ƒæ•°æ®çš„ä»»åŠ¡
            cal = (task or {}).get('calendar_info') or {}
            match = cal.get('match') or {}
            extracted = cal.get('extracted') or {}
            tmdb_id = match.get('tmdb_id')
            
            # å¦‚æœå·²ç»æœ‰å®Œæ•´çš„å…ƒæ•°æ®ï¼Œè·³è¿‡
            if tmdb_id and match.get('matched_show_name'):
                continue
                
            tasks_to_process.append(task)

        # å¦‚æœæ²¡æœ‰éœ€è¦å¤„ç†çš„ä»»åŠ¡ï¼Œç›´æ¥è¿”å›
        if not tasks_to_process:
            return

        # å¹¶è¡Œå¤„ç†ä»»åŠ¡
        import concurrent.futures
        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
            futures = []
            for task in tasks_to_process:
                future = executor.submit(process_single_task_async, task, tmdb_service, cal_db)
                futures.append(future)
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            for future in concurrent.futures.as_completed(futures):
                try:
                    future.result()
                except Exception as e:
                    logging.warning(f"å¤„ç†ä»»åŠ¡å¤±è´¥: {e}")

    except Exception as e:
        logging.warning(f"å¼‚æ­¥å¤„ç†æ–°ä»»åŠ¡å¤±è´¥: {e}")


def process_single_task_async(task, tmdb_service, cal_db):
    """å¤„ç†å•ä¸ªä»»åŠ¡çš„å…ƒæ•°æ®åŒ¹é…å’Œæµ·æŠ¥ä¸‹è½½"""
    try:
        cal = (task or {}).get('calendar_info') or {}
        match = cal.get('match') or {}
        extracted = cal.get('extracted') or {}
        tmdb_id = match.get('tmdb_id')
        
        # å¦‚æœè¿˜æ²¡æœ‰æå–ä¿¡æ¯ï¼Œå…ˆæå–
        if not extracted.get('show_name'):
            extractor = TaskExtractor()
            task_name = task.get('taskname') or task.get('task_name') or ''
            save_path = task.get('savepath', '')
            info = extractor.extract_show_info_from_path(save_path)
            extracted = {
                'show_name': info.get('show_name', ''),
                'year': info.get('year', ''),
                'content_type': info.get('type', 'other'),
            }
            cal['extracted'] = extracted
            task['calendar_info'] = cal

        # å¦‚æœè¿˜æ²¡æœ‰ TMDB åŒ¹é…ï¼Œè¿›è¡ŒåŒ¹é…
        if not tmdb_id and extracted.get('show_name'):
            try:
                search = tmdb_service.search_tv_show(extracted.get('show_name'), extracted.get('year') or None)
                if search and search.get('id'):
                    tmdb_id = search['id']
                    details = tmdb_service.get_tv_show_details(tmdb_id) or {}
                    seasons = details.get('seasons', [])
                    logging.debug(f"process_single_task_async - TMDBå­£æ•°æ•°æ®: {seasons}")
                    
                    # é€‰æ‹©å·²æ’­å‡ºçš„å­£ä¸­æœ€æ–°çš„ä¸€å­£
                    # ä½¿ç”¨æœ‰æ•ˆæ—¥æœŸåˆ¤æ–­å­£æ˜¯å¦å·²æ’­å‡ºï¼ˆè€ƒè™‘æ’­å‡ºé›†æ•°åˆ·æ–°æ—¶é—´ï¼‰
                    effective_date_str = get_effective_date_for_aired_count()
                    effective_date = datetime.strptime(effective_date_str, '%Y-%m-%d').date()
                    latest_season_number = 0
                    latest_air_date = None
                    
                    for s in seasons:
                        sn = s.get('season_number', 0)
                        air_date = s.get('air_date')
                        logging.debug(f"process_single_task_async - å­£æ•°: {sn}, æ’­å‡ºæ—¥æœŸ: {air_date}, ç±»å‹: {type(sn)}")
                        
                        # åªè€ƒè™‘å·²æ’­å‡ºçš„å­£ï¼ˆæœ‰air_dateä¸”æ—©äºæˆ–ç­‰äºæœ‰æ•ˆæ—¥æœŸï¼‰
                        if sn and sn > 0 and air_date:  # æ’é™¤ç¬¬0å­£ï¼ˆç‰¹æ®Šå­£ï¼‰
                            try:
                                season_air_date = datetime.strptime(air_date, '%Y-%m-%d').date()
                                if season_air_date <= effective_date:
                                    # é€‰æ‹©æ’­å‡ºæ—¥æœŸæœ€æ–°çš„å­£
                                    if latest_air_date is None or season_air_date > latest_air_date:
                                        latest_season_number = sn
                                        latest_air_date = season_air_date
                            except (ValueError, TypeError):
                                # æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè·³è¿‡
                                continue
                    
                    logging.debug(f"process_single_task_async - è®¡ç®—å‡ºçš„æœ€æ–°å·²æ’­å­£æ•°: {latest_season_number}")
                    
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å·²æ’­å‡ºçš„å­£ï¼Œå›é€€åˆ°ç¬¬1å­£
                    if latest_season_number == 0:
                        latest_season_number = 1
                        logging.debug(f"process_single_task_async - æ²¡æœ‰æ‰¾åˆ°å·²æ’­å‡ºçš„å­£ï¼Œå›é€€åˆ°ç¬¬1å­£: {latest_season_number}")

                    chinese_title = tmdb_service.get_chinese_title_with_fallback(tmdb_id, extracted.get('show_name', ''))
                    
                    cal['match'] = {
                        'matched_show_name': chinese_title,
                        'matched_year': (details.get('first_air_date') or '')[:4],
                        'tmdb_id': tmdb_id,
                        'latest_season_number': latest_season_number,
                        'latest_season_fetch_url': f"/tv/{tmdb_id}/season/{latest_season_number}",
                    }
                    task['calendar_info'] = cal
                    
                    # ç«‹å³é€šçŸ¥å‰ç«¯å…ƒæ•°æ®åŒ¹é…å®Œæˆ
                    try:
                        notify_calendar_changed('edit_metadata')
                    except Exception:
                        pass
                        
            except Exception as e:
                logging.warning(f"TMDB åŒ¹é…å¤±è´¥: task={task.get('taskname', '')}, err={e}")

        # å¦‚æœç°åœ¨æœ‰ TMDB IDï¼Œä¸‹è½½æµ·æŠ¥å¹¶æ›´æ–°æ•°æ®åº“
        if tmdb_id:
            try:
                # é‡æ–°è·å–æ›´æ–°åçš„matchä¿¡æ¯
                updated_match = cal.get('match') or {}
                logging.debug(f"process_single_task_async - æ›´æ–°åçš„matchä¿¡æ¯: {updated_match}")
                details = tmdb_service.get_tv_show_details(tmdb_id) or {}
                name = tmdb_service.get_chinese_title_with_fallback(tmdb_id, extracted.get('show_name', ''))
                first_air = (details.get('first_air_date') or '')[:4]
                raw_status = (details.get('status') or '')
                try:
                    localized_status = tmdb_service.get_localized_show_status(int(tmdb_id), int(updated_match.get('latest_season_number') or 1), raw_status)
                    status = localized_status
                except Exception:
                    status = raw_status
                # ä½¿ç”¨æµ·æŠ¥è¯­è¨€è®¾ç½®è·å–æµ·æŠ¥è·¯å¾„
                poster_path = tmdb_service.get_poster_path_with_language(int(tmdb_id)) if tmdb_service else (details.get('poster_path') or '')
                latest_season_number = updated_match.get('latest_season_number') or 1
                logging.debug(f"process_single_task_async - æœ€ç»ˆä½¿ç”¨çš„å­£æ•°: {latest_season_number}")

                # è·å–ç°æœ‰çš„ç»‘å®šå…³ç³»å’Œå†…å®¹ç±»å‹ï¼Œé¿å…è¢«è¦†ç›–
                existing_show = cal_db.get_show(int(tmdb_id))
                existing_bound_tasks = existing_show.get('bound_task_names', '') if existing_show else ''
                existing_content_type = existing_show.get('content_type', '') if existing_show else ''
                existing_poster_path = existing_show.get('poster_local_path', '') if existing_show else ''
                is_custom_poster = bool(existing_show.get('is_custom_poster', 0)) if existing_show else False
                
                poster_local_path = ''
                if poster_path:
                    poster_local_path = download_poster_local(poster_path, int(tmdb_id), existing_poster_path, is_custom_poster)
                cal_db.upsert_show(int(tmdb_id), name, first_air, status, poster_local_path, int(latest_season_number), 0, existing_bound_tasks, existing_content_type)
                
                # å¦‚æœæµ·æŠ¥è·¯å¾„å‘ç”Ÿå˜åŒ–ï¼Œè§¦å‘å­¤ç«‹æ–‡ä»¶æ¸…ç†
                if poster_local_path and poster_local_path != existing_poster_path:
                    try:
                        cleanup_orphaned_posters()
                    except Exception as e:
                        logging.warning(f"æ¸…ç†å­¤ç«‹æµ·æŠ¥å¤±è´¥: {e}")
                
                # æ›´æ–° seasons è¡¨
                refresh_url = f"/tv/{tmdb_id}/season/{latest_season_number}"
                # å¤„ç†å­£åç§°
                season_name_raw = ''
                try:
                    for s in (details.get('seasons') or []):
                        if int(s.get('season_number') or 0) == int(latest_season_number):
                            season_name_raw = s.get('name') or ''
                            break
                except Exception:
                    season_name_raw = ''
                try:
                    from sdk.tmdb_service import TMDBService as _T
                    season_name_processed = tmdb_service.process_season_name(season_name_raw) if isinstance(tmdb_service, _T) else season_name_raw
                except Exception:
                    season_name_processed = season_name_raw
                cal_db.upsert_season(
                    int(tmdb_id),
                    int(latest_season_number),
                    details_of_season_episode_count(tmdb_service, tmdb_id, latest_season_number),
                    refresh_url,
                    season_name_processed
                )

                # ç«‹å³æ‹‰å–æœ€æ–°ä¸€å­£çš„æ‰€æœ‰é›†å¹¶å†™å…¥æœ¬åœ°ï¼Œä¿è¯å‰ç«¯å¯ç«‹å³è¯»å–
                try:
                    season = tmdb_service.get_tv_show_episodes(int(tmdb_id), int(latest_season_number)) or {}
                    episodes = season.get('episodes', []) or []
                    # æ ¹å› ä¿®å¤ï¼šæ¸…ç†æœ¬åœ°è¯¥å­£ä¸­ TMDB ä¸å­˜åœ¨çš„å¤šä½™é›†
                    try:
                        valid_eps = []
                        for _ep in episodes:
                            try:
                                n = int(_ep.get('episode_number') or 0)
                                if n > 0:
                                    valid_eps.append(n)
                            except Exception:
                                pass
                        cal_db.prune_season_episodes_not_in(int(tmdb_id), int(latest_season_number), valid_eps)
                    except Exception:
                        pass
                    from time import time as _now
                    now_ts = int(_now())
                    for ep in episodes:
                        cal_db.upsert_episode(
                            tmdb_id=int(tmdb_id),
                            season_number=int(latest_season_number),
                            episode_number=int(ep.get('episode_number') or 0),
                            name=ep.get('name') or '',
                            overview=ep.get('overview') or '',
                            air_date=ep.get('air_date') or '',
                            runtime=ep.get('runtime'),
                            ep_type=(ep.get('episode_type') or ep.get('type')),
                            updated_at=now_ts,
                        )
                except Exception as _e:
                    logging.warning(f"å†™å…¥å‰§é›†å¤±è´¥ tmdb_id={tmdb_id}: {_e}")
                
                # ç»‘å®šä»»åŠ¡åˆ°èŠ‚ç›®
                task_final_name = task.get('taskname') or task.get('task_name') or ''
                ct = extracted.get('content_type', '')
                try:
                    cal_db.bind_task_and_content_type(tmdb_id, task_final_name, ct)
                except Exception as e:
                    logging.warning(f"ç»‘å®šä»»åŠ¡å¤±è´¥: {e}")
                
                # ç«‹å³é€šçŸ¥å‰ç«¯æµ·æŠ¥ä¸‹è½½å®Œæˆ
                try:
                    notify_calendar_changed('edit_metadata')
                except Exception:
                    pass
                    
            except Exception as e:
                logging.warning(f"å¤„ç†ä»»åŠ¡æµ·æŠ¥å¤±è´¥: task={task.get('taskname', '')}, err={e}")

    except Exception as e:
        logging.warning(f"å¤„ç†å•ä¸ªä»»åŠ¡å¤±è´¥: task={task.get('taskname', '')}, err={e}")


def do_calendar_bootstrap() -> tuple:
    """å†…éƒ¨æ–¹æ³•ï¼šæ‰§è¡Œæ—¥å†åˆå§‹åŒ–ã€‚è¿”å› (success: bool, message: str)"""
    try:
        ensure_calendar_info_for_tasks()

        tmdb_api_key = config_data.get('tmdb_api_key', '')
        if not tmdb_api_key:
            return False, 'TMDB APIæœªé…ç½®'

        poster_language = get_poster_language_setting()
        tmdb_service = TMDBService(tmdb_api_key, poster_language)
        cal_db = CalendarDB()

        tasks = config_data.get('tasklist', [])
        any_written = False
        for task in tasks:
            cal = (task or {}).get('calendar_info') or {}
            match = cal.get('match') or {}
            extracted = cal.get('extracted') or {}
            tmdb_id = match.get('tmdb_id')
            if not tmdb_id:
                continue

            details = tmdb_service.get_tv_show_details(tmdb_id) or {}
            # ä½¿ç”¨æ–°çš„æ–¹æ³•è·å–ä¸­æ–‡æ ‡é¢˜ï¼Œæ”¯æŒä»åˆ«åä¸­è·å–ä¸­å›½åœ°åŒºçš„åˆ«å
            name = tmdb_service.get_chinese_title_with_fallback(tmdb_id, extracted.get('show_name', ''))
            first_air = (details.get('first_air_date') or '')[:4]
            # å°†åŸå§‹çŠ¶æ€è½¬æ¢ä¸ºæœ¬åœ°åŒ–ä¸­æ–‡ï¼Œä¸”å¯¹ returning_series åœºæ™¯åšæœ¬å­£ç»ˆ/æ’­å‡ºä¸­åˆ¤æ–­
            raw_status = (details.get('status') or '')
            try:
                localized_status = tmdb_service.get_localized_show_status(int(tmdb_id), int(match.get('latest_season_number') or 1), raw_status)
                status = localized_status
            except Exception:
                status = raw_status
            # ä½¿ç”¨æµ·æŠ¥è¯­è¨€è®¾ç½®è·å–æµ·æŠ¥è·¯å¾„
            poster_path = tmdb_service.get_poster_path_with_language(int(tmdb_id)) if tmdb_service else (details.get('poster_path') or '')
            latest_season_number = match.get('latest_season_number') or 1

            # è·å–ç°æœ‰çš„ç»‘å®šå…³ç³»å’Œå†…å®¹ç±»å‹ï¼Œé¿å…è¢«è¦†ç›–
            existing_show = cal_db.get_show(int(tmdb_id))
            existing_bound_tasks = existing_show.get('bound_task_names', '') if existing_show else ''
            existing_content_type = existing_show.get('content_type', '') if existing_show else ''
            existing_poster_path = existing_show.get('poster_local_path', '') if existing_show else ''
            is_custom_poster = bool(existing_show.get('is_custom_poster', 0)) if existing_show else False
            
            poster_local_path = ''
            if poster_path:
                poster_local_path = download_poster_local(poster_path, int(tmdb_id), existing_poster_path, is_custom_poster)
            cal_db.upsert_show(int(tmdb_id), name, first_air, status, poster_local_path, int(latest_season_number), 0, existing_bound_tasks, existing_content_type)
            refresh_url = f"/tv/{tmdb_id}/season/{latest_season_number}"
            # å¤„ç†å­£åç§°
            season_name_raw = ''
            try:
                for s in (details.get('seasons') or []):
                    if int(s.get('season_number') or 0) == int(latest_season_number):
                        season_name_raw = s.get('name') or ''
                        break
            except Exception:
                season_name_raw = ''
            try:
                from sdk.tmdb_service import TMDBService as _T
                season_name_processed = tmdb_service.process_season_name(season_name_raw) if isinstance(tmdb_service, _T) else season_name_raw
            except Exception:
                season_name_processed = season_name_raw
            cal_db.upsert_season(
                int(tmdb_id),
                int(latest_season_number),
                details_of_season_episode_count(tmdb_service, tmdb_id, latest_season_number),
                refresh_url,
                season_name_processed
            )

            # ç«‹å³æ‹‰å–æœ€æ–°ä¸€å­£çš„æ‰€æœ‰é›†å¹¶å†™å…¥æœ¬åœ°ï¼Œä¿è¯å‰ç«¯å¯ç«‹å³è¯»å–
            try:
                season = tmdb_service.get_tv_show_episodes(int(tmdb_id), int(latest_season_number)) or {}
                episodes = season.get('episodes', []) or []
                # æ ¹å› ä¿®å¤ï¼šæ¸…ç†æœ¬åœ°è¯¥å­£ä¸­ TMDB ä¸å­˜åœ¨çš„å¤šä½™é›†
                try:
                    valid_eps = []
                    for _ep in episodes:
                        try:
                            n = int(_ep.get('episode_number') or 0)
                            if n > 0:
                                valid_eps.append(n)
                        except Exception:
                            pass
                    cal_db.prune_season_episodes_not_in(int(tmdb_id), int(latest_season_number), valid_eps)
                except Exception:
                    pass
                from time import time as _now
                now_ts = int(_now())
                for ep in episodes:
                    cal_db.upsert_episode(
                        tmdb_id=int(tmdb_id),
                        season_number=int(latest_season_number),
                        episode_number=int(ep.get('episode_number') or 0),
                        name=ep.get('name') or '',
                        overview=ep.get('overview') or '',
                        air_date=ep.get('air_date') or '',
                        runtime=ep.get('runtime'),
                        ep_type=(ep.get('episode_type') or ep.get('type')),
                        updated_at=now_ts,
                    )
                any_written = True
            except Exception as _e:
                logging.warning(f"bootstrap å†™å…¥å‰§é›†å¤±è´¥ tmdb_id={tmdb_id}: {_e}")
        try:
            if any_written:
                notify_calendar_changed('bootstrap')
        except Exception:
            pass
        return True, 'OK'
    except Exception as e:
        return False, f'bootstrapå¤±è´¥: {str(e)}'


@app.route("/api/calendar/bootstrap", methods=["POST"])
def calendar_bootstrap():
    if not is_login():
        return jsonify({"success": False, "message": "æœªç™»å½•"})
    success, msg = do_calendar_bootstrap()
    return jsonify({"success": success, "message": msg})


def details_of_season_episode_count(tmdb_service: TMDBService, tmdb_id: int, season_number: int) -> int:
    try:
        season = tmdb_service.get_tv_show_episodes(tmdb_id, season_number) or {}
        return len(season.get('episodes', []) or [])
    except Exception:
        return 0


def get_poster_language_setting():
    """è·å–æµ·æŠ¥è¯­è¨€è®¾ç½®"""
    return config_data.get('poster_language', 'zh-CN')

def clear_all_posters():
    """æ¸…ç©ºæ‰€æœ‰æµ·æŠ¥æ–‡ä»¶"""
    try:
        import shutil
        if os.path.exists(CACHE_IMAGES_DIR):
            shutil.rmtree(CACHE_IMAGES_DIR)
            os.makedirs(CACHE_IMAGES_DIR, exist_ok=True)
        return True
    except Exception as e:
        logging.error(f"æ¸…ç©ºæµ·æŠ¥æ–‡ä»¶å¤±è´¥: {e}")
        return False

def cleanup_orphaned_posters():
    """æ¸…ç†å­¤ç«‹çš„æ—§æµ·æŠ¥æ–‡ä»¶ï¼ˆä¸åœ¨æ•°æ®åº“ä¸­çš„æµ·æŠ¥æ–‡ä»¶ï¼‰"""
    try:
        from app.sdk.db import CalendarDB
        cal_db = CalendarDB()
        
        # è·å–æ•°æ®åº“ä¸­æ‰€æœ‰æ­£åœ¨ä½¿ç”¨çš„æµ·æŠ¥è·¯å¾„
        shows = cal_db.get_all_shows()
        used_posters = set()
        for show in shows:
            poster_path = show.get('poster_local_path', '')
            if poster_path and poster_path.startswith('/cache/images/'):
                poster_name = poster_path.replace('/cache/images/', '')
                used_posters.add(poster_name)
        
        # æ‰«æç¼“å­˜ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
        if os.path.exists(CACHE_IMAGES_DIR):
            orphaned_files = []
            for filename in os.listdir(CACHE_IMAGES_DIR):
                if filename not in used_posters:
                    file_path = os.path.join(CACHE_IMAGES_DIR, filename)
                    if os.path.isfile(file_path):
                        orphaned_files.append(file_path)
            
            # åˆ é™¤å­¤ç«‹æ–‡ä»¶
            deleted_count = 0
            for file_path in orphaned_files:
                try:
                    os.remove(file_path)
                    deleted_count += 1
                except Exception as e:
                    logging.warning(f"åˆ é™¤å­¤ç«‹æµ·æŠ¥æ–‡ä»¶å¤±è´¥: {e}")
            
            # åªåœ¨åˆ é™¤äº†æ–‡ä»¶æ—¶æ‰è¾“å‡ºæ—¥å¿—
            if deleted_count > 0:
                logging.info(f"æµ·æŠ¥æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {deleted_count} ä¸ªå­¤ç«‹æ–‡ä»¶")
            return deleted_count > 0
        
        return False
    except Exception as e:
        logging.error(f"æ¸…ç†å­¤ç«‹æµ·æŠ¥å¤±è´¥: {e}")
        return False

def redownload_all_posters():
    """é‡æ–°ä¸‹è½½æ‰€æœ‰æµ·æŠ¥"""
    try:
        from app.sdk.db import CalendarDB
        cal_db = CalendarDB()
        
        # è·å–æ‰€æœ‰èŠ‚ç›®
        shows = cal_db.get_all_shows()
        if not shows:
            return True
            
        tmdb_api_key = config_data.get('tmdb_api_key', '')
        if not tmdb_api_key:
            logging.warning("TMDB APIæœªé…ç½®ï¼Œæ— æ³•é‡æ–°ä¸‹è½½æµ·æŠ¥")
            return False
            
        poster_language = get_poster_language_setting()
        tmdb_service = TMDBService(tmdb_api_key, poster_language)
        
        success_count = 0
        total_count = len(shows)
        
        for show in shows:
            try:
                tmdb_id = show.get('tmdb_id')
                if not tmdb_id:
                    continue
                    
                # è·å–æ–°çš„æµ·æŠ¥è·¯å¾„
                new_poster_path = tmdb_service.get_poster_path_with_language(int(tmdb_id))
                if new_poster_path:
                    # è·å–ç°æœ‰æµ·æŠ¥ä¿¡æ¯
                    existing_poster_path = show.get('poster_local_path', '')
                    is_custom_poster = bool(show.get('is_custom_poster', 0))
                    # ä¸‹è½½æ–°æµ·æŠ¥
                    poster_local_path = download_poster_local(new_poster_path, int(tmdb_id), existing_poster_path, is_custom_poster)
                    if poster_local_path:
                        # æ›´æ–°æ•°æ®åº“ä¸­çš„æµ·æŠ¥è·¯å¾„
                        cal_db.update_show_poster(int(tmdb_id), poster_local_path)
                        success_count += 1
                        # é€šçŸ¥å‰ç«¯è¯¥èŠ‚ç›®æµ·æŠ¥å·²æ›´æ–°
                        try:
                            notify_calendar_changed(f'poster_updated:{int(tmdb_id)}')
                        except Exception:
                            pass
                        
            except Exception as e:
                logging.error(f"é‡æ–°ä¸‹è½½æµ·æŠ¥å¤±è´¥ (TMDB ID: {show.get('tmdb_id')}): {e}")
                continue
                
        # é‡æ–°ä¸‹è½½å®Œæˆåï¼Œæ¸…ç†å­¤ç«‹çš„æ—§æµ·æŠ¥æ–‡ä»¶
        try:
            cleanup_orphaned_posters()
        except Exception as e:
            logging.warning(f"æ¸…ç†å­¤ç«‹æµ·æŠ¥å¤±è´¥: {e}")
        
        return success_count > 0
        
    except Exception as e:
        logging.error(f"é‡æ–°ä¸‹è½½æ‰€æœ‰æµ·æŠ¥å¤±è´¥: {e}")
        return False

def download_poster_local(poster_path: str, tmdb_id: int = None, existing_poster_path: str = None, is_custom_poster: bool = False) -> str:
    """ä¸‹è½½ TMDB æµ·æŠ¥åˆ°æœ¬åœ° static/cache/images ä¸‹ï¼Œç­‰æ¯”ç¼©æ”¾ä¸ºå®½400pxï¼Œè¿”å›ç›¸å¯¹è·¯å¾„ã€‚
    
    Args:
        poster_path: TMDBæµ·æŠ¥è·¯å¾„
        tmdb_id: TMDB IDï¼Œç”¨äºæ£€æŸ¥è‡ªå®šä¹‰æµ·æŠ¥æ ‡è®°
        existing_poster_path: ç°æœ‰çš„æµ·æŠ¥è·¯å¾„ï¼Œç”¨äºæ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        is_custom_poster: æ˜¯å¦ä¸ºè‡ªå®šä¹‰æµ·æŠ¥æ ‡è®°
    """
    try:
        if not poster_path:
            return ''
            
        folder = CACHE_IMAGES_DIR
        # åŸºäº poster_path ç”Ÿæˆæ–‡ä»¶å
        safe_name = poster_path.strip('/').replace('/', '_') or 'poster.jpg'
        file_path = os.path.join(folder, safe_name)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™ç›´æ¥è¿”å›è·¯å¾„
        if os.path.exists(file_path):
            return f"/cache/images/{safe_name}"
        
        # å¦‚æœæä¾›äº†ç°æœ‰æµ·æŠ¥è·¯å¾„ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        if existing_poster_path and tmdb_id is not None:
            existing_file_name = existing_poster_path.replace('/cache/images/', '')
            new_file_name = safe_name
            
            # å¦‚æœæ–‡ä»¶åä¸åŒï¼Œè¯´æ˜TMDBæµ·æŠ¥æœ‰å˜æ›´
            if existing_file_name != new_file_name:
                # æ£€æŸ¥æ˜¯å¦æœ‰è‡ªå®šä¹‰æµ·æŠ¥æ ‡è®°
                if is_custom_poster:
                    return existing_poster_path
                else:
                    # åˆ é™¤æ—§æ–‡ä»¶
                    try:
                        old_file_path = os.path.join(folder, existing_file_name)
                        if os.path.exists(old_file_path):
                            os.remove(old_file_path)
                    except Exception as e:
                        logging.warning(f"åˆ é™¤æ—§æµ·æŠ¥æ–‡ä»¶å¤±è´¥: {e}")
        
        # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œéœ€è¦ä¸‹è½½
        base = "https://image.tmdb.org/t/p/w400"
        url = f"{base}{poster_path}"
        r = requests.get(url, timeout=10)
        if r.status_code != 200:
            return ''
            
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(folder, exist_ok=True)
        
        with open(file_path, 'wb') as f:
            f.write(r.content)
        # è¿”å›ç”¨äºå‰ç«¯å¼•ç”¨çš„ç›¸å¯¹è·¯å¾„ï¼ˆé€šè¿‡ /cache/images æš´éœ²ï¼‰
        return f"/cache/images/{safe_name}"
    except Exception:
        return ''


def download_custom_poster(poster_url: str, tmdb_id: int, target_safe_name: str = None) -> str:
    """ä¸‹è½½è‡ªå®šä¹‰æµ·æŠ¥åˆ°æœ¬åœ°ï¼Œå°½é‡è¦†ç›–åŸæœ‰æµ·æŠ¥æ–‡ä»¶åï¼Œè¿”å›ç›¸å¯¹è·¯å¾„ã€‚

    æ³¨æ„ï¼šä¸å¼•å…¥ä»»ä½•é¢å¤–ä¾èµ–ï¼Œä¸è¿›è¡Œç­‰æ¯”ç¼©æ”¾ã€‚å¦‚éœ€ç¼©æ”¾åº”åœ¨å®¹å™¨å…·å¤‡å·¥å…·æ—¶å†æ‰©å±•ã€‚
    """
    try:
        if not poster_url or not tmdb_id:
            return ''

        folder = CACHE_IMAGES_DIR
        # ç›®æ ‡æ–‡ä»¶åï¼šè‹¥æä¾›åˆ™ä½¿ç”¨ç°æœ‰æ–‡ä»¶åè¦†ç›–ï¼›å¦åˆ™æ ¹æ®å†…å®¹ç±»å‹/URLæ¨æ–­æ‰©å±•å
        default_ext = 'jpg'
        safe_name = (target_safe_name or '').strip()
        if not safe_name:
            # å°è¯•ä» URL æ¨æ–­æ‰©å±•å
            guessed_ext = None
            try:
                from urllib.parse import urlparse
                path = urlparse(poster_url).path
                base = os.path.basename(path)
                if '.' in base:
                    guessed_ext = base.split('.')[-1].lower()
            except Exception:
                guessed_ext = None
            ext = guessed_ext or default_ext
            # ç®€å•æ ‡å‡†åŒ–
            if ext in ('jpeg',):
                ext = 'jpg'
            safe_name = f"poster_{tmdb_id}.{ext}"
        file_path = os.path.join(folder, safe_name)

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(folder, exist_ok=True)

        # å¤„ç† file:// å‰ç¼€
        if poster_url.lower().startswith('file://'):
            poster_url = poster_url[7:]

        # å¤„ç†æœ¬åœ°æ–‡ä»¶è·¯å¾„
        if poster_url.startswith('/') or poster_url.startswith('./'):
            # æœ¬åœ°æ–‡ä»¶è·¯å¾„
            if os.path.exists(poster_url):
                # è‹¥æä¾›äº†ç›®æ ‡åä½†å…¶æ‰©å±•åä¸æºæ–‡ä»¶æ˜æ˜¾ä¸ç¬¦ï¼ˆä¾‹å¦‚æºä¸º .avifï¼‰ï¼Œåˆ™æ”¹ç”¨åŸºäº tmdb_id çš„æ ‡å‡†æ–‡ä»¶åå¹¶åŒ¹é…æ‰©å±•
                try:
                    src_ext = os.path.splitext(poster_url)[1].lower().lstrip('.')
                except Exception:
                    src_ext = ''
                if src_ext in ('jpeg',):
                    src_ext = 'jpg'
                if src_ext in ('jpg', 'png', 'webp', 'avif'):
                    target_ext = os.path.splitext(safe_name)[1].lower().lstrip('.') if '.' in safe_name else ''
                    if target_ext != src_ext:
                        safe_name = f"poster_{tmdb_id}.{src_ext or default_ext}"
                        file_path = os.path.join(folder, safe_name)
                import shutil
                shutil.copy2(poster_url, file_path)
                return f"/cache/images/{safe_name}"
            else:
                logging.warning(f"æœ¬åœ°æµ·æŠ¥æ–‡ä»¶ä¸å­˜åœ¨: {poster_url}")
                return ''
        else:
            # ç½‘ç»œURL
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            r = requests.get(poster_url, timeout=15, headers=headers)
            if r.status_code != 200:
                logging.warning(f"ä¸‹è½½è‡ªå®šä¹‰æµ·æŠ¥å¤±è´¥: {poster_url}, çŠ¶æ€ç : {r.status_code}")
                return ''

            # æ£€æŸ¥å†…å®¹ç±»å‹æ˜¯å¦ä¸ºå›¾ç‰‡ï¼ˆæ— æ³•ä¸¥æ ¼åˆ¤æ–­æ‰©å±•åï¼Œè¿™é‡Œä»…åŸºäºå“åº”å¤´ï¼‰
            content_type = (r.headers.get('content-type') or '').lower()
            if not any(img_type in content_type for img_type in ['image/jpeg', 'image/jpg', 'image/png', 'image/webp', 'image/avif']):
                logging.warning(f"è‡ªå®šä¹‰æµ·æŠ¥URLä¸æ˜¯æœ‰æ•ˆçš„å›¾ç‰‡æ ¼å¼: {poster_url}, å†…å®¹ç±»å‹: {content_type}")
                # ä¸å¼ºåˆ¶å¤±è´¥ï¼Œæ”¾è¡Œä¿å­˜ï¼Œéƒ¨åˆ†æœåŠ¡ä¸è¿”å›æ ‡å‡†content-type
                # return ''

            # è‹¥æœªæŒ‡å®šç›®æ ‡æ–‡ä»¶åï¼Œæˆ–æŒ‡å®šçš„æ‰©å±•ä¸å†…å®¹ç±»å‹ä¸ä¸€è‡´ï¼Œåˆ™æ ¹æ® content-type ä¿®æ­£æ‰©å±•å
            need_fix_ext = False
            if (target_safe_name or '').strip():
                # æ ¡éªŒå·²æœ‰ç›®æ ‡åçš„æ‰©å±•
                current_ext = os.path.splitext(safe_name)[1].lower().lstrip('.') if '.' in safe_name else ''
                if ('image/avif' in content_type and current_ext != 'avif') or \
                   ('image/webp' in content_type and current_ext != 'webp') or \
                   (('image/jpeg' in content_type or 'image/jpg' in content_type) and current_ext not in ('jpg','jpeg')) or \
                   ('image/png' in content_type and current_ext != 'png'):
                    need_fix_ext = True
            if not (target_safe_name or '').strip() or need_fix_ext:
                ext_map = {
                    'image/jpeg': 'jpg',
                    'image/jpg': 'jpg',
                    'image/png': 'png',
                    'image/webp': 'webp',
                    'image/avif': 'avif',
                }
                chosen_ext = None
                for k, v in ext_map.items():
                    if k in content_type:
                        chosen_ext = v
                        break
                if chosen_ext:
                    base_no_ext = f"poster_{tmdb_id}"
                    safe_name = f"{base_no_ext}.{chosen_ext}"
                    file_path = os.path.join(folder, safe_name)

            with open(file_path, 'wb') as f:
                f.write(r.content)

            # è‡ªå®šä¹‰æµ·æŠ¥ä¿å­˜æˆåŠŸï¼ˆé™é»˜ï¼‰
            return f"/cache/images/{safe_name}"

    except Exception as e:
        logging.error(f"ä¸‹è½½è‡ªå®šä¹‰æµ·æŠ¥å¤±è´¥: {e}")
        return ''


# åˆ·æ–°ï¼šæ‹‰å–æœ€æ–°ä¸€å­£æ‰€æœ‰é›†ï¼ŒæŒ‰æœ‰æ—  runtime è¿›è¡Œå¢é‡æ›´æ–°
@app.route("/api/calendar/refresh_latest_season")
def calendar_refresh_latest_season():
    try:
        if not is_login():
            return jsonify({"success": False, "message": "æœªç™»å½•"})

        tmdb_id = request.args.get('tmdb_id', type=int)
        if not tmdb_id:
            return jsonify({"success": False, "message": "ç¼ºå°‘ tmdb_id"})

        tmdb_api_key = config_data.get('tmdb_api_key', '')
        if not tmdb_api_key:
            return jsonify({"success": False, "message": "TMDB API æœªé…ç½®"})

        poster_language = get_poster_language_setting()
        tmdb_service = TMDBService(tmdb_api_key, poster_language)
        cal_db = CalendarDB()
        show = cal_db.get_show(int(tmdb_id))
        if not show:
            return jsonify({"success": False, "message": "æœªåˆå§‹åŒ–è¯¥å‰§ï¼ˆè¯·å…ˆ bootstrapï¼‰"})

        latest_season = int(show['latest_season_number'])
        season = tmdb_service.get_tv_show_episodes(tmdb_id, latest_season) or {}
        episodes = season.get('episodes', []) or []

        from time import time as _now
        now_ts = int(_now())

        any_written = False
        # æ ¹å› ä¿®å¤ï¼šæ¸…ç†æœ¬åœ°è¯¥å­£ä¸­ TMDB ä¸å­˜åœ¨çš„å¤šä½™é›†
        try:
            valid_eps = []
            for _ep in episodes:
                try:
                    n = int(_ep.get('episode_number') or 0)
                    if n > 0:
                        valid_eps.append(n)
                except Exception:
                    pass
            cal_db.prune_season_episodes_not_in(int(tmdb_id), int(latest_season), valid_eps)
        except Exception:
            pass
        for ep in episodes:
            cal_db.upsert_episode(
                tmdb_id=int(tmdb_id),
                season_number=latest_season,
                episode_number=int(ep.get('episode_number') or 0),
                name=ep.get('name') or '',
                overview=ep.get('overview') or '',
                air_date=ep.get('air_date') or '',
                runtime=ep.get('runtime'),
                ep_type=(ep.get('episode_type') or ep.get('type')),
                updated_at=now_ts,
            )
            any_written = True

        # åŒæ­¥æ›´æ–° seasons è¡¨çš„å­£åç§°ä¸æ€»é›†æ•°
        try:
            season_name_raw = season.get('name') or ''
            season_name_processed = tmdb_service.process_season_name(season_name_raw)
        except Exception:
            season_name_processed = season.get('name') or ''
        try:
            cal_db.upsert_season(
                int(tmdb_id),
                int(latest_season),
                len(episodes),
                f"/tv/{tmdb_id}/season/{latest_season}",
                season_name_processed
            )
            # å†™å› season_metricsï¼ˆair/totalï¼‰ï¼Œtransferred ç•™å¾…èšåˆæ›´æ–°
            try:
                # ä½¿ç”¨æœ‰æ•ˆæ—¥æœŸè®¡ç®—å·²æ’­å‡ºé›†æ•°
                effective_date = get_effective_date_for_aired_count()
                cur = cal_db.conn.cursor()
                cur.execute("""
                    SELECT COUNT(1) FROM episodes
                    WHERE tmdb_id=? AND season_number=? AND air_date IS NOT NULL AND air_date != '' AND air_date <= ?
                """, (int(tmdb_id), int(latest_season), effective_date))
                aired_cnt = int((cur.fetchone() or [0])[0])
                progress_pct = 0
                from time import time as _now
                cal_db.upsert_season_metrics(int(tmdb_id), int(latest_season), None, aired_cnt, int(len(episodes)), int(progress_pct), int(_now()))
            except Exception:
                pass
        except Exception:
            pass

        try:
            if any_written:
                notify_calendar_changed('refresh_latest_season')
        except Exception:
            pass
        return jsonify({"success": True, "updated": len(episodes)})
    except Exception as e:
        return jsonify({"success": False, "message": f"åˆ·æ–°å¤±è´¥: {str(e)}"})


# å¼ºåˆ¶åˆ·æ–°å•é›†æˆ–åˆå¹¶é›†çš„å…ƒæ•°æ®ï¼ˆæµ·æŠ¥è§†å›¾ä½¿ç”¨ï¼‰
@app.route("/api/calendar/refresh_episode")
def calendar_refresh_episode():
    try:
        if not is_login():
            return jsonify({"success": False, "message": "æœªç™»å½•"})

        tmdb_id = request.args.get('tmdb_id', type=int)
        season_number = request.args.get('season_number', type=int)
        episode_number = request.args.get('episode_number', type=int)
        
        if not tmdb_id or not season_number or not episode_number:
            return jsonify({"success": False, "message": "ç¼ºå°‘å¿…è¦å‚æ•°"})

        tmdb_api_key = config_data.get('tmdb_api_key', '')
        if not tmdb_api_key:
            return jsonify({"success": False, "message": "TMDB API æœªé…ç½®"})

        poster_language = get_poster_language_setting()
        tmdb_service = TMDBService(tmdb_api_key, poster_language)
        cal_db = CalendarDB()
        
        # éªŒè¯èŠ‚ç›®æ˜¯å¦å­˜åœ¨
        show = cal_db.get_show(int(tmdb_id))
        if not show:
            return jsonify({"success": False, "message": "æœªåˆå§‹åŒ–è¯¥å‰§ï¼ˆè¯·å…ˆ bootstrapï¼‰"})

        # è·å–æŒ‡å®šå­£çš„æ‰€æœ‰é›†æ•°æ®
        season = tmdb_service.get_tv_show_episodes(tmdb_id, season_number) or {}
        episodes = season.get('episodes', []) or []
        
        # æŸ¥æ‰¾æŒ‡å®šé›†
        target_episode = None
        for ep in episodes:
            if int(ep.get('episode_number') or 0) == episode_number:
                target_episode = ep
                break
        
        if not target_episode:
            return jsonify({"success": False, "message": f"æœªæ‰¾åˆ°ç¬¬ {season_number} å­£ç¬¬ {episode_number} é›†"})

        # å¼ºåˆ¶æ›´æ–°è¯¥é›†æ•°æ®ï¼ˆæ— è®ºæ˜¯å¦æœ‰ runtimeï¼‰
        from time import time as _now
        now_ts = int(_now())
        
        cal_db.upsert_episode(
            tmdb_id=int(tmdb_id),
            season_number=season_number,
            episode_number=episode_number,
            name=target_episode.get('name') or '',
            overview=target_episode.get('overview') or '',
            air_date=target_episode.get('air_date') or '',
            runtime=target_episode.get('runtime'),
            ep_type=(target_episode.get('episode_type') or target_episode.get('type')),
            updated_at=now_ts,
        )

        # é€šçŸ¥æ—¥å†æ•°æ®å˜æ›´
        try:
            notify_calendar_changed('refresh_episode')
        except Exception:
            pass
            
        # è·å–å‰§åç”¨äºé€šçŸ¥
        show_name = show.get('name', 'æœªçŸ¥å‰§é›†')
        return jsonify({"success": True, "message": f"ã€Š{show_name}ã€‹ç¬¬ {season_number} å­£ Â· ç¬¬ {episode_number} é›†åˆ·æ–°æˆåŠŸ"})
    except Exception as e:
        return jsonify({"success": False, "message": f"åˆ·æ–°å¤±è´¥: {str(e)}"})


# å¼ºåˆ¶åˆ·æ–°æ•´ä¸ªå­£çš„å…ƒæ•°æ®ï¼ˆå†…å®¹ç®¡ç†è§†å›¾ä½¿ç”¨ï¼‰
@app.route("/api/calendar/refresh_season")
def calendar_refresh_season():
    try:
        if not is_login():
            return jsonify({"success": False, "message": "æœªç™»å½•"})

        tmdb_id = request.args.get('tmdb_id', type=int)
        season_number = request.args.get('season_number', type=int)
        
        if not tmdb_id or not season_number:
            return jsonify({"success": False, "message": "ç¼ºå°‘å¿…è¦å‚æ•°"})

        tmdb_api_key = config_data.get('tmdb_api_key', '')
        if not tmdb_api_key:
            return jsonify({"success": False, "message": "TMDB API æœªé…ç½®"})

        poster_language = get_poster_language_setting()
        tmdb_service = TMDBService(tmdb_api_key, poster_language)
        cal_db = CalendarDB()
        
        # éªŒè¯èŠ‚ç›®æ˜¯å¦å­˜åœ¨
        show = cal_db.get_show(int(tmdb_id))
        if not show:
            return jsonify({"success": False, "message": "æœªåˆå§‹åŒ–è¯¥å‰§ï¼ˆè¯·å…ˆ bootstrapï¼‰"})

        # è·å–æŒ‡å®šå­£çš„æ‰€æœ‰é›†æ•°æ®
        season = tmdb_service.get_tv_show_episodes(tmdb_id, season_number) or {}
        episodes = season.get('episodes', []) or []
        
        if not episodes:
            return jsonify({"success": False, "message": f"ç¬¬ {season_number} å­£æ²¡æœ‰é›†æ•°æ®"})

        # å¼ºåˆ¶æ›´æ–°è¯¥å­£æ‰€æœ‰é›†æ•°æ®ï¼ˆæ— è®ºæ˜¯å¦æœ‰ runtimeï¼‰
        from time import time as _now
        now_ts = int(_now())
        
        # æ ¹å› ä¿®å¤ï¼šæ¸…ç†æœ¬åœ°è¯¥å­£ä¸­ TMDB ä¸å­˜åœ¨çš„å¤šä½™é›†
        try:
            valid_eps = []
            for _ep in episodes:
                try:
                    n = int(_ep.get('episode_number') or 0)
                    if n > 0:
                        valid_eps.append(n)
                except Exception:
                    pass
            cal_db.prune_season_episodes_not_in(int(tmdb_id), int(season_number), valid_eps)
        except Exception:
            pass

        updated_count = 0
        for ep in episodes:
            cal_db.upsert_episode(
                tmdb_id=int(tmdb_id),
                season_number=season_number,
                episode_number=int(ep.get('episode_number') or 0),
                name=ep.get('name') or '',
                overview=ep.get('overview') or '',
                air_date=ep.get('air_date') or '',
                runtime=ep.get('runtime'),
                ep_type=(ep.get('episode_type') or ep.get('type')),
                updated_at=now_ts,
            )
            updated_count += 1

        # åŒæ­¥æ›´æ–° seasons è¡¨çš„å­£åç§°ä¸æ€»é›†æ•°
        try:
            season_name_raw = season.get('name') or ''
            season_name_processed = tmdb_service.process_season_name(season_name_raw)
        except Exception:
            season_name_processed = season.get('name') or ''
        try:
            cal_db.upsert_season(
                int(tmdb_id),
                int(season_number),
                len(episodes),
                f"/tv/{tmdb_id}/season/{season_number}",
                season_name_processed
            )
            # å†™å› season_metricsï¼ˆair/totalï¼‰ï¼Œtransferred ç•™å¾…èšåˆæ›´æ–°
            try:
                # ä½¿ç”¨æœ‰æ•ˆæ—¥æœŸè®¡ç®—å·²æ’­å‡ºé›†æ•°
                effective_date = get_effective_date_for_aired_count()
                cur = cal_db.conn.cursor()
                cur.execute("""
                    SELECT COUNT(1) FROM episodes
                    WHERE tmdb_id=? AND season_number=? AND air_date IS NOT NULL AND air_date != '' AND air_date <= ?
                """, (int(tmdb_id), int(season_number), effective_date))
                aired_cnt = int((cur.fetchone() or [0])[0])
                from time import time as _now
                cal_db.upsert_season_metrics(int(tmdb_id), int(season_number), None, aired_cnt, int(len(episodes)), int(_now()))
            except Exception:
                pass
        except Exception:
            pass

        # é€šçŸ¥æ—¥å†æ•°æ®å˜æ›´
        try:
            notify_calendar_changed('refresh_season')
        except Exception:
            pass
            
        # è·å–å‰§åç”¨äºé€šçŸ¥
        show_name = show.get('name', 'æœªçŸ¥å‰§é›†')
        return jsonify({"success": True, "message": f"ã€Š{show_name}ã€‹ç¬¬ {season_number} å­£åˆ·æ–°æˆåŠŸï¼Œå…± {updated_count} é›†"})
    except Exception as e:
        return jsonify({"success": False, "message": f"åˆ·æ–°å¤±è´¥: {str(e)}"})


# åˆ·æ–°ï¼šæ‹‰å–å‰§çº§åˆ«çš„æœ€æ–°è¯¦æƒ…å¹¶æ›´æ–° shows è¡¨ï¼ˆç”¨äºæ›´æ–°èŠ‚ç›®çŠ¶æ€/ä¸­æ–‡å/é¦–æ’­å¹´/æµ·æŠ¥/æœ€æ–°å­£ï¼‰
@app.route("/api/calendar/refresh_show")
def calendar_refresh_show():
    try:
        if not is_login():
            return jsonify({"success": False, "message": "æœªç™»å½•"})

        tmdb_id = request.args.get('tmdb_id', type=int)
        if not tmdb_id:
            return jsonify({"success": False, "message": "ç¼ºå°‘ tmdb_id"})

        tmdb_api_key = config_data.get('tmdb_api_key', '')
        if not tmdb_api_key:
            return jsonify({"success": False, "message": "TMDB API æœªé…ç½®"})

        poster_language = get_poster_language_setting()
        tmdb_service = TMDBService(tmdb_api_key, poster_language)
        cal_db = CalendarDB()

        details = tmdb_service.get_tv_show_details(int(tmdb_id)) or {}
        if not details:
            return jsonify({"success": False, "message": "æœªè·å–åˆ°èŠ‚ç›®è¯¦æƒ…"})

        try:
            existing_show = cal_db.get_show(int(tmdb_id))
        except Exception:
            existing_show = None

        # æ ‡é¢˜ã€çŠ¶æ€ä¸æœ€æ–°å­£
        try:
            name = tmdb_service.get_chinese_title_with_fallback(int(tmdb_id), (existing_show or {}).get('name') or '')
        except Exception:
            name = (details.get('name') or details.get('original_name') or (existing_show or {}).get('name') or '')

        first_air = (details.get('first_air_date') or '')[:4]
        raw_status = (details.get('status') or '')
        try:
            latest_sn_for_status = int((existing_show or {}).get('latest_season_number') or 1)
            localized_status = tmdb_service.get_localized_show_status(int(tmdb_id), latest_sn_for_status, raw_status)
        except Exception:
            localized_status = raw_status

        latest_season_number = 0
        try:
            for s in (details.get('seasons') or []):
                sn = int(s.get('season_number') or 0)
                if sn > latest_season_number:
                    latest_season_number = sn
        except Exception:
            latest_season_number = 0
        if latest_season_number <= 0:
            try:
                latest_season_number = int((existing_show or {}).get('latest_season_number') or 1)
            except Exception:
                latest_season_number = 1

        # æµ·æŠ¥ - ä½¿ç”¨æµ·æŠ¥è¯­è¨€è®¾ç½®è·å–æµ·æŠ¥è·¯å¾„
        poster_path = tmdb_service.get_poster_path_with_language(int(tmdb_id)) if tmdb_service else (details.get('poster_path') or '')
        poster_local_path = ''
        try:
            if poster_path:
                existing_poster_path = existing_show.get('poster_local_path', '') if existing_show else ''
                is_custom_poster = bool(existing_show.get('is_custom_poster', 0)) if existing_show else False
                poster_local_path = download_poster_local(poster_path, int(tmdb_id), existing_poster_path, is_custom_poster)
            elif existing_show and existing_show.get('poster_local_path'):
                poster_local_path = existing_show.get('poster_local_path')
        except Exception:
            poster_local_path = (existing_show or {}).get('poster_local_path') or ''

        bound_task_names = (existing_show or {}).get('bound_task_names', '')
        content_type = (existing_show or {}).get('content_type', '')

        cal_db.upsert_show(
            int(tmdb_id),
            name,
            first_air,
            localized_status,
            poster_local_path,
            int(latest_season_number),
            0,
            bound_task_names,
            content_type
        )

        # å¦‚æœæµ·æŠ¥è·¯å¾„å‘ç”Ÿå˜åŒ–ï¼Œè§¦å‘å­¤ç«‹æ–‡ä»¶æ¸…ç†
        existing_poster_path = existing_show.get('poster_local_path', '') if existing_show else ''
        if poster_local_path and poster_local_path != existing_poster_path:
            try:
                cleanup_orphaned_posters()
            except Exception as e:
                logging.warning(f"æ¸…ç†å­¤ç«‹æµ·æŠ¥å¤±è´¥: {e}")

        try:
            notify_calendar_changed('refresh_show')
            # é€šçŸ¥å‰ç«¯æŒ‡å®šèŠ‚ç›®æµ·æŠ¥å¯èƒ½å·²æ›´æ–°ï¼Œç”¨äºè§¦å‘æŒ‰èŠ‚ç›®ç»´åº¦çš„ç¼“å­˜ç©¿é€
            try:
                if tmdb_id:
                    notify_calendar_changed(f'poster_updated:{int(tmdb_id)}')
            except Exception:
                pass
        except Exception:
            pass

        return jsonify({"success": True, "message": "å‰§ç›®è¯¦æƒ…å·²åˆ·æ–°"})
    except Exception as e:
        return jsonify({"success": False, "message": f"åˆ·æ–°å‰§å¤±è´¥: {str(e)}"})

# ç¼–è¾‘è¿½å‰§æ—¥å†å…ƒæ•°æ®ï¼šä¿®æ”¹ä»»åŠ¡åã€ä»»åŠ¡ç±»å‹ã€é‡ç»‘ TMDB
@app.route("/api/calendar/edit_metadata", methods=["POST"])
def calendar_edit_metadata():
    try:
        if not is_login():
            return jsonify({"success": False, "message": "æœªç™»å½•"})

        data = request.get_json(force=True) or {}
        task_name = (data.get('task_name') or '').strip()
        new_task_name = (data.get('new_task_name') or '').strip()
        new_content_type = (data.get('new_content_type') or '').strip()
        new_tmdb_id = data.get('new_tmdb_id')
        new_season_number = data.get('new_season_number')
        custom_poster_url = (data.get('custom_poster_url') or '').strip()

        if not task_name:
            return jsonify({"success": False, "message": "ç¼ºå°‘ä»»åŠ¡åç§°"})

        global config_data
        tasks = config_data.get('tasklist', [])
        target = None
        for t in tasks:
            tn = t.get('taskname') or t.get('task_name') or ''
            if tn == task_name:
                target = t
                break
        if not target:
            return jsonify({"success": False, "message": "æœªæ‰¾åˆ°ä»»åŠ¡"})

        cal = (target.get('calendar_info') or {})
        match = (cal.get('match') or {})
        old_tmdb_id = match.get('tmdb_id') or cal.get('tmdb_id')

        changed = False

        if new_task_name and new_task_name != task_name:
            target['taskname'] = new_task_name
            target['task_name'] = new_task_name
            changed = True

        valid_types = {'tv', 'anime', 'variety', 'documentary', 'other', ''}
        if new_content_type in valid_types:
            extracted = (target.setdefault('calendar_info', {}).setdefault('extracted', {}))
            if extracted.get('content_type') != new_content_type:
                # åŒæ­¥åˆ°ä»»åŠ¡é…ç½®ä¸­çš„ extracted ä¸é¡¶å±‚ content_typeï¼Œä¿è¯å‰ç«¯ä¸å…¶ä»–é€»è¾‘å¯è§
                extracted['content_type'] = new_content_type
                target['content_type'] = new_content_type
                # æœªåŒ¹é…ä»»åŠ¡ï¼šæ²¡æœ‰ old_tmdb_id æ—¶ï¼Œä¸è®¿é—®æ•°æ®åº“ï¼Œä»…æ›´æ–°é…ç½®
                # å·²åŒ¹é…ä»»åŠ¡ï¼šè‹¥å·²æœ‰ç»‘å®šçš„ tmdb_idï¼Œåˆ™ç«‹å³åŒæ­¥åˆ°æ•°æ®åº“
                try:
                    if old_tmdb_id:
                        cal_db = CalendarDB()
                        cal_db.update_show_content_type(int(old_tmdb_id), new_content_type)
                        # åŒæ­¥ä»»åŠ¡åä¸å†…å®¹ç±»å‹ç»‘å®šå…³ç³»
                        task_final_name = target.get('taskname') or target.get('task_name') or task_name
                        cal_db.bind_task_and_content_type(int(old_tmdb_id), task_final_name, new_content_type)
                except Exception as e:
                    logging.warning(f"åŒæ­¥å†…å®¹ç±»å‹åˆ°æ•°æ®åº“å¤±è´¥: {e}")
                changed = True

        did_rematch = False
        cal_db = CalendarDB()
        tmdb_api_key = config_data.get('tmdb_api_key', '')
        poster_language = get_poster_language_setting()
        tmdb_service = TMDBService(tmdb_api_key, poster_language) if tmdb_api_key else None
        # åœºæ™¯ä¸€ï¼šæä¾› new_tmdb_idï¼ˆé‡ç»‘èŠ‚ç›®ï¼Œå¯åŒæ—¶æŒ‡å®šå­£æ•°ï¼‰
        if new_tmdb_id:
            try:
                new_tid = int(str(new_tmdb_id).strip())
            except Exception:
                return jsonify({"success": False, "message": "TMDB ID éæ³•"})
            
            # ç‰¹æ®Šå¤„ç†ï¼štmdb_id ä¸º 0 è¡¨ç¤ºå–æ¶ˆåŒ¹é…
            if new_tid == 0:
                if old_tmdb_id:
                    # è§£ç»‘æ—§èŠ‚ç›®çš„ä»»åŠ¡å¼•ç”¨
                    try:
                        try:
                            _task_final_name = target.get('taskname') or target.get('task_name') or new_task_name or task_name
                        except Exception:
                            _task_final_name = task_name
                        cal_db.unbind_task_from_show(int(old_tmdb_id), _task_final_name)
                    except Exception as e:
                        logging.warning(f"è§£ç»‘æ—§èŠ‚ç›®ä»»åŠ¡å¤±è´¥: {e}")
                    
                    # æ¸…ç†æ—§èŠ‚ç›®çš„æ‰€æœ‰æ•°æ®ä¸æµ·æŠ¥ï¼ˆå¼ºåˆ¶æ¸…ç†ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»è§£ç»‘äº†ä»»åŠ¡ï¼‰
                    try:
                        purge_calendar_by_tmdb_id_internal(int(old_tmdb_id), force=True)
                    except Exception as e:
                        logging.warning(f"æ¸…ç†æ—§èŠ‚ç›®æ•°æ®å¤±è´¥: {e}")
                
                # æ¸…ç©ºä»»åŠ¡é…ç½®ä¸­çš„åŒ¹é…ä¿¡æ¯
                if 'calendar_info' not in target:
                    target['calendar_info'] = {}
                if 'match' in target['calendar_info']:
                    target['calendar_info']['match'] = {}
                
                changed = True
                msg = 'å·²å–æ¶ˆåŒ¹é…ï¼Œå¹¶æ¸…é™¤äº†åŸæœ‰çš„èŠ‚ç›®æ•°æ®'
                return jsonify({"success": True, "message": msg})
            
            try:
                season_no = int(new_season_number or 1)
            except Exception:
                season_no = 1

            # è‹¥ tmdb å‘ç”Ÿå˜æ›´ï¼Œå…ˆè§£ç»‘æ—§èŠ‚ç›®çš„ä»»åŠ¡å¼•ç”¨ï¼›å®é™…æ¸…ç†å»¶ååˆ°é…ç½®å†™ç›˜ä¹‹å
            old_to_purge_tmdb_id = None
            if old_tmdb_id and int(old_tmdb_id) != new_tid:
                # è§£ç»‘æ—§èŠ‚ç›®çš„ä»»åŠ¡å¼•ç”¨
                try:
                    try:
                        _task_final_name = target.get('taskname') or target.get('task_name') or new_task_name or task_name
                    except Exception:
                        _task_final_name = task_name
                    cal_db.unbind_task_from_show(int(old_tmdb_id), _task_final_name)
                except Exception as e:
                    logging.warning(f"è§£ç»‘æ—§èŠ‚ç›®ä»»åŠ¡å¤±è´¥: {e}")
                # è®°å½•å¾…æ¸…ç†çš„æ—§ tmdbï¼Œåœ¨é…ç½®æ›´æ–°å¹¶è½ç›˜åå†æ‰§è¡Œæ¸…ç†
                try:
                    old_to_purge_tmdb_id = int(old_tmdb_id)
                except Exception:
                    old_to_purge_tmdb_id = None

            show = cal_db.get_show(new_tid)
            if not show:
                if not tmdb_service:
                    return jsonify({"success": False, "message": "TMDB API æœªé…ç½®ï¼Œæ— æ³•åˆå§‹åŒ–æ–°èŠ‚ç›®"})
                # ç›´æ¥ä» TMDB è·å–è¯¦æƒ…å¹¶å†™å…¥æœ¬åœ°ï¼Œè€Œä¸æ˜¯è°ƒç”¨å…¨é‡ bootstrap
                details = tmdb_service.get_tv_show_details(new_tid) or {}
                if not details:
                    return jsonify({"success": False, "message": "æœªæ‰¾åˆ°æŒ‡å®š TMDB èŠ‚ç›®"})
                try:
                    chinese_title = tmdb_service.get_chinese_title_with_fallback(new_tid, details.get('name') or details.get('original_name') or '')
                except Exception:
                    chinese_title = details.get('name') or details.get('original_name') or ''
                poster_local_path = ''
                try:
                    poster_local_path = download_poster_local(details.get('poster_path') or '')
                except Exception:
                    poster_local_path = ''
                first_air = (details.get('first_air_date') or '')[:4]
                status = details.get('status') or ''
                # ä»¥ season_no ä½œä¸ºæœ€æ–°å­£å†™å…¥ shows
                cal_db.upsert_show(int(new_tid), chinese_title, first_air, status, poster_local_path, int(season_no), 0, '', (target.get('content_type') or ''))
                show = cal_db.get_show(new_tid)
                if not show:
                    return jsonify({"success": False, "message": "æœªæ‰¾åˆ°æŒ‡å®š TMDB èŠ‚ç›®"})

            task_final_name = target.get('taskname') or target.get('task_name') or new_task_name or task_name
            ct = (target.get('calendar_info') or {}).get('extracted', {}).get('content_type', '')
            try:
                cal_db.bind_task_and_content_type(new_tid, task_final_name, ct)
            except Exception as e:
                logging.warning(f"ç»‘å®šä»»åŠ¡å¤±è´¥: {e}")

            if 'calendar_info' not in target:
                target['calendar_info'] = {}
            if 'match' not in target['calendar_info']:
                target['calendar_info']['match'] = {}
            target['calendar_info']['match'].update({
                'tmdb_id': new_tid,
                'matched_show_name': show.get('name', ''),
                'matched_year': show.get('year', '')
            })
            target['calendar_info']['match']['latest_season_number'] = season_no

            try:
                season = tmdb_service.get_tv_show_episodes(new_tid, season_no) if tmdb_service else None
                eps = (season or {}).get('episodes', []) or []
                from time import time as _now
                now_ts = int(_now())
                # æ¸…ç†é™¤å½“å‰å­£å¤–çš„å…¶ä»–å­£æ•°æ®ï¼Œé¿å…æ®‹ç•™
                try:
                    cal_db.purge_other_seasons(int(new_tid), int(season_no))
                except Exception:
                    pass
                # æ ¹å› ä¿®å¤ï¼šæ¸…ç†æœ¬åœ°è¯¥å­£ä¸­ TMDB ä¸å­˜åœ¨çš„å¤šä½™é›†
                try:
                    valid_eps = []
                    for _ep in eps:
                        try:
                            n = int(_ep.get('episode_number') or 0)
                            if n > 0:
                                valid_eps.append(n)
                        except Exception:
                            pass
                    cal_db.prune_season_episodes_not_in(int(new_tid), int(season_no), valid_eps)
                except Exception:
                    pass
                for ep in eps:
                    cal_db.upsert_episode(
                        tmdb_id=int(new_tid),
                        season_number=int(season_no),
                        episode_number=int(ep.get('episode_number') or 0),
                        name=ep.get('name') or '',
                        overview=ep.get('overview') or '',
                        air_date=ep.get('air_date') or '',
                        runtime=ep.get('runtime'),
                        ep_type=(ep.get('episode_type') or ep.get('type')),
                        updated_at=now_ts,
                    )
                try:
                    sname_raw = (season or {}).get('name') or ''
                    sname = tmdb_service.process_season_name(sname_raw) if tmdb_service else sname_raw
                    cal_db.upsert_season(int(new_tid), int(season_no), len(eps), f"/tv/{new_tid}/season/{season_no}", sname)
                    cal_db.update_show_latest_season_number(int(new_tid), int(season_no))
                    # å†™å› season_metricsï¼ˆair/totalï¼‰ï¼Œtransferred ç•™ç»™èšåˆç¯èŠ‚è¡¥é½
                    try:
                        # ä½¿ç”¨æœ‰æ•ˆæ—¥æœŸè®¡ç®—å·²æ’­å‡ºé›†æ•°
                        effective_date = get_effective_date_for_aired_count()
                        cur = cal_db.conn.cursor()
                        cur.execute("""
                            SELECT COUNT(1) FROM episodes
                            WHERE tmdb_id=? AND season_number=? AND air_date IS NOT NULL AND air_date != '' AND air_date <= ?
                        """, (int(new_tid), int(season_no), effective_date))
                        aired_cnt = int((cur.fetchone() or [0])[0])
                        progress_pct = 0  # æ­¤å¤„æ—  transferred_countï¼Œç™¾åˆ†æ¯”æš‚ç½® 0ï¼Œç”±èšåˆç¯èŠ‚è¡¥é½
                        from time import time as _now
                        cal_db.upsert_season_metrics(int(new_tid), int(season_no), None, aired_cnt, int(len(eps)), int(progress_pct), int(_now()))
                    except Exception:
                        pass
                except Exception:
                    pass
            except Exception as e:
                logging.warning(f"åˆ·æ–°æ–°å­£å¤±è´¥: {e}")

            did_rematch = True
            changed = True
            # å¦‚æœéœ€è¦ï¼Œå»¶åæ¸…ç†æ—§èŠ‚ç›®çš„æ•°æ®ï¼ˆæ­¤æ—¶ä»»åŠ¡é…ç½®å·²æŒ‡å‘æ–°èŠ‚ç›®ï¼Œé¿å…è¢«æ¸…ç†å‡½æ•°è¯¯åˆ¤ä»è¢«å¼•ç”¨ï¼‰
            if old_to_purge_tmdb_id is not None:
                try:
                    purge_calendar_by_tmdb_id_internal(int(old_to_purge_tmdb_id))
                except Exception as e:
                    logging.warning(f"æ¸…ç†æ—§ tmdb å¤±è´¥: {e}")
            # åŸºäºæœ€æ–°ä»»åŠ¡æ˜ å°„æ¸…ç†å­¤å„¿å­£ä¸æŒ‡æ ‡
            try:
                _tasks = config_data.get('tasklist', [])
                _valid_names = []
                _valid_pairs = []
                for _t in _tasks:
                    _n = _t.get('taskname') or _t.get('task_name') or ''
                    _cal = (_t.get('calendar_info') or {})
                    _match = (_cal.get('match') or {})
                    _tid = _match.get('tmdb_id') or _cal.get('tmdb_id')
                    _sn = _match.get('latest_season_number') or _cal.get('latest_season_number')
                    if _n:
                        _valid_names.append(_n)
                    if _tid and _sn:
                        try:
                            _valid_pairs.append((int(_tid), int(_sn)))
                        except Exception:
                            pass
                CalendarDB().cleanup_orphan_data(_valid_pairs, _valid_names)
            except Exception:
                pass
        # åœºæ™¯äºŒï¼šæœªæä¾› new_tmdb_idï¼Œä½†æä¾›äº† new_season_numberï¼ˆä»…ä¿®æ”¹å­£æ•°ï¼‰
        elif (new_season_number is not None) and (str(new_season_number).strip() != '') and old_tmdb_id:
            try:
                season_no = int(new_season_number)
            except Exception:
                return jsonify({"success": False, "message": "å­£æ•°å¿…é¡»ä¸ºæ•°å­—"})

            # æ£€æŸ¥æ˜¯å¦ä¸å½“å‰åŒ¹é…çš„å­£æ•°ç›¸åŒï¼Œå¦‚æœç›¸åŒåˆ™è·³è¿‡å¤„ç†
            current_match_season = match.get('latest_season_number')
            if current_match_season and int(current_match_season) == season_no:
                # å­£æ•°æœªå˜åŒ–ï¼Œè·³è¿‡å¤„ç†
                pass
            else:
                if not tmdb_service:
                    return jsonify({"success": False, "message": "TMDB API æœªé…ç½®"})

                # æ›´æ–° shows è¡¨ä¸­çš„æœ€æ–°å­£ï¼Œæ¸…ç†å…¶ä»–å­£ï¼Œå¹¶æ‹‰å–æŒ‡å®šå­£æ•°æ®
                try:
                    cal_db.update_show_latest_season_number(int(old_tmdb_id), int(season_no))
                except Exception:
                    pass

                # æ‹‰å–è¯¥å­£æ•°æ®
                try:
                    season = tmdb_service.get_tv_show_episodes(int(old_tmdb_id), int(season_no)) or {}
                    eps = season.get('episodes', []) or []
                    from time import time as _now
                    now_ts = int(_now())
                    # æ¸…ç†é™¤å½“å‰å­£å¤–å…¶ä»–å­£ï¼Œé¿å…æ®‹ç•™
                    try:
                        cal_db.purge_other_seasons(int(old_tmdb_id), int(season_no))
                    except Exception:
                        pass
                    # æ ¹å› ä¿®å¤ï¼šæ¸…ç†æœ¬åœ°è¯¥å­£ä¸­ TMDB ä¸å­˜åœ¨çš„å¤šä½™é›†
                    try:
                        valid_eps = []
                        for _ep in eps:
                            try:
                                n = int(_ep.get('episode_number') or 0)
                                if n > 0:
                                    valid_eps.append(n)
                            except Exception:
                                pass
                        cal_db.prune_season_episodes_not_in(int(old_tmdb_id), int(season_no), valid_eps)
                    except Exception:
                        pass
                    for ep in eps:
                        cal_db.upsert_episode(
                            tmdb_id=int(old_tmdb_id),
                            season_number=int(season_no),
                            episode_number=int(ep.get('episode_number') or 0),
                            name=ep.get('name') or '',
                            overview=ep.get('overview') or '',
                            air_date=ep.get('air_date') or '',
                            runtime=ep.get('runtime'),
                            ep_type=(ep.get('episode_type') or ep.get('type')),
                            updated_at=now_ts,
                        )
                    try:
                        sname_raw = (season or {}).get('name') or ''
                        sname = tmdb_service.process_season_name(sname_raw)
                        cal_db.upsert_season(int(old_tmdb_id), int(season_no), len(eps), f"/tv/{old_tmdb_id}/season/{season_no}", sname)
                    except Exception:
                        pass
                except Exception as e:
                    return jsonify({"success": False, "message": f"åˆ·æ–°å­£æ•°æ®å¤±è´¥: {e}"})

                # æ›´æ–°ä»»åŠ¡é…ç½®ä¸­çš„ latest_season_number ä»¥ä¾¿å‰ç«¯å±•ç¤º
                try:
                    if 'calendar_info' not in target:
                        target['calendar_info'] = {}
                    if 'match' not in target['calendar_info']:
                        target['calendar_info']['match'] = {}
                    target['calendar_info']['match']['latest_season_number'] = int(season_no)
                except Exception:
                    pass

                changed = True
                # åŸºäºæœ€æ–°ä»»åŠ¡æ˜ å°„æ¸…ç†å­¤å„¿å­£ä¸æŒ‡æ ‡
                try:
                    _tasks = config_data.get('tasklist', [])
                    _valid_names = []
                    _valid_pairs = []
                    for _t in _tasks:
                        _n = _t.get('taskname') or _t.get('task_name') or ''
                        _cal = (_t.get('calendar_info') or {})
                        _match = (_cal.get('match') or {})
                        _tid = _match.get('tmdb_id') or _cal.get('tmdb_id')
                        _sn = _match.get('latest_season_number') or _cal.get('latest_season_number')
                        if _n:
                            _valid_names.append(_n)
                        if _tid and _sn:
                            try:
                                _valid_pairs.append((int(_tid), int(_sn)))
                            except Exception:
                                pass
                    CalendarDB().cleanup_orphan_data(_valid_pairs, _valid_names)
                except Exception:
                    pass

        # å¤„ç†è‡ªå®šä¹‰æµ·æŠ¥
        if custom_poster_url:
            # è·å–å½“å‰ä»»åŠ¡çš„TMDB ID
            current_tmdb_id = None
            if new_tmdb_id:
                current_tmdb_id = int(new_tmdb_id)
            elif old_tmdb_id:
                current_tmdb_id = int(old_tmdb_id)

            if current_tmdb_id:
                try:
                    # å°è¯•è¯»å–ç°æœ‰èŠ‚ç›®ï¼Œè‹¥æœ‰å·²æœ‰æµ·æŠ¥ï¼Œåˆ™è¦†ç›–åŒåæ–‡ä»¶ä»¥å®ç°åŸä½æ›¿æ¢
                    show_row = None
                    try:
                        show_row = cal_db.get_show(int(current_tmdb_id))
                    except Exception:
                        show_row = None

                    target_safe_name = None
                    if show_row and (show_row.get('poster_local_path') or '').strip():
                        try:
                            existing_path = (show_row.get('poster_local_path') or '').strip()
                            # æœŸæœ›æ ¼å¼ï¼š/cache/images/<filename>
                            target_safe_name = existing_path.split('/')[-1]
                        except Exception:
                            target_safe_name = None

                    # è¦†ç›–ä¿å­˜ï¼ˆä¸è¿›è¡Œç¼©æ”¾ï¼Œä¸æ–°å¢ä¾èµ–ï¼‰
                    saved_path = download_custom_poster(custom_poster_url, current_tmdb_id, target_safe_name)

                    if saved_path:
                        # æ›´æ–°æ•°æ®åº“è·¯å¾„ï¼Œæ ‡è®°ä¸ºè‡ªå®šä¹‰æµ·æŠ¥
                        try:
                            cal_db.update_show_poster(int(current_tmdb_id), saved_path, is_custom_poster=1)
                        except Exception as e:
                            logging.warning(f"æ›´æ–°æµ·æŠ¥è·¯å¾„å¤±è´¥: {e}")
                        
                        # è‹¥æ–‡ä»¶åå‘ç”Ÿå˜åŒ–åˆ™éœ€è¦åˆ é™¤æ—§æ–‡ä»¶
                        try:
                            existing_path = ''
                            if show_row:
                                existing_path = (show_row.get('poster_local_path') or '').strip()
                            if saved_path != existing_path:
                                # åˆ é™¤æ—§æ–‡ä»¶ï¼ˆè‹¥å­˜åœ¨ä¸”åœ¨ç¼“å­˜ç›®å½•ä¸‹ï¼‰
                                try:
                                    if existing_path and existing_path.startswith('/cache/images/'):
                                        old_name = existing_path.replace('/cache/images/', '')
                                        old_path = os.path.join(CACHE_IMAGES_DIR, old_name)
                                        if os.path.exists(old_path):
                                            os.remove(old_path)
                                except Exception as e:
                                    logging.warning(f"åˆ é™¤æ—§æµ·æŠ¥å¤±è´¥: {e}")
                        except Exception:
                            # å³ä½¿å¯¹æ¯”å¤±è´¥ä¹Ÿä¸å½±å“åŠŸèƒ½
                            pass
                        
                        # ç”¨æˆ·ä¸Šä¼ è‡ªå®šä¹‰æµ·æŠ¥åï¼Œæ€»æ˜¯è§¦å‘å­¤ç«‹æ–‡ä»¶æ¸…ç†
                        try:
                            cleanup_orphaned_posters()
                        except Exception as e:
                            logging.warning(f"æ¸…ç†å­¤ç«‹æµ·æŠ¥å¤±è´¥: {e}")

                        # æˆåŠŸæ›´æ–°è‡ªå®šä¹‰æµ·æŠ¥ï¼ˆé™é»˜ï¼‰
                        changed = True
                        # ä»…å½“è‡ªå®šä¹‰æµ·æŠ¥ä¿å­˜æˆåŠŸæ—¶ï¼Œé€šçŸ¥å‰ç«¯è¯¥èŠ‚ç›®æµ·æŠ¥å·²æ›´æ–°
                        try:
                            notify_calendar_changed(f'poster_updated:{int(current_tmdb_id)}')
                        except Exception:
                            pass
                    else:
                        logging.warning(f"è‡ªå®šä¹‰æµ·æŠ¥ä¿å­˜å¤±è´¥: {custom_poster_url}")
                except Exception as e:
                    logging.error(f"å¤„ç†è‡ªå®šä¹‰æµ·æŠ¥å¤±è´¥: {e}")
            else:
                logging.warning("æ— æ³•å¤„ç†è‡ªå®šä¹‰æµ·æŠ¥ï¼šç¼ºå°‘TMDB ID")

        if changed:
            Config.write_json(CONFIG_PATH, config_data)

        try:
            sync_task_config_with_database_bindings()
        except Exception as e:
            logging.warning(f"åŒæ­¥ç»‘å®šå¤±è´¥: {e}")

        try:
            notify_calendar_changed('edit_metadata')
        except Exception:
            pass

        msg = 'å…ƒæ•°æ®æ›´æ–°æˆåŠŸ'
        if did_rematch:
            msg = 'å…ƒæ•°æ®æ›´æ–°æˆåŠŸï¼Œå·²é‡æ–°åŒ¹é…å¹¶åˆ·æ–°å…ƒæ•°æ®'
        if custom_poster_url:
            if 'å·²é‡æ–°åŒ¹é…' in msg:
                msg = 'å…ƒæ•°æ®æ›´æ–°æˆåŠŸï¼Œå·²é‡æ–°åŒ¹é…å¹¶åˆ·æ–°å…ƒæ•°æ®ï¼Œè‡ªå®šä¹‰æµ·æŠ¥å·²æ›´æ–°'
            else:
                msg = 'å…ƒæ•°æ®æ›´æ–°æˆåŠŸï¼Œè‡ªå®šä¹‰æµ·æŠ¥å·²æ›´æ–°'
        return jsonify({"success": True, "message": msg})
    except Exception as e:
        return jsonify({"success": False, "message": f"ä¿å­˜å¤±è´¥: {str(e)}"})

# è·å–èŠ‚ç›®ä¿¡æ¯ï¼ˆç”¨äºè·å–æœ€æ–°å­£æ•°ï¼‰
@app.route("/api/calendar/show_info")
def get_calendar_show_info():
    try:
        if not is_login():
            return jsonify({"success": False, "message": "æœªç™»å½•"})

        tmdb_id = request.args.get('tmdb_id', type=int)
        if not tmdb_id:
            return jsonify({"success": False, "message": "ç¼ºå°‘ tmdb_id"})

        cal_db = CalendarDB()
        show = cal_db.get_show(int(tmdb_id))
        if not show:
            return jsonify({"success": False, "message": "æœªæ‰¾åˆ°è¯¥èŠ‚ç›®"})

        return jsonify({
            "success": True,
            "data": {
                "tmdb_id": show['tmdb_id'],
                "name": show['name'],
                "year": show['year'],
                "status": show['status'],
                "latest_season_number": show['latest_season_number'],
                "poster_local_path": show['poster_local_path']
            }
        })
    except Exception as e:
        return jsonify({"success": False, "message": f"è·å–èŠ‚ç›®ä¿¡æ¯å¤±è´¥: {str(e)}"})


# --------- æ—¥å†åˆ·æ–°è°ƒåº¦ï¼šæŒ‰æ€§èƒ½è®¾ç½®çš„å‘¨æœŸè‡ªåŠ¨åˆ·æ–°æœ€æ–°å­£ ---------
def restart_calendar_refresh_job():
    try:
        global _calendar_refresh_last_interval
        # è¯»å–ç”¨æˆ·é…ç½®çš„åˆ·æ–°å‘¨æœŸï¼ˆç§’ï¼‰ï¼Œé»˜è®¤21600ç§’ï¼ˆ6å°æ—¶ï¼‰
        perf = config_data.get('performance', {}) if isinstance(config_data, dict) else {}
        interval_seconds = int(perf.get('calendar_refresh_interval_seconds', 21600))
        if interval_seconds <= 0:
            # éæ³•æˆ–å…³é—­åˆ™ç§»é™¤
            try:
                scheduler.remove_job('calendar_refresh_job')
            except Exception:
                pass
            # åªåœ¨çŠ¶æ€æ”¹å˜æ—¶è¾“å‡ºæ—¥å¿—
            if _calendar_refresh_last_interval is not None:
                logging.info("å·²å…³é—­è¿½å‰§æ—¥å†å…ƒæ•°æ®è‡ªåŠ¨åˆ·æ–°")
                _calendar_refresh_last_interval = None
            return

        # é‡ç½®ä»»åŠ¡
        try:
            scheduler.remove_job('calendar_refresh_job')
        except Exception:
            pass
        scheduler.add_job(
            run_calendar_refresh_all_internal_wrapper,
            IntervalTrigger(seconds=interval_seconds),
            id='calendar_refresh_job',
            replace_existing=True,
            misfire_grace_time=None,
            coalesce=True,
            max_instances=1,
        )
        if scheduler.state == 0:
            scheduler.start()
        # å‹å¥½æç¤ºï¼šä»…åœ¨å‘¨æœŸå˜åŒ–æ—¶è¾“å‡ºæ—¥å¿—ï¼ˆé¿å…é‡å¤è¾“å‡ºï¼‰
        try:
            if IS_FLASK_SERVER_PROCESS:
                if _calendar_refresh_last_interval != interval_seconds:
                    logging.info(f"å·²å¯åŠ¨è¿½å‰§æ—¥å†è‡ªåŠ¨åˆ·æ–°ï¼Œå‘¨æœŸ {interval_seconds} ç§’")
                    _calendar_refresh_last_interval = interval_seconds
        except Exception:
            pass
    except Exception as e:
        logging.warning(f"é…ç½®è‡ªåŠ¨åˆ·æ–°ä»»åŠ¡å¤±è´¥: {e}")


def run_calendar_refresh_all_internal_wrapper():
    """
    è¿½å‰§æ—¥å†è‡ªåŠ¨åˆ·æ–°çš„åŒ…è£…å‡½æ•°ï¼Œç”¨äºæ£€æŸ¥ä¸Šä¸€æ¬¡ä»»åŠ¡æ˜¯å¦è¿˜åœ¨è¿è¡Œ
    """
    global _calendar_refresh_thread
    
    logging.info(f">>> å¼€å§‹æ‰§è¡Œè¿½å‰§æ—¥å†è‡ªåŠ¨åˆ·æ–°")
    
    # æ£€æŸ¥ä¸Šä¸€æ¬¡ä»»åŠ¡æ˜¯å¦è¿˜åœ¨è¿è¡Œ
    if _calendar_refresh_thread is not None:
        try:
            if _calendar_refresh_thread.is_alive():  # çº¿ç¨‹è¿˜åœ¨è¿è¡Œ
                logging.warning(f">>> æ£€æµ‹åˆ°ä¸Šä¸€æ¬¡è¿½å‰§æ—¥å†è‡ªåŠ¨åˆ·æ–°ä»åœ¨è¿è¡Œï¼Œå°†å¿½ç•¥å¹¶ç»§ç»­æ‰§è¡Œæ–°ä»»åŠ¡")
                # æ³¨æ„ï¼šPython çº¿ç¨‹æ— æ³•å¼ºåˆ¶ç»ˆæ­¢ï¼Œåªèƒ½è®°å½•è­¦å‘Š
                # ä½†ç”±äºè°ƒåº¦å™¨ä¼šç»§ç»­æ‰§è¡Œï¼Œä¸ä¼šé˜»å¡åç»­ä»»åŠ¡
            else:  # çº¿ç¨‹å·²ç»“æŸï¼ˆæ­£å¸¸æˆ–å¼‚å¸¸é€€å‡ºï¼‰
                logging.debug(f">>> ä¸Šä¸€æ¬¡è¿½å‰§æ—¥å†è‡ªåŠ¨åˆ·æ–°å·²ç»“æŸ")
        except Exception as e:
            logging.warning(f">>> æ£€æŸ¥ä¸Šä¸€æ¬¡è¿½å‰§æ—¥å†è‡ªåŠ¨åˆ·æ–°ä»»åŠ¡çŠ¶æ€æ—¶å‡ºé”™: {e}")
        finally:
            # æ— è®ºä»€ä¹ˆæƒ…å†µï¼Œéƒ½æ¸…é™¤çº¿ç¨‹å¯¹è±¡ï¼Œç¡®ä¿ä¸‹æ¬¡èƒ½æ­£å¸¸è¿è¡Œ
            _calendar_refresh_thread = None
    
    # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œä»»åŠ¡ï¼Œè®°å½•çº¿ç¨‹å¯¹è±¡ä»¥ä¾¿ä¸‹æ¬¡æ£€æŸ¥
    def run_in_thread():
        global _calendar_refresh_thread
        try:
            run_calendar_refresh_all_internal()
            logging.info(f">>> è¿½å‰§æ—¥å†è‡ªåŠ¨åˆ·æ–°æ‰§è¡ŒæˆåŠŸ")
        except Exception as e:
            logging.error(f">>> è¿½å‰§æ—¥å†è‡ªåŠ¨åˆ·æ–°æ‰§è¡Œå¼‚å¸¸: {str(e)}")
            import traceback
            logging.error(f">>> å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
        finally:
            # ä»»åŠ¡å®Œæˆï¼Œæ¸…é™¤çº¿ç¨‹å¯¹è±¡
            _calendar_refresh_thread = None
    
    _calendar_refresh_thread = Thread(target=run_in_thread, daemon=True)
    _calendar_refresh_thread.start()
    # ä¸ç­‰å¾…çº¿ç¨‹å®Œæˆï¼Œè®©è°ƒåº¦å™¨è®¤ä¸ºä»»åŠ¡å·²å¯åŠ¨
    # è¿™æ ·å³ä½¿ä»»åŠ¡è¿è¡Œæ—¶é—´å¾ˆé•¿ï¼Œä¹Ÿä¸ä¼šé˜»å¡åç»­ä»»åŠ¡


def run_calendar_refresh_all_internal():
    try:
        tmdb_api_key = config_data.get('tmdb_api_key', '')
        if not tmdb_api_key:
            return
        poster_language = get_poster_language_setting()
        tmdb_service = TMDBService(tmdb_api_key, poster_language)
        db = CalendarDB()
        shows = []
        # ç®€å•è¯»å–æ‰€æœ‰å·²åˆå§‹åŒ–çš„å‰§ç›®
        try:
            cur = db.conn.cursor()
            cur.execute('SELECT tmdb_id FROM shows')
            shows = [r[0] for r in cur.fetchall()]
        except Exception:
            shows = []
        any_written = False
        status_changed_any = False
        for tmdb_id in shows:
            try:
                # ç›´æ¥é‡ç”¨å†…éƒ¨é€»è¾‘
                with app.app_context():
                    # è°ƒç”¨ä¸ endpoint ç›¸åŒçš„åˆ·æ–°æµç¨‹
                    season = tmdb_service.get_tv_show_episodes(int(tmdb_id), int(db.get_show(int(tmdb_id))['latest_season_number'])) or {}
                    episodes = season.get('episodes', []) or []
                    from time import time as _now
                    now_ts = int(_now())
                    for ep in episodes:
                        db.upsert_episode(
                            tmdb_id=int(tmdb_id),
                            season_number=int(db.get_show(int(tmdb_id))['latest_season_number']),
                            episode_number=int(ep.get('episode_number') or 0),
                            name=ep.get('name') or '',
                            overview=ep.get('overview') or '',
                            air_date=ep.get('air_date') or '',
                            runtime=ep.get('runtime'),
                            ep_type=(ep.get('episode_type') or ep.get('type')),
                            updated_at=now_ts,
                        )
                        any_written = True

                    # æ–°å¢ï¼šèŠ‚ç›®çŠ¶æ€å˜æ›´æ£€æµ‹ä¸æ›´æ–°ï¼ˆå¦‚ Returning â†’ æœ¬å­£ç»ˆ/å·²å®Œç»“ ç­‰ï¼‰
                    try:
                        existing_show = db.get_show(int(tmdb_id)) or {}
                        raw_details = tmdb_service.get_tv_show_details(int(tmdb_id)) or {}
                        raw_status = (raw_details.get('status') or '')
                        latest_sn_for_status = int((existing_show or {}).get('latest_season_number') or 1)
                        try:
                            localized_status = tmdb_service.get_localized_show_status(int(tmdb_id), latest_sn_for_status, raw_status)
                        except Exception:
                            localized_status = raw_status

                        old_status = (existing_show or {}).get('status') or ''
                        if localized_status and localized_status != old_status:
                            # ä»…æ›´æ–° status ç­‰å¿…è¦å­—æ®µï¼Œå…¶ä»–æ²¿ç”¨åŸå€¼
                            db.upsert_show(
                                tmdb_id=int(tmdb_id),
                                name=(existing_show or {}).get('name') or '',
                                year=(existing_show or {}).get('year') or '',
                                status=localized_status,
                                poster_local_path=(existing_show or {}).get('poster_local_path') or '',
                                latest_season_number=int((existing_show or {}).get('latest_season_number') or 1),
                                last_refreshed_at=now_ts,
                                bound_task_names=(existing_show or {}).get('bound_task_names') or '',
                                content_type=(existing_show or {}).get('content_type') or '',
                                is_custom_poster=int((existing_show or {}).get('is_custom_poster') or 0),
                            )
                            status_changed_any = True
                    except Exception:
                        # çŠ¶æ€æ›´æ–°å¤±è´¥ä¸å½±å“æ•´ä½“åˆ·æ–°
                        pass
            except Exception as e:
                logging.warning(f"è‡ªåŠ¨åˆ·æ–°å¤±è´¥ tmdb_id={tmdb_id}: {e}")
        try:
            if any_written:
                notify_calendar_changed('auto_refresh')
            if status_changed_any:
                notify_calendar_changed('status_updated')
        except Exception:
            pass
    except Exception as e:
        logging.warning(f"è‡ªåŠ¨åˆ·æ–°ä»»åŠ¡å¼‚å¸¸: {e}")
# æœ¬åœ°ç¼“å­˜è¯»å–ï¼šè·å–æœ€æ–°ä¸€å­£çš„æœ¬åœ°å‰§é›†æ•°æ®
@app.route("/api/calendar/episodes_local")
def get_calendar_episodes_local():
    try:
        tmdb_id = request.args.get('tmdb_id')
        db = CalendarDB()
        # å»ºç«‹ tmdb_id -> ä»»åŠ¡ä¿¡æ¯ æ˜ å°„ï¼Œç”¨äºå‰ç«¯ç­›é€‰ï¼ˆä»»åŠ¡å/ç±»å‹ï¼‰
        tmdb_to_taskinfo = {}
        try:
            tasks = config_data.get('tasklist', [])
            for t in tasks:
                cal = (t.get('calendar_info') or {})
                match = (cal.get('match') or {})
                extracted = (cal.get('extracted') or {})
                tid = match.get('tmdb_id')
                if tid:
                    tmdb_to_taskinfo[int(tid)] = {
                        'task_name': t.get('taskname') or t.get('task_name') or '',
                        'content_type': extracted.get('content_type') or extracted.get('type') or 'other',
                        'progress': {}
                    }
            # è‹¥æœªèƒ½å»ºç«‹å®Œæ•´æ˜ å°„ï¼Œå°è¯•åŸºäº shows è¡¨åç§°ä¸ä»»åŠ¡ extracted.show_name åšä¸€æ¬¡å…œåº•ç»‘å®š
            if not tmdb_to_taskinfo:
                try:
                    cur = db.conn.cursor()
                    cur.execute('SELECT tmdb_id, name FROM shows')
                    rows = cur.fetchall() or []
                    for tid, name in rows:
                        name = name or ''
                        # æ‰¾åˆ°åç§°ä¸€è‡´çš„ä»»åŠ¡
                        tgt = next((t for t in tasks if ((t.get('calendar_info') or {}).get('extracted') or {}).get('show_name') == name), None)
                        if tgt:
                            extracted = ((tgt.get('calendar_info') or {}).get('extracted') or {})
                            tmdb_to_taskinfo[int(tid)] = {
                                'task_name': tgt.get('taskname') or tgt.get('task_name') or '',
                                'content_type': extracted.get('content_type') or extracted.get('type') or 'other',
                                'progress': {}
                            }
                except Exception:
                    pass
        except Exception:
            tmdb_to_taskinfo = {}
        # è¯»å–ä»»åŠ¡æœ€æ–°è½¬å­˜æ–‡ä»¶ï¼Œæ„å»º task_name -> è§£æè¿›åº¦ æ˜ å°„
        progress_by_task = {}
        try:
            # ç›´æ¥è¯»å–æ•°æ®åº“ï¼Œé¿å…ä¾èµ–ç™»å½•æ ¡éªŒçš„æ¥å£è°ƒç”¨
            extractor = TaskExtractor()
            rdb = RecordDB()
            cursor = rdb.conn.cursor()
            cursor.execute("""
                SELECT task_name, MAX(transfer_time) as latest_transfer_time
                FROM transfer_records
                WHERE task_name NOT IN ('rename', 'undo_rename')
                GROUP BY task_name
            """)
            latest_times = cursor.fetchall() or []
            latest_files = {}
            for task_name, latest_time in latest_times:
                if latest_time:
                    time_window = 60000
                    cursor.execute(
                        """
                        SELECT renamed_to, original_name, transfer_time, modify_date
                        FROM transfer_records
                        WHERE task_name = ? AND transfer_time >= ? AND transfer_time <= ?
                        ORDER BY id DESC
                        """,
                        (task_name, latest_time - time_window, latest_time + time_window)
                    )
                    files = cursor.fetchall() or []
                    best_file = None
                    if files:
                        if len(files) == 1:
                            best_file = files[0][0]
                        else:
                            file_list = []
                            for renamed_to, original_name, transfer_time, modify_date in files:
                                file_list.append({'file_name': renamed_to, 'original_name': original_name, 'updated_at': transfer_time})
                            try:
                                sorted_files = sorted(file_list, key=sort_file_by_name)
                                best_file = sorted_files[-1]['file_name']
                            except Exception:
                                best_file = files[0][0]
                    if best_file:
                        file_name_without_ext = os.path.splitext(best_file)[0]
                        processed_name = process_season_episode_info(file_name_without_ext, task_name)
                        latest_files[task_name] = processed_name
            rdb.close()
            for tname, latest in (latest_files or {}).items():
                parsed = extractor.extract_progress_from_latest_file(latest)
                if parsed and (parsed.get('episode_number') or parsed.get('air_date')):
                    progress_by_task[tname] = parsed
        except Exception:
            progress_by_task = {}

        if tmdb_id:
            show = db.get_show(int(tmdb_id))
            if not show:
                return jsonify({'success': True, 'data': {'episodes': [], 'total': 0}})
            eps = db.list_latest_season_episodes(int(tmdb_id), int(show['latest_season_number']))
            # æ³¨å…¥ä»»åŠ¡ä¿¡æ¯ä¸æ ‡å‡†åŒ–è¿›åº¦
            info = tmdb_to_taskinfo.get(int(tmdb_id))
            if info:
                for e in eps:
                    e['task_info'] = info
                    # åˆå¹¶æ ‡å‡†åŒ–è¿›åº¦
                    tname = info.get('task_name') or ''
                    p = progress_by_task.get(tname)
                    if p:
                        e['task_info']['progress'] = p
            return jsonify({'success': True, 'data': {'episodes': eps, 'total': len(eps), 'show': show}})
        else:
            # è¿”å›å…¨éƒ¨æœ€æ–°å­£æ±‡æ€»ï¼ˆä¾›å‘¨è§†å›¾åˆå¹¶å±•ç¤ºï¼‰
            eps = db.list_all_latest_episodes()
            for e in eps:
                info = tmdb_to_taskinfo.get(int(e.get('tmdb_id')))
                if info:
                    e['task_info'] = info
                    tname = info.get('task_name') or ''
                    p = progress_by_task.get(tname)
                    if p:
                        e['task_info']['progress'] = p
            return jsonify({'success': True, 'data': {'episodes': eps, 'total': len(eps)}})
    except Exception as e:
        return jsonify({'success': False, 'message': f'è¯»å–æœ¬åœ°å‰§é›†å¤±è´¥: {str(e)}', 'data': {'episodes': [], 'total': 0}})


# æ¸…ç†ç¼“å­˜ï¼šæŒ‰ tmdb_id åˆ é™¤å¯¹åº”å‰§ç›®çš„æ‰€æœ‰æœ¬åœ°ç¼“å­˜
@app.route("/api/calendar/purge_tmdb", methods=["POST"])
def purge_calendar_tmdb():
    try:
        tmdb_id = request.args.get('tmdb_id') or (request.json or {}).get('tmdb_id')
        if not tmdb_id:
            return jsonify({'success': False, 'message': 'ç¼ºå°‘ tmdb_id'})
        force = False
        try:
            fv = request.args.get('force') or (request.json or {}).get('force')
            force = True if str(fv).lower() in ('1', 'true', 'yes') else False
        except Exception:
            force = False
        ok = purge_calendar_by_tmdb_id_internal(int(tmdb_id), force=force)
        try:
            if ok:
                notify_calendar_changed('purge_tmdb')
        except Exception:
            pass
        return jsonify({'success': ok})
    except Exception as e:
        return jsonify({'success': False, 'message': f'æ¸…ç†å¤±è´¥: {str(e)}'})


# æ¸…ç†ç¼“å­˜ï¼šæŒ‰ä»»åŠ¡åæŸ¥æ‰¾ config ä¸­çš„ tmdb_id å¹¶æ¸…ç†
@app.route("/api/calendar/purge_by_task", methods=["POST"])
def purge_calendar_by_task():
    try:
        task_name = request.args.get('task_name') or (request.json or {}).get('task_name')
        if not task_name:
            return jsonify({'success': False, 'message': 'ç¼ºå°‘ task_name'})
        force = False
        try:
            fv = request.args.get('force') or (request.json or {}).get('force')
            force = True if str(fv).lower() in ('1', 'true', 'yes') else False
        except Exception:
            force = False
        # åœ¨é…ç½®ä¸­æŸ¥æ‰¾å¯¹åº”ä»»åŠ¡
        tasks = config_data.get('tasklist', [])
        target = next((t for t in tasks if t.get('taskname') == task_name or t.get('task_name') == task_name), None)
        if not target:
            # è‹¥ä»»åŠ¡ä¸å­˜åœ¨ï¼Œä½†ç”¨æˆ·å¸Œæœ›å¼ºåˆ¶æ¸…ç†ï¼šå°è¯•æŒ‰ tmdb_id åæŸ¥æ— å¼•ç”¨ show å¹¶æ¸…ç†ï¼ˆæ›´å®‰å…¨ï¼‰
            if force:
                # æ‰«æ shows è¡¨ï¼Œåˆ é™¤æœªè¢«ä»»ä½•ä»»åŠ¡å¼•ç”¨çš„è®°å½•ï¼ˆå­¤å„¿ï¼‰
                purged = purge_orphan_calendar_shows_internal()
                try:
                    if purged > 0:
                        notify_calendar_changed('purge_orphans')
                except Exception:
                    pass
                return jsonify({'success': True, 'message': f'ä»»åŠ¡ä¸å­˜åœ¨ï¼Œå·²å¼ºåˆ¶æ¸…ç†å­¤å„¿è®°å½• {purged} æ¡'})
            return jsonify({'success': True, 'message': 'ä»»åŠ¡ä¸å­˜åœ¨ï¼Œè§†ä¸ºå·²æ¸…ç†'})
        cal = (target or {}).get('calendar_info') or {}
        tmdb_id = cal.get('match', {}).get('tmdb_id') or cal.get('tmdb_id')
        if not tmdb_id:
            return jsonify({'success': True, 'message': 'ä»»åŠ¡æœªç»‘å®š tmdb_idï¼Œæ— éœ€æ¸…ç†'})
        ok = purge_calendar_by_tmdb_id_internal(int(tmdb_id), force=force)
        try:
            if ok:
                notify_calendar_changed('purge_by_task')
        except Exception:
            pass
        return jsonify({'success': ok})
    except Exception as e:
        return jsonify({'success': False, 'message': f'æ¸…ç†å¤±è´¥: {str(e)}'})
# è±†ç“£APIè·¯ç”±

# é€šç”¨ç”µå½±æ¥å£
@app.route("/api/douban/movie/recent_hot")
def get_movie_recent_hot():
    """è·å–ç”µå½±æ¦œå• - é€šç”¨æ¥å£"""
    try:
        category = request.args.get('category', 'çƒ­é—¨')
        type_param = request.args.get('type', 'å…¨éƒ¨')
        limit = int(request.args.get('limit', 20))
        start = int(request.args.get('start', 0))

        # æ˜ å°„categoryåˆ°main_category
        category_mapping = {
            'çƒ­é—¨': 'movie_hot',
            'æœ€æ–°': 'movie_latest',
            'è±†ç“£é«˜åˆ†': 'movie_top',
            'å†·é—¨ä½³ç‰‡': 'movie_underrated'
        }

        main_category = category_mapping.get(category, 'movie_hot')
        result = douban_service.get_list_data(main_category, type_param, limit, start)

        return jsonify(result)
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–ç”µå½±æ¦œå•å¤±è´¥: {str(e)}',
            'data': {'items': []}
        })

@app.route("/api/douban/movie/<movie_type>/<sub_category>")
def get_movie_list(movie_type, sub_category):
    """è·å–ç”µå½±æ¦œå•"""
    try:
        limit = int(request.args.get('limit', 20))
        start = int(request.args.get('start', 0))

        main_category = f"movie_{movie_type}"
        result = douban_service.get_list_data(main_category, sub_category, limit, start)

        return jsonify(result)
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–ç”µå½±æ¦œå•å¤±è´¥: {str(e)}',
            'data': {'items': []}
        })


# é€šç”¨ç”µè§†å‰§æ¥å£
@app.route("/api/douban/tv/recent_hot")
def get_tv_recent_hot():
    """è·å–ç”µè§†å‰§æ¦œå• - é€šç”¨æ¥å£"""
    try:
        category = request.args.get('category', 'tv')
        type_param = request.args.get('type', 'tv')
        limit = int(request.args.get('limit', 20))
        start = int(request.args.get('start', 0))

        # æ˜ å°„categoryåˆ°main_category
        if category == 'tv':
            main_category = 'tv_drama'
        elif category == 'show':
            main_category = 'tv_variety'
        elif category == 'tv_drama':
            main_category = 'tv_drama'
        elif category == 'tv_variety':
            main_category = 'tv_variety'
        else:
            main_category = 'tv_drama'

        result = douban_service.get_list_data(main_category, type_param, limit, start)

        return jsonify(result)
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–ç”µè§†å‰§æ¦œå•å¤±è´¥: {str(e)}',
            'data': {'items': []}
        })

@app.route("/api/douban/tv/<tv_type>/<sub_category>")
def get_tv_list(tv_type, sub_category):
    """è·å–ç”µè§†å‰§/ç»¼è‰ºæ¦œå•"""
    try:
        limit = int(request.args.get('limit', 20))
        start = int(request.args.get('start', 0))

        main_category = f"tv_{tv_type}"
        result = douban_service.get_list_data(main_category, sub_category, limit, start)

        return jsonify(result)
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–ç”µè§†å‰§æ¦œå•å¤±è´¥: {str(e)}',
            'data': {'items': []}
        })

@app.route("/api/calendar/update_content_type", methods=["POST"])
def update_show_content_type():
    """æ›´æ–°èŠ‚ç›®çš„å†…å®¹ç±»å‹"""
    try:
        data = request.get_json()
        tmdb_id = data.get('tmdb_id')
        content_type = data.get('content_type')
        
        if not tmdb_id or not content_type:
            return jsonify({
                'success': False,
                'message': 'ç¼ºå°‘å¿…è¦å‚æ•°ï¼štmdb_id æˆ– content_type'
            })
        
        from app.sdk.db import CalendarDB
        cal_db = CalendarDB()
        
        # æ›´æ–°å†…å®¹ç±»å‹
        success = cal_db.update_show_content_type(int(tmdb_id), content_type)
        
        if success:
            return jsonify({
                'success': True,
                'message': 'å†…å®¹ç±»å‹æ›´æ–°æˆåŠŸ'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'èŠ‚ç›®ä¸å­˜åœ¨æˆ–æ›´æ–°å¤±è´¥'
            })
            
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'æ›´æ–°å†…å®¹ç±»å‹å¤±è´¥: {str(e)}'
        })

@app.route("/api/calendar/content_types")
def get_content_types():
    """è·å–æ‰€æœ‰èŠ‚ç›®å†…å®¹ç±»å‹"""
    try:
        from app.sdk.db import CalendarDB
        cal_db = CalendarDB()
        content_types = cal_db.get_all_content_types()
        return jsonify({
            'success': True,
            'data': content_types
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'è·å–èŠ‚ç›®å†…å®¹ç±»å‹å¤±è´¥: {str(e)}'
        })

def cleanup_episode_patterns_config(config_data):
    """æ¸…ç†å‰§é›†è¯†åˆ«è§„åˆ™é…ç½®"""
    try:
        # éœ€è¦æ¸…ç†çš„é»˜è®¤å‰§é›†è¯†åˆ«è§„åˆ™ï¼ˆæŒ‰éƒ¨åˆ†è§„åˆ™åŒ¹é…ï¼‰
        default_pattern_parts = [
            "ç¬¬(\\d+)é›†",
            "ç¬¬(\\d+)æœŸ", 
            "ç¬¬(\\d+)è¯",
            "(\\d+)é›†",
            "(\\d+)æœŸ",
            "(\\d+)è¯",
            "[Ee][Pp]?(\\d+)",
            "(\\d+)[-_\\s]*4[Kk]",
            "(\\d+)[-_\\\\s]*4[Kk]",
            "\\[(\\d+)\\]",
            "ã€(\\d+)ã€‘",
            "_?(\\d+)_?"
        ]
        
        cleaned_tasks = 0
        cleaned_global = False
        
        # 1. æ¸…ç†ä»»åŠ¡çº§åˆ«çš„ config_data.episode_patterns
        if 'tasklist' in config_data:
            for task in config_data['tasklist']:
                if 'config_data' in task and 'episode_patterns' in task['config_data']:
                    del task['config_data']['episode_patterns']
                    cleaned_tasks += 1
                    # å¦‚æœ config_data ä¸ºç©ºï¼Œåˆ é™¤æ•´ä¸ª config_data
                    if not task['config_data']:
                        del task['config_data']
        
        # 2. æ¸…ç†å…¨å±€é…ç½®ä¸­çš„é»˜è®¤è§„åˆ™
        if 'episode_patterns' in config_data:
            current_patterns = config_data['episode_patterns']
            if isinstance(current_patterns, list):
                # è¿‡æ»¤æ‰åŒ…å«é»˜è®¤è§„åˆ™çš„é…ç½®
                filtered_patterns = []
                for pattern in current_patterns:
                    if isinstance(pattern, dict) and 'regex' in pattern:
                        pattern_regex = pattern['regex']
                        # ç”¨ç«–çº¿åˆ†å‰²è§„åˆ™
                        pattern_parts = pattern_regex.split('|')
                        # è¿‡æ»¤æ‰é»˜è®¤è§„åˆ™éƒ¨åˆ†ï¼Œä¿ç•™è‡ªå®šä¹‰è§„åˆ™
                        custom_parts = [part.strip() for part in pattern_parts if part.strip() not in default_pattern_parts]
                        
                        if custom_parts:
                            # å¦‚æœæœ‰è‡ªå®šä¹‰è§„åˆ™ï¼Œä¿ç•™å¹¶é‡æ–°ç»„åˆ
                            filtered_patterns.append({
                                'regex': '|'.join(custom_parts)
                            })
                    elif isinstance(pattern, str):
                        pattern_regex = pattern
                        # ç”¨ç«–çº¿åˆ†å‰²è§„åˆ™
                        pattern_parts = pattern_regex.split('|')
                        # è¿‡æ»¤æ‰é»˜è®¤è§„åˆ™éƒ¨åˆ†ï¼Œä¿ç•™è‡ªå®šä¹‰è§„åˆ™
                        custom_parts = [part.strip() for part in pattern_parts if part.strip() not in default_pattern_parts]
                        
                        if custom_parts:
                            # å¦‚æœæœ‰è‡ªå®šä¹‰è§„åˆ™ï¼Œä¿ç•™å¹¶é‡æ–°ç»„åˆ
                            filtered_patterns.append('|'.join(custom_parts))
                
                # æ›´æ–°é…ç½®
                if filtered_patterns:
                    config_data['episode_patterns'] = filtered_patterns
                else:
                    # å¦‚æœæ²¡æœ‰å‰©ä½™è§„åˆ™ï¼Œæ¸…ç©ºé…ç½®
                    config_data['episode_patterns'] = []
                    cleaned_global = True
        
        # é™é»˜æ‰§è¡Œæ¸…ç†æ“ä½œï¼Œä¸è¾“å‡ºæ—¥å¿—
        
        return True
        
    except Exception as e:
        logging.error(f"æ¸…ç†å‰§é›†è¯†åˆ«è§„åˆ™é…ç½®å¤±è´¥: {str(e)}")
        return False

@app.route("/api/calendar/cleanup_orphaned_posters", methods=["POST"])
def cleanup_orphaned_posters_api():
    """æ‰‹åŠ¨æ¸…ç†å­¤ç«‹çš„æ—§æµ·æŠ¥æ–‡ä»¶"""
    try:
        if not is_login():
            return jsonify({"success": False, "message": "æœªç™»å½•"})
        
        success = cleanup_orphaned_posters()
        if success:
            return jsonify({"success": True, "message": "å­¤ç«‹æµ·æŠ¥æ–‡ä»¶æ¸…ç†å®Œæˆ"})
        else:
            return jsonify({"success": True, "message": "æ²¡æœ‰å‘ç°éœ€è¦æ¸…ç†çš„å­¤ç«‹æ–‡ä»¶"})
    except Exception as e:
        return jsonify({"success": False, "message": f"æ¸…ç†å­¤ç«‹æµ·æŠ¥å¤±è´¥: {str(e)}"})

if __name__ == "__main__":
    IS_FLASK_SERVER_PROCESS = True
    init()
    reload_tasks()
    # åœ¨ reload_tasks() ä¹‹åé‡æ–°æ³¨å†Œä¼šè¢«æ¸…ç©ºçš„åå°ä»»åŠ¡ï¼ˆé¿å… remove_all_jobs çš„å½±å“ï¼‰
    try:
        restart_calendar_refresh_job()
    except Exception:
        pass
    try:
        restart_daily_aired_update_job()
    except Exception:
        pass
    # åˆå§‹åŒ–å…¨å±€dbå¯¹è±¡ï¼Œç¡®ä¿æ‰€æœ‰æ¥å£å¯ç”¨
    record_db = RecordDB()
    app.run(debug=DEBUG, host="0.0.0.0", port=PORT)
