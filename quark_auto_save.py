# !/usr/bin/env python3
# -*- coding: utf-8 -*-
# ConfigFile: quark_config.json
"""
new Env('å¤¸å…‹è‡ªåŠ¨è¿½æ›´');
0 8,18,20 * * * quark_auto_save.py
"""
import os
import re
import sys
import json
import time
import random
import requests
import importlib
import urllib.parse
from datetime import datetime

# æ·»åŠ æ•°æ®åº“å¯¼å…¥
try:
    from app.sdk.db import RecordDB, CalendarDB
except ImportError:
    # å¦‚æœç›´æ¥è¿è¡Œè„šæœ¬ï¼Œè·¯å¾„å¯èƒ½ä¸åŒ
    sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
    try:
        from app.sdk.db import RecordDB, CalendarDB
    except ImportError:
        # å®šä¹‰ä¸€ä¸ªç©ºçš„RecordDBç±»ï¼Œä»¥é˜²æ­¢å¯¼å…¥å¤±è´¥
        class RecordDB:
            def __init__(self, *args, **kwargs):
                self.enabled = False
            
            def add_record(self, *args, **kwargs):
                pass
            
            def close(self):
                pass
        
        # å®šä¹‰ä¸€ä¸ªç©ºçš„CalendarDBç±»ï¼Œä»¥é˜²æ­¢å¯¼å…¥å¤±è´¥
        class CalendarDB:
            def __init__(self, *args, **kwargs):
                self.enabled = False
            
            def get_task_metrics(self, *args, **kwargs):
                return None

def notify_calendar_changed_safe(reason):
    """å®‰å…¨åœ°è§¦å‘SSEé€šçŸ¥ï¼Œé¿å…å¯¼å…¥é”™è¯¯
    
    ä¿®å¤ï¼šä¸å†é€šè¿‡ç›´æ¥å¯¼å…¥ run.py è°ƒç”¨å‡½æ•°ï¼ˆè¯¥æ–¹å¼ä»…ä½œç”¨äºå½“å‰è¿›ç¨‹ï¼Œæ— æ³•é€šçŸ¥è¿è¡Œä¸­çš„ Flask æœåŠ¡ï¼‰ï¼Œ
    è€Œæ˜¯é€šè¿‡ HTTP è°ƒç”¨åç«¯æä¾›çš„ /api/calendar/notify æ¥å£ï¼Œç”±å®é™…çš„ Web è¿›ç¨‹ç»Ÿä¸€è´Ÿè´£å¹¿æ’­ SSE äº‹ä»¶ã€‚
    """
    try:
        # ä¼˜å…ˆä½¿ç”¨ä¸ Flask ç›¸åŒçš„ PORT ç¯å¢ƒå˜é‡ï¼›å…è®¸é€šè¿‡ CALENDAR_SERVER_BASE è‡ªå®šä¹‰æœåŠ¡åŸºå€
        port = os.environ.get("PORT", "5005")
        base_url = os.environ.get("CALENDAR_SERVER_BASE", f"http://127.0.0.1:{port}")
        requests.post(
            f"{base_url}/api/calendar/notify",
            json={"reason": reason},
            timeout=1
        )
    except Exception as e:
        # ä»…è¾“å‡ºæç¤ºï¼Œä¸å½±å“ä¸»æµç¨‹
        print(f"è§¦å‘SSEé€šçŸ¥å¤±è´¥: {e}")

def advanced_filter_files(file_list, filterwords):
    """
    é«˜çº§è¿‡æ»¤å‡½æ•°ï¼Œæ”¯æŒä¿ç•™è¯å’Œè¿‡æ»¤è¯
    
    Args:
        file_list: æ–‡ä»¶åˆ—è¡¨
        filterwords: è¿‡æ»¤è§„åˆ™å­—ç¬¦ä¸²ï¼Œæ”¯æŒä»¥ä¸‹æ ¼å¼ï¼š
            - "åŠ æ›´ï¼Œä¼åˆ’ï¼Œè¶…å‰ï¼Œ(1)ï¼Œmkvï¼Œnfo"  # åªæœ‰è¿‡æ»¤è¯
            - "æœŸ|åŠ æ›´ï¼Œä¼åˆ’ï¼Œè¶…å‰ï¼Œ(1)ï¼Œmkvï¼Œnfo"  # ä¿ç•™è¯|è¿‡æ»¤è¯
            - "æœŸï¼Œ2160P|åŠ æ›´ï¼Œä¼åˆ’ï¼Œè¶…å‰ï¼Œ(1)ï¼Œmkvï¼Œnfo"  # å¤šä¸ªä¿ç•™è¯(æˆ–å…³ç³»)|è¿‡æ»¤è¯
            - "æœŸ|2160P|åŠ æ›´ï¼Œä¼åˆ’ï¼Œè¶…å‰ï¼Œ(1)ï¼Œmkvï¼Œnfo"  # å¤šä¸ªä¿ç•™è¯(å¹¶å…³ç³»)|è¿‡æ»¤è¯
            - "æœŸï¼Œ2160P|"  # åªæœ‰ä¿ç•™è¯ï¼Œæ— è¿‡æ»¤è¯
    
    Returns:
        è¿‡æ»¤åçš„æ–‡ä»¶åˆ—è¡¨
    """
    if not filterwords or not filterwords.strip():
        return file_list
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«åˆ†éš”ç¬¦ |
    if '|' not in filterwords:
        # åªæœ‰è¿‡æ»¤è¯çš„æƒ…å†µ
        filterwords = filterwords.replace("ï¼Œ", ",")
        filterwords_list = [word.strip().lower() for word in filterwords.split(',') if word.strip()]
        
        filtered_files = []
        for file in file_list:
            file_name = file['file_name'].lower()
            file_ext = os.path.splitext(file_name)[1].lower().lstrip('.')
            
            # æ£€æŸ¥è¿‡æ»¤è¯æ˜¯å¦å­˜åœ¨äºæ–‡ä»¶åä¸­ï¼Œæˆ–è€…è¿‡æ»¤è¯ç­‰äºæ‰©å±•å
            if not any(word in file_name for word in filterwords_list) and not any(word == file_ext for word in filterwords_list):
                filtered_files.append(file)
        
        return filtered_files
    
    # åŒ…å«åˆ†éš”ç¬¦çš„æƒ…å†µï¼Œéœ€è¦è§£æä¿ç•™è¯å’Œè¿‡æ»¤è¯
    parts = filterwords.split('|')
    if len(parts) < 2:
        # æ ¼å¼é”™è¯¯ï¼Œè¿”å›åŸåˆ—è¡¨
        return file_list
    
    # æœ€åä¸€ä¸ª|åé¢çš„æ˜¯è¿‡æ»¤è¯
    filter_part = parts[-1].strip()
    # å‰é¢çš„éƒ½æ˜¯ä¿ç•™è¯
    keep_parts = [part.strip() for part in parts[:-1] if part.strip()]
    
    # è§£æè¿‡æ»¤è¯
    filterwords_list = []
    if filter_part:
        filter_part = filter_part.replace("ï¼Œ", ",")
        filterwords_list = [word.strip().lower() for word in filter_part.split(',') if word.strip()]
    
    # è§£æä¿ç•™è¯ï¼šæ¯ä¸ª|åˆ†éš”çš„éƒ¨åˆ†éƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ç­›é€‰æ¡ä»¶
    # è¿™äº›æ¡ä»¶éœ€è¦æŒ‰é¡ºåºä¾æ¬¡åº”ç”¨ï¼Œå½¢æˆé“¾å¼ç­›é€‰
    keep_conditions = []
    for part in keep_parts:
        if part.strip():
            if ',' in part or 'ï¼Œ' in part:
                # åŒ…å«é€—å·ï¼Œè¡¨ç¤ºæˆ–å…³ç³»
                part = part.replace("ï¼Œ", ",")
                or_words = [word.strip().lower() for word in part.split(',') if word.strip()]
                keep_conditions.append(("or", or_words))
            else:
                # ä¸åŒ…å«é€—å·ï¼Œè¡¨ç¤ºå•ä¸ªè¯
                keep_conditions.append(("single", [part.strip().lower()]))
    
    # ç¬¬ä¸€æ­¥ï¼šåº”ç”¨ä¿ç•™è¯ç­›é€‰ï¼ˆé“¾å¼ç­›é€‰ï¼‰
    if keep_conditions:
        for condition_type, words in keep_conditions:
            filtered_by_keep = []
            for file in file_list:
                file_name = file['file_name'].lower()
                
                if condition_type == "or":
                    # æˆ–å…³ç³»ï¼šåŒ…å«ä»»æ„ä¸€ä¸ªè¯å³å¯
                    if any(word in file_name for word in words):
                        filtered_by_keep.append(file)
                elif condition_type == "single":
                    # å•ä¸ªè¯ï¼šå¿…é¡»åŒ…å«
                    if words[0] in file_name:
                        filtered_by_keep.append(file)
            
            file_list = filtered_by_keep
    
    # ç¬¬äºŒæ­¥ï¼šåº”ç”¨è¿‡æ»¤è¯è¿‡æ»¤
    if filterwords_list:
        filtered_files = []
        for file in file_list:
            file_name = file['file_name'].lower()
            file_ext = os.path.splitext(file_name)[1].lower().lstrip('.')
            
            # æ£€æŸ¥è¿‡æ»¤è¯æ˜¯å¦å­˜åœ¨äºæ–‡ä»¶åä¸­ï¼Œæˆ–è€…è¿‡æ»¤è¯ç­‰äºæ‰©å±•å
            if not any(word in file_name for word in filterwords_list) and not any(word == file_ext for word in filterwords_list):
                filtered_files.append(file)
        
        return filtered_files
    
    return file_list

# å…¨å±€çš„æ–‡ä»¶æ’åºå‡½æ•°
def sort_file_by_name(file):
    """
    é€šç”¨çš„æ–‡ä»¶æ’åºå‡½æ•°ï¼Œç”¨äºæ ¹æ®æ–‡ä»¶åæ™ºèƒ½æ’åº
    æ”¯æŒå¤šç§æ ¼å¼çš„æ—¥æœŸã€æœŸæ•°ã€é›†æ•°ç­‰æå–å’Œæ’åº
    ä½¿ç”¨å¤šçº§æ’åºé”®ï¼ŒæŒ‰æ—¥æœŸã€æœŸæ•°ã€ä¸Šä¸­ä¸‹é¡ºåºæ’åº
    å¦‚æœä»¥ä¸Šå‡æ— æ³•æå–ï¼Œåˆ™ä½¿ç”¨æ–‡ä»¶æ›´æ–°æ—¶é—´å’Œæ‹¼éŸ³æ’åºä½œä¸ºæœ€åæ’åºä¾æ®
    """
    if isinstance(file, dict) and file.get("dir", False):  # è·³è¿‡æ–‡ä»¶å¤¹
        return (float('inf'), float('inf'), float('inf'), 0, "")

    # è·å–æ–‡ä»¶åï¼Œæ”¯æŒå­—ç¬¦ä¸²æˆ–æ–‡ä»¶å¯¹è±¡
    if isinstance(file, dict):
        filename = file.get("file_name", "")
        # è·å–æ›´æ–°æ—¶é—´ä½œä¸ºç¬¬å››çº§æ’åºä¾æ®
        update_time = file.get("updated_at", 0)
    else:
        filename = file
        update_time = 0

    # å¯¼å…¥æ‹¼éŸ³æ’åºå·¥å…·ç”¨äºç¬¬äº”çº§æ’åº
    try:
        from app.utils.pinyin_sort import get_filename_pinyin_sort_key
        pinyin_sort_key = get_filename_pinyin_sort_key(filename)
    except ImportError:
        # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„å°å†™æ’åºä½œä¸ºå¤‡ç”¨
        pinyin_sort_key = filename.lower()
    
    # æå–æ–‡ä»¶åï¼Œä¸å«æ‰©å±•å
    file_name_without_ext = os.path.splitext(filename)[0]
    
    # åˆå§‹åŒ–æ’åºå€¼
    date_value = float('inf')  # æ—¥æœŸé”®ï¼ˆç¬¬ä¸€çº§ï¼‰
    episode_value = float('inf')  # æœŸæ•°/é›†æ•°é”®ï¼ˆç¬¬äºŒçº§ï¼‰
    segment_value = 0  # ä¸Šä¸­ä¸‹/å…¶ä»–ç»†åˆ†é”®ï¼ˆç¬¬ä¸‰çº§ï¼‰
    
    # 1. æå–æ—¥æœŸ - ç¬¬ä¸€çº§æ’åºé”®
    
    # 1.1 YYYY-MM-DD æˆ– YYYY.MM.DD æˆ– YYYY/MM/DD æˆ– YYYY MM DDæ ¼å¼ï¼ˆå››ä½å¹´ä»½ï¼‰
    match_date_full = re.search(r'((?:19|20)\d{2})[-./\s](\d{1,2})[-./\s](\d{1,2})', filename)
    if match_date_full:
        year = int(match_date_full.group(1))
        month = int(match_date_full.group(2))
        day = int(match_date_full.group(3))
        date_value = year * 10000 + month * 100 + day
    
    # 1.2 YY-MM-DD æˆ– YY.MM.DD æˆ– YY/MM/DD æˆ– YY MM DDæ ¼å¼ï¼ˆä¸¤ä½å¹´ä»½ï¼‰
    if date_value == float('inf'):
        match_yy_date = re.search(r'((?:19|20)?\d{2})[-./\s](\d{1,2})[-./\s](\d{1,2})', filename)
        if match_yy_date and len(match_yy_date.group(1)) == 2:
            year_str = match_yy_date.group(1)
            # å¦‚æœæ˜¯ä¸¤ä½å¹´ä»½ï¼Œå‡è®¾20xxå¹´
            year = int("20" + year_str)
            month = int(match_yy_date.group(2))
            day = int(match_yy_date.group(3))
            date_value = year * 10000 + month * 100 + day
    
    # 1.3 å®Œæ•´çš„YYYYMMDDæ ¼å¼ï¼ˆæ— åˆ†éš”ç¬¦ï¼‰
    if date_value == float('inf'):
        match_date_compact = re.search(r'((?:19|20)\d{2})(\d{2})(\d{2})', filename)
        if match_date_compact:
            year = int(match_date_compact.group(1))
            month = int(match_date_compact.group(2))
            day = int(match_date_compact.group(3))
            date_value = year * 10000 + month * 100 + day
    
    # 1.4 YYMMDDæ ¼å¼ï¼ˆä¸¤ä½å¹´ä»½ï¼Œæ— åˆ†éš”ç¬¦ï¼‰
    if date_value == float('inf'):
        match_yy_compact = re.search(r'(?<!\d)(\d{2})(\d{2})(\d{2})(?!\d)', filename)
        if match_yy_compact:
            year_str = match_yy_compact.group(1)
            # æ£€æŸ¥æœˆä»½å’Œæ—¥æœŸçš„æœ‰æ•ˆæ€§
            month = int(match_yy_compact.group(2))
            day = int(match_yy_compact.group(3))
            if 1 <= month <= 12 and 1 <= day <= 31:
                # åˆç†çš„æœˆä»½å’Œæ—¥æœŸï¼Œå‡è®¾ä¸ºYY-MM-DD
                year = int("20" + year_str)
                date_value = year * 10000 + month * 100 + day
    
    # 1.5 MM/DD/YYYY æˆ– DD/MM/YYYY æ ¼å¼
    if date_value == float('inf'):
        match_date_alt = re.search(r'(\d{1,2})[-./\s](\d{1,2})[-./\s]((?:19|20)\d{2})', filename)
        if match_date_alt:
            # å‡è®¾ç¬¬ä¸€ä¸ªæ˜¯æœˆï¼Œç¬¬äºŒä¸ªæ˜¯æ—¥ï¼ˆç¾å¼æ—¥æœŸï¼‰
            month = int(match_date_alt.group(1))
            day = int(match_date_alt.group(2))
            year = int(match_date_alt.group(3))
            # æ£€æŸ¥æœˆä»½å€¼ï¼Œå¦‚æœå¤§äº12å¯èƒ½æ˜¯æ¬§å¼æ—¥æœŸæ ¼å¼ï¼ˆDD/MM/YYYYï¼‰
            if month > 12:
                month, day = day, month
            date_value = year * 10000 + month * 100 + day
    
    # 1.6 MM-DD æˆ– MM.DD æˆ– MM/DDæ ¼å¼ï¼ˆæ— å¹´ä»½ï¼Œä¸åŒ…æ‹¬ç©ºæ ¼åˆ†éš”ï¼‰
    if date_value == float('inf'):
        match_date_short = re.search(r'(?<!\d)(\d{1,2})[-./](\d{1,2})(?!\d)', filename)
        if match_date_short:
            # å‡è®¾ç¬¬ä¸€ä¸ªæ˜¯æœˆï¼Œç¬¬äºŒä¸ªæ˜¯æ—¥
            month = int(match_date_short.group(1))
            day = int(match_date_short.group(2))
            # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„æœˆæ—¥ç»„åˆ
            if ((month >= 1 and month <= 12 and day >= 1 and day <= 31) or
                (day >= 1 and day <= 12 and month >= 1 and month <= 31)):
                # æ£€æŸ¥æœˆä»½å€¼ï¼Œå¦‚æœå¤§äº12å¯èƒ½æ˜¯æ¬§å¼æ—¥æœŸæ ¼å¼ï¼ˆDD/MMï¼‰
                if month > 12:
                    month, day = day, month
                # ç”±äºæ²¡æœ‰å¹´ä»½ï¼Œä½¿ç”¨ä¸€ä¸ªè¾ƒä½çš„åŸºæ•°ï¼Œç¡®ä¿ä»»ä½•æœ‰å¹´ä»½çš„æ—¥æœŸéƒ½æ’åœ¨å‰é¢
                # ä½¿ç”¨20000000ä½œä¸ºåŸºå‡†ï¼Œæ‰€ä»¥æ— å¹´ä»½æ—¥æœŸéƒ½ä¼šæ’åœ¨æœ‰å¹´ä»½æ—¥æœŸä¹‹å
                date_value = 20000000 + month * 100 + day
    
    # 2. æå–æœŸæ•°/é›†æ•° - ç¬¬äºŒçº§æ’åºé”®
    
    # 2.1 "ç¬¬XæœŸ/é›†/è¯/éƒ¨/ç¯‡" æ ¼å¼ï¼ˆæ”¯æŒç©ºæ ¼ï¼‰
    match_chinese = re.search(r'ç¬¬\s*(\d+)\s*[æœŸé›†è¯éƒ¨ç¯‡]', filename)
    if match_chinese:
        episode_value = int(match_chinese.group(1))

    # 2.1.1 "ç¬¬[ä¸­æ–‡æ•°å­—]æœŸ/é›†/è¯/éƒ¨/ç¯‡" æ ¼å¼ï¼ˆæ”¯æŒç©ºæ ¼ï¼‰
    if episode_value == float('inf'):
        match_chinese_num = re.search(r'ç¬¬\s*([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)\s*[æœŸé›†è¯éƒ¨ç¯‡]', filename)
        if match_chinese_num:
            chinese_num = match_chinese_num.group(1)
            arabic_num = chinese_to_arabic(chinese_num)
            if arabic_num is not None:
                episode_value = arabic_num
    
    # 2.2 "Xé›†/æœŸ/è¯" æ ¼å¼
    if episode_value == float('inf'):
        match_chinese_simple = re.search(r'(\d+)[æœŸé›†è¯]', filename)
        if match_chinese_simple:
            episode_value = int(match_chinese_simple.group(1))
    
    # 2.2.1 "[ä¸­æ–‡æ•°å­—]é›†/æœŸ/è¯" æ ¼å¼
    if episode_value == float('inf'):
        match_chinese_simple_num = re.search(r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)[æœŸé›†è¯]', filename)
        if match_chinese_simple_num:
            chinese_num = match_chinese_simple_num.group(1)
            arabic_num = chinese_to_arabic(chinese_num)
            if arabic_num is not None:
                episode_value = arabic_num
    
    # 2.3 S01E01æ ¼å¼
    if episode_value == float('inf'):
        match_s_e = re.search(r'[Ss](\d+)[Ee](\d+)', filename)
        if match_s_e:
            season = int(match_s_e.group(1))
            episode = int(match_s_e.group(2))
            # ä½¿ç”¨å­£*1000+é›†ä½œä¸ºæœŸæ•°å€¼
            episode_value = episode  # åªç”¨é›†æ•°ä½œä¸ºæ’åºé”®
    
    # 2.4 E01/EP01æ ¼å¼
    if episode_value == float('inf'):
        match_e = re.search(r'[Ee][Pp]?(\d+)', filename)
        if match_e:
            # è‹¥æ•°å­—ä½äºå«å­—æ¯çš„ä¸­æ‹¬å·å†…éƒ¨ï¼Œè·³è¿‡è¯¥åŒ¹é…
            if not _in_alpha_brackets(filename, match_e.start(1), match_e.end(1)):
                episode_value = int(match_e.group(1))
    
    # 2.5 1x01æ ¼å¼
    if episode_value == float('inf'):
        match_x = re.search(r'(\d+)[Xx](\d+)', filename)
        if match_x:
            episode = int(match_x.group(2))
            episode_value = episode
    
    # 2.6 æ–¹æ‹¬å·/ä¸­æ‹¬å·åŒ…å›´çš„æ•°å­—
    if episode_value == float('inf'):
        match_bracket = re.search(r'\[(\d+)\]|ã€(\d+)ã€‘', filename)
        if match_bracket:
            episode_value = int(match_bracket.group(1) if match_bracket.group(1) else match_bracket.group(2))
    
    # 2.7 å…¶ä»–æ•°å­—æ ¼å¼ï¼ˆå¦‚æœæ²¡æœ‰æ˜ç¡®çš„æœŸæ•°ï¼‰
    if episode_value == float('inf'):
        # ä¼˜å…ˆå°è¯•çº¯æ•°å­—æ–‡ä»¶å
        if file_name_without_ext.isdigit():
            episode_value = int(file_name_without_ext)
        else:
            # é¢„å¤„ç†ï¼šç§»é™¤åˆ†è¾¨ç‡æ ‡è¯†ï¼ˆå¦‚ 720p, 1080P, 2160p ç­‰ï¼‰
            filename_without_resolution = filename
            resolution_patterns = [
                r'\b\d+[pP]\b',  # åŒ¹é… 720p, 1080P, 2160p ç­‰
                r'\b\d+x\d+\b',  # åŒ¹é… 1920x1080 ç­‰
                r'(?<!\d)[248]\s*[Kk](?!\d)',  # åŒ¹é… 2K/4K/8K
            ]

            for pattern in resolution_patterns:
                filename_without_resolution = re.sub(pattern, ' ', filename_without_resolution)

            # å¦åˆ™å°è¯•æå–ä»»ä½•æ•°å­—
            candidates = []
            for m in re.finditer(r'\d+', filename_without_resolution):
                num_str = m.group(0)
                # è¿‡æ»¤æ—¥æœŸæ¨¡å¼
                if is_date_format(num_str):
                    continue
                # è¿‡æ»¤ä¸­æ‹¬å·å†…ä¸”å«å­—æ¯çš„ç‰‡æ®µ
                span_l, span_r = m.start(), m.end()
                if _in_alpha_brackets(filename_without_resolution, span_l, span_r):
                    continue
                try:
                    value = int(num_str)
                except ValueError:
                    continue
                if value > 9999:
                    continue
                candidates.append((m.start(), value))
            if candidates:
                candidates.sort(key=lambda x: x[0])
                episode_value = candidates[0][1]
    
    # 3. æå–ä¸Šä¸­ä¸‹æ ‡è®°æˆ–å…¶ä»–ç»†åˆ† - ç¬¬ä¸‰çº§æ’åºé”®
    segment_base = 0  # åŸºç¡€å€¼ï¼šä¸Š=1, ä¸­=2, ä¸‹=3
    sequence_number = 0  # åºå·å€¼ï¼šç”¨äºå¤„ç†ä¸Šä¸­ä¸‹åçš„æ•°å­—æˆ–ä¸­æ–‡æ•°å­—åºå·

    # ä¸¥æ ¼åŒ¹é…ä¸Šä¸­ä¸‹æ ‡è®°ï¼šæ”¯æŒå¤šç§æ ¼å¼
    # 1. ç›´æ¥ç›¸é‚»ï¼šä¸Šé›†ã€æœŸä¸Š
    # 2. æ‹¬å·åˆ†éš”ï¼šæœŸï¼ˆä¸Šï¼‰ã€é›†ï¼ˆä¸­ï¼‰
    # 3. å…¶ä»–åˆ†éš”ç¬¦ï¼šæœŸ-ä¸Šã€é›†_ä¸­
    if re.search(r'ä¸Š[é›†æœŸè¯éƒ¨ç¯‡]|[é›†æœŸè¯éƒ¨ç¯‡]ä¸Š|[é›†æœŸè¯éƒ¨ç¯‡]\s*[ï¼ˆ(]\s*ä¸Š\s*[ï¼‰)]|[é›†æœŸè¯éƒ¨ç¯‡]\s*[-_Â·ä¸¨]\s*ä¸Š', filename):
        segment_base = 1
    elif re.search(r'ä¸­[é›†æœŸè¯éƒ¨ç¯‡]|[é›†æœŸè¯éƒ¨ç¯‡]ä¸­|[é›†æœŸè¯éƒ¨ç¯‡]\s*[ï¼ˆ(]\s*ä¸­\s*[ï¼‰)]|[é›†æœŸè¯éƒ¨ç¯‡]\s*[-_Â·ä¸¨]\s*ä¸­', filename):
        segment_base = 2
    elif re.search(r'ä¸‹[é›†æœŸè¯éƒ¨ç¯‡]|[é›†æœŸè¯éƒ¨ç¯‡]ä¸‹|[é›†æœŸè¯éƒ¨ç¯‡]\s*[ï¼ˆ(]\s*ä¸‹\s*[ï¼‰)]|[é›†æœŸè¯éƒ¨ç¯‡]\s*[-_Â·ä¸¨]\s*ä¸‹', filename):
        segment_base = 3

    # ç»Ÿä¸€çš„åºå·æå–é€»è¾‘ï¼Œæ”¯æŒå¤šç§åˆ†éš”ç¬¦å’Œæ ¼å¼
    # æ— è®ºæ˜¯å¦æœ‰ä¸Šä¸­ä¸‹æ ‡è®°ï¼Œéƒ½ä½¿ç”¨ç›¸åŒçš„åºå·æå–é€»è¾‘

    # å®šä¹‰åºå·æå–çš„æ¨¡å¼ï¼Œä½¿ç”¨æ­£å‘åŒ¹é…ç»„åˆçš„æ–¹å¼
    # è¿™æ ·å¯ä»¥ç²¾å‡†åŒ¹é…ï¼Œé¿å…è¯¯åˆ¤"æ˜ŸæœŸå…­"ç­‰å†…å®¹
    sequence_patterns = [
        # ç¬¬+ä¸­æ–‡æ•°å­—+æœŸé›†è¯éƒ¨ç¯‡+åºå·ï¼šç¬¬ä¸€æœŸï¼ˆä¸€ï¼‰ã€ç¬¬äº”åå…­æœŸ-äºŒã€ç¬¬ ä¸€ æœŸ ä¸‰
        (r'ç¬¬\s*[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+\s*[æœŸé›†è¯éƒ¨ç¯‡]\s*[ï¼ˆ(]\s*([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)\s*[ï¼‰)]', 'chinese'),
        (r'ç¬¬\s*[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+\s*[æœŸé›†è¯éƒ¨ç¯‡]\s*[ï¼ˆ(]\s*(\d+)\s*[ï¼‰)]', 'arabic'),
        (r'ç¬¬\s*[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+\s*[æœŸé›†è¯éƒ¨ç¯‡]\s*[-_Â·ä¸¨]\s*([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)', 'chinese'),
        (r'ç¬¬\s*[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+\s*[æœŸé›†è¯éƒ¨ç¯‡]\s*[-_Â·ä¸¨]\s*(\d+)', 'arabic'),
        (r'ç¬¬\s*[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+\s*[æœŸé›†è¯éƒ¨ç¯‡]\s+([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)(?![ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å])', 'chinese'),
        (r'ç¬¬\s*[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+\s*[æœŸé›†è¯éƒ¨ç¯‡]\s+(\d+)(?!\d)', 'arabic'),
        (r'ç¬¬\s*[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+\s*[æœŸé›†è¯éƒ¨ç¯‡]([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å])(?![ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å])', 'chinese'),
        (r'ç¬¬\s*[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+\s*[æœŸé›†è¯éƒ¨ç¯‡](\d+)(?!\d)', 'arabic'),

        # ç¬¬+é˜¿æ‹‰ä¼¯æ•°å­—+æœŸé›†è¯éƒ¨ç¯‡+åºå·ï¼šç¬¬1æœŸï¼ˆä¸€ï¼‰ã€ç¬¬100æœŸ-äºŒã€ç¬¬ 1 æœŸ ä¸‰
        (r'ç¬¬\s*\d+\s*[æœŸé›†è¯éƒ¨ç¯‡]\s*[ï¼ˆ(]\s*([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)\s*[ï¼‰)]', 'chinese'),
        (r'ç¬¬\s*\d+\s*[æœŸé›†è¯éƒ¨ç¯‡]\s*[ï¼ˆ(]\s*(\d+)\s*[ï¼‰)]', 'arabic'),
        (r'ç¬¬\s*\d+\s*[æœŸé›†è¯éƒ¨ç¯‡]\s*[-_Â·ä¸¨]\s*([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)', 'chinese'),
        (r'ç¬¬\s*\d+\s*[æœŸé›†è¯éƒ¨ç¯‡]\s*[-_Â·ä¸¨]\s*(\d+)', 'arabic'),
        (r'ç¬¬\s*\d+\s*[æœŸé›†è¯éƒ¨ç¯‡]\s+([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)(?![ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å])', 'chinese'),
        (r'ç¬¬\s*\d+\s*[æœŸé›†è¯éƒ¨ç¯‡]\s+(\d+)(?!\d)', 'arabic'),
        (r'ç¬¬\s*\d+\s*[æœŸé›†è¯éƒ¨ç¯‡]([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å])(?![ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å])', 'chinese'),
        (r'ç¬¬\s*\d+\s*[æœŸé›†è¯éƒ¨ç¯‡](\d+)(?!\d)', 'arabic'),

        # ä¸Šä¸­ä¸‹+é›†æœŸè¯éƒ¨ç¯‡+åºå·ï¼šä¸Šé›†ï¼ˆä¸€ï¼‰ã€ä¸­éƒ¨-äºŒã€ä¸‹ç¯‡ ä¸‰
        (r'[ä¸Šä¸­ä¸‹][é›†æœŸè¯éƒ¨ç¯‡]\s*[ï¼ˆ(]\s*([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)\s*[ï¼‰)]', 'chinese'),
        (r'[ä¸Šä¸­ä¸‹][é›†æœŸè¯éƒ¨ç¯‡]\s*[ï¼ˆ(]\s*(\d+)\s*[ï¼‰)]', 'arabic'),
        (r'[ä¸Šä¸­ä¸‹][é›†æœŸè¯éƒ¨ç¯‡]\s*[-_Â·ä¸¨]\s*([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)', 'chinese'),
        (r'[ä¸Šä¸­ä¸‹][é›†æœŸè¯éƒ¨ç¯‡]\s*[-_Â·ä¸¨]\s*(\d+)', 'arabic'),
        (r'[ä¸Šä¸­ä¸‹][é›†æœŸè¯éƒ¨ç¯‡]\s+([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)(?![ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å])', 'chinese'),
        (r'[ä¸Šä¸­ä¸‹][é›†æœŸè¯éƒ¨ç¯‡]\s+(\d+)(?!\d)', 'arabic'),
        (r'[ä¸Šä¸­ä¸‹][é›†æœŸè¯éƒ¨ç¯‡]([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å])(?![ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å])', 'chinese'),
        (r'[ä¸Šä¸­ä¸‹][é›†æœŸè¯éƒ¨ç¯‡](\d+)(?!\d)', 'arabic'),

        # é›†æœŸè¯éƒ¨ç¯‡+ä¸Šä¸­ä¸‹+åºå·ï¼šé›†ä¸Šï¼ˆä¸€ï¼‰ã€éƒ¨ä¸­-äºŒã€ç¯‡ä¸‹ ä¸‰
        (r'[é›†æœŸè¯éƒ¨ç¯‡][ä¸Šä¸­ä¸‹]\s*[ï¼ˆ(]\s*([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)\s*[ï¼‰)]', 'chinese'),
        (r'[é›†æœŸè¯éƒ¨ç¯‡][ä¸Šä¸­ä¸‹]\s*[ï¼ˆ(]\s*(\d+)\s*[ï¼‰)]', 'arabic'),
        (r'[é›†æœŸè¯éƒ¨ç¯‡][ä¸Šä¸­ä¸‹]\s*[-_Â·ä¸¨]\s*([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)', 'chinese'),
        (r'[é›†æœŸè¯éƒ¨ç¯‡][ä¸Šä¸­ä¸‹]\s*[-_Â·ä¸¨]\s*(\d+)', 'arabic'),
        (r'[é›†æœŸè¯éƒ¨ç¯‡][ä¸Šä¸­ä¸‹]\s+([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)(?![ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å])', 'chinese'),
        (r'[é›†æœŸè¯éƒ¨ç¯‡][ä¸Šä¸­ä¸‹]\s+(\d+)(?!\d)', 'arabic'),
        (r'[é›†æœŸè¯éƒ¨ç¯‡][ä¸Šä¸­ä¸‹]([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å])(?![ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å])', 'chinese'),
        (r'[é›†æœŸè¯éƒ¨ç¯‡][ä¸Šä¸­ä¸‹](\d+)(?!\d)', 'arabic'),
    ]

    # å°è¯•åŒ¹é…åºå·
    for pattern, num_type in sequence_patterns:
        match = re.search(pattern, filename)
        if match:
            if num_type == 'chinese':
                arabic_num = chinese_to_arabic(match.group(1))
                if arabic_num is not None:
                    sequence_number = arabic_num
                    # å¦‚æœä¹‹å‰æ²¡æœ‰æ£€æµ‹åˆ°ä¸Šä¸­ä¸‹æ ‡è®°ï¼Œç»™ä¸€ä¸ªåŸºç¡€å€¼
                    if segment_base == 0:
                        segment_base = 1
                    break
            else:  # arabic
                sequence_number = int(match.group(1))
                # å¦‚æœä¹‹å‰æ²¡æœ‰æ£€æµ‹åˆ°ä¸Šä¸­ä¸‹æ ‡è®°ï¼Œç»™ä¸€ä¸ªåŸºç¡€å€¼
                if segment_base == 0:
                    segment_base = 1
                break

    # ç»„åˆsegment_valueï¼šåŸºç¡€å€¼*1000 + åºå·å€¼ï¼Œç¡®ä¿æ’åºæ­£ç¡®
    segment_value = segment_base * 1000 + sequence_number
    
    # è¿”å›å¤šçº§æ’åºå…ƒç»„ï¼ŒåŠ å…¥æ›´æ–°æ—¶é—´ä½œä¸ºç¬¬å››çº§æ’åºé”®ï¼Œæ‹¼éŸ³æ’åºä½œä¸ºç¬¬äº”çº§æ’åºé”®
    return (date_value, episode_value, segment_value, update_time, pinyin_sort_key)


# å…¨å±€çš„å‰§é›†ç¼–å·æå–å‡½æ•°
def _in_alpha_brackets(text, start, end):
    """
    åˆ¤æ–­ [start,end) èŒƒå›´å†…çš„æ•°å­—æ˜¯å¦ä½äº"å«å­—æ¯çš„ä¸­æ‹¬å·å¯¹"å†…éƒ¨ã€‚
    æ”¯æŒè‹±æ–‡æ–¹æ‹¬å· [] å’Œä¸­æ–‡æ–¹æ‹¬å· ã€ã€‘ã€‚
    è¦æ±‚ï¼šæ•°å­—å·¦ä¾§æœ€è¿‘çš„æœªé—­åˆæ‹¬å·ä¸å³ä¾§æœ€è¿‘çš„å¯¹åº”é—­åˆæ‹¬å·å½¢æˆå¯¹ï¼Œä¸”æ‹¬å·å†…å®¹åŒ…å«å­—æ¯ã€‚
    ä½†æ˜¯å…è®¸ E/e å’Œ EP/ep/Ep è¿™æ ·çš„é›†æ•°æ ¼å¼ã€‚
    """
    if start < 0 or end > len(text):
        return False
    
    # æ£€æŸ¥è‹±æ–‡æ–¹æ‹¬å· []
    last_open_en = text.rfind('[', 0, start)
    if last_open_en != -1:
        close_before_en = text.rfind(']', 0, start)
        if close_before_en == -1 or close_before_en < last_open_en:
            close_after_en = text.find(']', end)
            if close_after_en != -1:
                content = text[last_open_en + 1:close_after_en]
                if _check_bracket_content(content):
                    return True
    
    # æ£€æŸ¥ä¸­æ–‡æ–¹æ‹¬å· ã€ã€‘
    last_open_cn = text.rfind('ã€', 0, start)
    if last_open_cn != -1:
        close_before_cn = text.rfind('ã€‘', 0, start)
        if close_before_cn == -1 or close_before_cn < last_open_cn:
            close_after_cn = text.find('ã€‘', end)
            if close_after_cn != -1:
                content = text[last_open_cn + 1:close_after_cn]
                if _check_bracket_content(content):
                    return True
    
    return False

def _check_bracket_content(content):
    """
    æ£€æŸ¥æ‹¬å·å†…å®¹æ˜¯å¦åº”è¯¥è¢«æ’é™¤
    """
    # æ£€æŸ¥æ˜¯å¦åŒ…å«å­—æ¯
    has_letters = bool(re.search(r'[A-Za-z]', content))
    if not has_letters:
        return False
    
    # å¦‚æœæ˜¯ E/e æˆ– EP/ep/Ep æ ¼å¼ï¼Œåˆ™å…è®¸é€šè¿‡
    if re.match(r'^[Ee][Pp]?\d+$', content):
        return False
    
    return True
def extract_episode_number(filename, episode_patterns=None, config_data=None):
    """
    ä»æ–‡ä»¶åä¸­æå–å‰§é›†ç¼–å·
    
    Args:
        filename: æ–‡ä»¶å
        episode_patterns: å¯é€‰çš„è‡ªå®šä¹‰åŒ¹é…æ¨¡å¼åˆ—è¡¨
        config_data: å¯é€‰çš„ä»»åŠ¡é…ç½®æ•°æ®
        
    Returns:
        int: æå–åˆ°çš„å‰§é›†å·ï¼Œå¦‚æœæ— æ³•æå–åˆ™è¿”å›None
    """
    # é¦–å…ˆå»é™¤æ–‡ä»¶æ‰©å±•å
    file_name_without_ext = os.path.splitext(filename)[0]
    
    # ç‰¹åˆ¤ï¼šSxxEyy.zz æ¨¡å¼ï¼ˆä¾‹å¦‚ S01E11.11ï¼‰ï¼Œåœ¨æ—¥æœŸæ¸…æ´—å‰ä¼˜å…ˆè¯†åˆ«
    m_spec = re.search(r'[Ss](\d+)[Ee](\d{1,2})[._\-/]\d{1,2}', file_name_without_ext)
    if m_spec:
        return int(m_spec.group(2))
    
    # é¢„å¤„ç†é¡ºåºè°ƒæ•´ï¼šå…ˆç§»é™¤æŠ€æœ¯è§„æ ¼ï¼Œå†ç§»é™¤æ—¥æœŸï¼Œé™ä½è¯¯åˆ¤
    # é¢„å¤„ç†ï¼šå…ˆç§»é™¤æŠ€æœ¯è§„æ ¼ä¿¡æ¯ï¼Œé¿å…è¯¯æå–æŠ€æœ¯å‚æ•°ä¸­çš„æ•°å­—ä¸ºé›†ç¼–å·
    filename_without_dates = file_name_without_ext
    tech_spec_patterns = [
        # åˆ†è¾¨ç‡ç›¸å…³ï¼ˆé™å®šå¸¸è§pæ¡£ï¼‰
        r'(?:240|360|480|540|720|900|960|1080|1440|2160|4320)[pP]',
        # å¸¸è§åˆ†è¾¨ç‡ WxHï¼ˆç™½åå•ï¼‰
        r'\b(?:640x360|640x480|720x480|720x576|854x480|960x540|1024x576|1280x720|1280x800|1280x960|1366x768|1440x900|1600x900|1920x1080|2560x1080|2560x1440|3440x1440|3840x1600|3840x2160|4096x2160|7680x4320)\b',
        r'(?<!\d)[248]\s*[Kk](?!\d)',  # åŒ¹é… 2K/4K/8K
        
        # è§†é¢‘ç¼–ç ç›¸å…³ï¼ˆåŒ…å«æ•°å­—çš„ç¼–ç ï¼‰
        r'\b[Hh]\.?(?:264|265)\b',  # åŒ¹é… h264/h265, h.264/h.265 ç­‰
        r'\b[Xx](?:264|265)\b',     # åŒ¹é… x264/x265, X264/X265
        
        # éŸ³é¢‘é‡‡æ ·ç‡ï¼ˆé™å®šå¸¸è§é‡‡æ ·ç‡ï¼‰
        r'\b(?:44\.1|48|96)\s*[Kk][Hh][Zz]\b',
        r'\b(?:44100|48000|96000)\s*[Hh][Zz]\b',
        
        # æ¯”ç‰¹ç‡
        # å¸¸è§ç ç‡ï¼ˆç™½åå•ï¼‰
        r'\b(?:64|96|128|160|192|256|320)\s*[Kk][Bb][Pp][Ss]\b',
        r'\b(?:1|1\.5|2|2\.5|3|4|5|6|8|10|12|15|20|25|30|35|40|50|80|100)\s*[Mm][Bb][Pp][Ss]\b',
        
        # è§†é¢‘ç›¸å…³
        # ä½æ·±ï¼ˆç™½åå•ï¼‰
        r'\b(?:8|10|12)\s*[Bb][Ii][Tt]s?\b',
        # ä¸¥æ ¼é™å®šå¸¸è§å¸§ç‡ï¼Œé¿å…å°† "07.30FPS" è§†ä¸ºå¸§ç‡ä»è€Œè¿å¸¦æ¸…é™¤é›†æ•°
        r'\b(?:23\.976|29\.97|59\.94|24|25|30|50|60|90|120)\s*[Ff][Pp][Ss]\b',
        # æ— ç©ºæ ¼çš„å¸§ç‡æ ¼å¼ï¼ˆå¦‚ 60fps, 30fps ç­‰ï¼‰
        r'(?:23\.976|29\.97|59\.94|24|25|30|50|60|90|120)[Ff][Pp][Ss]',
        # ä¸­æ–‡å¸§ç‡ï¼šå¸¦ç©ºæ ¼çš„å¦‚ "25 å¸§"ã€"30 å¸§"
        r'\b(?:23\.976|29\.97|59\.94|24|25|30|50|60|90|120)\s*å¸§\b',
        # ä¸­æ–‡å¸§ç‡ï¼šæ— ç©ºæ ¼çš„å¦‚ "25å¸§"ã€"30å¸§"ã€"60å¸§"
        r'(?:23\.976|29\.97|59\.94|24|25|30|50|60|90|120)å¸§',
        # ä¸­æ–‡â€œå¸§ç‡â€ï¼šå¸¦ç©ºæ ¼ä¸æ— ç©ºæ ¼ï¼ˆå¦‚ "60å¸§ç‡"ã€"60 å¸§ç‡"ï¼‰
        r'\b(?:23\.976|29\.97|59\.94|24|25|30|50|60|90|120)\s*å¸§ç‡\b',
        r'(?:23\.976|29\.97|59\.94|24|25|30|50|60|90|120)å¸§ç‡',
        
        # é¢‘ç‡ç›¸å…³
        # é¢‘ç‡ç›¸å…³ï¼ˆç™½åå•ï¼Œå«ç©ºæ ¼/æ— ç©ºæ ¼ï¼‰
        r'\b(?:100|144|200|240|400|800)\s*[Mm][Hh][Zz]\b',
        r'\b(?:1|1\.4|2|2\.4|5|5\.8)\s*[Gg][Hh][Zz]\b',
        r'\b(?:100|144|200|240|400|800)[Mm][Hh][Zz]\b',
        r'\b(?:1|1\.4|2|2\.4|5|5\.8)[Gg][Hh][Zz]\b',
        
        # å£°é“ç›¸å…³ï¼ˆé™å®šå¸¸è§å£°é“ï¼‰
        r'\b(?:1\.0|2\.0|5\.1|7\.1)\s*[Cc][Hh]\b',
        r'\b(?:1\.0|2\.0|5\.1|7\.1)[Cc][Hh]\b',
        r'\b(?:1\.0|2\.0|5\.1|7\.1)\s*[Cc][Hh][Aa][Nn][Nn][Ee][Ll]\b',
        
        # ä½æ·±ç›¸å…³
        r'\b\d+\.?\d*\s*[Bb][Ii][Tt][Ss]\b',  # åŒ¹é… 128bits, 256bits ç­‰
        
        # å…¶ä»–æŠ€æœ¯å‚æ•°
        # å…¶ä»–æŠ€æœ¯å‚æ•°ï¼ˆç™½åå•ï¼‰
        r'\b(?:8|12|16|24|32|48|50|64|108)\s*[Mm][Pp]\b',
        r'\b(?:720|1080|1440|1600|1920|2160|4320)\s*[Pp][Ii][Xx][Ee][Ll]\b',
        r'\b(?:5400|7200)\s*[Rr][Pp][Mm]\b',
        r'\b(?:720|1080|1440|1600|1920|2160|4320)[Pp][Ii][Xx][Ee][Ll]\b',
        r'\b(?:5400|7200)[Rr][Pp][Mm]\b',
    ]
    for pattern in tech_spec_patterns:
        filename_without_dates = re.sub(pattern, ' ', filename_without_dates, flags=re.IGNORECASE)

    # é¢„å¤„ç†ï¼šç§»é™¤å­£ç¼–å·æ ‡è¯†ï¼Œé¿å…è¯¯æå–å­£ç¼–å·ä¸ºé›†ç¼–å·ï¼ˆæ”¾åœ¨æ—¥æœŸæ¸…æ´—ä¹‹å‰ï¼‰
    season_patterns = [
        r'[Ss]\d+(?![Ee])',  # S1, S01 (ä½†ä¸åŒ…æ‹¬S01E01ä¸­çš„S01)
        r'[Ss]\s+\d+',  # S 1, S 01
        r'Season\s*\d+',  # Season1, Season 1
        r'ç¬¬\s*\d+\s*å­£',  # ç¬¬1å­£, ç¬¬ 1 å­£
        r'ç¬¬\s*[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+\s*å­£',  # ç¬¬ä¸€å­£, ç¬¬ äºŒ å­£
    ]

    for pattern in season_patterns:
        filename_without_dates = re.sub(pattern, ' ', filename_without_dates, flags=re.IGNORECASE)

    # é¢„å¤„ç†ï¼šå†æ’é™¤æ–‡ä»¶åä¸­å¯èƒ½æ˜¯æ—¥æœŸçš„éƒ¨åˆ†ï¼Œé¿å…è¯¯è¯†åˆ«
    date_patterns = [
        # YYYY-MM-DD æˆ– YYYY.MM.DD æˆ– YYYY/MM/DD æˆ– YYYY MM DDæ ¼å¼ï¼ˆå››ä½å¹´ä»½ï¼‰
        r'((?:19|20)\d{2})[-./\s](\d{1,2})[-./\s](\d{1,2})',
        # YY-MM-DD æˆ– YY.MM.DD æˆ– YY/MM/DD æˆ– YY MM DDæ ¼å¼ï¼ˆä¸¤ä½å¹´ä»½ï¼‰ï¼Œä½†æ’é™¤E/EPåé¢çš„æ•°å­—
        r'(?<![Ee])(?<![Ee][Pp])((?:19|20)?\d{2})[-./\s](\d{1,2})[-./\s](\d{1,2})',
        # å®Œæ•´çš„YYYYMMDDæ ¼å¼ï¼ˆæ— åˆ†éš”ç¬¦ï¼‰
        r'((?:19|20)\d{2})(\d{2})(\d{2})',
        # YYMMDDæ ¼å¼ï¼ˆä¸¤ä½å¹´ä»½ï¼Œæ— åˆ†éš”ç¬¦ï¼‰
        r'(?<!\d)(\d{2})(\d{2})(\d{2})(?!\d)',
        # MM/DD/YYYY æˆ– DD/MM/YYYY æ ¼å¼
        r'(\d{1,2})[-./\s](\d{1,2})[-./\s]((?:19|20)\d{2})',
        # MM-DD æˆ– MM.DD æˆ– MM/DDæ ¼å¼ï¼ˆæ— å¹´ä»½ï¼Œä¸åŒ…æ‹¬ç©ºæ ¼åˆ†éš”ï¼‰ï¼Œä½†æ’é™¤E/EPåé¢çš„æ•°å­—å’Œåˆ†è¾¨ç‡æ ‡è¯†
        r'(?<![Ee])(?<![Ee][Pp])(?<!\d)(\d{1,2})[-./](\d{1,2})(?!\d)(?![KkPp])',
    ]
    
    # ä»å·²æ¸…é™¤æŠ€æœ¯è§„æ ¼çš„ä¿¡æ¯ä¸­ç§»é™¤æ—¥æœŸéƒ¨åˆ†
    for pattern in date_patterns:
        matches = re.finditer(pattern, filename_without_dates)
        for match in matches:
            # æ£€æŸ¥åŒ¹é…çš„å†…å®¹æ˜¯å¦ç¡®å®æ˜¯æ—¥æœŸ
            date_str = match.group(0)
            # é’ˆå¯¹çŸ­æ—¥æœŸ x.x æˆ– xx.xxï¼šå‰ä¸€å­—ç¬¦ä¸º E/e/EP/Ep æ—¶ä¸æ¸…æ´—ï¼ˆä¿æŠ¤ E11.11, EP08.7 åœºæ™¯ï¼‰
            if re.match(r'^\d{1,2}[./-]\d{1,2}$', date_str):
                prev_chars = filename_without_dates[max(0, match.start()-2):match.start()]
                if prev_chars.endswith(('E', 'e', 'EP', 'Ep', 'ep')):
                    continue
            # ä¿æŠ¤ E/EP æ ¼å¼çš„é›†ç¼–å·ï¼Œå¦‚ E07, E14, EP08 ç­‰
            if re.match(r'^\d+$', date_str) and len(date_str) <= 3:
                prev_chars = filename_without_dates[max(0, match.start()-2):match.start()]
                if prev_chars.endswith(('E', 'e', 'EP', 'Ep', 'ep')):
                    continue
            month = None
            day = None
            
            # æ ¹æ®ä¸åŒæ¨¡å¼æå–æœˆå’Œæ—¥
            if len(match.groups()) >= 3:
                if re.match(r'(?:19|20)\d{2}', match.group(1)):  # é¦–ä¸ªåˆ†ç»„æ˜¯å¹´ä»½
                    month = int(match.group(2))
                    day = int(match.group(3))
                elif re.match(r'(?:19|20)\d{2}', match.group(3)):  # æœ«å°¾åˆ†ç»„æ˜¯å¹´ä»½
                    month = int(match.group(1))
                    day = int(match.group(2))
                else:
                    # å¤„ç†ä¸¤ä½æ•°å¹´ä»½çš„æƒ…å†µï¼ˆå¦‚25.03.21ï¼‰
                    try:
                        # å‡è®¾ç¬¬ä¸€ä¸ªæ˜¯å¹´ä»½ï¼Œç¬¬äºŒä¸ªæ˜¯æœˆï¼Œç¬¬ä¸‰ä¸ªæ˜¯æ—¥
                        year = int(match.group(1))
                        month = int(match.group(2))
                        day = int(match.group(3))
                        
                        # å¦‚æœæœˆå’Œæ—¥åœ¨æœ‰æ•ˆèŒƒå›´å†…ï¼Œåˆ™è¿™å¯èƒ½æ˜¯ä¸€ä¸ªæ—¥æœŸ
                        if 1 <= month <= 12 and 1 <= day <= 31:
                            pass  # ä¿æŒmonthå’Œdayçš„å€¼
                        else:
                            # å°è¯•å¦ä¸€ç§è§£é‡Šï¼šæœˆ.æ—¥.å¹´
                            month = int(match.group(1))
                            day = int(match.group(2))
                            # æ£€æŸ¥æœˆå’Œæ—¥çš„æœ‰æ•ˆæ€§
                            if not (1 <= month <= 12 and 1 <= day <= 31):
                                # ä»ç„¶æ— æ•ˆï¼Œé‡ç½®monthå’Œday
                                month = None
                                day = None
                    except ValueError:
                        # è½¬æ¢å¤±è´¥ï¼Œä¿æŒmonthå’Œdayä¸ºNone
                        pass
            elif len(match.groups()) == 2:
                # å¤„ç†ä¸¤ä¸ªåˆ†ç»„çš„æ¨¡å¼ï¼ˆå¦‚MM-DDæ ¼å¼ï¼‰
                try:
                    month = int(match.group(1))
                    day = int(match.group(2))
                    
                    # æ£€æŸ¥æœˆå’Œæ—¥çš„æœ‰æ•ˆæ€§
                    if not (1 <= month <= 12 and 1 <= day <= 31):
                        # å°è¯•å¦ä¸€ç§è§£é‡Šï¼šæ—¥-æœˆ
                        month = int(match.group(2))
                        day = int(match.group(1))
                        if not (1 <= month <= 12 and 1 <= day <= 31):
                            # ä»ç„¶æ— æ•ˆï¼Œé‡ç½®monthå’Œday
                            month = None
                            day = None
                except ValueError:
                    # è½¬æ¢å¤±è´¥ï¼Œä¿æŒmonthå’Œdayä¸ºNone
                    pass
            
            # å¦‚æœèƒ½ç¡®å®šæœˆæ—¥ä¸”æ˜¯æœ‰æ•ˆçš„æ—¥æœŸï¼Œåˆ™ä»æ–‡ä»¶åä¸­åˆ é™¤è¯¥æ—¥æœŸ
            if month and day and 1 <= month <= 12 and 1 <= day <= 31:
                filename_without_dates = filename_without_dates.replace(date_str, " ")

    # ä¼˜å…ˆåŒ¹é…SxxExxæ ¼å¼
    match_s_e = re.search(r'[Ss](\d+)[Ee](\d+)', filename_without_dates)
    if match_s_e:
        # ç›´æ¥è¿”å›Eåé¢çš„é›†æ•°
        return int(match_s_e.group(2))
    
    # å…¶æ¬¡åŒ¹é…E01æ ¼å¼
    match_e = re.search(r'[Ee][Pp]?(\d+)', filename_without_dates)
    if match_e:
        # è‹¥æ•°å­—ä½äºå«å­—æ¯çš„ä¸­æ‹¬å·å†…éƒ¨ï¼Œè·³è¿‡è¯¥åŒ¹é…
        if not _in_alpha_brackets(filename_without_dates, match_e.start(1), match_e.end(1)):
            return int(match_e.group(1))
    
    # æ·»åŠ ä¸­æ–‡æ•°å­—åŒ¹é…æ¨¡å¼ï¼ˆä¼˜å…ˆåŒ¹é…ï¼‰
    chinese_patterns = [
        r'ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)é›†',
        r'ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)æœŸ',
        r'ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)è¯',
        r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)é›†',
        r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)æœŸ',
        r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)è¯'
    ]
    
    # ä¼˜å…ˆåŒ¹é…ä¸­æ–‡æ•°å­—æ¨¡å¼
    for pattern_regex in chinese_patterns:
        try:
            match = re.search(pattern_regex, filename_without_dates)
            if match:
                chinese_num = match.group(1)
                arabic_num = chinese_to_arabic(chinese_num)
                if arabic_num is not None:
                    return arabic_num
        except:
            continue
    
    # å°è¯•åŒ¹é…æ›´å¤šæ ¼å¼ï¼ˆæ³¨æ„ï¼šé¿å…åŒ¹é…å­£æ•°ï¼‰
    default_patterns = [
        r'ç¬¬(\d+)é›†',
        r'ç¬¬(\d+)æœŸ',
        r'ç¬¬(\d+)è¯',
        r'(?<!ç¬¬\d+å­£\s*)(\d+)é›†',  # é¿å…åŒ¹é…"ç¬¬Xå­£ Yé›†"ä¸­çš„å­£æ•°
        r'(?<!ç¬¬\d+å­£\s*)(\d+)æœŸ',  # é¿å…åŒ¹é…"ç¬¬Xå­£ YæœŸ"ä¸­çš„å­£æ•°
        r'(?<!ç¬¬\d+å­£\s*)(\d+)è¯',  # é¿å…åŒ¹é…"ç¬¬Xå­£ Yè¯"ä¸­çš„å­£æ•°
        r'[Ee][Pp]?(\d+)',
        r'\[(\d+)\]',
        r'ã€(\d+)ã€‘',
        # ä¸­æ–‡æ•°å­—åŒ¹é…æ¨¡å¼
        r'ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)é›†',
        r'ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)æœŸ',
        r'ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)è¯',
        r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)é›†',
        r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)æœŸ',
        r'([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶ä¸¤]+)è¯',
        # å…ˆåŒ¹é…"å‰æ–¹æœ‰åˆ†éš”ç¬¦"çš„æ•°å­—ï¼Œé¿å…åä¸€ä¸ªè§„åˆ™ä¼˜å…ˆå‘½ä¸­å•å­—ç¬¦
        r'[- _\s\.]([0-9]+)',
        r'(?:^|[^0-9])(\d+)(?=[- _\s\.])',
        # æ–°å¢ï¼šæ–‡ä»¶åèµ·å§‹çº¯æ•°å­—åæ¥éæ•°å­—ï¼ˆå¦‚ 1094(1).mp4ï¼‰
        r'^(\d+)(?=\D)'
    ]
    
    # æ„å»ºæœ€ç»ˆçš„patternsï¼šé»˜è®¤æ¨¡å¼ + ç”¨æˆ·è¡¥å……æ¨¡å¼
    patterns = []
    
    # 1. é¦–å…ˆæ·»åŠ é»˜è®¤æ¨¡å¼ï¼ˆé™¤äº†æœ€åçš„çº¯æ•°å­—æ¨¡å¼ï¼‰
    default_non_numeric = [p for p in default_patterns if not re.match(r'^[- _\\s\\.]\([0-9]+\)', p) and not re.match(r'^\([^)]*\)\([0-9]+\)', p)]
    patterns.extend(default_non_numeric)
    
    # 2. æ·»åŠ ç”¨æˆ·è¡¥å……çš„æ¨¡å¼
    user_patterns = []
    
    # æ£€æŸ¥ä¼ å…¥çš„episode_patternså‚æ•°
    if episode_patterns:
        user_patterns = [p.get("regex", "(\\d+)") for p in episode_patterns if p.get("regex", "").strip()]
    # å¦‚æœé…ç½®äº†taskçš„è‡ªå®šä¹‰è§„åˆ™
    elif config_data and isinstance(config_data.get("episode_patterns"), list) and config_data["episode_patterns"]:
        user_patterns = [p.get("regex", "(\\d+)") for p in config_data["episode_patterns"] if p.get("regex", "").strip()]
    # å°è¯•ä»å…¨å±€é…ç½®è·å–
    elif 'CONFIG_DATA' in globals() and isinstance(globals()['CONFIG_DATA'].get("episode_patterns"), list) and globals()['CONFIG_DATA']["episode_patterns"]:
        user_patterns = [p.get("regex", "(\\d+)") for p in globals()['CONFIG_DATA']["episode_patterns"] if p.get("regex", "").strip()]
    
    # æ·»åŠ ç”¨æˆ·è¡¥å……çš„æ¨¡å¼
    patterns.extend(user_patterns)
    
    # 3. æœ€åæ·»åŠ é»˜è®¤çš„çº¯æ•°å­—æ¨¡å¼
    default_numeric = [p for p in default_patterns if re.match(r'^[- _\\s\\.]\([0-9]+\)', p) or re.match(r'^\([^)]*\)\([0-9]+\)', p)]
    patterns.extend(default_numeric)
    
    # å°è¯•ä½¿ç”¨æ¯ä¸ªæ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ–‡ä»¶åï¼ˆä½¿ç”¨ä¸å«æ—¥æœŸçš„æ–‡ä»¶åï¼‰
    for pattern_regex in patterns:
        try:
            # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœæ˜¯åŒ…å«å¤šä¸ªæ•è·ç»„çš„å¤åˆæ­£åˆ™è¡¨è¾¾å¼
            if '|' in pattern_regex and '(' in pattern_regex:
                # å…ˆå°è¯•åŒ¹é…é›†/æœŸ/è¯ç›¸å…³çš„æ¨¡å¼ï¼Œé¿å…è¯¯åŒ¹é…å­£æ•°
                episode_specific_patterns = [
                    r'ç¬¬(\d+)é›†', r'ç¬¬(\d+)æœŸ', r'ç¬¬(\d+)è¯',
                    r'(\d+)é›†', r'(\d+)æœŸ', r'(\d+)è¯'
                ]

                for ep_pattern in episode_specific_patterns:
                    ep_match = re.search(ep_pattern, filename_without_dates)
                    if ep_match:
                        # æ£€æŸ¥è¿™ä¸ªåŒ¹é…æ˜¯å¦ç´§è·Ÿåœ¨"ç¬¬Xå­£"åé¢ï¼Œå¦‚æœæ˜¯åˆ™è·³è¿‡
                        match_start = ep_match.start()
                        prefix = filename_without_dates[:match_start]
                        if re.search(r'ç¬¬\d+å­£\s*$', prefix):
                            continue  # è·³è¿‡ç´§è·Ÿåœ¨å­£æ•°åçš„åŒ¹é…

                        episode_num = int(ep_match.group(1))

                        # æ£€æŸ¥æå–çš„æ•°å­—æ˜¯å¦å¯èƒ½æ˜¯æ—¥æœŸçš„ä¸€éƒ¨åˆ†
                        if str(episode_num).isdigit() and is_date_format(str(episode_num)):
                            continue

                        return episode_num

                # å¦‚æœé›†/æœŸ/è¯æ¨¡å¼éƒ½æ²¡åŒ¹é…åˆ°ï¼Œå†å°è¯•åŸå§‹çš„å¤åˆæ­£åˆ™è¡¨è¾¾å¼
                match = re.search(pattern_regex, filename_without_dates)
                if match:
                    # éå†æ‰€æœ‰æ•è·ç»„ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªéç©ºçš„
                    for group_num in range(1, len(match.groups()) + 1):
                        if match.group(group_num):
                            # è‹¥æ•°å­—ä½äºå«å­—æ¯çš„ä¸­æ‹¬å·å†…éƒ¨ï¼Œè·³è¿‡
                            span_l, span_r = match.start(group_num), match.end(group_num)
                            if _in_alpha_brackets(filename_without_dates, span_l, span_r):
                                continue
                            episode_num = int(match.group(group_num))

                            # æ£€æŸ¥æå–çš„æ•°å­—æ˜¯å¦å¯èƒ½æ˜¯æ—¥æœŸçš„ä¸€éƒ¨åˆ†
                            if str(episode_num).isdigit() and is_date_format(str(episode_num)):
                                continue

                            # é¢å¤–æ£€æŸ¥ï¼šå¦‚æœåŒ¹é…çš„æ•°å­—æ¥è‡ª"ç¬¬Xå­£"æ ¼å¼ï¼Œè·³è¿‡
                            match_start = match.start()
                            match_end = match.end()

                            # æ£€æŸ¥åŒ¹é…å‰åçš„ä¸Šä¸‹æ–‡ï¼Œçœ‹æ˜¯å¦æ˜¯"ç¬¬Xå­£"æ ¼å¼
                            context_start = max(0, match_start - 2)
                            context_end = min(len(filename_without_dates), match_end + 1)
                            context = filename_without_dates[context_start:context_end]

                            if re.search(r'ç¬¬\d+å­£', context):
                                continue

                            return episode_num
            else:
                # å•ä¸€æ¨¡å¼çš„æ­£åˆ™è¡¨è¾¾å¼
                match = re.search(pattern_regex, filename_without_dates)
                if match:
                    # è‹¥æ•°å­—ä½äºå«å­—æ¯çš„ä¸­æ‹¬å·å†…éƒ¨ï¼Œè·³è¿‡
                    span_l, span_r = match.start(1), match.end(1)
                    if _in_alpha_brackets(filename_without_dates, span_l, span_r):
                        continue
                    episode_num = int(match.group(1))

                    # æ£€æŸ¥æå–çš„æ•°å­—æ˜¯å¦å¯èƒ½æ˜¯æ—¥æœŸçš„ä¸€éƒ¨åˆ†
                    if str(episode_num).isdigit() and is_date_format(str(episode_num)):
                        continue

                    return episode_num
        except:
            continue
    
    # å¦‚æœæ–‡ä»¶åæ˜¯çº¯æ•°å­—ï¼Œä¸”ä¸æ˜¯æ—¥æœŸæ ¼å¼ï¼Œåˆ™å¯èƒ½æ˜¯å‰§é›†å·
    if filename_without_dates.isdigit() and not is_date_format(filename_without_dates):
        return int(filename_without_dates)
    
    # æœ€åå°è¯•æå–ä»»ä½•æ•°å­—ï¼Œä½†è¦æ’é™¤æ—¥æœŸå¯èƒ½æ€§
    candidates = []
    for m in re.finditer(r'\d+', filename_without_dates):
        num_str = m.group(0)
        # è¿‡æ»¤æ—¥æœŸæ¨¡å¼
        if is_date_format(num_str):
            continue
        # è¿‡æ»¤ä¸­æ‹¬å·å†…ä¸”å«å­—æ¯çš„ç‰‡æ®µ
        span_l, span_r = m.start(), m.end()
        if _in_alpha_brackets(filename_without_dates, span_l, span_r):
            continue
        try:
            value = int(num_str)
        except ValueError:
            continue
        if value > 9999:
            continue
        candidates.append((m.start(), value))
    if candidates:
        candidates.sort(key=lambda x: x[0])
        return candidates[0][1]
 
    return None

# å…¨å±€å˜é‡
VERSION = "2.9.0"
CONFIG_PATH = "quark_config.json"
COOKIE_PATH = "quark_cookie.txt"
CONFIG_DATA = {}
LOG_LIST = []
NOTIFYS = []

def is_date_format(number_str):
    """
    åˆ¤æ–­ä¸€ä¸ªçº¯æ•°å­—å­—ç¬¦ä¸²æ˜¯å¦å¯èƒ½æ˜¯æ—¥æœŸæ ¼å¼
    æ”¯æŒçš„æ ¼å¼ï¼šYYYYMMDD, YYMMDD
    """
    # åˆ¤æ–­YYYYMMDDæ ¼å¼ (8ä½æ•°å­—)
    if len(number_str) == 8 and number_str.startswith('20'):
        year = int(number_str[:4])
        month = int(number_str[4:6])
        day = int(number_str[6:8])
        
        # ç®€å•æ£€æŸ¥æœˆä»½å’Œæ—¥æœŸæ˜¯å¦æœ‰æ•ˆ
        if 1 <= month <= 12 and 1 <= day <= 31:
            # å¯èƒ½æ˜¯æ—¥æœŸæ ¼å¼
            return True
    
    # åˆ¤æ–­YYMMDDæ ¼å¼ (6ä½æ•°å­—)
    elif len(number_str) == 6:
        year_str = number_str[:2]
        month = int(number_str[2:4])
        day = int(number_str[4:6])
        
        # æ£€æŸ¥æœˆä»½å’Œæ—¥æœŸæ˜¯å¦æœ‰æ•ˆ
        if 1 <= month <= 12 and 1 <= day <= 31:
            # å¯èƒ½æ˜¯æ—¥æœŸæ ¼å¼
            return True
    
    # ä¸å†å°†4ä½çº¯æ•°å­—æŒ‰MMDDè§†ä¸ºæ—¥æœŸï¼Œé¿å…è¯¯ä¼¤é›†å·ï¼ˆå¦‚1124ï¼‰
    
    # å…¶ä»–æ ¼å¼ä¸è§†ä¸ºæ—¥æœŸæ ¼å¼
    return False

def chinese_to_arabic(chinese):
    """
    å°†ä¸­æ–‡æ•°å­—è½¬æ¢ä¸ºé˜¿æ‹‰ä¼¯æ•°å­—
    æ”¯æŒæ ¼å¼ï¼šä¸€ã€äºŒã€ä¸‰ã€å››ã€äº”ã€å…­ã€ä¸ƒã€å…«ã€ä¹ã€åã€ç™¾ã€åƒã€ä¸‡
    ä»¥åŠï¼šé›¶ã€ä¸¤ï¼ˆç‰¹æ®Šå¤„ç†ä¸º2ï¼‰
    
    Args:
        chinese: ä¸­æ–‡æ•°å­—å­—ç¬¦ä¸²
        
    Returns:
        int: è½¬æ¢åçš„é˜¿æ‹‰ä¼¯æ•°å­—ï¼Œå¦‚æœæ— æ³•è½¬æ¢åˆ™è¿”å›None
    """
    if not chinese:
        return None
        
    # æ•°å­—æ˜ å°„
    digit_map = {
        'é›¶': 0, 'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 
        'äº”': 5, 'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9, 
        'ä¸¤': 2
    }
    
    # å•ä½æ˜ å°„
    unit_map = {
        'å': 10, 
        'ç™¾': 100, 
        'åƒ': 1000, 
        'ä¸‡': 10000
    }
    
    # å¦‚æœæ˜¯å•ä¸ªå­—ç¬¦ï¼Œç›´æ¥è¿”å›å¯¹åº”æ•°å­—
    if len(chinese) == 1:
        if chinese == 'å':
            return 10
        return digit_map.get(chinese)
    
    result = 0
    section = 0
    number = 0
    
    # ä»å·¦å‘å³å¤„ç†
    for i in range(len(chinese)):
        char = chinese[i]
        
        if char in digit_map:
            number = digit_map[char]
        elif char in unit_map:
            unit = unit_map[char]
            # å¦‚æœå‰é¢æ²¡æœ‰æ•°å­—ï¼Œé»˜è®¤ä¸º1ï¼Œä¾‹å¦‚"å"è¡¨ç¤º1*10=10
            section += (number or 1) * unit
            number = 0
            
            # å¦‚æœæ˜¯ä¸‡çº§å•ä½ï¼Œç´¯åŠ åˆ°ç»“æœå¹¶é‡ç½®section
            if unit == 10000:
                result += section
                section = 0
        else:
            # éæ³•å­—ç¬¦
            return None
    
    # åŠ ä¸Šæœ€åçš„æ•°å­—å’Œå°èŠ‚
    result += section + number
    
    return result

# å…¼å®¹é’é¾™
try:
    from treelib import Tree
except:
    print("æ­£åœ¨å°è¯•è‡ªåŠ¨å®‰è£…ä¾èµ–...")
    os.system("pip3 install treelib &> /dev/null")
    from treelib import Tree


MAGIC_REGEX = {
    "$TV": {
        "pattern": r".*?([Ss]\d{1,2})?(?:[ç¬¬EePpXx\.\-\_\( ]{1,2}|^)(\d{1,3})(?!\d).*?\.(mp4|mkv)",
        "replace": r"\1E\2.\3",
    },
    "$BLACK_WORD": {
        "pattern": r"^(?!.*çº¯äº«)(?!.*åŠ æ›´)(?!.*è¶…å‰ä¼åˆ’)(?!.*è®­ç»ƒå®¤)(?!.*è’¸è’¸æ—¥ä¸Š).*",
        "replace": "",
    },
}


# å‘é€é€šçŸ¥æ¶ˆæ¯
def send_ql_notify(title, body):
    try:
        # å¯¼å…¥é€šçŸ¥æ¨¡å—
        import notify

        # å¦‚æœªé…ç½® push_config åˆ™ä½¿ç”¨é’é¾™ç¯å¢ƒé€šçŸ¥è®¾ç½®
        if CONFIG_DATA.get("push_config"):
            notify.push_config = CONFIG_DATA["push_config"].copy()
            notify.push_config["CONSOLE"] = notify.push_config.get("CONSOLE", True)
        notify.send(title, body)
    except Exception as e:
        if e:
            print("å‘é€é€šçŸ¥æ¶ˆæ¯å¤±è´¥ï¼")


# æ·»åŠ æ¶ˆæ¯
def add_notify(text):
    global NOTIFYS
    # é˜²æ­¢é‡å¤æ·»åŠ ç›¸åŒçš„é€šçŸ¥
    # ä½†æ˜¯å¯¹äºæ–‡ä»¶æ ‘æ˜¾ç¤ºï¼Œå…è®¸ç›¸åŒæ–‡æœ¬ï¼ˆå› ä¸ºå¯èƒ½æ˜¯ä¸åŒç›®å½•ä¸‹çš„åŒåæ–‡ä»¶ï¼‰
    # é€šè¿‡æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«æ–‡ä»¶æ ‘å‰ç¼€ï¼ˆâ”œâ”€â”€ æˆ– â””â”€â”€ï¼‰æ¥åˆ¤æ–­
    is_file_tree_line = "â”œâ”€â”€ " in text or "â””â”€â”€ " in text
    if text in NOTIFYS and not is_file_tree_line:
        return text
    
    # æ£€æŸ¥æ¨é€é€šçŸ¥ç±»å‹é…ç½®
    push_notify_type = CONFIG_DATA.get("push_notify_type", "full")
    
    # å®šä¹‰å…³é”®å­—ï¼ˆå¤ç”¨äºè¿‡æ»¤ä¸åˆ†éš”ï¼‰
    failure_keywords = ["âŒ", "â—", "å¤±è´¥", "å¤±æ•ˆ", "é”™è¯¯", "å¼‚å¸¸", "æ— æ•ˆ", "ç™»å½•å¤±è´¥"]
    invalid_keywords = ["åˆ†äº«èµ„æºå·²å¤±æ•ˆ", "åˆ†äº«è¯¦æƒ…è·å–å¤±è´¥", "åˆ†äº«ä¸ºç©º", "æ–‡ä»¶å·²è¢«åˆ†äº«è€…åˆ é™¤"]
    
    # å¦‚æœè®¾ç½®ä¸ºä»…æ¨é€æˆåŠŸä¿¡æ¯ï¼Œåˆ™è¿‡æ»¤æ‰å¤±è´¥å’Œé”™è¯¯ä¿¡æ¯
    if push_notify_type == "success_only":
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤±è´¥æˆ–é”™è¯¯ç›¸å…³çš„å…³é”®è¯
        if any(keyword in text for keyword in failure_keywords):
            # åªæ‰“å°åˆ°æ§åˆ¶å°ï¼Œä¸æ·»åŠ åˆ°é€šçŸ¥åˆ—è¡¨
            print(text)
            return text
    
    # å¦‚æœè®¾ç½®ä¸ºæ’é™¤å¤±æ•ˆä¿¡æ¯ï¼Œåˆ™è¿‡æ»¤æ‰èµ„æºå¤±æ•ˆä¿¡æ¯ï¼Œä½†ä¿ç•™è½¬å­˜å¤±è´¥ä¿¡æ¯
    elif push_notify_type == "exclude_invalid":
        # æ£€æŸ¥æ˜¯å¦åŒ…å«èµ„æºå¤±æ•ˆç›¸å…³çš„å…³é”®è¯ï¼ˆä¸»è¦æ˜¯åˆ†äº«èµ„æºå¤±æ•ˆï¼‰
        if any(keyword in text for keyword in invalid_keywords):
            # åªæ‰“å°åˆ°æ§åˆ¶å°ï¼Œä¸æ·»åŠ åˆ°é€šçŸ¥åˆ—è¡¨
            print(text)
            return text
    
    # åœ¨æ¯ä¸ªä»»åŠ¡å—ä¹‹é—´æ’å…¥ä¸€ä¸ªç©ºè¡Œï¼Œå¢å¼ºå¯è¯»æ€§
    # æˆåŠŸå—ï¼šä»¥â€œâœ…ã€Šâ€å¼€å¤´ï¼›å¤±è´¥/é”™è¯¯å—ï¼šä»¥â€œâŒâ€â€œâ—â€å¼€å¤´æˆ–åŒ…å«å¤±è´¥ç›¸å…³å…³é”®è¯
    is_success_block = text.startswith("âœ…ã€Š")
    is_failure_block = text.startswith("âŒ") or text.startswith("â—") or any(k in text for k in failure_keywords if k not in ["âœ…"])
    if is_success_block or is_failure_block:
        if NOTIFYS and NOTIFYS[-1] != "":
            NOTIFYS.append("")
            # ä»…åœ¨é€šçŸ¥ä½“ä¸­æ·»åŠ ç©ºè¡Œï¼Œä¸é¢å¤–æ‰“å°æ§åˆ¶å°ç©ºè¡Œ
    
    NOTIFYS.append(text)
    print(text)
    return text


# æ ¼å¼åŒ–æ–‡ä»¶æ˜¾ç¤ºï¼Œç»Ÿä¸€å›¾æ ‡å’Œæ–‡ä»¶åä¹‹é—´çš„ç©ºæ ¼
def format_file_display(prefix, icon, name):
    """
    æ ¼å¼åŒ–æ–‡ä»¶/æ–‡ä»¶å¤¹çš„æ˜¾ç¤ºï¼Œç¡®ä¿å›¾æ ‡å’Œåç§°ä¹‹é—´åªæœ‰ä¸€ä¸ªç©ºæ ¼
    
    Args:
        prefix: æ ‘å½¢ç»“æ„çš„å‰ç¼€ï¼ˆå¦‚"â”œâ”€â”€ "ï¼‰
        icon: æ–‡ä»¶/æ–‡ä»¶å¤¹å›¾æ ‡
        name: æ–‡ä»¶/æ–‡ä»¶å¤¹åç§°
        
    Returns:
        æ ¼å¼åŒ–åçš„æ˜¾ç¤ºå­—ç¬¦ä¸²
    """
    # å»é™¤å›¾æ ‡å’Œåç§°ä¸­å¯èƒ½å­˜åœ¨çš„ç©ºæ ¼
    clean_icon = icon.strip() if icon else ""
    clean_name = name.strip() if name else ""
    
    # å¦‚æœæœ‰å›¾æ ‡ï¼Œç¡®ä¿å›¾æ ‡å’Œåç§°ä¹‹é—´åªæœ‰ä¸€ä¸ªç©ºæ ¼
    if clean_icon:
        return f"{prefix}{clean_icon} {clean_name}"
    else:
        return f"{prefix}{clean_name}"

# å®šä¹‰ä¸€ä¸ªé€šç”¨çš„æ–‡ä»¶ç±»å‹å›¾æ ‡é€‰æ‹©å‡½æ•°
def get_file_icon(file_name, is_dir=False):
    """æ ¹æ®æ–‡ä»¶æ‰©å±•åè¿”å›å¯¹åº”çš„å›¾æ ‡"""
    # å¦‚æœæ˜¯æ–‡ä»¶å¤¹ï¼Œç›´æ¥è¿”å›æ–‡ä»¶å¤¹å›¾æ ‡
    if is_dir:
        return "ğŸ“"

    # æ–‡ä»¶åè½¬å°å†™ä¾¿äºåŒ¹é…
    lower_name = file_name.lower()

    # è§†é¢‘æ–‡ä»¶
    if any(lower_name.endswith(ext) for ext in ['.mp4', '.mkv', '.avi', '.mov', '.rmvb', '.flv', '.wmv', '.m4v', '.ts', '.webm', '.3gp', '.f4v']):
        return "ğŸï¸"

    # å›¾ç‰‡æ–‡ä»¶
    if any(lower_name.endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp', '.tiff', '.svg']):
        return "ğŸ–¼ï¸"

    # éŸ³é¢‘æ–‡ä»¶
    if any(lower_name.endswith(ext) for ext in ['.mp3', '.wav', '.flac', '.aac', '.ogg', '.m4a', '.wma']):
        return "ğŸµ"

    # æ–‡æ¡£æ–‡ä»¶
    if any(lower_name.endswith(ext) for ext in ['.pdf', '.doc', '.docx', '.xls', '.xlsx', '.ppt', '.pptx', '.txt', '.md', '.csv']):
        return "ğŸ“„"

    # å‹ç¼©æ–‡ä»¶
    if any(lower_name.endswith(ext) for ext in ['.zip', '.rar', '.7z', '.tar', '.gz', '.bz2']):
        return "ğŸ“¦"

    # ä»£ç æ–‡ä»¶
    if any(lower_name.endswith(ext) for ext in ['.py', '.js', '.html', '.css', '.java', '.c', '.cpp', '.php', '.go', '.json']):
        return "ğŸ“"

    # å­—å¹•æ–‡ä»¶
    if any(lower_name.endswith(ext) for ext in ['.srt', '.ass', '.ssa', '.vtt', '.sup']):
        return "ğŸ’¬"

    # æ­Œè¯æ–‡ä»¶
    if any(lower_name.endswith(ext) for ext in ['.lrc']):
        return "ğŸ’¬"

    # é»˜è®¤å›¾æ ‡ï¼ˆå…¶ä»–æ–‡ä»¶ç±»å‹ï¼‰
    return ""

# å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥å»é™¤æ–‡ä»¶åä¸­çš„æ‰€æœ‰å›¾æ ‡
def remove_file_icons(filename):
    """å»é™¤æ–‡ä»¶åå¼€å¤´çš„æ‰€æœ‰å›¾æ ‡"""
    # å®šä¹‰æ‰€æœ‰å¯èƒ½çš„æ–‡ä»¶å›¾æ ‡
    icons = ["ğŸï¸", "ğŸ–¼ï¸", "ğŸµ", "ğŸ“„", "ğŸ“¦", "ğŸ“", "ğŸ’¬", "ğŸ“"]

    # å»é™¤å¼€å¤´çš„å›¾æ ‡å’Œç©ºæ ¼
    clean_name = filename
    for icon in icons:
        if clean_name.startswith(icon):
            clean_name = clean_name[len(icon):].lstrip()
            break

    return clean_name

# å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥æ£€æµ‹å­—å¹•æ–‡ä»¶å¹¶åº”ç”¨è¯­è¨€ä»£ç åç¼€
def apply_subtitle_naming_rule(filename, task_settings):
    """
    æ£€æµ‹å­—å¹•æ–‡ä»¶å¹¶åº”ç”¨è¯­è¨€ä»£ç åç¼€
    
    Args:
        filename: åŸå§‹æ–‡ä»¶å
        task_settings: ä»»åŠ¡è®¾ç½®ï¼ŒåŒ…å«å­—å¹•å‘½åè§„åˆ™é…ç½®
    
    Returns:
        å¤„ç†åçš„æ–‡ä»¶å
    """
    # ä»ä»»åŠ¡è®¾ç½®ä¸­è·å–å­—å¹•å‘½åè§„åˆ™é…ç½®
    subtitle_add_language_code = task_settings.get("subtitle_add_language_code", False)
    subtitle_naming_rule = task_settings.get("subtitle_naming_rule", "zh")
    
    # å¦‚æœä»»åŠ¡è®¾ç½®ä¸­æ²¡æœ‰é…ç½®ï¼Œå°è¯•ä»å…¨å±€é…ç½®ä¸­è·å–
    if not subtitle_add_language_code:
        try:
            if 'CONFIG_DATA' in globals() and CONFIG_DATA:
                global_task_settings = CONFIG_DATA.get("task_settings", {})
                subtitle_add_language_code = global_task_settings.get("subtitle_add_language_code", False)
                subtitle_naming_rule = global_task_settings.get("subtitle_naming_rule", "zh")
        except (KeyError, AttributeError, TypeError):
            # é…ç½®è·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
            pass
    
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†å­—å¹•å‘½åè§„åˆ™
    if not subtitle_add_language_code or not subtitle_naming_rule:
        return filename
    
    # æ£€æµ‹æ˜¯å¦ä¸ºå­—å¹•æ–‡ä»¶
    lower_name = filename.lower()
    subtitle_extensions = ['.srt', '.ass', '.ssa', '.vtt', '.sup']
    
    if not any(lower_name.endswith(ext) for ext in subtitle_extensions):
        return filename
    
    # åˆ†ç¦»æ–‡ä»¶åå’Œæ‰©å±•å
    name_without_ext, ext = os.path.splitext(filename)
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å«è¯­è¨€ä»£ç åç¼€ï¼Œé¿å…é‡å¤æ·»åŠ 
    if f".{subtitle_naming_rule}" in name_without_ext:
        return filename
    
    # æ·»åŠ è¯­è¨€ä»£ç åç¼€
    return f"{name_without_ext}.{subtitle_naming_rule}{ext}"


class Config:
    # ä¸‹è½½é…ç½®
    def download_file(url, save_path):
        response = requests.get(url)
        if response.status_code == 200:
            with open(save_path, "wb") as file:
                file.write(response.content)
            return True
        else:
            return False

    # è¯»å– JSON æ–‡ä»¶å†…å®¹
    def read_json(config_path):
        with open(config_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        return data

    # å°†æ•°æ®å†™å…¥ JSON æ–‡ä»¶
    def write_json(config_path, data):
        with open(config_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, sort_keys=False, indent=2)

    # è¯»å–CK
    def get_cookies(cookie_val):
        if isinstance(cookie_val, list):
            return cookie_val
        elif cookie_val:
            if "\n" in cookie_val:
                return cookie_val.split("\n")
            else:
                return [cookie_val]
        else:
            return False

    def load_plugins(plugins_config={}, plugins_dir="plugins"):
        PLUGIN_FLAGS = os.environ.get("PLUGIN_FLAGS", "").split(",")
        plugins_available = {}
        task_plugins_config = {}
        all_modules = [
            f.replace(".py", "") for f in os.listdir(plugins_dir) if f.endswith(".py")
        ]
        # è°ƒæ•´æ¨¡å—ä¼˜å…ˆçº§
        priority_path = os.path.join(plugins_dir, "_priority.json")
        try:
            with open(priority_path, encoding="utf-8") as f:
                priority_modules = json.load(f)
            if priority_modules:
                all_modules = [
                    module for module in priority_modules if module in all_modules
                ] + [module for module in all_modules if module not in priority_modules]
        except (FileNotFoundError, json.JSONDecodeError):
            priority_modules = []
        for module_name in all_modules:
            if f"-{module_name}" in PLUGIN_FLAGS:
                continue
            try:
                module = importlib.import_module(f"{plugins_dir}.{module_name}")
                ServerClass = getattr(module, module_name.capitalize())
                # æ£€æŸ¥é…ç½®ä¸­æ˜¯å¦å­˜åœ¨è¯¥æ¨¡å—çš„é…ç½®
                if module_name in plugins_config:
                    plugin = ServerClass(**plugins_config[module_name])
                    plugins_available[module_name] = plugin
                else:
                    plugin = ServerClass()
                    plugins_config[module_name] = plugin.default_config
                # æ£€æŸ¥æ’ä»¶æ˜¯å¦æ”¯æŒå•ç‹¬ä»»åŠ¡é…ç½®
                if hasattr(plugin, "default_task_config"):
                    task_plugins_config[module_name] = plugin.default_task_config
            except (ImportError, AttributeError) as e:
                print(f"è½½å…¥æ¨¡å— {module_name} å¤±è´¥: {e}")
        print()
        return plugins_available, plugins_config, task_plugins_config

    def breaking_change_update(config_data):
        if config_data.get("emby"):
            print("ğŸ”¼ Update config v0.3.6.1 to 0.3.7")
            config_data.setdefault("media_servers", {})["emby"] = {
                "url": config_data["emby"]["url"],
                "token": config_data["emby"]["apikey"],
            }
            del config_data["emby"]
            for task in config_data.get("tasklist", {}):
                task["media_id"] = task.get("emby_id", "")
                if task.get("emby_id"):
                    del task["emby_id"]
        if config_data.get("media_servers"):
            print("ğŸ”¼ Update config v0.3.8 to 0.3.9")
            config_data["plugins"] = config_data.get("media_servers")
            del config_data["media_servers"]
            for task in config_data.get("tasklist", {}):
                task["addition"] = {
                    "emby": {
                        "media_id": task.get("media_id", ""),
                    }
                }
                if task.get("media_id"):
                    del task["media_id"]
                    


class Quark:
    BASE_URL = "https://drive-pc.quark.cn"
    BASE_URL_APP = "https://drive-m.quark.cn"
    USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) quark-cloud-drive/3.14.2 Chrome/112.0.5615.165 Electron/24.1.3.8 Safari/537.36 Channel/pckk_other_ch"

    def __init__(self, cookie, index=None):
        self.cookie = cookie.strip()
        self.index = index + 1
        self.is_active = False
        self.nickname = ""
        self.mparam = self._match_mparam_form_cookie(cookie)
        self.savepath_fid = {"/": "0"}

    def _match_mparam_form_cookie(self, cookie):
        mparam = {}
        kps_match = re.search(r"(?<!\w)kps=([a-zA-Z0-9%+/=]+)[;&]?", cookie)
        sign_match = re.search(r"(?<!\w)sign=([a-zA-Z0-9%+/=]+)[;&]?", cookie)
        vcode_match = re.search(r"(?<!\w)vcode=([a-zA-Z0-9%+/=]+)[;&]?", cookie)
        if kps_match and sign_match and vcode_match:
            mparam = {
                "kps": kps_match.group(1).replace("%25", "%"),
                "sign": sign_match.group(1).replace("%25", "%"),
                "vcode": vcode_match.group(1).replace("%25", "%"),
            }
        return mparam

    def _send_request(self, method, url, **kwargs):
        headers = {
            "cookie": self.cookie,
            "content-type": "application/json",
            "user-agent": self.USER_AGENT,
        }
        if "headers" in kwargs:
            headers = kwargs["headers"]
            del kwargs["headers"]
        if self.mparam and "share" in url and self.BASE_URL in url:
            url = url.replace(self.BASE_URL, self.BASE_URL_APP)
            kwargs["params"].update(
                {
                    "device_model": "M2011K2C",
                    "entry": "default_clouddrive",
                    "_t_group": "0%3A_s_vp%3A1",
                    "dmn": "Mi%2B11",
                    "fr": "android",
                    "pf": "3300",
                    "bi": "35937",
                    "ve": "7.4.5.680",
                    "ss": "411x875",
                    "mi": "M2011K2C",
                    "nt": "5",
                    "nw": "0",
                    "kt": "4",
                    "pr": "ucpro",
                    "sv": "release",
                    "dt": "phone",
                    "data_from": "ucapi",
                    "kps": self.mparam.get("kps"),
                    "sign": self.mparam.get("sign"),
                    "vcode": self.mparam.get("vcode"),
                    "app": "clouddrive",
                    "kkkk": "1",
                }
            )
            del headers["cookie"]
        try:
            response = requests.request(method, url, headers=headers, **kwargs)
            # print(f"{response.text}")
            # response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸï¼Œä½†è¿”å›é200ä¹Ÿä¼šæŠ›å‡ºå¼‚å¸¸
            
            # æ£€æŸ¥å“åº”å†…å®¹ä¸­æ˜¯å¦åŒ…å«inner errorï¼Œå°†å…¶è½¬æ¢ä¸ºrequest error
            try:
                response_json = response.json()
                if isinstance(response_json, dict) and response_json.get("message"):
                    error_message = response_json.get("message", "")
                    if "inner error" in error_message.lower():
                        # å°†inner errorè½¬æ¢ä¸ºrequest errorï¼Œé¿å…è¯¯åˆ¤ä¸ºèµ„æºå¤±æ•ˆ
                        response_json["message"] = "request error"
                        response._content = json.dumps(response_json).encode('utf-8')
            except:
                pass  # å¦‚æœJSONè§£æå¤±è´¥ï¼Œä¿æŒåŸå“åº”ä¸å˜
                
            return response
        except Exception as e:
            print(f"_send_request error:\n{e}")
            fake_response = requests.Response()
            fake_response.status_code = 500
            fake_response._content = b'{"status": 500, "message": "request error"}'
            return fake_response

    def init(self):
        account_info = self.get_account_info()
        if account_info:
            self.is_active = True
            self.nickname = account_info["nickname"]
            return account_info
        else:
            return False

    def get_account_info(self):
        url = "https://pan.quark.cn/account/info"
        querystring = {"fr": "pc", "platform": "pc"}
        response = self._send_request("GET", url, params=querystring).json()
        if response.get("data"):
            return response["data"]
        else:
            return False

    def get_growth_info(self):
        url = f"{self.BASE_URL_APP}/1/clouddrive/capacity/growth/info"
        querystring = {
            "pr": "ucpro",
            "fr": "android",
            "kps": self.mparam.get("kps"),
            "sign": self.mparam.get("sign"),
            "vcode": self.mparam.get("vcode"),
        }
        headers = {
            "content-type": "application/json",
        }
        response = self._send_request(
            "GET", url, headers=headers, params=querystring
        ).json()
        if response.get("data"):
            return response["data"]
        else:
            return False

    def get_growth_sign(self):
        url = f"{self.BASE_URL_APP}/1/clouddrive/capacity/growth/sign"
        querystring = {
            "pr": "ucpro",
            "fr": "android",
            "kps": self.mparam.get("kps"),
            "sign": self.mparam.get("sign"),
            "vcode": self.mparam.get("vcode"),
        }
        payload = {
            "sign_cyclic": True,
        }
        headers = {
            "content-type": "application/json",
        }
        response = self._send_request(
            "POST", url, json=payload, headers=headers, params=querystring
        ).json()
        if response.get("data"):
            return True, response["data"]["sign_daily_reward"]
        else:
            return False, response["message"]

    # å¯éªŒè¯èµ„æºæ˜¯å¦å¤±æ•ˆ
    def get_stoken(self, pwd_id, passcode=""):
        url = f"{self.BASE_URL}/1/clouddrive/share/sharepage/token"
        querystring = {"pr": "ucpro", "fr": "pc"}
        payload = {"pwd_id": pwd_id, "passcode": passcode}
        response = self._send_request(
            "POST", url, json=payload, params=querystring
        ).json()
        if response.get("status") == 200:
            return True, response["data"]["stoken"]
        else:
            return False, response["message"]

    def is_recoverable_error(self, error_message):
        """
        æ£€æŸ¥é”™è¯¯æ˜¯å¦ä¸ºå¯æ¢å¤çš„é”™è¯¯ï¼ˆç½‘ç»œé”™è¯¯ã€æœåŠ¡ç«¯ä¸´æ—¶é”™è¯¯ç­‰ï¼‰
        
        Args:
            error_message: é”™è¯¯æ¶ˆæ¯
            
        Returns:
            bool: æ˜¯å¦ä¸ºå¯æ¢å¤é”™è¯¯
        """
        if not error_message:
            return False
            
        error_message = error_message.lower()
        recoverable_errors = [
            "inner error",
            "request error", 
            "ç½‘ç»œé”™è¯¯",
            "æœåŠ¡ç«¯é”™è¯¯",
            "ä¸´æ—¶é”™è¯¯",
            "timeout",
            "connection error",
            "server error"
        ]
        
        return any(error in error_message for error in recoverable_errors)

    def get_detail(self, pwd_id, stoken, pdir_fid, _fetch_share=0, max_retries=3):
        list_merge = []
        page = 1
        retry_count = 0
        
        while True:
            url = f"{self.BASE_URL}/1/clouddrive/share/sharepage/detail"
            querystring = {
                "pr": "ucpro",
                "fr": "pc",
                "pwd_id": pwd_id,
                "stoken": stoken,
                "pdir_fid": pdir_fid,
                "force": "0",
                "_page": page,
                "_size": "50",
                "_fetch_banner": "0",
                "_fetch_share": _fetch_share,
                "_fetch_total": "1",
                "_sort": "file_type:asc,updated_at:desc",
            }
            # å…¼å®¹ç½‘ç»œé”™è¯¯æˆ–æœåŠ¡ç«¯å¼‚å¸¸
            try:
                response = self._send_request("GET", url, params=querystring).json()
            except Exception:
                return {"error": "request error"}

            # æ£€æŸ¥å“åº”ä¸­æ˜¯å¦åŒ…å«inner erroræˆ–å…¶ä»–å¯æ¢å¤é”™è¯¯
            if isinstance(response, dict) and response.get("message"):
                error_message = response.get("message", "")
                if "inner error" in error_message.lower():
                    # å¯¹äºinner errorï¼Œå°è¯•é‡è¯•
                    if retry_count < max_retries:
                        retry_count += 1
                        # é™é»˜é‡è¯•ï¼Œä¸è¾“å‡ºé‡è¯•ä¿¡æ¯ï¼Œé¿å…æ—¥å¿—æ±¡æŸ“
                        # åªæœ‰åœ¨è°ƒè¯•æ¨¡å¼ä¸‹æ‰è®°å½•è¯¦ç»†é‡è¯•ä¿¡æ¯
                        try:
                            import os
                            if os.environ.get("DEBUG", "false").lower() == "true":
                                print(f"[DEBUG] é‡åˆ°inner errorï¼Œè¿›è¡Œç¬¬{retry_count}æ¬¡é‡è¯•...")
                        except:
                            pass  # å¦‚æœæ— æ³•è·å–DEBUGç¯å¢ƒå˜é‡ï¼Œé™é»˜å¤„ç†
                        time.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
                        continue
                    else:
                        return {"error": "request error"}  # é‡è¯•æ¬¡æ•°ç”¨å°½ï¼Œè¿”å›request error

            # ç»Ÿä¸€åˆ¤é”™ï¼šæŸäº›æƒ…å†µä¸‹è¿”å›æ²¡æœ‰ code å­—æ®µ
            code = response.get("code")
            status = response.get("status")
            if code not in (0, None):
                return {"error": response.get("message", "unknown error")}
            if status not in (None, 200):
                return {"error": response.get("message", "request error")}

            data = response.get("data") or {}
            metadata = response.get("metadata") or {}

            if data.get("list"):
                list_merge += data["list"]
                page += 1
            else:
                break
            # é˜²å¾¡æ€§ï¼šmetadata æˆ– _total ç¼ºå¤±æ—¶ä¸å†è®¿é—®åµŒå¥—é”®
            total = metadata.get("_total") if isinstance(metadata, dict) else None
            if isinstance(total, int) and len(list_merge) >= total:
                break
        # ç»Ÿä¸€è¾“å‡ºç»“æ„ï¼Œç¼ºå¤±å­—æ®µæ—¶æä¾›é»˜è®¤å€¼
        if not isinstance(data, dict):
            return {"error": response.get("message", "request error")}
        data["list"] = list_merge
        if "paths" not in data:
            data["paths"] = []
        return data

    def get_fids(self, file_paths):
        fids = []
        while True:
            url = f"{self.BASE_URL}/1/clouddrive/file/info/path_list"
            querystring = {"pr": "ucpro", "fr": "pc"}
            payload = {"file_path": file_paths[:50], "namespace": "0"}
            response = self._send_request(
                "POST", url, json=payload, params=querystring
            ).json()
            if response["code"] == 0:
                fids += response["data"]
                file_paths = file_paths[50:]
            else:
                print(f"è·å–ç›®å½•ID: å¤±è´¥, {response['message']}")
                break
            if len(file_paths) == 0:
                break
        return fids

    def ls_dir(self, pdir_fid, **kwargs):
        file_list = []
        page = 1
        # ä¼˜åŒ–ï¼šå¢åŠ æ¯é¡µå¤§å°ï¼Œå‡å°‘APIè°ƒç”¨æ¬¡æ•°
        page_size = kwargs.get("page_size", 200)  # ä»50å¢åŠ åˆ°200

        while True:
            url = f"{self.BASE_URL}/1/clouddrive/file/sort"
            querystring = {
                "pr": "ucpro",
                "fr": "pc",
                "uc_param_str": "",
                "pdir_fid": pdir_fid,
                "_page": page,
                "_size": str(page_size),
                "_fetch_total": "1",
                "_fetch_sub_dirs": "0",
                "_sort": "file_type:asc,updated_at:desc",
                "_fetch_full_path": kwargs.get("fetch_full_path", 0),
            }
            response = self._send_request("GET", url, params=querystring).json()
            if response["code"] != 0:
                return {"error": response["message"]}
            if response["data"]["list"]:
                file_list += response["data"]["list"]
                page += 1
            else:
                break
            if len(file_list) >= response["metadata"]["_total"]:
                break
        
        # ä¿®å¤æ–‡ä»¶å¤¹å¤§å°æ˜¾ç¤ºé—®é¢˜ï¼šå½“include_itemså­—æ®µä¸å­˜åœ¨æ—¶ï¼Œé€šè¿‡é¢å¤–APIè°ƒç”¨è·å–
        file_list = self._fix_folder_sizes(file_list)
        
        return file_list

    def _fix_folder_sizes(self, file_list):
        """
        ä¿®å¤æ–‡ä»¶å¤¹å¤§å°æ˜¾ç¤ºé—®é¢˜
        å½“include_itemså­—æ®µä¸å­˜åœ¨æ—¶ï¼Œé€šè¿‡é¢å¤–APIè°ƒç”¨è·å–æ–‡ä»¶å¤¹é¡¹ç›®æ•°é‡
        """
        if not isinstance(file_list, list):
            return file_list
            
        for item in file_list:
            if item.get("dir", False) and "include_items" not in item:
                folder_id = item.get("fid")
                if folder_id:
                    # è·å–æ–‡ä»¶å¤¹é¡¹ç›®æ•°é‡
                    item_count = self._get_folder_item_count(folder_id)
                    item["include_items"] = item_count
                    
        return file_list
    
    def _get_folder_item_count(self, folder_id):
        """
        è·å–æ–‡ä»¶å¤¹é¡¹ç›®æ•°é‡
        """
        try:
            url = f"{self.BASE_URL}/1/clouddrive/file/sort"
            querystring = {
                "pr": "ucpro",
                "fr": "pc",
                "uc_param_str": "",
                "pdir_fid": folder_id,
                "_page": 1,
                "_size": 1,  # åªè·å–ç¬¬ä¸€é¡µï¼Œç”¨äºè·å–æ€»æ•°
                "_fetch_total": "1",
                "_fetch_sub_dirs": "0",
                "_sort": "file_type:asc,updated_at:desc",
                "_fetch_full_path": 0,
            }
            
            response = self._send_request("GET", url, params=querystring).json()
            if response.get("code") == 0:
                metadata = response.get("metadata", {})
                return metadata.get("_total", 0)
            else:
                return 0
        except Exception:
            return 0

    def get_paths(self, folder_id):
        """
        è·å–æŒ‡å®šæ–‡ä»¶å¤¹IDçš„å®Œæ•´è·¯å¾„ä¿¡æ¯
        
        Args:
            folder_id: æ–‡ä»¶å¤¹ID
            
        Returns:
            list: è·¯å¾„ä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«fidå’Œname
        """
        if folder_id == "0" or folder_id == 0:
            return []
            
        url = f"{self.BASE_URL}/1/clouddrive/file/sort"
        querystring = {
            "pr": "ucpro",
            "fr": "pc",
            "uc_param_str": "",
            "pdir_fid": folder_id,
            "_page": 1,
            "_size": "50",
            "_fetch_total": "1",
            "_fetch_sub_dirs": "0",
            "_sort": "file_type:asc,updated_at:desc",
            "_fetch_full_path": 1,
        }
        
        try:
            response = self._send_request("GET", url, params=querystring).json()
            if response["code"] == 0 and "full_path" in response["data"]:
                paths = []
                for item in response["data"]["full_path"]:
                    paths.append({
                        "fid": item["fid"],
                        "name": item["file_name"]
                    })
                return paths
        except Exception as e:
            print(f"è·å–æ–‡ä»¶å¤¹è·¯å¾„å‡ºé”™: {str(e)}")
            
        return []

    def save_file(self, fid_list, fid_token_list, to_pdir_fid, pwd_id, stoken):
        url = f"{self.BASE_URL}/1/clouddrive/share/sharepage/save"
        querystring = {
            "pr": "ucpro",
            "fr": "pc",
            "uc_param_str": "",
            "app": "clouddrive",
            "__dt": int(random.uniform(1, 5) * 60 * 1000),
            "__t": datetime.now().timestamp(),
        }
        payload = {
            "fid_list": fid_list,
            "fid_token_list": fid_token_list,
            "to_pdir_fid": to_pdir_fid,
            "pwd_id": pwd_id,
            "stoken": stoken,
            "pdir_fid": "0",
            "scene": "link",
        }
        response = self._send_request(
            "POST", url, json=payload, params=querystring
        ).json()
        return response

    def query_task(self, task_id):
        retry_index = 0
        while True:
            url = f"{self.BASE_URL}/1/clouddrive/task"
            querystring = {
                "pr": "ucpro",
                "fr": "pc",
                "uc_param_str": "",
                "task_id": task_id,
                "retry_index": retry_index,
                "__dt": int(random.uniform(1, 5) * 60 * 1000),
                "__t": datetime.now().timestamp(),
            }
            response = self._send_request("GET", url, params=querystring).json()
            if response["data"]["status"] != 0:
                if retry_index > 0:
                    print()
                break
            else:
                if retry_index == 0:
                    print(
                        f"æ­£åœ¨ç­‰å¾…ã€Œ{response['data']['task_title']}ã€æ‰§è¡Œç»“æœ",
                        end="",
                        flush=True,
                    )
                else:
                    print(".", end="", flush=True)
                retry_index += 1
                time.sleep(0.500)
        return response

    def cloud_unarchive(self, fid, to_pdir_fid="0"):
        """
        äº‘è§£å‹å‹ç¼©æ–‡ä»¶ï¼ˆéœ€è¦å¤¸å…‹é«˜çº§ä¼šå‘˜ï¼‰
        
        å‚æ•°:
            fid: å‹ç¼©æ–‡ä»¶çš„ fid
            to_pdir_fid: è§£å‹ç›®æ ‡ç›®å½• fidï¼Œ'0' è¡¨ç¤ºæ ¹ç›®å½•
        
        è¿”å›:
            è§£å‹ç»“æœï¼ŒåŒ…å« task_id å’Œè§£å‹åçš„æ–‡ä»¶ä¿¡æ¯
        """
        url = f"{self.BASE_URL}/1/clouddrive/archive/unarchive"
        querystring = {
            "pr": "ucpro",
            "fr": "pc",
            "uc_param_str": "",
        }
        payload = {
            "fid": fid,
            "select_mode": 1,  # 1 è¡¨ç¤ºå…¨éƒ¨è§£å‹
            "to_pdir_fid": to_pdir_fid,
        }
        response = self._send_request("POST", url, json=payload, params=querystring).json()
        
        if response.get("code") == 0:
            return response
        
        # é”™è¯¯å¤„ç†
        error_code = response.get("code")
        error_msg = response.get("message", "")
        
        if error_code == 23008 and "doloading" in error_msg:
            # æ–‡ä»¶æ­£åœ¨å¤„ç†ä¸­
            return {"code": 23008, "message": "æ–‡ä»¶æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨åé‡è¯•"}
        elif error_code == 31001:
            # é SVIP ä¼šå‘˜
            return {"code": 31001, "message": "äº‘è§£å‹éœ€è¦å¤¸å…‹ 88VIPã€SVIPã€SVIP+ ç­‰é«˜çº§ä¼šå‘˜"}
        else:
            return response

    def query_unarchive_task(self, task_id, timeout=300):
        """
        æŸ¥è¯¢è§£å‹ä»»åŠ¡çŠ¶æ€
        
        å‚æ•°:
            task_id: è§£å‹ä»»åŠ¡ ID
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        
        è¿”å›:
            è§£å‹ä»»åŠ¡ç»“æœï¼ŒåŒ…å«è§£å‹åçš„æ–‡ä»¶ä¿¡æ¯
        """
        start_time = time.time()
        retry_index = 0
        
        while time.time() - start_time < timeout:
            url = f"{self.BASE_URL}/1/clouddrive/task"
            querystring = {
                "pr": "ucpro",
                "fr": "pc",
                "uc_param_str": "",
                "task_id": task_id,
                "retry_index": retry_index,
            }
            response = self._send_request("GET", url, params=querystring).json()
            
            if response.get("code") == 0:
                data = response.get("data", {})
                status = data.get("status")
                
                if status == 2:  # å®Œæˆ
                    return {"code": 0, "data": data}
                elif status == 4:  # å¤±è´¥
                    # å°è¯•ä»ä»»åŠ¡ç»“æœä¸­æå–æ›´å…·ä½“çš„å¤±è´¥åŸå› 
                    unarchive_result = data.get("unarchive_result", {})
                    task_msg = unarchive_result.get("message") or data.get("message") or response.get("message", "")
                    error_msg = task_msg if task_msg else "è§£å‹ä»»åŠ¡å¤±è´¥"
                    return {"code": -1, "message": error_msg, "data": data}
                else:
                    # ä»»åŠ¡è¿›è¡Œä¸­
                    retry_index += 1
                    time.sleep(1)
            else:
                return response
        
        return {"code": -1, "message": "è§£å‹ä»»åŠ¡è¶…æ—¶"}

    def _is_file_size_extract_error(self, error_msg):
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ–‡ä»¶å¤§å°/é™åˆ¶å¯¼è‡´çš„è§£å‹å¤±è´¥ï¼Œæ­¤ç±»æƒ…å†µå»ºè®®ä½¿ç”¨å¤¸å…‹å®¢æˆ·ç«¯è§£å‹"""
        if not error_msg:
            return False
        msg_lower = error_msg.lower()
        size_keywords = ("å¤§å°", "è¶…é™", "è¶…è¿‡", "é™åˆ¶", "è¿‡å¤§", "size", "limit", "mb", "gb", "ä¸æ”¯æŒ")
        return any(kw in msg_lower for kw in size_keywords)

    def is_archive_file(self, filename):
        """åˆ¤æ–­æ˜¯å¦ä¸ºå‹ç¼©æ–‡ä»¶"""
        lower_name = filename.lower()
        archive_extensions = ['.zip', '.rar', '.7z', '.tar', '.gz', '.bz2', '.tar.gz', '.tar.bz2']
        return any(lower_name.endswith(ext) for ext in archive_extensions)

    def process_auto_extract(self, archive_fid, archive_name, target_pdir_fid, extract_mode, task=None):
        """
        å¤„ç†å‹ç¼©æ–‡ä»¶çš„è‡ªåŠ¨è§£å‹
        
        å‚æ•°:
            archive_fid: å‹ç¼©æ–‡ä»¶çš„ fid
            archive_name: å‹ç¼©æ–‡ä»¶å
            target_pdir_fid: ç›®æ ‡ç›®å½•çš„ fid
            extract_mode: è§£å‹æ¨¡å¼ (keep_structure_keep_archive, flat_files_keep_archive, 
                          keep_structure_delete_archive, flat_files_delete_archive)
            task: ä»»åŠ¡ä¿¡æ¯ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        
        è¿”å›:
            dict: åŒ…å«è§£å‹ç»“æœä¿¡æ¯
        """
        task_name = task.get("taskname", "æœªçŸ¥ä»»åŠ¡") if task else "æœªçŸ¥ä»»åŠ¡"
        
        # è§£æè§£å‹æ¨¡å¼
        keep_structure = "keep_structure" in extract_mode
        delete_archive = "delete_archive" in extract_mode
        
        # ç¬¬ä¸€æ­¥ï¼šæ‰§è¡Œäº‘è§£å‹ï¼ˆè§£å‹åˆ°æ ¹ç›®å½•ï¼‰
        unarchive_result = self.cloud_unarchive(archive_fid, "0")
        
        if unarchive_result.get("code") == 23008:
            # æ–‡ä»¶æ­£åœ¨å¤„ç†ä¸­ï¼Œç­‰å¾…åé‡è¯•
            print(f"  â³ æ–‡ä»¶æ­£åœ¨å¤„ç†ä¸­ï¼Œç­‰å¾… 15 ç§’åé‡è¯•...")
            time.sleep(15)
            unarchive_result = self.cloud_unarchive(archive_fid, "0")
        
        if unarchive_result.get("code") != 0:
            error_msg = unarchive_result.get("message", "æœªçŸ¥é”™è¯¯")
            print(f"  âŒ äº‘è§£å‹å¤±è´¥: {error_msg}")
            suggest_client = self._is_file_size_extract_error(error_msg)
            return {"success": False, "message": error_msg, "suggest_client": suggest_client}
        
        # è·å–è§£å‹ä»»åŠ¡ ID
        unarchive_task_id = unarchive_result.get("data", {}).get("task_id")
        if not unarchive_task_id:
            print(f"  âŒ æœªè·å–åˆ°è§£å‹ä»»åŠ¡ ID")
            return {"success": False, "message": "æœªè·å–åˆ°è§£å‹ä»»åŠ¡ ID"}
        
        # ç¬¬äºŒæ­¥ï¼šç­‰å¾…è§£å‹ä»»åŠ¡å®Œæˆï¼ˆ30 ç§’è¶…æ—¶ï¼Œè¶…æ—¶åˆ™æ”¾å¼ƒè§£å‹ï¼ŒæŒ‰æ— æ³•è§£å‹å¤„ç†ï¼‰
        task_result = self.query_unarchive_task(unarchive_task_id, timeout=30)
        
        if task_result.get("code") != 0:
            error_msg = task_result.get("message", "è§£å‹ä»»åŠ¡å¤±è´¥")
            if "è¶…æ—¶" in error_msg:
                print(f"  â±ï¸ äº‘è§£å‹å¼‚å¸¸è¶…æ—¶ï¼Œæ”¾å¼ƒè§£å‹: {archive_name}")
                print()
            else:
                print(f"  âŒ {error_msg}")
            suggest_client = self._is_file_size_extract_error(error_msg)
            return {"success": False, "message": error_msg, "suggest_client": suggest_client}
        
        # è·å–è§£å‹åçš„æ–‡ä»¶å¤¹ä¿¡æ¯
        unarchive_data = task_result.get("data", {})
        unarchive_result_info = unarchive_data.get("unarchive_result", {})
        extracted_list = unarchive_result_info.get("list", [])
        
        if not extracted_list:
            print(f"  âš ï¸ æœªè·å–åˆ°è§£å‹ç»“æœ")
            return {"success": False, "message": "æœªè·å–åˆ°è§£å‹ç»“æœ"}
        
        # è§£å‹åçš„æ–‡ä»¶å¤¹ï¼ˆåœ¨æ ¹ç›®å½•ï¼‰
        extracted_folder = extracted_list[0]
        extracted_folder_fid = extracted_folder.get("fid")
        extracted_folder_name = extracted_folder.get("file_name")
        
        # ç¬¬ä¸‰æ­¥ï¼šè·å–è§£å‹åçš„æ‰€æœ‰æ–‡ä»¶
        extracted_files = self.ls_dir(extracted_folder_fid)
        
        # æ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„æ–‡ä»¶ï¼ˆé€’å½’è·å–ï¼‰
        all_files = []
        folders_to_delete = [extracted_folder_fid]  # éœ€è¦åˆ é™¤çš„æ–‡ä»¶å¤¹åˆ—è¡¨
        
        def collect_files_recursive(folder_fid, relative_path=""):
            """é€’å½’æ”¶é›†æ–‡ä»¶å¤¹å†…çš„æ‰€æœ‰æ–‡ä»¶"""
            files = self.ls_dir(folder_fid)
            for f in files:
                file_relative_path = f"{relative_path}/{f['file_name']}" if relative_path else f['file_name']
                if f.get("dir"):
                    folders_to_delete.append(f["fid"])
                    collect_files_recursive(f["fid"], file_relative_path)
                else:
                    all_files.append({
                        "fid": f["fid"],
                        "file_name": f["file_name"],
                        "relative_path": file_relative_path,
                        "size": f.get("size", 0),
                        "parent_fid": folder_fid,
                    })
        
        collect_files_recursive(extracted_folder_fid)
        
        # ç¬¬å››æ­¥ï¼šåº”ç”¨è¿‡æ»¤è§„åˆ™å¹¶åˆ é™¤è¢«è¿‡æ»¤æ‰çš„æ–‡ä»¶
        if task and task.get("filterwords"):
            # åº”ç”¨è¿‡æ»¤è§„åˆ™ï¼Œè·å–é€šè¿‡è¿‡æ»¤çš„æ–‡ä»¶åˆ—è¡¨
            filtered_files = advanced_filter_files(all_files, task["filterwords"])
            
            # æ‰¾å‡ºè¢«è¿‡æ»¤æ‰çš„æ–‡ä»¶ï¼ˆä¸åœ¨è¿‡æ»¤åçš„åˆ—è¡¨ä¸­ï¼‰
            filtered_file_fids = {f["fid"] for f in filtered_files}
            files_to_delete = [f for f in all_files if f["fid"] not in filtered_file_fids]
            
            # åˆ é™¤è¢«è¿‡æ»¤æ‰çš„æ–‡ä»¶
            if files_to_delete:
                for file_to_delete in files_to_delete:
                    delete_result = self.delete([file_to_delete["fid"]])
                    if delete_result.get("code") != 0:
                        print(f"    âš ï¸ åˆ é™¤è¢«è¿‡æ»¤æ–‡ä»¶å¤±è´¥: {file_to_delete['file_name']} - {delete_result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                
                # æ›´æ–° all_files åˆ—è¡¨ï¼Œåªä¿ç•™é€šè¿‡è¿‡æ»¤çš„æ–‡ä»¶
                all_files = filtered_files
        
        # ç¬¬äº”æ­¥ï¼šæ ¹æ®æ¨¡å¼ç§»åŠ¨æ–‡ä»¶
        moved_files = []
        
        if keep_structure:
            # ä¿æŒåŸç›®å½•ç»“æ„ï¼šå°†æ•´ä¸ªè§£å‹æ–‡ä»¶å¤¹ç§»åŠ¨åˆ°ç›®æ ‡ç›®å½•
            move_result = self.move([extracted_folder_fid], target_pdir_fid)
            if move_result.get("code") == 0:
                moved_files = all_files
                folders_to_delete = []  # ä¸éœ€è¦åˆ é™¤ï¼Œå› ä¸ºå·²ç»ç§»åŠ¨äº†
                # è®°å½•éœ€è¦åç»­é‡å‘½åçš„å­ç›®å½•ï¼ˆä¸é¡¶å±‚ç›¸åŒè§„åˆ™ï¼‰
                if task is not None:
                    subdir_path = f"/{extracted_folder_name}"
                    auto_subdirs = task.get("_auto_extract_subdirs") or []
                    if subdir_path not in auto_subdirs:
                        auto_subdirs.append(subdir_path)
                        task["_auto_extract_subdirs"] = auto_subdirs
            else:
                print(f"  âŒ ç§»åŠ¨æ–‡ä»¶å¤¹å¤±è´¥: {move_result.get('message')}")
        else:
            # ä»…ä¿ç•™æ–‡ä»¶ï¼šå°†æ‰€æœ‰æ–‡ä»¶ç§»åŠ¨åˆ°ç›®æ ‡ç›®å½•ï¼ˆæ‰å¹³åŒ–ï¼‰
            for f in all_files:
                move_result = self.move([f["fid"]], target_pdir_fid)
                if move_result.get("code") == 0:
                    moved_files.append(f)
                else:
                    print(f"    âŒ {f['file_name']}: {move_result.get('message')}")
            
            # åˆ é™¤è§£å‹åçš„ç©ºæ–‡ä»¶å¤¹ï¼ˆä»æœ€æ·±å±‚å¼€å§‹åˆ é™¤ï¼‰
            for folder_fid in reversed(folders_to_delete):
                self.delete([folder_fid])
        
        # ç¬¬å…­æ­¥ï¼šæ ¹æ®æ¨¡å¼å¤„ç†åŸå‹ç¼©æ–‡ä»¶
        archive_deleted = False
        if delete_archive:
            # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿ä¹‹å‰çš„æ“ä½œå®Œæˆ
            time.sleep(0.5)
            fid_to_delete = str(archive_fid) if archive_fid is not None else None
            if fid_to_delete:
                delete_result = self.delete([fid_to_delete])
                if delete_result.get("code") == 0:
                    archive_deleted = True
                else:
                    error_msg = delete_result.get("message", "æœªçŸ¥é”™è¯¯")
                    print(f"  âš ï¸ åˆ é™¤å‹ç¼©æ–‡ä»¶å¤±è´¥: {error_msg}")
                    # é‡è¯•ï¼šåœ¨ç›®æ ‡ç›®å½•ä¸­æŒ‰æ–‡ä»¶åé‡æ–°æŸ¥æ‰¾å‹ç¼©åŒ…å¹¶åˆ é™¤ï¼ˆè§£å‹/ç§»åŠ¨å fid å¯èƒ½å˜åŒ–ï¼‰
                    time.sleep(1)
                    try:
                        current_list = self.ls_dir(target_pdir_fid)
                        for item in current_list:
                            if not item.get("dir", False) and item.get("file_name") == archive_name:
                                retry_result = self.delete([str(item["fid"])])
                                if retry_result.get("code") == 0:
                                    archive_deleted = True
                                break
                        if not archive_deleted and keep_structure and extracted_folder_name:
                            subdir_list = self.ls_dir(target_pdir_fid)
                            for d in subdir_list:
                                if d.get("dir") and d.get("file_name") == extracted_folder_name:
                                    inside = self.ls_dir(d["fid"])
                                    for item in inside:
                                        if not item.get("dir", False) and item.get("file_name") == archive_name:
                                            retry_result = self.delete([str(item["fid"])])
                                            if retry_result.get("code") == 0:
                                                archive_deleted = True
                                            break
                                    break
                    except Exception:
                        pass
                    if not archive_deleted:
                        print(f"  âŒ é‡è¯•åˆ é™¤ä»ç„¶å¤±è´¥")

        # è®°å½•æœ¬æ¬¡å·²è§£å‹çš„å‹ç¼©åŒ…æ–‡ä»¶åï¼Œä¾› do_rename_task æ ¹ç›®å½•è·³è¿‡å†æ¬¡è½¬å­˜ï¼ˆæ‰å¹³åŒ–ä¸å†™ _auto_extract_subdirsï¼Œéœ€å•ç‹¬æ ‡è®°ï¼‰
        if task is not None:
            extracted_names = task.get("_extracted_archive_names") or []
            if archive_name not in extracted_names:
                extracted_names = list(extracted_names) + [archive_name]
                task["_extracted_archive_names"] = extracted_names

        return {
            "success": True,
            "extracted_folder_name": extracted_folder_name,
            "extracted_folder_fid": extracted_folder_fid if keep_structure else None,
            "moved_files": moved_files,
            "total_files": len(all_files),
            "archive_deleted": archive_deleted,
            "delete_requested": delete_archive,
        }

    def download(self, fids):
        url = f"{self.BASE_URL}/1/clouddrive/file/download"
        querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
        payload = {"fids": fids}
        response = self._send_request("POST", url, json=payload, params=querystring)
        set_cookie = response.cookies.get_dict()
        cookie_str = "; ".join([f"{key}={value}" for key, value in set_cookie.items()])
        return response.json(), cookie_str

    def mkdir(self, dir_path):
        url = f"{self.BASE_URL}/1/clouddrive/file"
        querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
        payload = {
            "pdir_fid": "0",
            "file_name": "",
            "dir_path": dir_path,
            "dir_init_lock": False,
        }
        response = self._send_request(
            "POST", url, json=payload, params=querystring
        ).json()
        return response

    def mkdir_in_folder(self, parent_fid, folder_name):
        """åœ¨æŒ‡å®šçˆ¶ç›®å½•ä¸‹åˆ›å»ºæ–°æ–‡ä»¶å¤¹"""
        url = f"{self.BASE_URL}/1/clouddrive/file"
        querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
        payload = {
            "pdir_fid": parent_fid,
            "file_name": folder_name,
            "dir_path": "",
            "dir_init_lock": False,
        }
        response = self._send_request(
            "POST", url, json=payload, params=querystring
        ).json()
        return response

    def rename(self, fid, file_name):
        url = f"{self.BASE_URL}/1/clouddrive/file/rename"
        querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
        payload = {"fid": fid, "file_name": file_name}
        response = self._send_request(
            "POST", url, json=payload, params=querystring
        ).json()
        return response

    def delete(self, filelist):
        url = f"{self.BASE_URL}/1/clouddrive/file/delete"
        querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
        payload = {"action_type": 2, "filelist": filelist, "exclude_fids": []}
        response = self._send_request(
            "POST", url, json=payload, params=querystring
        ).json()
        return response

    def move(self, filelist, to_pdir_fid):
        """ç§»åŠ¨æ–‡ä»¶åˆ°æŒ‡å®šç›®å½•"""
        url = f"{self.BASE_URL}/1/clouddrive/file/move"
        querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
        payload = {
            "action_type": 2,
            "filelist": filelist,
            "to_pdir_fid": to_pdir_fid,
            "exclude_fids": []
        }
        response = self._send_request(
            "POST", url, json=payload, params=querystring
        ).json()
        return response

    def recycle_list(self, page=1, size=30):
        url = f"{self.BASE_URL}/1/clouddrive/file/recycle/list"
        querystring = {
            "_page": page,
            "_size": size,
            "pr": "ucpro",
            "fr": "pc",
            "uc_param_str": "",
        }
        response = self._send_request("GET", url, params=querystring).json()
        return response["data"]["list"]

    def recycle_remove(self, record_list):
        url = f"{self.BASE_URL}/1/clouddrive/file/recycle/remove"
        querystring = {"uc_param_str": "", "fr": "pc", "pr": "ucpro"}
        payload = {
            "select_mode": 2,
            "record_list": record_list,
        }
        response = self._send_request(
            "POST", url, json=payload, params=querystring
        ).json()
        return response

    # â†‘ è¯·æ±‚å‡½æ•°
    # â†“ æ“ä½œå‡½æ•°

    # é­”æ³•æ­£åˆ™åŒ¹é…
    def magic_regex_func(self, pattern, replace, taskname=None, magic_regex={}):
        magic_regex = magic_regex or CONFIG_DATA.get("magic_regex") or MAGIC_REGEX
        keyword = pattern
        if keyword in magic_regex:
            pattern = magic_regex[keyword]["pattern"]
            if replace == "":
                replace = magic_regex[keyword]["replace"]
        if taskname:
            replace = replace.replace("$TASKNAME", taskname)
        return pattern, replace

    # def get_id_from_url(self, url):
    #     url = url.replace("https://pan.quark.cn/s/", "")
    #     pattern = r"(\w+)(\?pwd=(\w+))?(#/list/share.*/(\w+))?"
    #     match = re.search(pattern, url)
    #     if match:
    #         pwd_id = match.group(1)
    #         passcode = match.group(3) if match.group(3) else ""
    #         pdir_fid = match.group(5) if match.group(5) else 0
    #         return pwd_id, passcode, pdir_fid
    #     else:
    #         return None

    def extract_url(self, url):
        # pwd_id
        match_id = re.search(r"/s/(\w+)", url)
        pwd_id = match_id.group(1) if match_id else None
        # passcode
        match_pwd = re.search(r"pwd=(\w+)", url)
        passcode = match_pwd.group(1) if match_pwd else ""
        # path: fid-name
        paths = []
        matches = re.findall(r"/(\w{32})-?([^/]+)?", url)
        for match in matches:
            fid = match[0]
            name = urllib.parse.unquote(match[1])
            paths.append({"fid": fid, "name": name})
        pdir_fid = paths[-1]["fid"] if matches else 0
        return pwd_id, passcode, pdir_fid, paths

    def update_savepath_fid(self, tasklist):
        dir_paths = [
            re.sub(r"/{2,}", "/", f"/{item['savepath']}")
            for item in tasklist
            if not item.get("enddate")
            or (
                datetime.now().date()
                <= datetime.strptime(item["enddate"], "%Y-%m-%d").date()
            )
        ]
        # å»æ‰æ¯ä¸ªè·¯å¾„å¼€å¤´çš„æ–œæ ï¼Œç¡®ä¿æ ¼å¼ä¸€è‡´
        dir_paths = [path.lstrip('/') for path in dir_paths]
        
        if not dir_paths:
            return False
            
        # é‡æ–°æ·»åŠ æ–œæ å‰ç¼€ï¼Œç¡®ä¿æ ¼å¼ä¸€è‡´
        dir_paths = [f"/{path}" for path in dir_paths]
        
        dir_paths_exist_arr = self.get_fids(dir_paths)
        dir_paths_exist = [item["file_path"] for item in dir_paths_exist_arr]
        # æ¯”è¾ƒåˆ›å»ºä¸å­˜åœ¨çš„
        dir_paths_unexist = list(set(dir_paths) - set(dir_paths_exist) - set(["/"]))
        for dir_path in dir_paths_unexist:
            mkdir_return = self.mkdir(dir_path)
            if mkdir_return["code"] == 0:
                new_dir = mkdir_return["data"]
                dir_paths_exist_arr.append(
                    {"file_path": dir_path, "fid": new_dir["fid"]}
                )
                # print(f"åˆ›å»ºæ–‡ä»¶å¤¹ï¼š{dir_path}")
            else:
                # print(f"åˆ›å»ºæ–‡ä»¶å¤¹ï¼š{dir_path} å¤±è´¥, {mkdir_return['message']}")
                pass
        # å‚¨å­˜ç›®æ ‡ç›®å½•çš„fid
        for dir_path in dir_paths_exist_arr:
            self.savepath_fid[dir_path["file_path"]] = dir_path["fid"]
        # print(dir_paths_exist_arr)

    def do_save_check(self, shareurl, savepath):
        try:
            pwd_id, passcode, pdir_fid, _ = self.extract_url(shareurl)
            _, stoken = self.get_stoken(pwd_id, passcode)
            share_file_list = self.get_detail(pwd_id, stoken, pdir_fid)["list"]
            fid_list = [item["fid"] for item in share_file_list]
            fid_token_list = [item["share_fid_token"] for item in share_file_list]
            file_name_list = [item["file_name"] for item in share_file_list]
            if not fid_list:
                return
            get_fids = self.get_fids([savepath])
            to_pdir_fid = (
                get_fids[0]["fid"] if get_fids else self.mkdir(savepath)["data"]["fid"]
            )
            save_file = self.save_file(
                fid_list, fid_token_list, to_pdir_fid, pwd_id, stoken
            )
            if save_file["code"] == 41017:
                return
            elif save_file["code"] == 0:
                dir_file_list = self.ls_dir(to_pdir_fid)
                del_list = [
                    item["fid"]
                    for item in dir_file_list
                    if (item["file_name"] in file_name_list)
                    and ((datetime.now().timestamp() - item["created_at"]) < 60)
                ]
                if del_list:
                    self.delete(del_list)
                    recycle_list = self.recycle_list()
                    record_id_list = [
                        item["record_id"]
                        for item in recycle_list
                        if item["fid"] in del_list
                    ]
                    self.recycle_remove(record_id_list)
                return save_file
            else:
                return False
        except Exception as e:
            print(f"è½¬å­˜æµ‹è¯•å¤±è´¥: {str(e)}")

    def save_transfer_record(self, task, file_info, renamed_to=""):
        """ä¿å­˜è½¬å­˜è®°å½•åˆ°æ•°æ®åº“
        
        Args:
            task: ä»»åŠ¡ä¿¡æ¯
            file_info: æ–‡ä»¶ä¿¡æ¯
            renamed_to: é‡å‘½ååçš„åç§°
        """
        try:
            # åˆå§‹åŒ–æ•°æ®åº“
            db = RecordDB()
            
            # æå–æ–‡ä»¶ä¿¡æ¯
            original_name = file_info.get("file_name", "")
            file_size = file_info.get("size", 0)
            
            # å¤„ç†ä¿®æ”¹æ—¥æœŸ
            # æ£€æŸ¥updated_atæ˜¯å¦ä¸ºæœªæ¥æ—¥æœŸ
            current_time = int(time.time())
            modify_date = file_info.get("updated_at", current_time)
            
            # å¦‚æœä¿®æ”¹æ—¥æœŸæ˜¯æ¯«ç§’çº§æ—¶é—´æˆ³ï¼Œè½¬æ¢ä¸ºç§’çº§
            if isinstance(modify_date, int) and modify_date > 9999999999:
                modify_date = int(modify_date / 1000)
                
            # ç¡®ä¿ä¿®æ”¹æ—¥æœŸæ˜¯åˆç†çš„å€¼ï¼ˆä¸æ˜¯æœªæ¥æ—¥æœŸï¼‰
            if modify_date > current_time:
                # ä½¿ç”¨å½“å‰æ—¶é—´ä½œä¸ºå¤‡ç”¨å€¼
                modify_date = current_time
                
            file_id = file_info.get("fid", "")
            file_type = os.path.splitext(original_name)[1].lower().lstrip(".") if original_name else ""
            
            # å¦‚æœæ²¡æœ‰é‡å‘½åä¿¡æ¯ï¼Œä½¿ç”¨åŸå§‹åç§°
            if not renamed_to:
                renamed_to = original_name
            
            # æå–è§†é¢‘ä¿¡æ¯ï¼ˆæ—¶é•¿å’Œåˆ†è¾¨ç‡ï¼‰
            duration = ""
            resolution = ""
            # å¯¹å¸¸è§è§†é¢‘æ ¼å¼æ·»åŠ æ—¶é•¿å’Œåˆ†è¾¨ç‡ä¿¡æ¯
            video_exts = ["mp4", "mkv", "avi", "mov", "wmv", "flv", "m4v", "webm"]
            if file_type in video_exts:
                # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œå¯ä»¥é€šè¿‡åª’ä½“å¤„ç†åº“æå–æ—¶é•¿å’Œåˆ†è¾¨ç‡
                # ç›®å‰åªæ˜¯æ·»åŠ å ä½ç¬¦ï¼Œæœªæ¥å¯ä»¥æ‰©å±•åŠŸèƒ½
                pass
            
            # è·å–ä¿å­˜è·¯å¾„
            save_path = task.get("savepath", "")
            # å¦‚æœfile_infoä¸­æœ‰å­ç›®å½•è·¯å¾„ä¿¡æ¯ï¼Œåˆ™æ‹¼æ¥å®Œæ•´è·¯å¾„
            subdir_path = file_info.get("subdir_path", "")
            if subdir_path:
                # ç¡®ä¿è·¯å¾„æ ¼å¼æ­£ç¡®ï¼Œé¿å…åŒæ–œæ 
                if save_path.endswith('/') and subdir_path.startswith('/'):
                    save_path = save_path + subdir_path[1:]
                elif not save_path.endswith('/') and not subdir_path.startswith('/'):
                    save_path = save_path + '/' + subdir_path
                else:
                    save_path = save_path + subdir_path
            
            # æ·»åŠ è®°å½•åˆ°æ•°æ®åº“
            db.add_record(
                task_name=task.get("taskname", ""),
                original_name=original_name,
                renamed_to=renamed_to,
                file_size=file_size,
                modify_date=modify_date,
                duration=duration,
                resolution=resolution,
                file_id=file_id,
                file_type=file_type,
                save_path=save_path
            )
            # è°ƒç”¨åç«¯æ¥å£è§¦å‘è¯¥ä»»åŠ¡çš„æŒ‡æ ‡å®æ—¶åŒæ­¥ï¼ˆè¿›åº¦çƒ­æ›´æ–°ï¼‰
            # ä¿®å¤ï¼šä¸å†å†™æ­»ç«¯å£ 9898ï¼Œè€Œæ˜¯ä¼˜å…ˆä½¿ç”¨ä¸ Flask ç›¸åŒçš„ PORT ç¯å¢ƒå˜é‡ï¼Œ
            # åŒæ—¶æ”¯æŒé€šè¿‡ CALENDAR_SERVER_BASE è¦†ç›–å®Œæ•´æœåŠ¡åœ°å€ï¼Œé¿å…ç«¯å£/åœ°å€ä¸ä¸€è‡´å¯¼è‡´çƒ­æ›´æ–°å¤±æ•ˆ
            try:
                _tname = task.get("taskname", "")
                if _tname:
                    port = os.environ.get("PORT", "5005")
                    base_url = os.environ.get("CALENDAR_SERVER_BASE", f"http://127.0.0.1:{port}")
                    requests.post(
                        f"{base_url}/api/calendar/metrics/sync_task",
                        json={"task_name": _tname},
                        timeout=1
                    )
            except Exception:
                # ä»»ä½•é”™è¯¯éƒ½ä¸å½±å“ä¸»æµç¨‹ï¼Œåªå½±å“çƒ­æ›´æ–°åŠæ—¶æ€§
                pass
            
            # å…³é—­æ•°æ®åº“è¿æ¥
            db.close()
            
            # è§¦å‘SSEé€šçŸ¥ï¼Œè®©å‰ç«¯å®æ—¶æ„ŸçŸ¥è½¬å­˜è®°å½•å˜åŒ–
            notify_calendar_changed_safe('transfer_record_created')
                
        except Exception as e:
            print(f"ä¿å­˜è½¬å­˜è®°å½•å¤±è´¥: {e}")
    
    # æ·»åŠ ä¸€ä¸ªæ–°çš„å‡½æ•°ï¼ŒåŠŸèƒ½ä¸save_transfer_recordç›¸åŒï¼Œä½†åç§°æ›´æ¸…æ™°è¡¨ç¤ºå…¶ç”¨é€”
    def create_transfer_record(self, task, file_info, renamed_to=""):
        """åˆ›å»ºæ–°çš„è½¬å­˜è®°å½•
        
        æ­¤å‡½æ•°ä¸save_transfer_recordåŠŸèƒ½å®Œå…¨ç›¸åŒï¼Œä½†åç§°æ›´æ˜ç¡®åœ°è¡¨è¾¾äº†å…¶ç›®çš„
        - ç”¨äºåœ¨æ–‡ä»¶åˆæ¬¡è½¬å­˜æ—¶åˆ›å»ºè®°å½•
        
        Args:
            task: ä»»åŠ¡ä¿¡æ¯
            file_info: æ–‡ä»¶ä¿¡æ¯
            renamed_to: é‡å‘½ååçš„åç§°ï¼ˆå¦‚æœæœ‰ï¼‰
        """
        self.save_transfer_record(task, file_info, renamed_to)

    def update_transfer_record(self, task, file_info, renamed_to):
        """æ›´æ–°è½¬å­˜è®°å½•çš„é‡å‘½åä¿¡æ¯
        
        Args:
            task: ä»»åŠ¡ä¿¡æ¯
            file_info: æ–‡ä»¶ä¿¡æ¯
            renamed_to: é‡å‘½ååçš„åç§°
        """
        try:
            # åˆå§‹åŒ–æ•°æ®åº“
            db = RecordDB()
            
            # æå–ä¿¡æ¯ç”¨äºæŸ¥æ‰¾è®°å½•
            original_name = file_info.get("file_name", "")
            file_id = file_info.get("fid", "")
            task_name = task.get("taskname", "")
            
            # è·å–ä¿å­˜è·¯å¾„
            save_path = task.get("savepath", "")
            # å¦‚æœfile_infoä¸­æœ‰å­ç›®å½•è·¯å¾„ä¿¡æ¯ï¼Œåˆ™æ‹¼æ¥å®Œæ•´è·¯å¾„
            subdir_path = file_info.get("subdir_path", "")
            if subdir_path:
                # ç¡®ä¿è·¯å¾„æ ¼å¼æ­£ç¡®ï¼Œé¿å…åŒæ–œæ 
                if save_path.endswith('/') and subdir_path.startswith('/'):
                    save_path = save_path + subdir_path[1:]
                elif not save_path.endswith('/') and not subdir_path.startswith('/'):
                    save_path = save_path + '/' + subdir_path
                else:
                    save_path = save_path + subdir_path
            
            # æ›´æ–°è®°å½•
            updated = db.update_renamed_to(
                file_id=file_id,
                original_name=original_name,
                renamed_to=renamed_to,
                task_name=task_name,
                save_path=save_path
            )
            
            # å…³é—­æ•°æ®åº“è¿æ¥
            db.close()
            
            # å¦‚æœæ›´æ–°æˆåŠŸï¼Œè§¦å‘SSEé€šçŸ¥
            if updated > 0:
                notify_calendar_changed_safe('transfer_record_updated')
            
            return updated > 0
        except Exception as e:
            print(f"æ›´æ–°è½¬å­˜è®°å½•å¤±è´¥: {e}")
            return False
    
    # æ·»åŠ ä¸€ä¸ªä¸“é—¨ä»é‡å‘½åæ—¥å¿—æ›´æ–°è®°å½•çš„æ–¹æ³•
    def update_transfer_record_from_log(self, task, rename_log, actual_file_names=None):
        """ä»é‡å‘½åæ—¥å¿—ä¸­æå–ä¿¡æ¯å¹¶æ›´æ–°è®°å½•

        Args:
            task: ä»»åŠ¡ä¿¡æ¯
            rename_log: é‡å‘½åæ—¥å¿—ï¼Œæ ¼å¼ä¸º "é‡å‘½å: æ—§å â†’ æ–°å"
            actual_file_names: å®é™…æ–‡ä»¶åæ˜ å°„å­—å…¸ï¼Œç”¨äºä¿®æ­£æ˜¾ç¤ºçš„æ–‡ä»¶å
        """
        try:
            # ä½¿ç”¨å­—ç¬¦ä¸²åˆ†å‰²æ–¹æ³•æå–æ–‡ä»¶åï¼Œæ›´å¯é åœ°è·å–å®Œæ•´æ–‡ä»¶å
            if "é‡å‘½å:" not in rename_log or " â†’ " not in rename_log:
                return False

            # å…ˆåˆ†å‰²å‡º"é‡å‘½å:"åé¢çš„éƒ¨åˆ†
            parts = rename_log.split("é‡å‘½å:", 1)[1].strip()
            # å†æŒ‰ç®­å¤´åˆ†å‰²
            if " â†’ " not in parts:
                return False

            old_name, expected_new_name = parts.split(" â†’ ", 1)

            # å¦‚æœæ–°åç§°åŒ…å«"å¤±è´¥"ï¼Œåˆ™æ˜¯å¤±è´¥çš„é‡å‘½åï¼Œè·³è¿‡
            if "å¤±è´¥" in expected_new_name:
                return False

            # å¤„ç†å¯èƒ½çš„æˆªæ–­æ ‡è®°ï¼Œåªä¿ç•™å®é™…æ–‡ä»¶åéƒ¨åˆ†
            # æ³¨æ„ï¼šåªæœ‰æ˜ç¡®æ˜¯å¤±è´¥æ¶ˆæ¯æ‰åº”è¯¥æˆªæ–­
            if " å¤±è´¥ï¼Œ" in expected_new_name:
                expected_new_name = expected_new_name.split(" å¤±è´¥ï¼Œ")[0]

            # å»é™¤é¦–å°¾ç©ºæ ¼
            old_name = old_name.strip()
            expected_new_name = expected_new_name.strip()

            # ç¡®ä¿æå–åˆ°çš„æ˜¯å®Œæ•´æ–‡ä»¶å
            if not old_name or not expected_new_name:
                return False

            # è·å–å®é™…çš„æ–‡ä»¶åï¼ˆå¦‚æœæä¾›äº†æ˜ å°„ï¼‰
            actual_new_name = expected_new_name
            if actual_file_names and old_name in actual_file_names:
                actual_new_name = actual_file_names[old_name]

            # åˆå§‹åŒ–æ•°æ®åº“
            db = RecordDB()

            # ä½¿ç”¨åŸæ–‡ä»¶åå’Œä»»åŠ¡åæŸ¥æ‰¾è®°å½•
            task_name = task.get("taskname", "")

            # è·å–ä¿å­˜è·¯å¾„
            save_path = task.get("savepath", "")
            # æ³¨æ„ï¼šä»æ—¥å¿—ä¸­æ— æ³•è·å–å­ç›®å½•ä¿¡æ¯ï¼Œåªèƒ½ä½¿ç”¨ä»»åŠ¡çš„ä¸»ä¿å­˜è·¯å¾„

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨äºè®°å½•ä¸­
            # å…ˆæŸ¥è¯¢æ˜¯å¦æœ‰åŒ¹é…çš„è®°å½•
            cursor = db.conn.cursor()
            query = "SELECT file_id FROM transfer_records WHERE original_name = ? AND task_name = ? AND save_path = ?"
            cursor.execute(query, (old_name, task_name, save_path))
            result = cursor.fetchone()

            # å¦‚æœæ‰¾åˆ°äº†åŒ¹é…çš„è®°å½•ï¼Œä½¿ç”¨file_idè¿›è¡Œæ›´æ–°
            file_id = result[0] if result else ""

            # æ›´æ–°è®°å½•ï¼Œä½¿ç”¨å®é™…çš„æ–‡ä»¶å
            if file_id:
                # ä½¿ç”¨file_idæ›´æ–°
                updated = db.update_renamed_to(
                    file_id=file_id,
                    original_name="",  # ä¸ä½¿ç”¨åŸæ–‡ä»¶åï¼Œå› ä¸ºå·²æœ‰file_id
                    renamed_to=actual_new_name,  # ä½¿ç”¨å®é™…çš„æ–‡ä»¶å
                    task_name=task_name,
                    save_path=save_path
                )
            else:
                # ä½¿ç”¨åŸæ–‡ä»¶åæ›´æ–°
                updated = db.update_renamed_to(
                    file_id="",  # ä¸ä½¿ç”¨file_idæŸ¥è¯¢ï¼Œå› ä¸ºåœ¨æ—¥å¿—ä¸­æ— æ³•è·å–
                    original_name=old_name,
                    renamed_to=actual_new_name,  # ä½¿ç”¨å®é™…çš„æ–‡ä»¶å
                    task_name=task_name,
                    save_path=save_path
                )

            # å…³é—­æ•°æ®åº“è¿æ¥
            db.close()

            return updated > 0
        except Exception as e:
            print(f"æ ¹æ®æ—¥å¿—æ›´æ–°è½¬å­˜è®°å½•å¤±è´¥: {e}")
            return False
    
    # æ‰¹é‡å¤„ç†é‡å‘½åæ—¥å¿—
    def process_rename_logs(self, task, rename_logs):
        """å¤„ç†é‡å‘½åæ—¥å¿—åˆ—è¡¨ï¼Œæ›´æ–°æ•°æ®åº“è®°å½•

        Args:
            task: ä»»åŠ¡ä¿¡æ¯
            rename_logs: é‡å‘½åæ—¥å¿—åˆ—è¡¨
        """
        # è·å–å®é™…çš„æ–‡ä»¶åæ˜ å°„
        actual_file_names = self.get_actual_file_names_from_directory(task, rename_logs)

        for log in rename_logs:
            if "é‡å‘½å:" in log and "â†’" in log and "å¤±è´¥" not in log:
                self.update_transfer_record_from_log(task, log, actual_file_names)

    def get_actual_file_names_from_directory(self, task, rename_logs):
        """ä»ç›®å½•ä¸­è·å–å®é™…çš„æ–‡ä»¶åï¼Œç”¨äºä¿®æ­£è½¬å­˜è®°å½•å’Œæ—¥å¿—æ˜¾ç¤º

        Args:
            task: ä»»åŠ¡ä¿¡æ¯
            rename_logs: é‡å‘½åæ—¥å¿—åˆ—è¡¨

        Returns:
            dict: åŸæ–‡ä»¶ååˆ°å®é™…æ–‡ä»¶åçš„æ˜ å°„
        """
        try:
            # è·å–ä¿å­˜è·¯å¾„
            savepath = re.sub(r"/{2,}", "/", f"/{task['savepath']}")

            # è·å–å½“å‰ç›®å½•çš„æ–‡ä»¶åˆ—è¡¨
            if hasattr(self, 'savepath_fid') and self.savepath_fid.get(savepath):
                dir_file_list = self.ls_dir(self.savepath_fid[savepath])
            else:
                return {}

            # ä»é‡å‘½åæ—¥å¿—ä¸­æå–é¢„æœŸçš„é‡å‘½åæ˜ å°„ï¼ˆåŒ…æ‹¬å¤±è´¥çš„é‡å‘½åï¼‰
            expected_renames = {}
            for log in rename_logs:
                if "é‡å‘½å:" in log and " â†’ " in log:
                    parts = log.split("é‡å‘½å:", 1)[1].strip()
                    if " â†’ " in parts:
                        old_name, new_name = parts.split(" â†’ ", 1)
                        # å¤„ç†å¯èƒ½çš„å¤±è´¥ä¿¡æ¯
                        if " å¤±è´¥ï¼Œ" in new_name:
                            new_name = new_name.split(" å¤±è´¥ï¼Œ")[0]
                        old_name = old_name.strip()
                        new_name = new_name.strip()
                        expected_renames[old_name] = new_name

            # è·å–ç›®å½•ä¸­å®é™…å­˜åœ¨çš„æ–‡ä»¶å
            actual_files = [f["file_name"] for f in dir_file_list if not f["dir"]]

            # åˆ›å»ºå®é™…æ–‡ä»¶åæ˜ å°„
            actual_renames = {}

            # å¯¹äºæ¯ä¸ªé¢„æœŸçš„é‡å‘½åï¼Œæ£€æŸ¥å®é™…æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            for old_name, expected_new_name in expected_renames.items():
                if expected_new_name in actual_files:
                    # é¢„æœŸçš„é‡å‘½åæˆåŠŸäº†
                    actual_renames[old_name] = expected_new_name
                elif old_name in actual_files:
                    # é‡å‘½åå¤±è´¥ï¼Œæ–‡ä»¶ä¿æŒåŸå
                    actual_renames[old_name] = old_name
                else:
                    # å°è¯•æ¨¡ç³ŠåŒ¹é…ï¼Œå¯èƒ½æ–‡ä»¶åæœ‰ç»†å¾®å·®å¼‚
                    for actual_file in actual_files:
                        # ç®€å•çš„ç›¸ä¼¼åº¦æ£€æŸ¥ï¼šå¦‚æœæ–‡ä»¶ååŒ…å«é¢„æœŸåç§°çš„ä¸»è¦éƒ¨åˆ†
                        if (len(expected_new_name) > 10 and
                            expected_new_name[:10] in actual_file and
                            actual_file not in actual_renames.values()):
                            actual_renames[old_name] = actual_file
                            break
                    else:
                        # å¦‚æœæ‰¾ä¸åˆ°åŒ¹é…ï¼Œä½¿ç”¨é¢„æœŸåç§°ï¼ˆå¯èƒ½æ–‡ä»¶å·²è¢«åˆ é™¤æˆ–ç§»åŠ¨ï¼‰
                        actual_renames[old_name] = expected_new_name

            return actual_renames

        except Exception as e:
            print(f"è·å–å®é™…æ–‡ä»¶åå¤±è´¥: {e}")
            return {}
    
    def check_file_exists_in_records(self, file_id, task=None):
        """æ£€æŸ¥æ–‡ä»¶IDæ˜¯å¦å­˜åœ¨äºè½¬å­˜è®°å½•ä¸­
        
        Args:
            file_id: è¦æ£€æŸ¥çš„æ–‡ä»¶ID
            task: å¯é€‰çš„ä»»åŠ¡ä¿¡æ¯ï¼Œç”¨äºè¿›ä¸€æ­¥ç­›é€‰
            
        Returns:
            bool: æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨äºè®°å½•ä¸­
        """
        if not file_id:
            return False
            
        try:
            # åˆå§‹åŒ–æ•°æ®åº“
            db = RecordDB()
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            conditions = ["file_id = ?"]
            params = [file_id]
            
            # å¦‚æœæä¾›äº†ä»»åŠ¡ä¿¡æ¯ï¼Œæ·»åŠ ä»»åŠ¡åç§°æ¡ä»¶
            if task and task.get("taskname"):
                conditions.append("task_name = ?")
                params.append(task.get("taskname"))
            
            # æ„å»ºWHEREå­å¥
            where_clause = " AND ".join(conditions)
            
            # æŸ¥è¯¢æ˜¯å¦å­˜åœ¨åŒ¹é…çš„è®°å½•
            cursor = db.conn.cursor()
            query = f"SELECT COUNT(*) FROM transfer_records WHERE {where_clause}"
            cursor.execute(query, params)
            count = cursor.fetchone()[0]
            
            # å…³é—­æ•°æ®åº“è¿æ¥
            db.close()
            
            return count > 0
        except Exception as e:
            print(f"æ£€æŸ¥æ–‡ä»¶è®°å½•æ—¶å‡ºé”™: {e}")
            return False

    def do_save_task(self, task):
        # åˆ¤æ–­èµ„æºå¤±æ•ˆè®°å½•
        if task.get("shareurl_ban"):
            add_notify(f"â—ã€Š{task['taskname']}ã€‹åˆ†äº«èµ„æºå·²å¤±æ•ˆ: {task['shareurl_ban']}\n")
            return
            
        # æ ‡å‡†åŒ–ä¿å­˜è·¯å¾„ï¼Œå»æ‰å¯èƒ½å­˜åœ¨çš„é¦–ä½æ–œæ ï¼Œç„¶åé‡æ–°æ·»åŠ 
        savepath = task["savepath"].lstrip('/')
        task["savepath"] = savepath  # æ›´æ–°ä»»åŠ¡ä¸­çš„è·¯å¾„ï¼Œç¡®ä¿åç»­å¤„ç†ä¸€è‡´
            
        # æå–é“¾æ¥å‚æ•°
        pwd_id, passcode, pdir_fid, paths = self.extract_url(task["shareurl"])
        if not pwd_id:
            task["shareurl_ban"] = f"æå–é“¾æ¥å‚æ•°å¤±è´¥ï¼Œè¯·æ£€æŸ¥åˆ†äº«é“¾æ¥æ˜¯å¦æœ‰æ•ˆ"
            print(f"æå–é“¾æ¥å‚æ•°å¤±è´¥ï¼Œè¯·æ£€æŸ¥åˆ†äº«é“¾æ¥æ˜¯å¦æœ‰æ•ˆ")
            return
        # è·å–åˆ†äº«è¯¦æƒ…
        is_sharing, stoken = self.get_stoken(pwd_id, passcode)
        if not is_sharing:
            # å¦‚æœæ˜¯å¯æ¢å¤é”™è¯¯ï¼ˆç½‘ç»œ/ä¸´æ—¶ï¼‰ï¼Œä¸è¦è®¾ç½®ä¸ºå¤±æ•ˆèµ„æº
            try:
                error_text = str(stoken or "")
                if self.is_recoverable_error(error_text):
                    print(f"åˆ†äº«è¯¦æƒ…è·å–å¤±è´¥ï¼ˆç½‘ç»œå¼‚å¸¸ï¼‰: {error_text}")
                    return  # ç›´æ¥è¿”å›ï¼Œä¸è®¾ç½® shareurl_ban
            except Exception:
                pass
            # éå¯æ¢å¤é”™è¯¯ï¼ŒæŒ‰å¤±æ•ˆå¤„ç†
            task["shareurl_ban"] = stoken
            add_notify(f"â—ã€Š{task['taskname']}ã€‹åˆ†äº«è¯¦æƒ…è·å–å¤±è´¥: {stoken}\n")
            return
        share_detail = self.get_detail(pwd_id, stoken, pdir_fid, _fetch_share=1)
        # å¦‚æœè·å–è¯¦æƒ…è¿”å›é”™è¯¯ï¼ŒæŒ‰å¯æ¢å¤æ€§åˆ¤æ–­
        if isinstance(share_detail, dict) and share_detail.get("error"):
            error_text = str(share_detail.get("error") or "")
            if self.is_recoverable_error(error_text):
                print(f"è·å–åˆ†äº«è¯¦æƒ…å¤±è´¥ï¼ˆç½‘ç»œå¼‚å¸¸ï¼‰: {error_text}")
                return  # ç›´æ¥è¿”å›ï¼Œä¸è®¾ç½® shareurl_ban
            else:
                task["shareurl_ban"] = self.format_unrecoverable_error(error_text) if hasattr(self, 'format_unrecoverable_error') else error_text
                add_notify(f"â—ã€Š{task['taskname']}ã€‹è·å–åˆ†äº«è¯¦æƒ…å¤±è´¥: {task['shareurl_ban']}\n")
                return
        # è·å–ä¿å­˜è·¯å¾„fid
        savepath = task["savepath"]
        if not self.savepath_fid.get(savepath):
            # æ£€æŸ¥è§„èŒƒåŒ–è·¯å¾„æ˜¯å¦å·²åœ¨å­—å…¸ä¸­
            norm_savepath = re.sub(r"/{2,}", "/", f"/{savepath}")
            if norm_savepath != savepath and self.savepath_fid.get(norm_savepath):
                self.savepath_fid[savepath] = self.savepath_fid[norm_savepath]
            else:
                savepath_fids = self.get_fids([savepath])
                if not savepath_fids:
                    # print(f"ä¿å­˜è·¯å¾„ä¸å­˜åœ¨ï¼Œå‡†å¤‡æ–°å»ºï¼š{savepath}")
                    mkdir_result = self.mkdir(savepath)
                    if mkdir_result["code"] == 0:
                        self.savepath_fid[savepath] = mkdir_result["data"]["fid"]
                        # print(f"ä¿å­˜è·¯å¾„æ–°å»ºæˆåŠŸï¼š{savepath}")
                    else:
                        # print(f"ä¿å­˜è·¯å¾„æ–°å»ºå¤±è´¥ï¼š{mkdir_result['message']}")
                        return
                else:
                    # è·¯å¾„å·²å­˜åœ¨ï¼Œç›´æ¥è®¾ç½®fid
                    self.savepath_fid[savepath] = savepath_fids[0]["fid"]

        # æ”¯æŒé¡ºåºå‘½åæ¨¡å¼
        if task.get("use_sequence_naming") and task.get("sequence_naming"):
            # é¡ºåºå‘½åæ¨¡å¼ä¸‹å·²ç»åœ¨do_saveä¸­æ‰“å°äº†é¡ºåºå‘½åä¿¡æ¯ï¼Œè¿™é‡Œä¸å†é‡å¤æ‰“å°
            # è®¾ç½®æ­£åˆ™æ¨¡å¼ä¸ºç©º
            task["regex_pattern"] = None
            # æ„å»ºé¡ºåºå‘½åçš„æ­£åˆ™è¡¨è¾¾å¼
            sequence_pattern = task["sequence_naming"]
            # å°†{}æ›¿æ¢ä¸º(\d+)ç”¨äºåŒ¹é…
            if sequence_pattern == "{}":
                # å¯¹äºå•ç‹¬çš„{}ï¼Œä½¿ç”¨ç‰¹æ®ŠåŒ¹é…
                regex_pattern = "(\\d+)"
            else:
                regex_pattern = re.escape(sequence_pattern).replace('\\{\\}', '(\\d+)')
            task["regex_pattern"] = regex_pattern
        # æ”¯æŒå‰§é›†å‘½åæ¨¡å¼
        elif task.get("use_episode_naming") and task.get("episode_naming"):
            # å‰§é›†å‘½åæ¨¡å¼ä¸‹å·²ç»åœ¨do_saveä¸­æ‰“å°äº†å‰§é›†å‘½åä¿¡æ¯ï¼Œè¿™é‡Œä¸å†é‡å¤æ‰“å°
            # æ„å»ºå‰§é›†å‘½åçš„æ­£åˆ™è¡¨è¾¾å¼
            episode_pattern = task["episode_naming"]
            # å…ˆæ£€æŸ¥æ˜¯å¦åŒ…å«åˆæ³•çš„[]å­—ç¬¦
            if "[]" in episode_pattern:
                # å¯¹äºæ‰€æœ‰åŒ…å«[]çš„æ¨¡å¼ï¼Œä½¿ç”¨å®Œæ•´çš„å‰§é›†å·è¯†åˆ«è§„åˆ™
                regex_pattern = "SPECIAL_EPISODE_PATTERN"  # è¿™ä¸ªæ ‡è®°åç»­ç”¨äºç‰¹æ®Šå¤„ç†
                task["use_complex_episode_extraction"] = True  # æ·»åŠ ä¸€ä¸ªæ ‡è®°
                # ä¿å­˜åŸå§‹æ¨¡å¼ï¼Œç”¨äºç”Ÿæˆæ–°æ–‡ä»¶å
                task["original_episode_pattern"] = episode_pattern
            else:
                # å¦‚æœè¾“å…¥æ¨¡å¼ä¸åŒ…å«[]ï¼Œåˆ™ä½¿ç”¨ç®€å•åŒ¹é…æ¨¡å¼ï¼Œé¿å…æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯
                regex_pattern = "^" + re.escape(episode_pattern) + "(\\d+)$"

            task["regex_pattern"] = regex_pattern
        else:
            # æ­£åˆ™å‘½åæ¨¡å¼
            pattern, replace = self.magic_regex_func(
                task.get("pattern", ""), task.get("replace", ""), task["taskname"]
            )
            # æ³¨é‡Šæ‰è¿™é‡Œçš„æ­£åˆ™è¡¨è¾¾å¼æ‰“å°ï¼Œå› ä¸ºåœ¨do_saveå‡½æ•°ä¸­å·²ç»æ‰“å°äº†
            # åªæœ‰åœ¨éé­”æ³•å˜é‡æƒ…å†µä¸‹æ‰æ˜¾ç¤ºå±•å¼€åçš„æ­£åˆ™è¡¨è¾¾å¼
            # å¯¹äºé­”æ³•å˜é‡($TVç­‰)ï¼Œæ˜¾ç¤ºåŸå§‹è¾“å…¥
            # if pattern and task.get("pattern") and task.get("pattern") not in CONFIG_DATA.get("magic_regex", MAGIC_REGEX):
            #     print(f"æ­£åˆ™åŒ¹é…: {pattern}")
            #     print(f"æ­£åˆ™æ›¿æ¢: {replace}")
            
        # ä¿å­˜æ–‡ä»¶
        tree = self.dir_check_and_save(task, pwd_id, stoken, pdir_fid)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ–‡ä»¶è½¬å­˜
        if tree and tree.size() <= 1:  # åªæœ‰æ ¹èŠ‚ç‚¹æ„å‘³ç€æ²¡æœ‰æ–°æ–‡ä»¶
            return False
            
        return tree

    def dir_check_and_save(self, task, pwd_id, stoken, pdir_fid="", subdir_path="", parent_dir_info=None):
        tree = Tree()
        # è·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨
        share_file_list = self.get_detail(pwd_id, stoken, pdir_fid)["list"]
        # print("share_file_list: ", share_file_list)

        if not share_file_list:
            if subdir_path == "":
                task["shareurl_ban"] = "åˆ†äº«ä¸ºç©ºï¼Œæ–‡ä»¶å·²è¢«åˆ†äº«è€…åˆ é™¤"
                add_notify(f"âŒã€Š{task['taskname']}ã€‹: {task['shareurl_ban']}\n")
            return tree
        elif (
            len(share_file_list) == 1
            and share_file_list[0]["dir"]
            and subdir_path == ""
        ):  # ä»…æœ‰ä¸€ä¸ªæ–‡ä»¶å¤¹
            print("ğŸ§  è¯¥åˆ†äº«æ˜¯ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œè¯»å–æ–‡ä»¶å¤¹å†…åˆ—è¡¨")
            share_file_list = self.get_detail(
                pwd_id, stoken, share_file_list[0]["fid"]
            )["list"]
            
        # æ·»åŠ çˆ¶ç›®å½•ä¿¡æ¯ä¼ é€’ï¼Œç”¨äºç¡®å®šæ˜¯å¦åœ¨æ›´æ–°ç›®å½•å†…
        if parent_dir_info is None:
            parent_dir_info = {
                "in_update_dir": False,  # æ ‡è®°æ˜¯å¦åœ¨æ›´æ–°ç›®å½•å†…
                "update_dir_pattern": task.get("update_subdir", ""),  # ä¿å­˜æ›´æ–°ç›®å½•çš„æ­£åˆ™è¡¨è¾¾å¼
                "dir_path": []  # ä¿å­˜ç›®å½•è·¯å¾„
            }
            
        # å¯¹æ–‡ä»¶åˆ—è¡¨è¿›è¡Œæ’åºï¼Œä½¿ç”¨å…¨å±€æ–‡ä»¶æ’åºå‡½æ•°çš„å€’åºæ’åº
        # è¿™æ ·å¯ä»¥ç¡®ä¿èµ·å§‹æ–‡ä»¶è¿‡æ»¤é€»è¾‘æ­£ç¡®å·¥ä½œ
        share_file_list.sort(key=sort_file_by_name, reverse=True)

        # åº”ç”¨è¿‡æ»¤è¯è¿‡æ»¤
        if task.get("filterwords"):
            # è®°å½•è¿‡æ»¤å‰çš„æ–‡ä»¶æ€»æ•°ï¼ˆåŒ…æ‹¬æ–‡ä»¶å¤¹ï¼‰
            original_total_count = len(share_file_list)

            # ä½¿ç”¨é«˜çº§è¿‡æ»¤å‡½æ•°å¤„ç†ä¿ç•™è¯å’Œè¿‡æ»¤è¯
            share_file_list = advanced_filter_files(share_file_list, task["filterwords"])
            
            # æ‰“å°è¿‡æ»¤ä¿¡æ¯ï¼ˆæ ¼å¼ä¿æŒä¸å˜ï¼‰
            # è®¡ç®—å‰©ä½™æ–‡ä»¶æ•°
            remaining_count = len(share_file_list)
            
            # åŒºåˆ†ä¸åŒæ¨¡å¼çš„æ˜¾ç¤ºé€»è¾‘ï¼š
            # é¡ºåºå‘½åå’Œå‰§é›†å‘½åæ¨¡å¼ä¸å¤„ç†æ–‡ä»¶å¤¹ï¼Œåº”è¯¥æ’é™¤æ–‡ä»¶å¤¹è®¡æ•°
            # æ­£åˆ™å‘½åæ¨¡å¼ä¼šå¤„ç†æ–‡ä»¶å¤¹ï¼Œä½†åªå¤„ç†ç¬¦åˆæ­£åˆ™è¡¨è¾¾å¼çš„æ–‡ä»¶å¤¹
            if task.get("use_sequence_naming") or task.get("use_episode_naming"):
                # è®¡ç®—å‰©ä½™çš„å®é™…å¯ç”¨æ–‡ä»¶æ•°ï¼ˆæ’é™¤æ–‡ä»¶å¤¹ï¼‰
                remaining_usable_count = len([f for f in share_file_list if not f.get("dir", False)])
                print(f"ğŸ“‘ åº”ç”¨è¿‡æ»¤è¯: {task['filterwords']}ï¼Œå‰©ä½™ {remaining_usable_count} ä¸ªé¡¹ç›®")
            else:
                # æ­£åˆ™æ¨¡å¼ä¸‹ï¼Œéœ€è¦å…ˆæ£€æŸ¥å“ªäº›æ–‡ä»¶/æ–‡ä»¶å¤¹ä¼šè¢«å®é™…è½¬å­˜
                pattern, replace = "", ""
                # æ£€æŸ¥æ˜¯å¦æ˜¯å‰§é›†å‘½åæ¨¡å¼
                if task.get("use_episode_naming") and task.get("regex_pattern"):
                    # ä½¿ç”¨é¢„å…ˆå‡†å¤‡å¥½çš„æ­£åˆ™è¡¨è¾¾å¼
                    pattern = task["regex_pattern"]
                else:
                    # æ™®é€šæ­£åˆ™å‘½åæ¨¡å¼
                    pattern, replace = self.magic_regex_func(
                        task.get("pattern", ""), task.get("replace", ""), task["taskname"]
                    )
                
                # ç¡®ä¿patternä¸ä¸ºç©ºï¼Œé¿å…æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯
                if not pattern:
                    pattern = ".*"
                
                # è®¡ç®—çœŸæ­£ä¼šè¢«è½¬å­˜çš„é¡¹ç›®æ•°é‡ï¼Œä½¿ç”¨ç®€åŒ–çš„é€»è¾‘
                try:
                    # ç®€åŒ–çš„è®¡ç®—é€»è¾‘ï¼šåªæ£€æŸ¥æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…
                    processable_items = []
                    for share_file in share_file_list:
                        # æ£€æŸ¥æ˜¯å¦ç¬¦åˆæ­£åˆ™è¡¨è¾¾å¼
                        if not re.search(pattern, share_file["file_name"]):
                            continue
                        processable_items.append(share_file)
                    
                    remaining_count = len(processable_items)
                except Exception as e:
                    # å‡ºé”™æ—¶å›é€€åˆ°ç®€å•è®¡æ•°æ–¹å¼
                    print(f"âš ï¸ è®¡ç®—å¯å¤„ç†é¡¹ç›®æ—¶å‡ºé”™: {str(e)}")
                    remaining_count = len([f for f in share_file_list if re.search(pattern, f["file_name"])])
                
                print(f"ğŸ“‘ åº”ç”¨è¿‡æ»¤è¯: {task['filterwords']}ï¼Œå‰©ä½™ {remaining_count} ä¸ªé¡¹ç›®")
            print()

        # è·å–ç›®æ ‡ç›®å½•æ–‡ä»¶åˆ—è¡¨
        savepath = re.sub(r"/{2,}", "/", f"/{task['savepath']}{subdir_path}")
        if not self.savepath_fid.get(savepath):
            # æ£€æŸ¥è§„èŒƒåŒ–è·¯å¾„æ˜¯å¦å·²åœ¨å­—å…¸ä¸­
            norm_savepath = re.sub(r"/{2,}", "/", f"/{savepath}")
            if norm_savepath != savepath and self.savepath_fid.get(norm_savepath):
                self.savepath_fid[savepath] = self.savepath_fid[norm_savepath]
            else:
                savepath_fids = self.get_fids([savepath])
                if not savepath_fids:
                    # print(f"ä¿å­˜è·¯å¾„ä¸å­˜åœ¨ï¼Œå‡†å¤‡æ–°å»ºï¼š{savepath}")
                    mkdir_result = self.mkdir(savepath)
                    if mkdir_result["code"] == 0:
                        self.savepath_fid[savepath] = mkdir_result["data"]["fid"]
                        # print(f"ä¿å­˜è·¯å¾„æ–°å»ºæˆåŠŸï¼š{savepath}")
                    else:
                        # print(f"ä¿å­˜è·¯å¾„æ–°å»ºå¤±è´¥ï¼š{mkdir_result['message']}")
                        return
                else:
                    # è·¯å¾„å·²å­˜åœ¨ï¼Œç›´æ¥è®¾ç½®fid
                    self.savepath_fid[savepath] = savepath_fids[0]["fid"]
        to_pdir_fid = self.savepath_fid[savepath]
        dir_file_list = self.ls_dir(to_pdir_fid)
        
        # æ£€æŸ¥æ ¹èŠ‚ç‚¹æ˜¯å¦å·²å­˜åœ¨
        if not tree.contains(pdir_fid):
            tree.create_node(
                savepath,
                pdir_fid,
                data={
                    "is_dir": True,
                },
            )

        # å¤„ç†é¡ºåºå‘½åæ¨¡å¼
        if task.get("use_sequence_naming") and task.get("sequence_naming"):
            # é¡ºåºå‘½åæ¨¡å¼
            current_sequence = 1
            sequence_pattern = task["sequence_naming"]
            regex_pattern = task.get("regex_pattern")
            
            # æŸ¥æ‰¾ç›®å½•ä¸­ç°æœ‰çš„æœ€å¤§åºå·
            for dir_file in dir_file_list:
                if not dir_file["dir"]:  # åªæ£€æŸ¥æ–‡ä»¶
                    if sequence_pattern == "{}":
                        # å¯¹äºå•ç‹¬çš„{}ï¼Œç›´æ¥å°è¯•åŒ¹é…æ•´ä¸ªæ–‡ä»¶åæ˜¯å¦ä¸ºæ•°å­—
                        file_name_without_ext = os.path.splitext(dir_file["file_name"])[0]
                        if file_name_without_ext.isdigit():
                            try:
                                seq_num = int(file_name_without_ext)
                                current_sequence = max(current_sequence, seq_num + 1)
                            except (ValueError, IndexError):
                                pass
                    elif matches := re.match(regex_pattern, dir_file["file_name"]):
                        try:
                            seq_num = int(matches.group(1))
                            current_sequence = max(current_sequence, seq_num + 1)
                        except (ValueError, IndexError):
                            pass
            
            # æ„å»ºç›®æ ‡ç›®å½•ä¸­æ‰€æœ‰æ–‡ä»¶çš„æŸ¥é‡ç´¢å¼•ï¼ˆæŒ‰å¤§å°å’Œä¿®æ”¹æ—¶é—´ï¼‰
            dir_files_map = {}
            for dir_file in dir_file_list:
                if not dir_file["dir"]:  # ä»…å¤„ç†æ–‡ä»¶
                    file_size = dir_file.get("size", 0)
                    file_ext = os.path.splitext(dir_file["file_name"])[1].lower()
                    update_time = dir_file.get("updated_at", 0)
                    
                    # åˆ›å»ºå¤§å°+æ‰©å±•åçš„ç´¢å¼•ï¼Œç”¨äºå¿«é€ŸæŸ¥é‡
                    key = f"{file_size}_{file_ext}"
                    if key not in dir_files_map:
                        dir_files_map[key] = []
                    dir_files_map[key].append({
                        "file_name": dir_file["file_name"],
                        "updated_at": update_time,
                    })
            
            # é¢„å…ˆè¿‡æ»¤æ‰å·²ç»å­˜åœ¨çš„æ–‡ä»¶ï¼ˆæŒ‰å¤§å°å’Œæ‰©å±•åæ¯”å¯¹ï¼‰
            # åªä¿ç•™æ–‡ä»¶ï¼Œä¸ä¿ç•™æ–‡ä»¶å¤¹
            filtered_share_files = []
            start_fid = task.get("startfid", "")
            start_file_found = False



            for share_file in share_file_list:
                if share_file["dir"]:
                    # é¡ºåºå‘½åæ¨¡å¼ä¸‹ï¼Œæœªè®¾ç½®update_subdiræ—¶ä¸å¤„ç†æ–‡ä»¶å¤¹
                    continue

                # æ”¹è¿›çš„èµ·å§‹æ–‡ä»¶è¿‡æ»¤é€»è¾‘ - ä¼˜å…ˆæ‰§è¡Œï¼Œåœ¨æ•°æ®åº“æŸ¥é‡ä¹‹å‰
                if start_fid:
                    if share_file["fid"] == start_fid:
                        start_file_found = True
                        # æ‰¾åˆ°èµ·å§‹æ–‡ä»¶ï¼Œä½†ä¸åŒ…å«èµ·å§‹æ–‡ä»¶æœ¬èº«ï¼Œåªå¤„ç†æ¯”å®ƒæ›´æ–°çš„æ–‡ä»¶
                        continue
                    elif start_file_found:
                        # å·²ç»æ‰¾åˆ°èµ·å§‹æ–‡ä»¶ï¼Œè·³è¿‡åç»­ï¼ˆæ›´æ—§çš„ï¼‰æ–‡ä»¶
                        continue
                    # å¦‚æœè¿˜æ²¡æ‰¾åˆ°èµ·å§‹æ–‡ä»¶ï¼Œè¯´æ˜å½“å‰æ–‡ä»¶æ¯”èµ·å§‹æ–‡ä»¶æ›´æ–°ï¼Œéœ€è¦å¤„ç†
                else:
                    # æ²¡æœ‰è®¾ç½®èµ·å§‹æ–‡ä»¶ï¼Œå¤„ç†æ‰€æœ‰æ–‡ä»¶
                    pass

                # æ£€æŸ¥æ–‡ä»¶IDæ˜¯å¦å­˜åœ¨äºè½¬å­˜è®°å½•ä¸­
                file_id = share_file.get("fid", "")
                if file_id and self.check_file_exists_in_records(file_id, task):
                    # æ–‡ä»¶IDå·²å­˜åœ¨äºè®°å½•ä¸­ï¼Œè·³è¿‡å¤„ç†
                    continue

                file_size = share_file.get("size", 0)
                file_ext = os.path.splitext(share_file["file_name"])[1].lower()
                share_update_time = share_file.get("last_update_at", 0) or share_file.get("updated_at", 0)

                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒå¤§å°å’Œæ‰©å±•åçš„æ–‡ä»¶
                key = f"{file_size}_{file_ext}"
                is_duplicate = False
                if key in dir_files_map:
                    for existing_file in dir_files_map[key]:
                        existing_update_time = existing_file.get("updated_at", 0)
                        # é˜²æ­¢é™¤é›¶é”™è¯¯
                        if existing_update_time == 0:
                            continue
                        # å¦‚æœä¿®æ”¹æ—¶é—´ç›¸è¿‘ï¼ˆ30å¤©å†…ï¼‰æˆ–è€…å·®è·ä¸å¤§ï¼ˆ10%ä»¥å†…ï¼‰ï¼Œè®¤ä¸ºæ˜¯åŒä¸€ä¸ªæ–‡ä»¶
                        time_diff = abs(share_update_time - existing_update_time)
                        time_ratio = abs(1 - (share_update_time / existing_update_time)) if existing_update_time else 1
                        if time_diff < 2592000 or time_ratio < 0.1:
                            # æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†
                            is_duplicate = True
                            break

                # åªæœ‰éé‡å¤æ–‡ä»¶æ‰è¿›è¡Œå¤„ç†
                if not is_duplicate:
                    filtered_share_files.append(share_file)
            
            # å®ç°é«˜çº§æ’åºç®—æ³•
            def extract_sorting_value(file):
                # ä½¿ç”¨å…¨å±€æ’åºå‡½æ•°
                sort_tuple = sort_file_by_name(file)
                # è¿”å›æ’åºå…ƒç»„ï¼Œå®ç°å¤šçº§æ’åº
                return sort_tuple

            # å¯¹è¿‡æ»¤åçš„æ–‡ä»¶è¿›è¡Œæ’åºï¼ˆæ­£åºï¼Œç¡®ä¿é¡ºåºå‘½åæŒ‰æ­£ç¡®é¡ºåºè¿›è¡Œï¼‰
            # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨æ­£åºæ’åºï¼Œå› ä¸ºé¡ºåºå‘½åéœ€è¦æŒ‰ç…§æ­£ç¡®çš„é¡ºåºåˆ†é…åºå·
            filtered_share_files.sort(key=extract_sorting_value)

            # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨å•ç‹¬çš„{}æ¨¡å¼

            # éœ€ä¿å­˜çš„æ–‡ä»¶æ¸…å•
            need_save_list = []
            
            # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ†é…åºå·
            for share_file in filtered_share_files:
                # è·å–æ–‡ä»¶æ‰©å±•å
                file_ext = os.path.splitext(share_file["file_name"])[1]
                # ç”Ÿæˆæ–°æ–‡ä»¶å
                save_name = sequence_pattern.replace("{}", f"{current_sequence:02d}") + file_ext
                
                # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                save_name = apply_subtitle_naming_rule(save_name, task)
                
                # æ£€æŸ¥ç›®æ ‡ç›®å½•æ˜¯å¦å·²å­˜åœ¨æ­¤æ–‡ä»¶ï¼Œæ”¯æŒå¿½ç•¥åç¼€é€‰é¡¹
                if task.get("ignore_extension", False):
                    # å¿½ç•¥åç¼€æ¨¡å¼ï¼šåªæ¯”è¾ƒæ–‡ä»¶åéƒ¨åˆ†ï¼Œä¸æ¯”è¾ƒæ‰©å±•å
                    save_name_base = os.path.splitext(save_name)[0]
                    file_exists = any(
                        os.path.splitext(dir_file["file_name"])[0] == save_name_base for dir_file in dir_file_list
                    )
                else:
                    # ä¸å¿½ç•¥åç¼€æ¨¡å¼ï¼šå®Œæ•´æ–‡ä»¶åå¿…é¡»åŒ¹é…
                    file_exists = any(
                        dir_file["file_name"] == save_name for dir_file in dir_file_list
                    )
                
                if not file_exists:
                    # è®¾ç½®ä¿å­˜æ–‡ä»¶åï¼ˆå•ç‹¬çš„{}ä¸åœ¨è¿™é‡Œé‡å‘½åï¼Œè€Œæ˜¯åœ¨do_rename_taskä¸­å¤„ç†ï¼‰
                    if sequence_pattern == "{}":
                        share_file["save_name"] = share_file["file_name"]  # ä¿æŒåŸæ–‡ä»¶åï¼Œç¨ååœ¨do_rename_taskä¸­å¤„ç†
                    else:
                        share_file["save_name"] = save_name
                    share_file["original_name"] = share_file["file_name"]  # ä¿å­˜åŸæ–‡ä»¶åï¼Œç”¨äºæ’åº
                    need_save_list.append(share_file)
                    current_sequence += 1
                else:
                    # print(f"è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶: {save_name}")
                    pass
                
                # è¿™é‡Œä¸éœ€è¦å†æ¬¡æ£€æŸ¥èµ·å§‹æ–‡ä»¶ï¼Œå› ä¸ºåœ¨å‰é¢çš„è¿‡æ»¤ä¸­å·²ç»å¤„ç†äº†
                    
            # å¤„ç†å­æ–‡ä»¶å¤¹
            for share_file in share_file_list:
                if share_file["dir"] and task.get("update_subdir", False):
                    # ç¡®å®šæ˜¯å¦å¤„ç†æ­¤ç›®å½•ï¼š
                    # 1. å¦‚æœå½“å‰åœ¨æ›´æ–°ç›®å½•å†…ï¼Œåˆ™å¤„ç†æ‰€æœ‰å­ç›®å½•
                    # 2. å¦‚æœä¸åœ¨æ›´æ–°ç›®å½•å†…ï¼Œåªå¤„ç†ç¬¦åˆæ›´æ–°ç›®å½•è§„åˆ™çš„å­ç›®å½•
                    if (parent_dir_info and parent_dir_info.get("in_update_dir", False)) or re.search(task["update_subdir"], share_file["file_name"]):
                        # print(f"æ£€æŸ¥å­ç›®å½•: {savepath}/{share_file['file_name']}")
                        
                        # åˆ›å»ºä¸€ä¸ªå­ä»»åŠ¡å¯¹è±¡ï¼Œä¿ç•™åŸä»»åŠ¡çš„å±æ€§ï¼Œä½†ä¸“é—¨ç”¨äºå­ç›®å½•å¤„ç†
                        subdir_task = task.copy()
                        # ç¡®ä¿å­ç›®å½•ä¹Ÿå¯ä»¥ä½¿ç”¨å¿½ç•¥åç¼€åŠŸèƒ½
                        
                        # å°†å­ç›®å½•ä»»åŠ¡è®¾ç½®ä¸ºæ­£åˆ™å‘½åæ¨¡å¼
                        # å¦‚æœåŸä»»åŠ¡æ²¡æœ‰è®¾ç½®patternï¼Œæˆ–è€…ä½¿ç”¨çš„æ˜¯é¡ºåº/å‰§é›†å‘½åï¼Œç¡®ä¿æœ‰åŸºæœ¬çš„pattern
                        if (not subdir_task.get("pattern") or 
                            subdir_task.get("use_sequence_naming") or 
                            subdir_task.get("use_episode_naming")):
                            subdir_task["pattern"] = ".*"
                            subdir_task["replace"] = ""
                            # å–æ¶ˆé¡ºåºå‘½åå’Œå‰§é›†å‘½åæ¨¡å¼ï¼Œå¼ºåˆ¶ä½¿ç”¨æ­£åˆ™æ¨¡å¼
                            subdir_task["use_sequence_naming"] = False
                            subdir_task["use_episode_naming"] = False
                            
                        # æ›´æ–°å­ç›®å½•çš„parent_dir_infoï¼Œè·Ÿè¸ªç›®å½•è·¯å¾„å’Œæ›´æ–°çŠ¶æ€
                        current_parent_info = parent_dir_info.copy() if parent_dir_info else {
                            "in_update_dir": False,
                            "update_dir_pattern": task.get("update_subdir", ""),
                            "dir_path": []
                        }
                        
                        # å¦‚æœå½“å‰æ–‡ä»¶å¤¹ç¬¦åˆæ›´æ–°ç›®å½•è§„åˆ™ï¼Œæ ‡è®°ä¸ºåœ¨æ›´æ–°ç›®å½•å†…
                        if re.search(task["update_subdir"], share_file["file_name"]):
                            current_parent_info["in_update_dir"] = True
                            
                        # æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
                        current_parent_info["dir_path"] = current_parent_info["dir_path"].copy() if "dir_path" in current_parent_info else []
                        current_parent_info["dir_path"].append(share_file["file_name"])
                        
                        subdir_tree = self.dir_check_and_save(
                            subdir_task,
                            pwd_id,
                            stoken,
                            share_file["fid"],
                            f"{subdir_path}/{share_file['file_name']}",
                            current_parent_info
                        )
                        # åªæœ‰å½“å­ç›®å½•æ ‘æœ‰å®é™…å†…å®¹ï¼ˆå¤§äº1è¡¨ç¤ºä¸åªæœ‰æ ¹èŠ‚ç‚¹ï¼‰æ—¶æ‰å¤„ç†
                        if subdir_tree.size(1) > 0:
                            # æ£€æŸ¥å­ç›®å½•æ ‘æ˜¯å¦åªåŒ…å«æ–‡ä»¶å¤¹è€Œæ²¡æœ‰æ–‡ä»¶
                            has_files = False
                            for node in subdir_tree.all_nodes_itr():
                                # æ£€æŸ¥æ˜¯å¦æœ‰éç›®å½•èŠ‚ç‚¹ï¼ˆå³æ–‡ä»¶èŠ‚ç‚¹ï¼‰
                                if node.data and not node.data.get("is_dir", False):
                                    has_files = True
                                    break
                                    
                            # åªæœ‰å½“å­ç›®å½•åŒ…å«æ–‡ä»¶æ—¶æ‰å°†å…¶åˆå¹¶åˆ°ä¸»æ ‘ä¸­
                            if has_files:
                                # è·å–ä¿å­˜è·¯å¾„çš„æœ€åä¸€éƒ¨åˆ†ç›®å½•å
                                save_path_basename = os.path.basename(task.get("savepath", "").rstrip("/"))
                                
                                # è·³è¿‡ä¸ä¿å­˜è·¯å¾„åŒåçš„ç›®å½•
                                if share_file["file_name"] == save_path_basename:
                                    continue
                                
                                # åˆå¹¶å­ç›®å½•æ ‘
                                tree.create_node(
                                    f"ğŸ“{share_file['file_name']}",
                                    share_file["fid"],
                                    parent=pdir_fid,
                                    data={
                                        "is_dir": share_file["dir"],
                                    },
                                )
                                tree.merge(share_file["fid"], subdir_tree, deep=False)
                                
                                # æ ‡è®°æ­¤æ–‡ä»¶å¤¹æœ‰æ›´æ–°
                                # æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å·²æ·»åŠ åˆ°need_save_list
                                folder_in_list = False
                                for item in need_save_list:
                                    if item.get("fid") == share_file["fid"]:
                                        item["has_updates"] = True
                                        folder_in_list = True
                                        break
                                
                                # å¦‚æœæ–‡ä»¶å¤¹æœªæ·»åŠ åˆ°need_save_listï¼Œéœ€è¦æ·»åŠ 
                                if not folder_in_list and has_files:
                                    # æ£€æŸ¥ç›®æ ‡ç›®å½•ä¸­æ˜¯å¦å·²å­˜åœ¨åŒåæ–‡ä»¶å¤¹
                                    dir_exists = False
                                    for dir_file in dir_file_list:
                                        if dir_file["dir"] and dir_file["file_name"] == share_file["file_name"]:
                                            dir_exists = True
                                            break
                                    
                                    # å¦‚æœå­˜åœ¨åŒåæ–‡ä»¶å¤¹ï¼Œæ£€æŸ¥æ–‡ä»¶å¤¹å†…æ˜¯å¦æœ‰æ›´æ–°
                                    # å¦‚æœä¸å­˜åœ¨åŒåæ–‡ä»¶å¤¹ï¼Œæˆ–è€…æ–‡ä»¶å¤¹å†…æœ‰æ›´æ–°ï¼Œåˆ™æ·»åŠ åˆ°ä¿å­˜åˆ—è¡¨
                                    if not dir_exists or has_files:
                                        share_file["save_name"] = share_file["file_name"]
                                        share_file["original_name"] = share_file["file_name"]
                                        share_file["has_updates"] = True
                                        need_save_list.append(share_file)
                
        elif task.get("use_episode_naming") and task.get("episode_naming"):
            # å‰§é›†å‘½åæ¨¡å¼
            need_save_list = []

            # æ„å»ºç›®æ ‡ç›®å½•ä¸­æ‰€æœ‰æ–‡ä»¶çš„æŸ¥é‡ç´¢å¼•ï¼ˆæŒ‰å¤§å°å’Œä¿®æ”¹æ—¶é—´ï¼‰
            dir_files_map = {}
            for dir_file in dir_file_list:
                if not dir_file["dir"]:  # ä»…å¤„ç†æ–‡ä»¶
                    file_size = dir_file.get("size", 0)
                    file_ext = os.path.splitext(dir_file["file_name"])[1].lower()
                    update_time = dir_file.get("updated_at", 0)

                    # åˆ›å»ºå¤§å°+æ‰©å±•åçš„ç´¢å¼•ï¼Œç”¨äºå¿«é€ŸæŸ¥é‡
                    key = f"{file_size}_{file_ext}"
                    if key not in dir_files_map:
                        dir_files_map[key] = []
                    dir_files_map[key].append({
                        "file_name": dir_file["file_name"],
                        "updated_at": update_time,
                    })

            # é¢„å…ˆè¿‡æ»¤åˆ†äº«æ–‡ä»¶åˆ—è¡¨ï¼Œå»é™¤å·²å­˜åœ¨çš„æ–‡ä»¶
            filtered_share_files = []
            start_fid = task.get("startfid", "")
            start_file_found = False

            for share_file in share_file_list:
                if share_file["dir"]:
                    # å¤„ç†å­ç›®å½•
                    if task.get("update_subdir") and re.search(task["update_subdir"], share_file["file_name"]):
                        filtered_share_files.append(share_file)
                    continue

                # æ”¹è¿›çš„èµ·å§‹æ–‡ä»¶è¿‡æ»¤é€»è¾‘ - ä¼˜å…ˆæ‰§è¡Œï¼Œåœ¨æ•°æ®åº“æŸ¥é‡ä¹‹å‰
                if start_fid:
                    if share_file["fid"] == start_fid:
                        start_file_found = True
                        # æ‰¾åˆ°èµ·å§‹æ–‡ä»¶ï¼Œä½†ä¸åŒ…å«èµ·å§‹æ–‡ä»¶æœ¬èº«ï¼Œåªå¤„ç†æ¯”å®ƒæ›´æ–°çš„æ–‡ä»¶
                        continue
                    elif start_file_found:
                        # å·²ç»æ‰¾åˆ°èµ·å§‹æ–‡ä»¶ï¼Œè·³è¿‡åç»­ï¼ˆæ›´æ—§çš„ï¼‰æ–‡ä»¶
                        continue
                    # å¦‚æœè¿˜æ²¡æ‰¾åˆ°èµ·å§‹æ–‡ä»¶ï¼Œè¯´æ˜å½“å‰æ–‡ä»¶æ¯”èµ·å§‹æ–‡ä»¶æ›´æ–°ï¼Œéœ€è¦å¤„ç†
                else:
                    # æ²¡æœ‰è®¾ç½®èµ·å§‹æ–‡ä»¶ï¼Œå¤„ç†æ‰€æœ‰æ–‡ä»¶
                    pass

                # æ£€æŸ¥æ–‡ä»¶IDæ˜¯å¦å­˜åœ¨äºè½¬å­˜è®°å½•ä¸­
                file_id = share_file.get("fid", "")
                if file_id and self.check_file_exists_in_records(file_id, task):
                    # æ–‡ä»¶IDå·²å­˜åœ¨äºè®°å½•ä¸­ï¼Œè·³è¿‡å¤„ç†
                    continue

                # ä»å…±äº«æ–‡ä»¶ä¸­æå–å‰§é›†å·
                episode_num = extract_episode_number(share_file["file_name"])
                is_duplicate = False

                # é€šè¿‡æ–‡ä»¶ååˆ¤æ–­æ˜¯å¦å·²å­˜åœ¨ï¼ˆæ–°çš„æŸ¥é‡é€»è¾‘ï¼‰
                if not is_duplicate:
                    # å¦‚æœæ²¡æœ‰é‡å‘½åï¼Œåˆ¤æ–­åŸæ–‡ä»¶åæ˜¯å¦å·²å­˜åœ¨
                    original_name = share_file["file_name"]
                    # å¦‚æœæœ‰å‰§é›†å·ï¼Œåˆ¤æ–­é‡å‘½ååçš„æ–‡ä»¶åæ˜¯å¦å·²å­˜åœ¨
                    file_ext = os.path.splitext(original_name)[1]

                    if episode_num is not None:
                        # æ ¹æ®å‰§é›†å‘½åæ¨¡å¼ç”Ÿæˆç›®æ ‡æ–‡ä»¶å
                        episode_pattern = task["episode_naming"]
                        if episode_pattern == "[]":
                            target_name = f"{episode_num:02d}{file_ext}"
                        else:
                            target_name = episode_pattern.replace("[]", f"{episode_num:02d}") + file_ext
                        
                        # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                        target_name = apply_subtitle_naming_rule(target_name, task)

                        # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶åæ˜¯å¦å·²å­˜åœ¨ï¼Œæ”¯æŒå¿½ç•¥åç¼€é€‰é¡¹
                        if task.get("ignore_extension", False):
                            # å¿½ç•¥åç¼€æ¨¡å¼ï¼šåªæ¯”è¾ƒæ–‡ä»¶åéƒ¨åˆ†ï¼Œä¸æ¯”è¾ƒæ‰©å±•å
                            target_name_base = os.path.splitext(target_name)[0]
                            target_exists = any(
                                os.path.splitext(dir_file["file_name"])[0] == target_name_base for dir_file in dir_file_list
                            )
                        else:
                            # ä¸å¿½ç•¥åç¼€æ¨¡å¼ï¼šå®Œæ•´æ–‡ä»¶åå¿…é¡»åŒ¹é…
                            target_exists = any(dir_file["file_name"] == target_name for dir_file in dir_file_list)

                        if target_exists:
                            is_duplicate = True

                    # å¦‚æœæ²¡æœ‰é‡å¤ï¼Œæ£€æŸ¥æ–‡ä»¶å¤§å°å’Œæ‰©å±•åæ˜¯å¦é‡å¤
                    if not is_duplicate:
                        file_size = share_file.get("size", 0)
                        file_ext_lower = file_ext.lower()
                        share_update_time = share_file.get("last_update_at", 0) or share_file.get("updated_at", 0)

                        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒå¤§å°å’Œæ‰©å±•åçš„æ–‡ä»¶
                        key = f"{file_size}_{file_ext_lower}"
                        if key in dir_files_map:
                            for existing_file in dir_files_map[key]:
                                existing_update_time = existing_file.get("updated_at", 0)
                                # é˜²æ­¢é™¤é›¶é”™è¯¯
                                if existing_update_time == 0:
                                    continue
                                # å¦‚æœä¿®æ”¹æ—¶é—´ç›¸è¿‘ï¼ˆ30å¤©å†…ï¼‰æˆ–è€…å·®è·ä¸å¤§ï¼ˆ10%ä»¥å†…ï¼‰ï¼Œè®¤ä¸ºæ˜¯åŒä¸€ä¸ªæ–‡ä»¶
                                time_diff = abs(share_update_time - existing_update_time)
                                time_ratio = abs(1 - (share_update_time / existing_update_time)) if existing_update_time else 1
                                if time_diff < 2592000 or time_ratio < 0.1:
                                    # æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†
                                    is_duplicate = True
                                    break

                if not is_duplicate:
                    share_file["save_name"] = share_file["file_name"]  # å‰§é›†å‘½åæ¨¡å¼ä¸‹ä¿æŒåŸæ–‡ä»¶åï¼Œé‡å‘½ååœ¨åç»­æ­¥éª¤è¿›è¡Œ
                    share_file["original_name"] = share_file["file_name"]
                    filtered_share_files.append(share_file)

            # å®ç°é«˜çº§æ’åºç®—æ³•
            def sort_by_episode(file):
                if file["dir"]:
                    return (float('inf'), 0)

                filename = file["file_name"]

                # ä¼˜å…ˆåŒ¹é…S01E01æ ¼å¼
                match_s_e = re.search(r'[Ss](\d+)[Ee](\d+)', filename)
                if match_s_e:
                    season = int(match_s_e.group(1))
                    episode = int(match_s_e.group(2))
                    return (season * 1000 + episode, 0)

                # ä½¿ç”¨ç»Ÿä¸€çš„å‰§é›†æå–å‡½æ•°
                episode_num = extract_episode_number(filename)
                if episode_num is not None:
                    return (episode_num, 0)

                # æ— æ³•è¯†åˆ«ï¼Œå›é€€åˆ°ä¿®æ”¹æ—¶é—´æ’åº
                return (float('inf'), file.get("last_update_at", 0))

            # è¿‡æ»¤å‡ºæ–‡ä»¶å¹¶æ’åº
            files_to_process = [f for f in filtered_share_files if not f["dir"]]
            sorted_files = sorted(files_to_process, key=sort_by_episode)

            # è¦ä¿å­˜çš„æ–‡ä»¶åˆ—è¡¨
            need_save_list = []

            # æ·»åŠ æ’åºåçš„æ–‡ä»¶åˆ°ä¿å­˜åˆ—è¡¨
            for share_file in sorted_files:
                need_save_list.append(share_file)

            # å¤„ç†æ–‡ä»¶å¤¹
            for share_file in filtered_share_files:
                if share_file["dir"]:
                    need_save_list.append(share_file)

        else:
            # æ­£åˆ™å‘½åæ¨¡å¼ï¼ˆæ™®é€šæ­£åˆ™å‘½åæ¨¡å¼ï¼‰
            need_save_list = []

            # æ„å»ºç›®æ ‡ç›®å½•ä¸­æ‰€æœ‰æ–‡ä»¶çš„æŸ¥é‡ç´¢å¼•ï¼ˆæŒ‰å¤§å°å’Œä¿®æ”¹æ—¶é—´ï¼‰- åŠ å…¥æ–‡ä»¶æŸ¥é‡æœºåˆ¶
            dir_files_map = {}
            for dir_file in dir_file_list:
                if not dir_file["dir"]:  # ä»…å¤„ç†æ–‡ä»¶
                    file_size = dir_file.get("size", 0)
                    file_ext = os.path.splitext(dir_file["file_name"])[1].lower()
                    update_time = dir_file.get("updated_at", 0)

                    # åˆ›å»ºå¤§å°+æ‰©å±•åçš„ç´¢å¼•ï¼Œç”¨äºå¿«é€ŸæŸ¥é‡
                    key = f"{file_size}_{file_ext}"
                    if key not in dir_files_map:
                        dir_files_map[key] = []
                    dir_files_map[key].append({
                        "file_name": dir_file["file_name"],
                        "updated_at": update_time,
                    })

            # åº”ç”¨èµ·å§‹æ–‡ä»¶è¿‡æ»¤é€»è¾‘
            start_fid = task.get("startfid", "")
            if start_fid:
                # æ‰¾åˆ°èµ·å§‹æ–‡ä»¶çš„ç´¢å¼•
                start_index = -1
                for i, share_file in enumerate(share_file_list):
                    if share_file["fid"] == start_fid:
                        start_index = i
                        break

                if start_index >= 0:
                    # åªå¤„ç†èµ·å§‹æ–‡ä»¶ä¹‹å‰çš„æ–‡ä»¶ï¼ˆæ¯”èµ·å§‹æ–‡ä»¶æ›´æ–°çš„æ–‡ä»¶ï¼Œä¸åŒ…æ‹¬èµ·å§‹æ–‡ä»¶æœ¬èº«ï¼‰
                    share_file_list = share_file_list[:start_index]

            # æ·»åŠ ç¬¦åˆçš„
            for share_file in share_file_list:
                # æ£€æŸ¥æ–‡ä»¶IDæ˜¯å¦å­˜åœ¨äºè½¬å­˜è®°å½•ä¸­
                file_id = share_file.get("fid", "")
                if file_id and self.check_file_exists_in_records(file_id, task):
                    # æ–‡ä»¶IDå·²å­˜åœ¨äºè®°å½•ä¸­ï¼Œè·³è¿‡å¤„ç†
                    continue
                    
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆé€šè¿‡å¤§å°å’Œæ‰©å±•åï¼‰- æ–°å¢çš„æ–‡ä»¶æŸ¥é‡é€»è¾‘
                is_duplicate = False
                if not share_file["dir"]:  # æ–‡ä»¶å¤¹ä¸è¿›è¡Œå†…å®¹æŸ¥é‡
                    # æ–°çš„æŸ¥é‡é€»è¾‘ï¼šä¼˜å…ˆä½¿ç”¨æ–‡ä»¶åæŸ¥é‡ï¼Œæ”¯æŒå¿½ç•¥åç¼€
                    original_file_name = share_file["file_name"]
                    original_name_base = os.path.splitext(original_file_name)[0]
                    
                    # åˆ¤æ–­æ˜¯å¦ç”¨æ­£åˆ™æ›¿æ¢åçš„æ–‡ä»¶å
                    if task.get("pattern") and task.get("replace") is not None:
                        pattern, replace = self.magic_regex_func(
                            task.get("pattern", ""), task.get("replace", ""), task.get("taskname", "")
                        )
                        # ç¡®ä¿patternä¸ä¸ºç©ºï¼Œé¿å…æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯
                        if pattern:
                            try:
                                # å°è¯•åº”ç”¨æ­£åˆ™æ›¿æ¢
                                if re.search(pattern, original_file_name):
                                    renamed_file = re.sub(pattern, replace, original_file_name)
                                    # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                                    renamed_file = apply_subtitle_naming_rule(renamed_file, task)
                                    renamed_base = os.path.splitext(renamed_file)[0]
                                else:
                                    renamed_file = None
                                    renamed_base = None
                            except Exception:
                                # æ­£åˆ™å‡ºé”™æ—¶ä½¿ç”¨åŸæ–‡ä»¶å
                                renamed_file = None
                                renamed_base = None
                        else:
                            renamed_file = None
                            renamed_base = None
                    else:
                        renamed_file = None
                        renamed_base = None
                    
                    # æŸ¥é‡é€»è¾‘ï¼ŒåŒæ—¶è€ƒè™‘åŸæ–‡ä»¶åå’Œé‡å‘½ååçš„æ–‡ä»¶å
                    for dir_file in dir_file_list:
                        if dir_file["dir"]:
                            continue
                        
                        if task.get("ignore_extension", False):
                            # å¿½ç•¥åç¼€ï¼šåªæ¯”è¾ƒæ–‡ä»¶åéƒ¨åˆ†ï¼Œä¸ç®¡æ‰©å±•å
                            existing_name_base = os.path.splitext(dir_file["file_name"])[0]
                            
                            # å¦‚æœåŸæ–‡ä»¶åæˆ–é‡å‘½ååæ–‡ä»¶åä¸ç›®æ ‡ç›®å½•ä¸­æ–‡ä»¶åç›¸åŒï¼ˆå¿½ç•¥åç¼€ï¼‰ï¼Œåˆ™è§†ä¸ºå·²å­˜åœ¨
                            if (existing_name_base == original_name_base or 
                                (renamed_file and existing_name_base == renamed_base)):
                                is_duplicate = True
                                break
                        else:
                            # ä¸å¿½ç•¥åç¼€ï¼šæ–‡ä»¶åå’Œæ‰©å±•åéƒ½è¦ä¸€è‡´æ‰è§†ä¸ºåŒä¸€ä¸ªæ–‡ä»¶
                            if (dir_file["file_name"] == original_file_name or 
                                (renamed_file and dir_file["file_name"] == renamed_file)):
                                is_duplicate = True
                                break
                    

                # å¦‚æœæ–‡ä»¶å·²ç»å­˜åœ¨å¹¶ä¸”ä¸æ˜¯ç›®å½•ï¼Œè·³è¿‡åç»­å¤„ç†
                if is_duplicate and not share_file["dir"]:
                    continue
                    
                # è®¾ç½®åŒ¹é…æ¨¡å¼ï¼šç›®å½•ä½¿ç”¨update_subdirï¼Œæ–‡ä»¶ä½¿ç”¨æ™®é€šæ­£åˆ™
                if share_file["dir"] and task.get("update_subdir", False):
                    # ç¡®å®šæ˜¯å¦å¤„ç†æ­¤ç›®å½•ï¼š
                    # 1. å¦‚æœå½“å‰åœ¨æ›´æ–°ç›®å½•å†…ï¼Œåˆ™å¤„ç†æ‰€æœ‰å­ç›®å½•
                    # 2. å¦‚æœä¸åœ¨æ›´æ–°ç›®å½•å†…ï¼Œåªå¤„ç†ç¬¦åˆæ›´æ–°ç›®å½•è§„åˆ™çš„å­ç›®å½•
                    if parent_dir_info and parent_dir_info.get("in_update_dir", False):
                        # å·²ç»åœ¨æ›´æ–°ç›®å½•å†…ï¼Œå¤„ç†æ‰€æœ‰å­ç›®å½•
                        pass
                    elif not re.search(task["update_subdir"], share_file["file_name"]):
                        # ä¸åœ¨æ›´æ–°ç›®å½•å†…ï¼Œä¸”ä¸ç¬¦åˆæ›´æ–°ç›®å½•è§„åˆ™ï¼Œè·³è¿‡å¤„ç†
                        continue
                    
                    # å…ˆæ£€æŸ¥ç›®æ ‡ç›®å½•ä¸­æ˜¯å¦å·²å­˜åœ¨è¿™ä¸ªå­ç›®å½•
                    dir_exists = False
                    for dir_file in dir_file_list:
                        if dir_file["dir"] and dir_file["file_name"] == share_file["file_name"]:
                            dir_exists = True
                            break
                    
                    # å¦‚æœç›®æ ‡ä¸­å·²ç»å­˜åœ¨æ­¤å­ç›®å½•ï¼Œåˆ™ç›´æ¥æ£€æŸ¥å­ç›®å½•çš„å†…å®¹æ›´æ–°ï¼Œä¸è¦é‡å¤è½¬å­˜
                    if dir_exists:
                        # å­ç›®å½•å­˜åœ¨ï¼Œç›´æ¥é€’å½’å¤„ç†å…¶ä¸­çš„æ–‡ä»¶ï¼Œä¸åœ¨ä¸»ç›®å½•çš„å¤„ç†ä¸­å†è½¬å­˜ä¸€æ¬¡
                        # print(f"æ£€æŸ¥å­ç›®å½•: {savepath}/{share_file['file_name']} (å·²å­˜åœ¨)")
                        
                        # åˆ›å»ºä¸€ä¸ªå­ä»»åŠ¡å¯¹è±¡ï¼Œä¸“é—¨ç”¨äºå­ç›®å½•å¤„ç†
                        subdir_task = task.copy()
                        if (not subdir_task.get("pattern") or 
                            subdir_task.get("use_sequence_naming") or 
                            subdir_task.get("use_episode_naming")):
                            subdir_task["pattern"] = ".*"
                            subdir_task["replace"] = ""
                            # å–æ¶ˆé¡ºåºå‘½åå’Œå‰§é›†å‘½åæ¨¡å¼ï¼Œå¼ºåˆ¶ä½¿ç”¨æ­£åˆ™æ¨¡å¼
                            subdir_task["use_sequence_naming"] = False
                            subdir_task["use_episode_naming"] = False
                        
                        # æ›´æ–°å­ç›®å½•çš„parent_dir_infoï¼Œè·Ÿè¸ªç›®å½•è·¯å¾„å’Œæ›´æ–°çŠ¶æ€
                        current_parent_info = parent_dir_info.copy() if parent_dir_info else {
                            "in_update_dir": False,
                            "update_dir_pattern": task.get("update_subdir", ""),
                            "dir_path": []
                        }
                        
                        # å¦‚æœå½“å‰æ–‡ä»¶å¤¹ç¬¦åˆæ›´æ–°ç›®å½•è§„åˆ™ï¼Œæ ‡è®°ä¸ºåœ¨æ›´æ–°ç›®å½•å†…
                        if re.search(task["update_subdir"], share_file["file_name"]):
                            current_parent_info["in_update_dir"] = True
                            
                        # æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
                        current_parent_info["dir_path"] = current_parent_info["dir_path"].copy() if "dir_path" in current_parent_info else []
                        current_parent_info["dir_path"].append(share_file["file_name"])
                        
                        # é€’å½’å¤„ç†å­ç›®å½•ä½†ä¸åœ¨need_save_listä¸­æ·»åŠ ç›®å½•æœ¬èº«
                        subdir_tree = self.dir_check_and_save(
                            subdir_task,
                            pwd_id,
                            stoken,
                            share_file["fid"],
                            f"{subdir_path}/{share_file['file_name']}",
                            current_parent_info
                        )
                        
                        # å¦‚æœå­ç›®å½•æœ‰æ–°å†…å®¹ï¼Œåˆå¹¶åˆ°ä¸»æ ‘ä¸­
                        if subdir_tree and subdir_tree.size() > 1:
                            has_files = False
                            for node in subdir_tree.all_nodes_itr():
                                if node.data and not node.data.get("is_dir", False):
                                    has_files = True
                                    break
                            
                            if has_files:
                                # æ·»åŠ ç›®å½•åˆ°æ ‘ä¸­ä½†ä¸æ·»åŠ åˆ°ä¿å­˜åˆ—è¡¨
                                if not tree.contains(share_file["fid"]):
                                    tree.create_node(
                                        f"ğŸ“{share_file['file_name']}",
                                        share_file["fid"],
                                        parent=pdir_fid,
                                        data={
                                            "is_dir": share_file["dir"],
                                        },
                                    )
                                # åˆå¹¶å­ç›®å½•æ ‘
                                tree.merge(share_file["fid"], subdir_tree, deep=False)
                        
                        # è·³è¿‡åç»­å¤„ç†ï¼Œä¸å¯¹å·²å­˜åœ¨çš„å­ç›®å½•å†åšè½¬å­˜å¤„ç†
                        continue
                    
                    # ç›®å½•ä¸å­˜åœ¨ï¼Œç»§ç»­æ­£å¸¸æµç¨‹
                    pattern, replace = task["update_subdir"], ""
                else:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å‰§é›†å‘½åæ¨¡å¼
                    if task.get("use_episode_naming") and task.get("regex_pattern"):
                        # ä½¿ç”¨é¢„å…ˆå‡†å¤‡å¥½çš„æ­£åˆ™è¡¨è¾¾å¼
                        pattern = task["regex_pattern"]
                        replace = ""
                    else:
                        # æ™®é€šæ­£åˆ™å‘½åæ¨¡å¼
                        pattern, replace = self.magic_regex_func(
                            task.get("pattern", ""), task.get("replace", ""), task["taskname"]
                        )
                
                # ç¡®ä¿patternä¸ä¸ºç©ºï¼Œé¿å…æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯
                if not pattern:
                    pattern = ".*"
                    
                # æ­£åˆ™æ–‡ä»¶ååŒ¹é…
                try:
                    if re.search(pattern, share_file["file_name"]):
                        # æ›¿æ¢åçš„æ–‡ä»¶å
                        save_name = (
                            re.sub(pattern, replace, share_file["file_name"])
                            if replace != ""
                            else share_file["file_name"]
                        )
                        
                        # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                        save_name = apply_subtitle_naming_rule(save_name, task)
                        
                        # æ£€æŸ¥æ–°åç§°æ˜¯å¦å­˜åœ¨é‡å¤çš„å‰ç¼€
                        if replace and " - " in save_name:
                            parts = save_name.split(" - ")
                            if len(parts) >= 2 and parts[0] == parts[1]:
                                # å¦‚æœæ–°åç§°åŒ…å«é‡å¤å‰ç¼€ï¼Œä½¿ç”¨åŸæ–‡ä»¶å
                                save_name = share_file["file_name"]
                            
                            # æ£€æŸ¥æ˜¯å¦ä»»åŠ¡åå·²ç»å­˜åœ¨äºåŸæ–‡ä»¶åä¸­
                            taskname = task.get("taskname", "")
                            if taskname and taskname in share_file["file_name"] and share_file["file_name"].startswith(taskname):
                                # å¦‚æœåŸæ–‡ä»¶åå·²åŒ…å«ä»»åŠ¡åä½œä¸ºå‰ç¼€ï¼Œä¿æŒåŸæ ·
                                save_name = share_file["file_name"]
                        
                        # ä¸ºæ­£åˆ™æ¨¡å¼å®ç°åŸºäºæ–‡ä»¶åçš„æŸ¥é‡é€»è¾‘ï¼Œæ”¯æŒå¿½ç•¥åç¼€é€‰é¡¹
                        # åˆ¤æ–­ç›®æ ‡ç›®å½•æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                        file_exists = False
                        for dir_file in dir_file_list:
                            if dir_file["dir"] and share_file["dir"]:
                                # å¦‚æœéƒ½æ˜¯ç›®å½•ï¼Œåªè¦åç§°ç›¸åŒå°±è§†ä¸ºå·²å­˜åœ¨
                                if dir_file["file_name"] == share_file["file_name"]:
                                    file_exists = True
                                    break
                            elif not dir_file["dir"] and not share_file["dir"]:
                                # å¦‚æœéƒ½æ˜¯æ–‡ä»¶
                                if task.get("ignore_extension", False):
                                    # å¿½ç•¥åç¼€ï¼šåªæ¯”è¾ƒæ–‡ä»¶åéƒ¨åˆ†ï¼Œä¸ç®¡æ‰©å±•å
                                    original_name_base = os.path.splitext(share_file["file_name"])[0]
                                    renamed_name_base = os.path.splitext(save_name)[0]
                                    existing_name_base = os.path.splitext(dir_file["file_name"])[0]
                                    
                                    # å¦‚æœåŸæ–‡ä»¶åæˆ–é‡å‘½ååæ–‡ä»¶åä¸ç›®æ ‡ç›®å½•ä¸­æ–‡ä»¶åç›¸åŒï¼ˆå¿½ç•¥åç¼€ï¼‰ï¼Œåˆ™è§†ä¸ºå·²å­˜åœ¨
                                    if existing_name_base == original_name_base or existing_name_base == renamed_name_base:
                                        file_exists = True
                                        break
                                else:
                                    # ä¸å¿½ç•¥åç¼€ï¼šæ–‡ä»¶åå’Œæ‰©å±•åéƒ½è¦ä¸€è‡´æ‰è§†ä¸ºåŒä¸€ä¸ªæ–‡ä»¶
                                    if dir_file["file_name"] == share_file["file_name"] or dir_file["file_name"] == save_name:
                                        file_exists = True
                                        break
                                
                        if not file_exists:
                            # ä¸æ‰“å°ä¿å­˜ä¿¡æ¯
                            share_file["save_name"] = save_name
                            share_file["original_name"] = share_file["file_name"]  # ä¿å­˜åŸæ–‡ä»¶åï¼Œç”¨äºæ’åº
                            
                            # æ–‡ä»¶å¤¹éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œæ ‡è®°ä¸ºhas_updates=Falseï¼Œç­‰å¾…åç»­æ£€æŸ¥
                            # åªæœ‰åœ¨æ–‡ä»¶å¤¹åŒ¹é…update_subdiræ—¶æ‰è®¾ç½®
                            if share_file["dir"]:
                                share_file["has_updates"] = False
                                
                            # å°†æ–‡ä»¶æ·»åŠ åˆ°ä¿å­˜åˆ—è¡¨
                            need_save_list.append(share_file)
                        elif share_file["dir"]:
                            # æ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼Œæ ¹æ®æ˜¯å¦é€’å½’å¤„ç†å­ç›®å½•å†³å®šæ“ä½œ
                            
                            # å¦‚æœå¼€å¯äº†å­ç›®å½•é€’å½’ï¼Œå¤„ç†å­ç›®å½•ç»“æ„
                            if task.get("update_subdir", False):
                                # print(f"æ£€æŸ¥å­ç›®å½•: {savepath}/{share_file['file_name']}")
                                
                                # åˆ›å»ºä¸€ä¸ªå­ä»»åŠ¡å¯¹è±¡ï¼Œä¿ç•™åŸä»»åŠ¡çš„å±æ€§ï¼Œä½†ä¸“é—¨ç”¨äºå­ç›®å½•å¤„ç†
                                subdir_task = task.copy()
                                # ç¡®ä¿å­ç›®å½•ä¹Ÿå¯ä»¥ä½¿ç”¨å¿½ç•¥åç¼€åŠŸèƒ½
                                
                                # å¦‚æœåŸä»»åŠ¡æ²¡æœ‰è®¾ç½®patternï¼Œç¡®ä¿æœ‰åŸºæœ¬çš„pattern
                                if not subdir_task.get("pattern"):
                                    subdir_task["pattern"] = ".*"  # åœ¨å­ç›®å½•ä¸­åŒ¹é…æ‰€æœ‰æ–‡ä»¶
                                    subdir_task["replace"] = ""
                                
                                # æ›´æ–°å­ç›®å½•çš„parent_dir_infoï¼Œè·Ÿè¸ªç›®å½•è·¯å¾„å’Œæ›´æ–°çŠ¶æ€
                                current_parent_info = parent_dir_info.copy() if parent_dir_info else {
                                    "in_update_dir": False,
                                    "update_dir_pattern": task.get("update_subdir", ""),
                                    "dir_path": []
                                }
                                
                                # å¦‚æœå½“å‰æ–‡ä»¶å¤¹ç¬¦åˆæ›´æ–°ç›®å½•è§„åˆ™ï¼Œæ ‡è®°ä¸ºåœ¨æ›´æ–°ç›®å½•å†…
                                if re.search(task["update_subdir"], share_file["file_name"]):
                                    current_parent_info["in_update_dir"] = True
                                    
                                # æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
                                current_parent_info["dir_path"] = current_parent_info["dir_path"].copy() if "dir_path" in current_parent_info else []
                                current_parent_info["dir_path"].append(share_file["file_name"])
                                
                                # é€’å½’å¤„ç†å­ç›®å½•
                                subdir_tree = self.dir_check_and_save(
                                    subdir_task,
                                    pwd_id,
                                    stoken,
                                    share_file["fid"],
                                    f"{subdir_path}/{share_file['file_name']}",
                                    current_parent_info
                                )
                                
                                # åªæœ‰å½“å­ç›®å½•æ ‘æœ‰å®é™…å†…å®¹ï¼ˆå¤§äº1è¡¨ç¤ºä¸åªæœ‰æ ¹èŠ‚ç‚¹ï¼‰æ—¶æ‰å¤„ç†
                                if subdir_tree and subdir_tree.size() > 1:
                                    # æ£€æŸ¥å­ç›®å½•æ ‘æ˜¯å¦åªåŒ…å«æ–‡ä»¶å¤¹è€Œæ²¡æœ‰æ–‡ä»¶
                                    has_files = False
                                    for node in subdir_tree.all_nodes_itr():
                                        # æ£€æŸ¥æ˜¯å¦æœ‰éç›®å½•èŠ‚ç‚¹ï¼ˆå³æ–‡ä»¶èŠ‚ç‚¹ï¼‰
                                        if node.data and not node.data.get("is_dir", False):
                                            has_files = True
                                            break
                                    
                                    # åªæœ‰å½“å­ç›®å½•åŒ…å«æ–‡ä»¶æ—¶æ‰å°†å…¶åˆå¹¶åˆ°ä¸»æ ‘ä¸­
                                    if has_files:
                                        # è·å–ä¿å­˜è·¯å¾„çš„æœ€åä¸€éƒ¨åˆ†ç›®å½•å
                                        save_path_basename = os.path.basename(task.get("savepath", "").rstrip("/"))
                                        
                                        # è·³è¿‡ä¸ä¿å­˜è·¯å¾„åŒåçš„ç›®å½•
                                        if share_file["file_name"] == save_path_basename:
                                            continue
                                        
                                        # æ·»åŠ ç›®å½•åˆ°æ ‘ä¸­
                                        # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å·²å­˜åœ¨äºæ ‘ä¸­ï¼Œé¿å…é‡å¤æ·»åŠ 
                                        if not tree.contains(share_file["fid"]):
                                            tree.create_node(
                                                f"ğŸ“{share_file['file_name']}",
                                                share_file["fid"],
                                                parent=pdir_fid,
                                                data={
                                                    "is_dir": share_file["dir"],
                                                },
                                            )
                                        # åˆå¹¶å­ç›®å½•æ ‘
                                        tree.merge(share_file["fid"], subdir_tree, deep=False)
                                        
                                        # æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å·²æ·»åŠ åˆ°need_save_list
                                        folder_in_list = False
                                        for item in need_save_list:
                                            if item.get("fid") == share_file["fid"]:
                                                # æ–‡ä»¶å¤¹å·²åœ¨åˆ—è¡¨ä¸­ï¼Œè®¾ç½®ä¸ºæœ‰æ›´æ–°
                                                item["has_updates"] = True
                                                folder_in_list = True
                                                break
                                        
                                        # å¦‚æœæ–‡ä»¶å¤¹æœªæ·»åŠ åˆ°need_save_listä¸”æœ‰æ–‡ä»¶æ›´æ–°ï¼Œåˆ™æ·»åŠ 
                                        if not folder_in_list:
                                            # æ£€æŸ¥ç›®æ ‡ç›®å½•ä¸­æ˜¯å¦å·²å­˜åœ¨åŒåå­ç›®å½•
                                            dir_exists = False
                                            for dir_file in dir_file_list:
                                                if dir_file["dir"] and dir_file["file_name"] == share_file["file_name"]:
                                                    dir_exists = True
                                                    break
                                            
                                            # åªæœ‰å½“ç›®å½•ä¸å­˜åœ¨äºç›®æ ‡ä½ç½®æ—¶ï¼Œæ‰å°†å…¶æ·»åŠ åˆ°è½¬å­˜åˆ—è¡¨
                                            if not dir_exists:
                                                # å°†çˆ¶æ–‡ä»¶å¤¹æ·»åŠ åˆ°ä¿å­˜åˆ—è¡¨ï¼Œç¡®ä¿å­ç›®å½•çš„å˜åŒ–èƒ½è¢«å¤„ç†
                                                share_file["save_name"] = share_file["file_name"]
                                                share_file["original_name"] = share_file["file_name"]
                                                share_file["has_updates"] = True  # æ ‡è®°ä¸ºæœ‰æ›´æ–°
                                                need_save_list.append(share_file)
                                                print(f"å‘ç°å­ç›®å½• {share_file['file_name']} æœ‰æ›´æ–°ï¼Œå°†åŒ…å«åˆ°è½¬å­˜åˆ—è¡¨")
                                            else:
                                                # å¦‚æœå­ç›®å½•å·²å­˜åœ¨ï¼Œåªæ˜¾ç¤ºæç¤ºæ¶ˆæ¯ï¼Œä¸æ·»åŠ åˆ°è½¬å­˜åˆ—è¡¨
                                                print(f"å‘ç°å­ç›®å½• {share_file['file_name']} æœ‰æ›´æ–°ï¼Œå°†æ›´æ–°åˆ°å·²å­˜åœ¨çš„æ–‡ä»¶å¤¹ä¸­")
                except Exception as e:
                    print(f"âš ï¸ æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯: {str(e)}, pattern: {pattern}")
                    # ä½¿ç”¨å®‰å…¨çš„é»˜è®¤å€¼
                    share_file["save_name"] = share_file["file_name"]
                    share_file["original_name"] = share_file["file_name"]
                    need_save_list.append(share_file)

        fid_list = [item["fid"] for item in need_save_list]
        fid_token_list = [item["share_fid_token"] for item in need_save_list]
        
        # è¿‡æ»¤æ‰æ²¡æœ‰çœŸæ­£å†…å®¹æ›´æ–°çš„æ–‡ä»¶å¤¹ï¼ˆä»…åœ¨æ­£åˆ™å‘½åæ¨¡å¼ä¸‹ï¼‰
        if not task.get("use_sequence_naming") and not task.get("use_episode_naming") and need_save_list:
            # è®¡ç®—éç›®å½•æ–‡ä»¶æ•°é‡
            non_dir_files = [item for item in need_save_list if not item.get("dir", False)]
            
            # å¦‚æœæœ‰å¸¸è§„æ–‡ä»¶ï¼Œä»£è¡¨æœ‰çœŸæ­£çš„æ›´æ–°
            has_file_updates = len(non_dir_files) > 0
            
            # æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦æ ‡è®°ä¸ºæœ‰æ›´æ–°
            folders_with_updates = [item for item in need_save_list if item.get("dir", False) and item.get("has_updates", False) == True]
            has_folder_updates = len(folders_with_updates) > 0
            
            # è·å–ä¿å­˜è·¯å¾„çš„æœ€åä¸€éƒ¨åˆ†ç›®å½•å
            save_path_basename = os.path.basename(task.get("savepath", "").rstrip("/"))
            
            # ä»åˆ—è¡¨ä¸­ç§»é™¤æ²¡æœ‰çœŸæ­£æ›´æ–°çš„æ–‡ä»¶å¤¹å’Œä¸ä¿å­˜è·¯å¾„åŒåçš„ç›®å½•
            filtered_need_save_list = []
            for item in need_save_list:
                # è·³è¿‡ä¸ä¿å­˜è·¯å¾„åŒåçš„ç›®å½•
                if item.get("dir", False) and item.get("save_name") == save_path_basename:
                    continue
                    
                # è·³è¿‡æ²¡æœ‰æ›´æ–°çš„æ–‡ä»¶å¤¹
                if item.get("dir", False) and item.get("has_updates", False) == False and not has_file_updates and not has_folder_updates:
                    continue
                    
                # ä¿ç•™å…¶ä»–æ‰€æœ‰é¡¹ç›®
                filtered_need_save_list.append(item)
                
            need_save_list = filtered_need_save_list
            
            # å¦‚æœè¿‡æ»¤ååˆ—è¡¨ä¸ºç©ºï¼Œç›´æ¥è¿”å›æ ‘å¯¹è±¡
            if not need_save_list:
                return tree
            
            # æ›´æ–°fidåˆ—è¡¨
            fid_list = [item["fid"] for item in need_save_list]
            fid_token_list = [item["share_fid_token"] for item in need_save_list]
        
        if fid_list:
            # åªåœ¨æœ‰æ–°æ–‡ä»¶éœ€è¦è½¬å­˜æ—¶æ‰å¤„ç†
            save_file_return = self.save_file(
                fid_list, fid_token_list, to_pdir_fid, pwd_id, stoken
            )
            err_msg = None
            if save_file_return["code"] == 0:
                task_id = save_file_return["data"]["task_id"]
                query_task_return = self.query_task(task_id)
                if query_task_return["code"] == 0:
                    # ç­‰å¾…æ–‡ä»¶ä¿å­˜å®Œæˆ
                    time.sleep(1)
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨è§£å‹å‹ç¼©æ–‡ä»¶
                    auto_extract_mode = task.get("auto_extract_archive", "disabled")
                    if auto_extract_mode != "disabled":
                        # è·å–åˆšè½¬å­˜çš„æ–‡ä»¶åˆ—è¡¨
                        fresh_files = self.ls_dir(to_pdir_fid)

                        # æ£€æŸ¥æ˜¯å¦æœ‰å‹ç¼©æ–‡ä»¶éœ€è¦è§£å‹
                        items_to_remove = []
                        items_to_add = []
                        
                        for saved_item in need_save_list:
                            if not saved_item.get("dir", False) and self.is_archive_file(saved_item["file_name"]):
                                # åœ¨ç›®æ ‡ç›®å½•ä¸­æ‰¾åˆ°å¯¹åº”çš„å‹ç¼©æ–‡ä»¶
                                archive_file = None
                                for f in fresh_files:
                                    if f["file_name"] == saved_item["file_name"]:
                                        archive_file = f
                                        break
                                
                                if archive_file:
                                    # æ‰§è¡Œè‡ªåŠ¨è§£å‹
                                    extract_result = self.process_auto_extract(
                                        archive_fid=archive_file["fid"],
                                        archive_name=archive_file["file_name"],
                                        target_pdir_fid=to_pdir_fid,
                                        extract_mode=auto_extract_mode,
                                        task=task
                                    )
                                    
                                    if extract_result.get("success"):
                                        # åªæœ‰åœ¨å‹ç¼©æ–‡ä»¶ç¡®å®è¢«åˆ é™¤æ—¶ï¼Œæ‰ä»åˆ—è¡¨ä¸­ç§»é™¤å®ƒ
                                        # è¿™æ ·å¯ä»¥é¿å…åç»­é‡å‘½åæ“ä½œå¤„ç†ä¸å­˜åœ¨çš„æ–‡ä»¶
                                        if extract_result.get("archive_deleted", False):
                                            items_to_remove.append(saved_item)
                                        # æ·»åŠ è§£å‹å‡ºçš„æ–‡ä»¶åˆ°åˆ—è¡¨
                                        for moved_file in extract_result.get("moved_files", []):
                                            items_to_add.append({
                                                "fid": moved_file["fid"],
                                                "file_name": moved_file["file_name"],
                                                "save_name": moved_file["file_name"],
                                                "original_name": moved_file["file_name"],
                                                "size": moved_file["size"],
                                                "dir": False,
                                                "obj_category": "default",
                                                "share_fid_token": "",
                                                "_from_extraction": True,  # æ ‡è®°æ¥è‡ªè§£å‹
                                            })
                        
                        # ä¸è®ºä½•ç§å‘½åæ¨¡å¼ï¼Œåˆ é™¤å‹ç¼©åŒ…æ—¶éƒ½ä¿ç•™å…¶è½¬å­˜è®°å½•ï¼Œä¾¿äºåç»­æŸ¥é‡ã€é¿å…é‡å¤è½¬å­˜
                        for item in items_to_remove:
                            self.create_transfer_record(
                                task=task,
                                file_info=item,
                                renamed_to=item.get("file_name", item.get("save_name", ""))
                            )
                        # æ›´æ–° need_save_list
                        for item in items_to_remove:
                            if item in need_save_list:
                                need_save_list.remove(item)
                        need_save_list.extend(items_to_add)
                    
                    # å»ºç«‹ç›®å½•æ ‘
                    saved_files = []

                    for index, item in enumerate(need_save_list):
                        icon = (
                            "ğŸ“"
                            if item["dir"] == True
                            else "ğŸï¸" if item["obj_category"] == "video" else get_file_icon(item["save_name"], False)
                        )
                        
                        # ä¿®å¤æ–‡ä»¶æ ‘æ˜¾ç¤ºé—®é¢˜ - é˜²æ­¢æ–‡ä»¶åé‡å¤é‡å¤æ˜¾ç¤º
                        # å¯¹äºé¡ºåºå‘½åå’Œå‰§é›†å‘½åæ¨¡å¼ï¼Œè½¬å­˜æ—¶ä½¿ç”¨åŸæ–‡ä»¶åæ˜¾ç¤º
                        # å› ä¸ºå®é™…æ–‡ä»¶æ˜¯ä»¥åŸåä¿å­˜çš„ï¼Œé‡å‘½ååœ¨åç»­æ­¥éª¤è¿›è¡Œ
                        if task.get("use_sequence_naming") or task.get("use_episode_naming"):
                            display_name = item['file_name']  # ä½¿ç”¨åŸæ–‡ä»¶å
                        else:
                            # å…¶ä»–æ¨¡å¼ä½¿ç”¨save_name
                            display_name = item['save_name']
                        
                        # ç¡®ä¿åªæ˜¾ç¤ºæ–‡ä»¶/æ–‡ä»¶å¤¹åï¼Œè€Œä¸æ˜¯å®Œæ•´è·¯å¾„
                        if "/" in display_name:
                            # åªå–è·¯å¾„çš„æœ€åä¸€éƒ¨åˆ†ä½œä¸ºæ˜¾ç¤ºå
                            display_name = display_name.split("/")[-1]
                        
                        # ä¸å†è‡ªåŠ¨æ·»åŠ ä»»åŠ¡åç§°å‰ç¼€ï¼Œå°Šé‡ç”¨æˆ·é€‰æ‹©
                        
                        # ä¿å­˜åˆ°æ ‘ä¸­
                        saved_files.append(format_file_display("", icon, display_name))
                        # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å·²å­˜åœ¨äºæ ‘ä¸­ï¼Œé¿å…é‡å¤æ·»åŠ 
                        if not tree.contains(item["fid"]):
                            # å®‰å…¨åœ°è·å–save_as_top_fidsä¸­çš„fidï¼Œé˜²æ­¢ç´¢å¼•è¶Šç•Œ
                            save_as_top_fids = query_task_return.get('data', {}).get('save_as', {}).get('save_as_top_fids', [])
                            saved_fid = save_as_top_fids[index] if index < len(save_as_top_fids) else item["fid"]

                            # æ ‡è®°è¯¥èŠ‚ç‚¹æ˜¯å¦æ¥è‡ªè‡ªåŠ¨è§£å‹ï¼ˆä»…å¯¹æ–‡ä»¶ç”Ÿæ•ˆï¼‰
                            from_extraction = item.get("_from_extraction", False) if not item["dir"] else False

                            tree.create_node(
                                display_name,  # åªå­˜å‚¨æ–‡ä»¶åï¼Œä¸åŒ…å«å›¾æ ‡
                                item["fid"],
                                parent=pdir_fid,
                                data={
                                    "fid": f"{saved_fid}",
                                    "path": f"{savepath}/{item['save_name']}",
                                    "is_dir": item["dir"],
                                    "icon": icon,  # å°†å›¾æ ‡å­˜å‚¨åœ¨dataä¸­
                                    "from_extraction": from_extraction,
                                },
                            )
                            
                            # ä¿å­˜è½¬å­˜è®°å½•åˆ°æ•°æ®åº“
                            if not item["dir"]:  # åªè®°å½•æ–‡ä»¶ï¼Œä¸è®°å½•æ–‡ä»¶å¤¹
                                # è½¬å­˜æ—¶å…ˆç”¨åŸæ–‡ä»¶åè®°å½•ï¼Œé‡å‘½ååå†æ›´æ–°
                                self.create_transfer_record(
                                    task=task,
                                    file_info=item,
                                    renamed_to=item["file_name"]  # è½¬å­˜æ—¶ä½¿ç”¨åŸæ–‡ä»¶å
                                )
                    
                    # ç§»é™¤é€šçŸ¥ç”Ÿæˆï¼Œç”±do_saveå‡½æ•°ç»Ÿä¸€å¤„ç†
                    # é¡ºåºå‘½åæ¨¡å¼å’Œå‰§é›†å‘½åæ¨¡å¼éƒ½ä¸åœ¨æ­¤å¤„ç”Ÿæˆé€šçŸ¥
                else:
                    err_msg = query_task_return["message"]
            else:
                err_msg = save_file_return["message"]
            if err_msg:
                add_notify(f"âŒã€Š{task['taskname']}ã€‹è½¬å­˜å¤±è´¥: {err_msg}\n")
        else:
            # æ²¡æœ‰æ–°æ–‡ä»¶éœ€è¦è½¬å­˜
            if not subdir_path:  # åªåœ¨é¡¶å±‚ï¼ˆéå­ç›®å½•ï¼‰æ‰“å°ä¸€æ¬¡æ¶ˆæ¯
                pass
        return tree

    def do_rename_task(self, task, subdir_path=""):
        # æ£€æŸ¥æ˜¯å¦ä¸ºé¡ºåºå‘½åæ¨¡å¼
        if task.get("use_sequence_naming") and task.get("sequence_naming"):
            # ä½¿ç”¨é¡ºåºå‘½åæ¨¡å¼
            sequence_pattern = task["sequence_naming"]
            # æ›¿æ¢å ä½ç¬¦ä¸ºæ­£åˆ™è¡¨è¾¾å¼æ•è·ç»„
            if sequence_pattern == "{}":
                # å¯¹äºå•ç‹¬çš„{}ï¼Œä½¿ç”¨ç‰¹æ®ŠåŒ¹é…
                regex_pattern = "(\\d+)"
            else:
                regex_pattern = re.escape(sequence_pattern).replace('\\{\\}', '(\\d+)')
            
            savepath = re.sub(r"/{2,}", "/", f"/{task['savepath']}{subdir_path}")
            if not self.savepath_fid.get(savepath):
                # è·¯å¾„å·²å­˜åœ¨ï¼Œç›´æ¥è®¾ç½®fid
                self.savepath_fid[savepath] = self.get_fids([savepath])[0]["fid"]
            dir_file_list = self.ls_dir(self.savepath_fid[savepath])
            dir_file_name_list = [item["file_name"] for item in dir_file_list]
            
            # åˆ¤æ–­ç›®å½•æ˜¯å¦ä¸ºç©ºï¼ˆåªåŒ…å«éç›®å½•æ–‡ä»¶ï¼‰
            non_dir_files = [f for f in dir_file_list if not f.get("dir", False)]
            is_empty_dir = len(non_dir_files) == 0

            # åº”ç”¨è¿‡æ»¤è¯è¿‡æ»¤ï¼ˆä¿®å¤bugï¼šä¸ºæœ¬åœ°æ–‡ä»¶é‡å‘½åæ·»åŠ è¿‡æ»¤è§„åˆ™ï¼‰
            if task.get("filterwords"):
                # è®°å½•è¿‡æ»¤å‰çš„æ–‡ä»¶æ€»æ•°
                original_total_count = len(dir_file_list)
                
                # ä½¿ç”¨é«˜çº§è¿‡æ»¤å‡½æ•°å¤„ç†ä¿ç•™è¯å’Œè¿‡æ»¤è¯
                dir_file_list = advanced_filter_files(dir_file_list, task["filterwords"])
                dir_file_name_list = [item["file_name"] for item in dir_file_list]

            # æ‰¾å‡ºå½“å‰æœ€å¤§åºå·
            max_sequence = 0
            # å…ˆæ£€æŸ¥ç›®å½•ä¸­æ˜¯å¦æœ‰ç¬¦åˆå‘½åè§„åˆ™çš„æ–‡ä»¶
            has_matching_files = False

            for dir_file in dir_file_list:
                if dir_file.get("dir", False):
                    continue  # è·³è¿‡æ–‡ä»¶å¤¹

                if sequence_pattern == "{}":
                    # å¯¹äºå•ç‹¬çš„{}ï¼Œç›´æ¥å°è¯•åŒ¹é…æ•´ä¸ªæ–‡ä»¶åæ˜¯å¦ä¸ºæ•°å­—
                    file_name_without_ext = os.path.splitext(dir_file["file_name"])[0]
                    if file_name_without_ext.isdigit():
                        # å¢åŠ åˆ¤æ–­ï¼šå¦‚æœæ˜¯æ—¥æœŸæ ¼å¼çš„çº¯æ•°å­—ï¼Œä¸åº”è¢«è§†ä¸ºåºå·
                        if not is_date_format(file_name_without_ext):
                            try:
                                current_seq = int(file_name_without_ext)
                                max_sequence = max(max_sequence, current_seq)
                                has_matching_files = True
                            except (ValueError, IndexError):
                                pass
                elif matches := re.match(regex_pattern, dir_file["file_name"]):
                    try:
                        current_seq = int(matches.group(1))
                        max_sequence = max(max_sequence, current_seq)
                        has_matching_files = True
                    except (IndexError, ValueError):
                        pass

            if not has_matching_files:
                # æ²¡æœ‰ç¬¦åˆå‘½åè§„åˆ™çš„æ–‡ä»¶æ—¶ï¼Œæ£€æŸ¥æ•°æ®åº“ä¸­çš„è½¬å­˜è®°å½•
                try:
                    from app.sdk.db import RecordDB
                    db = RecordDB()

                    # è·å–å½“å‰ä¿å­˜è·¯å¾„
                    current_save_path = task.get("savepath", "")
                    if subdir_path:
                        current_save_path = f"{current_save_path}/{subdir_path}"

                    # æŸ¥è¯¢è¯¥ç›®å½•çš„è½¬å­˜è®°å½•
                    records = db.get_records_by_save_path(current_save_path, include_subpaths=False)

                    # ä»è½¬å­˜è®°å½•ä¸­æå–æœ€å¤§åºå·
                    max_sequence_from_records = 0
                    for record in records:
                        renamed_to = record.get("renamed_to", "")
                        if renamed_to:
                            if sequence_pattern == "{}":
                                # å¯¹äºå•ç‹¬çš„{}ï¼Œç›´æ¥å°è¯•åŒ¹é…æ•´ä¸ªæ–‡ä»¶åæ˜¯å¦ä¸ºæ•°å­—
                                file_name_without_ext = os.path.splitext(renamed_to)[0]
                                if file_name_without_ext.isdigit():
                                    try:
                                        seq_num = int(file_name_without_ext)
                                        max_sequence_from_records = max(max_sequence_from_records, seq_num)
                                    except (ValueError, IndexError):
                                        pass
                            elif matches := re.match(regex_pattern, renamed_to):
                                try:
                                    seq_num = int(matches.group(1))
                                    max_sequence_from_records = max(max_sequence_from_records, seq_num)
                                except (ValueError, IndexError):
                                    pass

                    # ä½¿ç”¨è®°å½•ä¸­çš„æœ€å¤§åºå·
                    max_sequence = max_sequence_from_records
                    db.close()
                except Exception as e:
                    max_sequence = 0
            
            # å®ç°é«˜çº§æ’åºç®—æ³•
            def extract_sorting_value(file):
                # ä½¿ç”¨å…¨å±€æ’åºå‡½æ•°
                sort_tuple = sort_file_by_name(file)
                # è¿”å›æ’åºå…ƒç»„ï¼Œå®ç°å¤šçº§æ’åº
                return sort_tuple
            
            # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨å•ç‹¬çš„{}æ¨¡å¼
            
            # åˆå§‹åŒ–sorted_filesåˆ—è¡¨ï¼Œç”¨äºæ”¶é›†éœ€è¦é‡å‘½åçš„æ–‡ä»¶
            sorted_files = []
            
            # å¯¹äºå•ç‹¬çš„{}æ¨¡å¼ï¼Œå¢åŠ é¢å¤–æ£€æŸ¥
            if sequence_pattern == "{}":
                # æ”¶é›†æ‰€æœ‰ä¸æ˜¯çº¯æ•°å­—å‘½åçš„æ–‡ä»¶
                for dir_file in dir_file_list:
                    if dir_file["dir"]:
                        continue  # è·³è¿‡æ–‡ä»¶å¤¹
                    
                    file_name_without_ext = os.path.splitext(dir_file["file_name"])[0]
                    # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦ä¸ºçº¯æ•°å­—ï¼Œå¦‚æœæ˜¯åˆ™è·³è¿‡ï¼ˆå·²ç»å‘½åå¥½çš„ï¼‰
                    if file_name_without_ext.isdigit():
                        # å¢åŠ åˆ¤æ–­ï¼šå¦‚æœæ˜¯æ—¥æœŸæ ¼å¼çš„çº¯æ•°å­—ï¼Œä¸è§†ä¸ºå·²å‘½å
                        if not is_date_format(file_name_without_ext):
                            # ä¸æ˜¯æ—¥æœŸæ ¼å¼ï¼Œæ˜¯çº¯æ•°å­—åºå·ï¼Œè·³è¿‡
                            continue
                        # æ˜¯æ—¥æœŸæ ¼å¼ï¼Œéœ€è¦é‡å‘½åï¼Œæ‰€ä»¥ä¸è·³è¿‡
                    
                    # æ·»åŠ åˆ°éœ€è¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
                    sorted_files.append(dir_file)
            else:
                # å¯¹äºéå•ç‹¬{}çš„æ¨¡å¼ï¼Œæ”¶é›†æ‰€æœ‰ä¸ç¬¦åˆæ¨¡å¼çš„æ–‡ä»¶
                for dir_file in dir_file_list:
                    if dir_file["dir"]:
                        continue  # è·³è¿‡æ–‡ä»¶å¤¹
                    
                    # æ£€æŸ¥æ˜¯å¦å·²ç¬¦åˆå‘½åæ¨¡å¼
                    if re.match(regex_pattern, dir_file["file_name"]):
                        continue  # è·³è¿‡å·²ç»ç¬¦åˆå‘½åè§„åˆ™çš„æ–‡ä»¶
                    
                    # æ·»åŠ åˆ°éœ€è¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
                    sorted_files.append(dir_file)
            
            # ä½¿ç”¨extract_sorting_valueå‡½æ•°å¯¹æ‰€æœ‰éœ€è¦å¤„ç†çš„æ–‡ä»¶è¿›è¡Œæ’åº
            sorted_files = sorted(sorted_files, key=extract_sorting_value)
            
            # æ”¶é›†æ‰€æœ‰éœ€è¦é‡å‘½åçš„æ–‡ä»¶ï¼Œå¹¶æŒ‰é¡ºåºå¤„ç†
            renamed_pairs = []
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æœ€å¤§åºå·ï¼Œä»1å¼€å§‹å‘½å
            if max_sequence == 0:
                current_sequence = 0  # ä¼šç«‹å³åŠ 1ï¼Œæ‰€ä»¥ä»0å¼€å§‹
            else:
                current_sequence = max_sequence
            
            # å¯¹æ’åºå¥½çš„æ–‡ä»¶åº”ç”¨é¡ºåºå‘½å
            for dir_file in sorted_files:
                current_sequence += 1
                file_ext = os.path.splitext(dir_file["file_name"])[1]
                # æ ¹æ®é¡ºåºå‘½åæ¨¡å¼ç”Ÿæˆæ–°çš„æ–‡ä»¶å
                if sequence_pattern == "{}":
                    # å¯¹äºå•ç‹¬çš„{}ï¼Œç›´æ¥ä½¿ç”¨æ•°å­—åºå·ä½œä¸ºæ–‡ä»¶åï¼Œä¸å†ä½¿ç”¨æ—¥æœŸæ ¼å¼
                    save_name = f"{current_sequence:02d}{file_ext}"
                else:
                    save_name = sequence_pattern.replace("{}", f"{current_sequence:02d}") + file_ext
                
                # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                save_name = apply_subtitle_naming_rule(save_name, task)
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å‘½åï¼Œæ”¯æŒå¿½ç•¥åç¼€é€‰é¡¹
                name_conflict = False
                if task.get("ignore_extension", False):
                    # å¿½ç•¥åç¼€æ¨¡å¼ï¼šåªæ¯”è¾ƒæ–‡ä»¶åéƒ¨åˆ†ï¼Œä¸æ¯”è¾ƒæ‰©å±•å
                    save_name_base = os.path.splitext(save_name)[0]
                    name_conflict = any(
                        os.path.splitext(existing_name)[0] == save_name_base for existing_name in dir_file_name_list
                    )
                else:
                    # ä¸å¿½ç•¥åç¼€æ¨¡å¼ï¼šå®Œæ•´æ–‡ä»¶åå¿…é¡»åŒ¹é…
                    name_conflict = save_name in dir_file_name_list

                if save_name != dir_file["file_name"] and not name_conflict:
                    # æ”¶é›†é‡å‘½åå¯¹ï¼ŒåŒ…å«åŸå§‹æ–‡ä»¶ä¿¡æ¯ä»¥ä¾¿æ’åº
                    renamed_pairs.append((dir_file, save_name, current_sequence))
                    dir_file_name_list.append(save_name)
            
            # ç¡®ä¿æŒ‰ç…§åºå·é¡ºåºæ‰§è¡Œé‡å‘½åæ“ä½œ
            renamed_pairs.sort(key=lambda x: x[2])
            
            is_rename_count = 0
            rename_logs = []  # åˆå§‹åŒ–é‡å‘½åæ—¥å¿—åˆ—è¡¨
            # æ‰§è¡Œé‡å‘½åï¼Œå¹¶æŒ‰é¡ºåºæ‰“å°
            for dir_file, save_name, _ in renamed_pairs:
                try:
                    rename_return = self.rename(dir_file["fid"], save_name)
                    # é˜²æ­¢ç½‘ç»œé—®é¢˜å¯¼è‡´çš„é”™è¯¯
                    if isinstance(rename_return, dict) and rename_return.get("code") == 0:
                        rename_log = f"é‡å‘½å: {dir_file['file_name']} â†’ {save_name}"
                        rename_logs.append(rename_log)
                        # ç§»é™¤ç›´æ¥æ‰“å°çš„éƒ¨åˆ†ï¼Œç”±do_saveè´Ÿè´£æ‰“å°
                        # print(rename_log)
                        is_rename_count += 1
                        
                        # æ›´æ–°é‡å‘½åè®°å½•åˆ°æ•°æ®åº“ï¼ˆåªæ›´æ–°renamed_toå­—æ®µï¼‰
                        self.update_transfer_record(
                            task=task,
                            file_info=dir_file,
                            renamed_to=save_name
                        )
                    else:
                        error_msg = rename_return.get("message", "æœªçŸ¥é”™è¯¯")
                        rename_log = f"é‡å‘½å: {dir_file['file_name']} â†’ {save_name} å¤±è´¥ï¼Œ{error_msg}"
                        rename_logs.append(rename_log)
                        # ç§»é™¤ç›´æ¥æ‰“å°çš„éƒ¨åˆ†ï¼Œç”±do_saveè´Ÿè´£æ‰“å°
                        # print(rename_log)
                except Exception as e:
                    rename_log = f"é‡å‘½åå‡ºé”™: {dir_file['file_name']} â†’ {save_name}ï¼Œé”™è¯¯: {str(e)}"
                    rename_logs.append(rename_log)
                    # ç§»é™¤ç›´æ¥æ‰“å°çš„éƒ¨åˆ†ï¼Œç”±do_saveè´Ÿè´£æ‰“å°
                    # print(rename_log)
            
            return is_rename_count > 0, rename_logs

        # æ£€æŸ¥æ˜¯å¦ä¸ºå‰§é›†å‘½åæ¨¡å¼
        elif task.get("use_episode_naming") and task.get("episode_naming"):
            # ä½¿ç”¨å‰§é›†å‘½åæ¨¡å¼
            episode_pattern = task["episode_naming"]
            regex_pattern = task.get("regex_pattern")
            
            # åˆå§‹åŒ–å˜é‡
            already_renamed_files = set()  # ç”¨äºé˜²æ­¢é‡å¤é‡å‘½å
            
            # è·å–ç›®å½•æ–‡ä»¶åˆ—è¡¨ - æ·»åŠ è¿™è¡Œä»£ç åˆå§‹åŒ–dir_file_list
            savepath = re.sub(r"/{2,}", "/", f"/{task['savepath']}{subdir_path}")
            if not self.savepath_fid.get(savepath):
                # è·¯å¾„å·²å­˜åœ¨ï¼Œç›´æ¥è®¾ç½®fid
                savepath_fids = self.get_fids([savepath])
                if not savepath_fids:
                    # print(f"ä¿å­˜è·¯å¾„ä¸å­˜åœ¨ï¼Œå‡†å¤‡æ–°å»ºï¼š{savepath}")
                    mkdir_result = self.mkdir(savepath)
                    if mkdir_result["code"] == 0:
                        self.savepath_fid[savepath] = mkdir_result["data"]["fid"]
                        # print(f"ä¿å­˜è·¯å¾„æ–°å»ºæˆåŠŸï¼š{savepath}")
                    else:
                        # print(f"ä¿å­˜è·¯å¾„æ–°å»ºå¤±è´¥ï¼š{mkdir_result['message']}")
                        return False, []
                else:
                    self.savepath_fid[savepath] = savepath_fids[0]["fid"]
            
            dir_file_list = self.ls_dir(self.savepath_fid[savepath])
            rename_logs = []  # å…¨å‰§é›†åˆ†æ”¯å…±ç”¨ï¼šè½¬å­˜/è§£å‹åé‡å‘½åä¸æœ¬åœ°æ–‡ä»¶é‡å‘½åçš„æ—¥å¿—
            is_rename_count = 0  # å…¨åˆ†æ”¯å…±ç”¨ï¼Œä¾›æœ€ç»ˆ return (is_rename_count > 0, rename_logs)

            # æ„å»ºç›®æ ‡ç›®å½•ä¸­æ‰€æœ‰æ–‡ä»¶çš„æŸ¥é‡ç´¢å¼•ï¼ˆæŒ‰å¤§å°å’Œä¿®æ”¹æ—¶é—´ï¼‰
            dir_files_map = {}
            for dir_file in dir_file_list:
                if not dir_file["dir"]:  # ä»…å¤„ç†æ–‡ä»¶
                    file_size = dir_file.get("size", 0)
                    file_ext = os.path.splitext(dir_file["file_name"])[1].lower()
                    update_time = dir_file.get("updated_at", 0)
                    
                    # åˆ›å»ºå¤§å°+æ‰©å±•åçš„ç´¢å¼•ï¼Œç”¨äºå¿«é€ŸæŸ¥é‡
                    key = f"{file_size}_{file_ext}"
                    if key not in dir_files_map:
                        dir_files_map[key] = []
                    dir_files_map[key].append({
                        "file_name": dir_file["file_name"],
                        "updated_at": update_time,
                    })
            
            # å®ç°åºå·æå–å‡½æ•°
            def extract_episode_number_local(filename):
                # ä½¿ç”¨å…¨å±€çš„ç»Ÿä¸€æå–å‡½æ•°ï¼Œç›´æ¥ä½¿ç”¨å…¨å±€CONFIG_DATA
                if 'CONFIG_DATA' not in globals() or not CONFIG_DATA:
                    return extract_episode_number(filename)
                return extract_episode_number(filename, config_data=CONFIG_DATA)
                
            # æ‰¾å‡ºå·²å‘½åçš„æ–‡ä»¶åˆ—è¡¨ï¼Œé¿å…é‡å¤è½¬å­˜
            existing_episode_numbers = set()
            for dir_file in dir_file_list:
                if not dir_file["dir"]:
                    try:
                        # å¯¹äºå‰§é›†å‘½åæ¨¡å¼ï¼Œç›´æ¥ä½¿ç”¨extract_episode_numberå‡½æ•°æå–å‰§é›†å·
                        episode_num = extract_episode_number_local(dir_file["file_name"])
                        if episode_num is not None:
                            existing_episode_numbers.add(episode_num)
                    except:
                        pass
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ä»åˆ†äº«é“¾æ¥è·å–æ•°æ®
            if task.get("shareurl"):
                # å¦‚æœä»»åŠ¡å·²ç»æœ‰ shareurl_banï¼Œè¯´æ˜åˆ†äº«å·²å¤±æ•ˆï¼Œä¸éœ€è¦å†å°è¯•è·å–åˆ†äº«è¯¦æƒ…
                if task.get("shareurl_ban"):
                    return False, []
                try:
                    # æå–é“¾æ¥å‚æ•°
                    pwd_id, passcode, pdir_fid, paths = self.extract_url(task["shareurl"])
                    if not pwd_id:
                        print(f"æå–é“¾æ¥å‚æ•°å¤±è´¥ï¼Œè¯·æ£€æŸ¥åˆ†äº«é“¾æ¥æ˜¯å¦æœ‰æ•ˆ")
                        return False, []
                    
                    # è·å–åˆ†äº«è¯¦æƒ…
                    is_sharing, stoken = self.get_stoken(pwd_id, passcode)
                    if not is_sharing:
                        # å¦‚æœä»»åŠ¡å·²ç»æœ‰ shareurl_banï¼Œè¯´æ˜å·²ç»åœ¨ do_save_task ä¸­å¤„ç†è¿‡äº†ï¼Œä¸éœ€è¦é‡å¤è¾“å‡º
                        if not task.get("shareurl_ban"):
                            print(f"åˆ†äº«è¯¦æƒ…è·å–å¤±è´¥: {stoken}")
                        return False, []
                    
                    # è·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨
                    share_file_list = self.get_detail(pwd_id, stoken, pdir_fid)["list"]
                    if not share_file_list:
                        # å¦‚æœä»»åŠ¡å·²ç»æœ‰ shareurl_banï¼Œè¯´æ˜å·²ç»åœ¨ do_save_task ä¸­å¤„ç†è¿‡äº†ï¼Œä¸éœ€è¦é‡å¤è¾“å‡º
                        if not task.get("shareurl_ban"):
                            print("åˆ†äº«ä¸ºç©ºï¼Œæ–‡ä»¶å·²è¢«åˆ†äº«è€…åˆ é™¤")
                        return False, []

                    # åœ¨å‰§é›†å‘½åæ¨¡å¼ä¸­ï¼Œéœ€è¦å…ˆå¯¹æ–‡ä»¶åˆ—è¡¨è¿›è¡Œæ’åºï¼Œç„¶åå†åº”ç”¨èµ·å§‹æ–‡ä»¶è¿‡æ»¤
                    # ä½¿ç”¨å…¨å±€æ’åºå‡½æ•°è¿›è¡Œæ’åºï¼ˆå€’åºï¼Œæœ€æ–°çš„åœ¨å‰ï¼‰
                    share_file_list = sorted(share_file_list, key=sort_file_by_name, reverse=True)

                    # é¢„å…ˆè¿‡æ»¤åˆ†äº«æ–‡ä»¶åˆ—è¡¨ï¼Œå»é™¤å·²å­˜åœ¨çš„æ–‡ä»¶
                    filtered_share_files = []
                    start_fid = task.get("startfid", "")
                    start_file_found = False

                    for share_file in share_file_list:
                        if share_file["dir"]:
                            # å¤„ç†å­ç›®å½•
                            if task.get("update_subdir") and re.search(task["update_subdir"], share_file["file_name"]):
                                filtered_share_files.append(share_file)
                            continue

                        # æ£€æŸ¥æ–‡ä»¶IDæ˜¯å¦å­˜åœ¨äºè½¬å­˜è®°å½•ä¸­
                        file_id = share_file.get("fid", "")
                        if file_id and self.check_file_exists_in_records(file_id, task):
                            # æ–‡ä»¶IDå·²å­˜åœ¨äºè®°å½•ä¸­ï¼Œè·³è¿‡å¤„ç†
                            continue

                        # æ”¹è¿›çš„èµ·å§‹æ–‡ä»¶è¿‡æ»¤é€»è¾‘
                        if start_fid:
                            if share_file["fid"] == start_fid:
                                start_file_found = True
                                # æ‰¾åˆ°èµ·å§‹æ–‡ä»¶ï¼Œä½†ä¸åŒ…å«èµ·å§‹æ–‡ä»¶æœ¬èº«ï¼Œåªå¤„ç†æ¯”å®ƒæ›´æ–°çš„æ–‡ä»¶
                                continue
                            elif start_file_found:
                                # å·²ç»æ‰¾åˆ°èµ·å§‹æ–‡ä»¶ï¼Œè·³è¿‡åç»­ï¼ˆæ›´æ—§çš„ï¼‰æ–‡ä»¶
                                continue
                            # å¦‚æœè¿˜æ²¡æ‰¾åˆ°èµ·å§‹æ–‡ä»¶ï¼Œè¯´æ˜å½“å‰æ–‡ä»¶æ¯”èµ·å§‹æ–‡ä»¶æ›´æ–°ï¼Œéœ€è¦å¤„ç†
                        else:
                            # æ²¡æœ‰è®¾ç½®èµ·å§‹æ–‡ä»¶ï¼Œå¤„ç†æ‰€æœ‰æ–‡ä»¶
                            pass

                        # æ ¹ç›®å½•ä¸‹å·²ç”± do_save_task è§£å‹è¿‡çš„å‹ç¼©åŒ…ä¸å†è½¬å­˜ï¼Œé¿å…é‡æ–°ä¿å­˜ååªè¢«é‡å‘½åè€Œæ®‹ç•™
                        if not subdir_path and self.is_archive_file(share_file["file_name"]):
                            # ä¿æŒåŸç›®å½•ç»“æ„ï¼šç”¨ _auto_extract_subdirsï¼ˆå¦‚ /26ï¼‰åˆ¤æ–­
                            auto_subs = task.get("_auto_extract_subdirs") or []
                            base = os.path.splitext(share_file["file_name"])[0]
                            if f"/{base}" in auto_subs:
                                continue
                            # æ‰å¹³åŒ–æˆ–å…¶å®ƒï¼šç”¨æœ¬æ¬¡ä»»åŠ¡å·²è§£å‹æ–‡ä»¶ååˆ—è¡¨åˆ¤æ–­
                            if share_file["file_name"] in (task.get("_extracted_archive_names") or []):
                                continue
                            
                        # ä»å…±äº«æ–‡ä»¶ä¸­æå–å‰§é›†å·
                        episode_num = extract_episode_number_local(share_file["file_name"])
                        is_duplicate = False
                        
                        # é€šè¿‡æ–‡ä»¶ååˆ¤æ–­æ˜¯å¦å·²å­˜åœ¨ï¼ˆæ–°çš„æŸ¥é‡é€»è¾‘ï¼‰
                        if not is_duplicate:
                            # å¦‚æœæ²¡æœ‰é‡å‘½åï¼Œåˆ¤æ–­åŸæ–‡ä»¶åæ˜¯å¦å·²å­˜åœ¨
                            original_name = share_file["file_name"]
                            # å¦‚æœæœ‰å‰§é›†å·ï¼Œåˆ¤æ–­é‡å‘½ååçš„æ–‡ä»¶åæ˜¯å¦å·²å­˜åœ¨
                            file_ext = os.path.splitext(original_name)[1]
                            
                            # æ„å»ºå¯èƒ½çš„æ–°æ–‡ä»¶å
                            if episode_num is not None:
                                if episode_pattern == "[]":
                                    new_name = f"{episode_num:02d}{file_ext}"
                                else:
                                    new_name = episode_pattern.replace("[]", f"{episode_num:02d}") + file_ext
                                # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                                new_name = apply_subtitle_naming_rule(new_name, task)
                            else:
                                new_name = None
                            
                            # æ ¹æ®æ˜¯å¦å¿½ç•¥åç¼€è¿›è¡Œæ£€æŸ¥
                            if task.get("ignore_extension", False):
                                # å¿½ç•¥åç¼€æ¨¡å¼ï¼šåªæ¯”è¾ƒæ–‡ä»¶åï¼Œä¸æ¯”è¾ƒæ‰©å±•å
                                original_name_base = os.path.splitext(original_name)[0]
                                
                                # æ£€æŸ¥åŸæ–‡ä»¶åæ˜¯å¦å­˜åœ¨
                                exists_original = any(os.path.splitext(dir_file["file_name"])[0] == original_name_base for dir_file in dir_file_list)
                                
                                # å¦‚æœæœ‰æ–°æ–‡ä»¶åï¼Œæ£€æŸ¥æ–°æ–‡ä»¶åæ˜¯å¦å­˜åœ¨
                                exists_new = False
                                if new_name:
                                    new_name_base = os.path.splitext(new_name)[0]
                                    exists_new = any(os.path.splitext(dir_file["file_name"])[0] == new_name_base for dir_file in dir_file_list)
                                
                                is_duplicate = exists_original or exists_new
                            else:
                                # ä¸å¿½ç•¥åç¼€æ¨¡å¼ï¼šæ–‡ä»¶åå’Œæ‰©å±•åéƒ½è¦ä¸€è‡´
                                exists_original = any(dir_file["file_name"] == original_name for dir_file in dir_file_list)
                                
                                # å¦‚æœæœ‰æ–°æ–‡ä»¶åï¼Œæ£€æŸ¥æ–°æ–‡ä»¶åæ˜¯å¦å­˜åœ¨
                                exists_new = False
                                if new_name:
                                    exists_new = any(dir_file["file_name"] == new_name for dir_file in dir_file_list)
                                
                                is_duplicate = exists_original or exists_new
                        
                        # åªå¤„ç†éé‡å¤æ–‡ä»¶
                        if not is_duplicate:
                            filtered_share_files.append(share_file)
                    
                    # å®ç°é«˜çº§æ’åºç®—æ³•
                    def sort_by_episode(file):
                        if file["dir"]:
                            return (float('inf'), 0)
                        
                        filename = file["file_name"]
                        
                        # ä¼˜å…ˆåŒ¹é…S01E01æ ¼å¼
                        match_s_e = re.search(r'[Ss](\d+)[Ee](\d+)', filename)
                        if match_s_e:
                            season = int(match_s_e.group(1))
                            episode = int(match_s_e.group(2))
                            return (season * 1000 + episode, 0)
                        
                        # ä½¿ç”¨ç»Ÿä¸€çš„å‰§é›†æå–å‡½æ•°
                        episode_num = extract_episode_number_local(filename)
                        if episode_num is not None:
                            return (episode_num, 0)
                        
                        # æ— æ³•è¯†åˆ«ï¼Œå›é€€åˆ°ä¿®æ”¹æ—¶é—´æ’åº
                        return (float('inf'), file.get("last_update_at", 0))
                        
                    # è¿‡æ»¤å‡ºæ–‡ä»¶å¹¶æ’åº
                    files_to_process = [f for f in filtered_share_files if not f["dir"]]
                    sorted_files = sorted(files_to_process, key=sort_by_episode)
                    
                    # è¦ä¿å­˜çš„æ–‡ä»¶åˆ—è¡¨
                    need_save_list = []
                    
                    # ç”Ÿæˆæ–‡ä»¶åå¹¶æ·»åŠ åˆ°åˆ—è¡¨
                    for share_file in sorted_files:
                        episode_num = extract_episode_number_local(share_file["file_name"])
                        if episode_num is not None:
                            # ç”Ÿæˆæ–°æ–‡ä»¶å
                            file_ext = os.path.splitext(share_file["file_name"])[1]
                            if episode_pattern == "[]":
                                # å¯¹äºå•ç‹¬çš„[]ï¼Œç›´æ¥ä½¿ç”¨æ•°å­—åºå·ä½œä¸ºæ–‡ä»¶å
                                save_name = f"{episode_num:02d}{file_ext}"
                            else:
                                save_name = episode_pattern.replace("[]", f"{episode_num:02d}") + file_ext
                            
                            # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                            save_name = apply_subtitle_naming_rule(save_name, task)
                            
                            # æ£€æŸ¥è¿‡æ»¤è¯
                            should_filter = False
                            if task.get("filterwords"):
                                # ä½¿ç”¨é«˜çº§è¿‡æ»¤å‡½æ•°æ£€æŸ¥æ–‡ä»¶å
                                temp_file_list = [{"file_name": share_file["file_name"]}]
                                if advanced_filter_files(temp_file_list, task["filterwords"]):
                                    # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶å
                                    temp_save_list = [{"file_name": save_name}]
                                    if not advanced_filter_files(temp_save_list, task["filterwords"]):
                                        should_filter = True
                                else:
                                    should_filter = True
                            
                            # åªå¤„ç†ä¸éœ€è¦è¿‡æ»¤çš„æ–‡ä»¶
                            if not should_filter:
                                # æ·»åŠ åˆ°ä¿å­˜åˆ—è¡¨
                                share_file["save_name"] = save_name
                                share_file["original_name"] = share_file["file_name"]
                                need_save_list.append(share_file)
                        else:
                            # æ— æ³•æå–é›†å·ï¼Œä½¿ç”¨åŸæ–‡ä»¶åï¼ˆä»ç„¶æ£€æŸ¥è¿‡æ»¤è¯ï¼‰
                            # æ£€æŸ¥è¿‡æ»¤è¯
                            should_filter = False
                            if task.get("filterwords"):
                                # ä½¿ç”¨é«˜çº§è¿‡æ»¤å‡½æ•°æ£€æŸ¥æ–‡ä»¶å
                                temp_file_list = [{"file_name": share_file["file_name"]}]
                                if not advanced_filter_files(temp_file_list, task["filterwords"]):
                                    should_filter = True
                            
                            # åªå¤„ç†ä¸éœ€è¦è¿‡æ»¤çš„æ–‡ä»¶
                            if not should_filter:
                                share_file["save_name"] = share_file["file_name"]
                                share_file["original_name"] = share_file["file_name"]
                                need_save_list.append(share_file)
                    
                    # è‹¥å½“å‰å­ç›®å½•æ¥è‡ªè‡ªåŠ¨è§£å‹ï¼ˆ_auto_extract_subdirsï¼‰ï¼Œåˆ™ä¸å†ä¿å­˜ä¸è§£å‹ï¼Œä»…åšé‡å‘½å
                    auto_extract_subdirs_ep = task.get("_auto_extract_subdirs") or []
                    is_auto_extracted_subdir_ep = subdir_path and subdir_path in auto_extract_subdirs_ep
                    
                    if is_auto_extracted_subdir_ep:
                        # è‡ªåŠ¨è§£å‹å­ç›®å½•ï¼šåŸºäºç°æœ‰æ–‡ä»¶æ„å»º need_save_listï¼Œä»…åšé‡å‘½å
                        need_save_list = []
                        for f in dir_file_list:
                            if not f.get("dir", False):
                                fname = f["file_name"]
                                ep_num = extract_episode_number_local(fname)
                                if ep_num is not None:
                                    ext = os.path.splitext(fname)[1]
                                    save_name = episode_pattern.replace("[]", f"{ep_num:02d}") + ext if episode_pattern != "[]" else f"{ep_num:02d}{ext}"
                                    save_name = apply_subtitle_naming_rule(save_name, task)
                                else:
                                    save_name = fname
                                need_save_list.append({"file_name": fname, "original_name": fname, "save_name": save_name})
                    
                    # ä¿å­˜æ–‡ä»¶ï¼ˆè‡ªåŠ¨è§£å‹äº§ç”Ÿçš„å­ç›®å½•è·³è¿‡ä¿å­˜ä¸è§£å‹ï¼‰ï¼Œæˆ–ä»…æ‰§è¡Œé‡å‘½å
                    run_rename_block = False
                    if need_save_list:
                        if is_auto_extracted_subdir_ep:
                            run_rename_block = True
                        else:
                            fid_list = [item["fid"] for item in need_save_list]
                            fid_token_list = [item["share_fid_token"] for item in need_save_list]
                            save_file_return = self.save_file(
                                fid_list, fid_token_list, self.savepath_fid[savepath], pwd_id, stoken
                            )
                            if save_file_return["code"] == 0:
                                task_id = save_file_return["data"]["task_id"]
                                query_task_return = self.query_task(task_id)
                                
                                if query_task_return["code"] == 0:
                                    # è¿›è¡Œé‡å‘½åæ“ä½œï¼Œç¡®ä¿æ–‡ä»¶æŒ‰ç…§é¢„è§ˆåç§°ä¿å­˜
                                    time.sleep(1)  # ç­‰å¾…æ–‡ä»¶ä¿å­˜å®Œæˆ
                                    
                                    # æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨è§£å‹å‹ç¼©æ–‡ä»¶
                                    # æ ¹ç›®å½•ï¼ˆsubdir_path ä¸ºç©ºï¼‰çš„è§£å‹å·²åœ¨ do_save_task ä¸­æ‰§è¡Œï¼Œæ­¤å¤„ä»…å¤„ç†å­ç›®å½•ï¼Œé¿å…åŒä¸€å‹ç¼©åŒ…è§£å‹ä¸¤æ¬¡
                                    # è‹¥å½“å‰å­ç›®å½•æ¥è‡ªè‡ªåŠ¨è§£å‹ï¼ˆ_auto_extract_subdirsï¼‰ï¼Œåˆ™ä¸å†è§£å‹ï¼Œé¿å…é‡å¤è§£å‹å¯¼è‡´åµŒå¥—
                                    auto_extract_subdirs = task.get("_auto_extract_subdirs") or []
                                    is_auto_extracted_subdir = subdir_path and subdir_path in auto_extract_subdirs
                                    
                                    auto_extract_mode = task.get("auto_extract_archive", "disabled")
                                    if auto_extract_mode != "disabled" and subdir_path and not is_auto_extracted_subdir:
                                        # è·å–åˆšè½¬å­˜çš„æ–‡ä»¶åˆ—è¡¨
                                        fresh_files = self.ls_dir(self.savepath_fid[savepath])
                                        
                                        # ç”¨äºå®‰å…¨æ›´æ–° need_save_list çš„ä¸´æ—¶åˆ—è¡¨
                                        items_to_remove_ep = []
                                        items_to_add_ep = []
                                        
                                        # æ£€æŸ¥æ˜¯å¦æœ‰å‹ç¼©æ–‡ä»¶éœ€è¦è§£å‹
                                        for saved_item in need_save_list:
                                            if not saved_item.get("dir", False) and self.is_archive_file(saved_item["file_name"]):
                                                # åœ¨ç›®æ ‡ç›®å½•ä¸­æ‰¾åˆ°å¯¹åº”çš„å‹ç¼©æ–‡ä»¶
                                                archive_file = None
                                                for f in fresh_files:
                                                    if f["file_name"] == saved_item["file_name"]:
                                                        archive_file = f
                                                        break
                                                
                                                if archive_file:
                                                    # æ‰§è¡Œè‡ªåŠ¨è§£å‹
                                                    extract_result = self.process_auto_extract(
                                                        archive_fid=archive_file["fid"],
                                                        archive_name=archive_file["file_name"],
                                                        target_pdir_fid=self.savepath_fid[savepath],
                                                        extract_mode=auto_extract_mode,
                                                        task=task
                                                    )
                                                    
                                                    if extract_result.get("success"):
                                                        # åªæœ‰åœ¨å‹ç¼©æ–‡ä»¶ç¡®å®è¢«åˆ é™¤æ—¶ï¼Œæ‰ä»åˆ—è¡¨ä¸­ç§»é™¤å®ƒ
                                                        if extract_result.get("archive_deleted", False):
                                                            items_to_remove_ep.append(saved_item)
                                                        # æ·»åŠ è§£å‹åçš„æ–‡ä»¶åˆ°å¾…æ·»åŠ åˆ—è¡¨
                                                        for moved_file in extract_result.get("moved_files", []):
                                                            # å…³é”®ä¿®å¤ï¼šä¸ºè§£å‹å‡ºçš„æ–‡ä»¶ç”Ÿæˆæ­£ç¡®çš„ save_nameï¼ˆæ ¹æ®å‰§é›†å‘½åè§„åˆ™ï¼‰
                                                            moved_file_name = moved_file["file_name"]
                                                            episode_num = extract_episode_number_local(moved_file_name)
                                                            if episode_num is not None:
                                                                # æ ¹æ®å‰§é›†å‘½åè§„åˆ™ç”Ÿæˆ save_name
                                                                file_ext = os.path.splitext(moved_file_name)[1]
                                                                if episode_pattern == "[]":
                                                                    save_name = f"{episode_num:02d}{file_ext}"
                                                                else:
                                                                    save_name = episode_pattern.replace("[]", f"{episode_num:02d}") + file_ext
                                                                # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                                                                save_name = apply_subtitle_naming_rule(save_name, task)
                                                            else:
                                                                # æ— æ³•æå–å‰§é›†å·ï¼Œä½¿ç”¨åŸæ–‡ä»¶å
                                                                save_name = moved_file_name
                                                            
                                                            items_to_add_ep.append({
                                                                "fid": moved_file["fid"],
                                                                "file_name": moved_file_name,
                                                                "original_name": moved_file_name,
                                                                "save_name": save_name,
                                                                "size": moved_file["size"],
                                                                "dir": False,
                                                                "_from_extraction": True,
                                                            })
                                        
                                        # å‰§é›†æ¨¡å¼ä¸‹æ­¤å¤„ä¹Ÿä¼šç§»é™¤å·²è§£å‹çš„å‹ç¼©åŒ…ï¼ŒåŒæ ·ä¿ç•™è½¬å­˜è®°å½•ï¼ˆå…¶å®ƒå‘½åæ¨¡å¼åœ¨ do_save_task ä¸­å·²ç»Ÿä¸€è®°å½•ï¼‰
                                        for item in items_to_remove_ep:
                                            self.create_transfer_record(
                                                task=task,
                                                file_info=item,
                                                renamed_to=item.get("file_name", item.get("save_name", ""))
                                            )
                                        # åº”ç”¨è§£å‹åçš„åˆ—è¡¨æ›´æ–°
                                        for item in items_to_remove_ep:
                                            if item in need_save_list:
                                                need_save_list.remove(item)
                                        need_save_list.extend(items_to_add_ep)
                                    
                                    # ä¿å­˜è½¬å­˜è®°å½•åˆ°æ•°æ®åº“ï¼ˆä»…éè‡ªåŠ¨è§£å‹å­ç›®å½•ï¼‰
                                    if not is_auto_extracted_subdir:
                                        for saved_item in need_save_list:
                                            if not saved_item.get("dir", False):  # åªè®°å½•æ–‡ä»¶ï¼Œä¸è®°å½•æ–‡ä»¶å¤¹
                                                # è½¬å­˜æ—¶å…ˆç”¨åŸæ–‡ä»¶åè®°å½•ï¼Œé‡å‘½ååå†æ›´æ–°
                                                self.create_transfer_record(
                                                    task=task,
                                                    file_info=saved_item,
                                                    renamed_to=saved_item["file_name"]  # è½¬å­˜æ—¶ä½¿ç”¨åŸæ–‡ä»¶å
                                                )
                                    
                                    run_rename_block = True
                                else:
                                    err_msg = query_task_return["message"]
                                    add_notify(f"âŒã€Š{task['taskname']}ã€‹è½¬å­˜å¤±è´¥: {err_msg}\n")
                            else:
                                add_notify(f"âŒã€Š{task['taskname']}ã€‹è½¬å­˜å¤±è´¥: {save_file_return['message']}\n")
                    # é‡å‘½åé€»è¾‘ï¼šè‡ªåŠ¨è§£å‹å­ç›®å½•æˆ–ä¿å­˜æˆåŠŸåæ‰§è¡Œ
                    if run_rename_block:
                        # åˆ·æ–°ç›®å½•åˆ—è¡¨ä»¥è·å–æ–°ä¿å­˜çš„æ–‡ä»¶
                        fresh_dir_file_list = self.ls_dir(self.savepath_fid[savepath])
                        
                        # åˆ›å»ºä¸€ä¸ªæ˜ å°„æ¥å­˜å‚¨åŸå§‹æ–‡ä»¶ååˆ°ä¿å­˜é¡¹çš„æ˜ å°„
                        original_name_to_item = {}
                        for saved_item in need_save_list:
                            # ä½¿ç”¨æ–‡ä»¶åå‰ç¼€ä½œä¸ºé”®ï¼Œå¤„ç†å¯èƒ½çš„æ–‡ä»¶åå˜åŒ–
                            file_prefix = saved_item["original_name"].split(".")[0]
                            original_name_to_item[file_prefix] = saved_item
                            # åŒæ—¶ä¿å­˜å®Œæ•´æ–‡ä»¶åçš„æ˜ å°„
                            original_name_to_item[saved_item["original_name"]] = saved_item
                        
                        # åˆ›å»ºä¸€ä¸ªåˆ—è¡¨æ¥æ”¶é›†æ‰€æœ‰é‡å‘½åæ“ä½œ
                        rename_operations = []
                        
                        # é¦–å…ˆå°è¯•ä½¿ç”¨å‰§é›†å·è¿›è¡Œæ™ºèƒ½åŒ¹é…
                        for dir_file in fresh_dir_file_list:
                            if dir_file["dir"]:
                                continue
                            # ä»æ–‡ä»¶åä¸­æå–å‰§é›†å·
                            episode_num = extract_episode_number_local(dir_file["file_name"])
                            if episode_num is None:
                                continue
                            
                            # æŸ¥æ‰¾å¯¹åº”çš„ç›®æ ‡æ–‡ä»¶
                            for saved_item in need_save_list:
                                saved_episode_num = extract_episode_number_local(saved_item["original_name"])
                                if saved_episode_num == episode_num:
                                    # å…³é”®ä¿®å¤ï¼šé˜²æ­¢å°†è§†é¢‘æ–‡ä»¶é”™è¯¯åŒ¹é…åˆ°å‹ç¼©æ–‡ä»¶é¡¹
                                    if self.is_archive_file(dir_file["file_name"]) != self.is_archive_file(saved_item["original_name"]):
                                        continue
                                    target_name = saved_item["save_name"]
                                    if target_name not in [f["file_name"] for f in fresh_dir_file_list]:
                                        rename_operations.append((dir_file, target_name, episode_num))
                                        break
                                    else:
                                        name_base, ext = os.path.splitext(target_name)
                                        alt_name = f"{name_base} ({episode_num}){ext}"
                                        if alt_name not in [f["file_name"] for f in fresh_dir_file_list]:
                                            rename_operations.append((dir_file, alt_name, episode_num))
                                            break
                        
                        # å¯¹äºæœªèƒ½é€šè¿‡å‰§é›†å·åŒ¹é…çš„æ–‡ä»¶ï¼Œå°è¯•ä½¿ç”¨æ–‡ä»¶ååŒ¹é…
                        for dir_file in fresh_dir_file_list:
                            if dir_file["dir"]:
                                continue
                            if any(op[0]["fid"] == dir_file["fid"] for op in rename_operations):
                                continue
                            if dir_file["file_name"] in original_name_to_item:
                                saved_item = original_name_to_item[dir_file["file_name"]]
                                if self.is_archive_file(dir_file["file_name"]) != self.is_archive_file(saved_item["original_name"]):
                                    continue
                                target_name = saved_item["save_name"]
                                episode_num = extract_episode_number_local(saved_item["original_name"]) or 9999
                                if target_name not in [f["file_name"] for f in fresh_dir_file_list]:
                                    rename_operations.append((dir_file, target_name, episode_num))
                                continue
                            dir_file_prefix = dir_file["file_name"].split(".")[0]
                            for prefix, saved_item in list(original_name_to_item.items()):
                                if prefix in dir_file_prefix or dir_file_prefix in prefix:
                                    if self.is_archive_file(dir_file["file_name"]) != self.is_archive_file(saved_item["original_name"]):
                                        continue
                                    target_name = saved_item["save_name"]
                                    episode_num = extract_episode_number_local(saved_item["original_name"]) or 9999
                                    if target_name not in [f["file_name"] for f in fresh_dir_file_list]:
                                        rename_operations.append((dir_file, target_name, episode_num))
                                        original_name_to_item.pop(prefix, None)
                                        break
                        
                        # æŒ‰å‰§é›†å·æ’åºé‡å‘½åæ“ä½œ
                        rename_operations.sort(key=lambda x: x[2])
                        
                        # æ‰§è¡Œæ’åºåçš„é‡å‘½åæ“ä½œï¼Œæ”¶é›†åˆ°åˆ†æ”¯å…±ç”¨çš„ rename_logs
                        renamed_count = 0
                        for dir_file, target_name, _ in rename_operations:
                            rename_result = self.rename(dir_file["fid"], target_name)
                            if rename_result["code"] == 0:
                                log_message = f"é‡å‘½å: {dir_file['file_name']} â†’ {target_name}"
                                rename_logs.append(log_message)
                                renamed_count += 1
                                for df in fresh_dir_file_list:
                                    if df["fid"] == dir_file["fid"]:
                                        df["file_name"] = target_name
                                        break
                            else:
                                error_log = f"é‡å‘½å: {dir_file['file_name']} â†’ {target_name} å¤±è´¥ï¼Œ{rename_result['message']}"
                                rename_logs.append(error_log)
                        is_rename_count += renamed_count
                        
                        # æ›´æ–°dir_file_listä»¥åŒ…å«æ–°è½¬å­˜çš„æ–‡ä»¶
                        dir_file_list = self.ls_dir(self.savepath_fid[savepath])
                    else:
                        # print("æ²¡æœ‰éœ€è¦ä¿å­˜çš„æ–°æ–‡ä»¶")
                        pass
                except Exception as e:
                    add_notify(f"âŒã€Š{task['taskname']}ã€‹å¤„ç†åˆ†äº«é“¾æ¥æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}\n")

            # å¯¹æœ¬åœ°å·²æœ‰æ–‡ä»¶è¿›è¡Œé‡å‘½åï¼ˆå³ä½¿æ²¡æœ‰åˆ†äº«é“¾æ¥æˆ–å¤„ç†å¤±è´¥ä¹Ÿæ‰§è¡Œï¼‰
            renamed_files = {}
            
            # åº”ç”¨è¿‡æ»¤è¯è¿‡æ»¤ï¼ˆä¿®å¤bugï¼šä¸ºæœ¬åœ°æ–‡ä»¶é‡å‘½åæ·»åŠ è¿‡æ»¤è§„åˆ™ï¼‰
            if task.get("filterwords"):
                # è®°å½•è¿‡æ»¤å‰çš„æ–‡ä»¶æ€»æ•°
                original_total_count = len(dir_file_list)
                
                # ä½¿ç”¨é«˜çº§è¿‡æ»¤å‡½æ•°å¤„ç†ä¿ç•™è¯å’Œè¿‡æ»¤è¯
                dir_file_list = advanced_filter_files(dir_file_list, task["filterwords"])
            
            # ä½¿ç”¨ä¸€ä¸ªåˆ—è¡¨æ”¶é›†æ‰€æœ‰éœ€è¦é‡å‘½åçš„æ“ä½œï¼ˆrename_logs å·²åœ¨åˆ†æ”¯å¼€å¤´åˆå§‹åŒ–ï¼Œæ­¤å¤„åªè¿½åŠ ï¼‰
            rename_operations = []
            
            # ç­›é€‰å‡ºéœ€è¦é‡å‘½åçš„æ–‡ä»¶
            for dir_file in dir_file_list:
                if dir_file["dir"]:
                    continue

                # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å‘½å
                episode_num = extract_episode_number_local(dir_file["file_name"])
                if episode_num is not None:
                    # æ ¹æ®å‰§é›†å‘½åæ¨¡å¼ç”Ÿæˆç›®æ ‡æ–‡ä»¶å
                    file_ext = os.path.splitext(dir_file["file_name"])[1]
                    if episode_pattern == "[]":
                        # ä½¿ç”¨å®Œæ•´çš„å‰§é›†å·è¯†åˆ«é€»è¾‘ï¼Œè€Œä¸æ˜¯ç®€å•çš„çº¯æ•°å­—åˆ¤æ–­
                        # ç”Ÿæˆæ–°æ–‡ä»¶å
                        new_name = f"{episode_num:02d}{file_ext}"
                        # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                        new_name = apply_subtitle_naming_rule(new_name, task)
                        # åªæœ‰å½“å½“å‰æ–‡ä»¶åä¸ç›®æ ‡æ–‡ä»¶åä¸åŒæ—¶æ‰é‡å‘½å
                        if dir_file["file_name"] != new_name:
                            rename_operations.append((dir_file, new_name, episode_num))
                    else:
                        # ç”Ÿæˆç›®æ ‡æ–‡ä»¶å
                        new_name = episode_pattern.replace("[]", f"{episode_num:02d}") + file_ext
                        # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                        new_name = apply_subtitle_naming_rule(new_name, task)
                        # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦å·²ç»ç¬¦åˆç›®æ ‡æ ¼å¼
                        if dir_file["file_name"] != new_name:
                            rename_operations.append((dir_file, new_name, episode_num))
            
            # æŒ‰å‰§é›†å·æ’åº
            rename_operations.sort(key=lambda x: x[2])

            # æ‰§è¡Œé‡å‘½åæ“ä½œï¼Œä½†ä¸ç«‹å³æ‰“å°æ—¥å¿—
            for dir_file, new_name, _ in rename_operations:
                # é˜²æ­¢é‡åï¼Œæ”¯æŒå¿½ç•¥åç¼€é€‰é¡¹
                name_conflict = False
                if task.get("ignore_extension", False):
                    # å¿½ç•¥åç¼€æ¨¡å¼ï¼šåªæ¯”è¾ƒæ–‡ä»¶åéƒ¨åˆ†ï¼Œä¸æ¯”è¾ƒæ‰©å±•å
                    new_name_base = os.path.splitext(new_name)[0]
                    name_conflict = any(
                        os.path.splitext(f["file_name"])[0] == new_name_base for f in dir_file_list
                    )
                else:
                    # ä¸å¿½ç•¥åç¼€æ¨¡å¼ï¼šå®Œæ•´æ–‡ä»¶åå¿…é¡»åŒ¹é…
                    name_conflict = new_name in [f["file_name"] for f in dir_file_list]

                if not name_conflict:
                    try:
                        rename_return = self.rename(dir_file["fid"], new_name)
                        if rename_return["code"] == 0:
                            # æ”¶é›†æ—¥å¿—ä½†ä¸æ‰“å°
                            rename_logs.append(f"é‡å‘½å: {dir_file['file_name']} â†’ {new_name}")
                            is_rename_count += 1
                            # æ›´æ–°dir_file_listä¸­çš„æ–‡ä»¶åï¼Œé˜²æ­¢åç»­é‡ååˆ¤æ–­å‡ºé”™
                            for df in dir_file_list:
                                if df["fid"] == dir_file["fid"]:
                                    df["file_name"] = new_name
                                    break
                            # è®°å½•å·²é‡å‘½åçš„æ–‡ä»¶
                            already_renamed_files.add(new_name)
                            
                            # ä¸åœ¨è¿™é‡Œç›´æ¥è°ƒç”¨update_transfer_recordï¼Œè€Œæ˜¯åœ¨do_saveä¸­ç»Ÿä¸€å¤„ç†
                            # self.update_transfer_record(
                            #     task=task,
                            #     file_info=dir_file,
                            #     renamed_to=new_name
                            # )
                        else:
                            # æ”¶é›†é”™è¯¯æ—¥å¿—ä½†ä¸æ‰“å°
                            error_msg = rename_return.get("message", "æœªçŸ¥é”™è¯¯")
                            
                            # åˆ·æ–°ç›®å½•åˆ—è¡¨ï¼Œæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å®é™…å·²é‡å‘½åæˆåŠŸ
                            fresh_dir_file_list = self.ls_dir(self.savepath_fid[savepath])
                            target_exists = any(df["file_name"] == new_name for df in fresh_dir_file_list)
                            
                            # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œè¯´æ˜é‡å‘½åå·²ç»æˆåŠŸæˆ–æœ‰åŒåæ–‡ä»¶
                            if target_exists:
                                # å¯¹äºå·²ç»æˆåŠŸçš„æƒ…å†µï¼Œæˆ‘ä»¬ä»ç„¶è®°å½•æˆåŠŸ
                                rename_logs.append(f"é‡å‘½å: {dir_file['file_name']} â†’ {new_name}")
                                is_rename_count += 1
                                # æ›´æ–°dir_file_listä¸­çš„æ–‡ä»¶å
                                for df in dir_file_list:
                                    if df["fid"] == dir_file["fid"]:
                                        df["file_name"] = new_name
                                        break
                                # è®°å½•å·²é‡å‘½åçš„æ–‡ä»¶
                                already_renamed_files.add(new_name)
                            else:
                                # çœŸæ­£çš„é”™è¯¯æƒ…å†µ
                                # æ³¨é‡Šæ‰é”™è¯¯æ¶ˆæ¯è®°å½•
                                # rename_logs.append(f"é‡å‘½å: {dir_file['file_name']} â†’ {new_name} å¤±è´¥ï¼Œ{error_msg}")
                                pass
                    except Exception as e:
                        # æ”¶é›†é”™è¯¯æ—¥å¿—ä½†ä¸æ‰“å°
                        # æ³¨é‡Šæ‰å¼‚å¸¸ä¿¡æ¯è®°å½•
                        # rename_logs.append(f"é‡å‘½åå‡ºé”™: {dir_file['file_name']} â†’ {new_name}ï¼Œé”™è¯¯ï¼š{str(e)}")
                        pass
                else:
                    # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å·²ç»å­˜åœ¨ä¸”æ˜¯æˆ‘ä»¬æƒ³è¦é‡å‘½åçš„ç»“æœ
                    # è¿™å¯èƒ½æ˜¯å› ä¸ºä¹‹å‰çš„æ“ä½œå·²ç»æˆåŠŸï¼Œä½†APIè¿”å›äº†é”™è¯¯
                    fresh_dir_file_list = self.ls_dir(self.savepath_fid[savepath])
                    if any(df["file_name"] == new_name and df["fid"] != dir_file["fid"] for df in fresh_dir_file_list):
                        # çœŸæ­£å­˜åœ¨åŒåæ–‡ä»¶
                        # æ³¨é‡Šæ‰åŒåæ–‡ä»¶è­¦å‘Šä¿¡æ¯è®°å½•
                        # rename_logs.append(f"é‡å‘½å: {dir_file['file_name']} â†’ {new_name} å¤±è´¥ï¼Œç›®æ ‡æ–‡ä»¶åå·²å­˜åœ¨")
                        pass
                    else:
                        # ç›®æ ‡æ–‡ä»¶å¯èƒ½æ˜¯ä¹‹å‰æ“ä½œçš„ç»“æœï¼Œä¸æ˜¾ç¤ºé”™è¯¯
                        pass
            
            # è¿”å›é‡å‘½åæ—¥å¿—å’ŒæˆåŠŸæ ‡å¿—
            return (is_rename_count > 0), rename_logs

        # æ­£åˆ™æ¨¡å¼æˆ–æ— ç‰¹æ®Šå‘½åæ¨¡å¼ï¼Œç›´æ¥è¿”å›ç©ºç»“æœ
        else:
            # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åˆ™æ¨¡å¼çš„é…ç½®
            pattern = task.get("pattern", "")
            replace = task.get("replace", "")
            
            # å¦‚æœæ²¡æœ‰è®¾ç½®æ­£åˆ™åŒ¹é…æ¨¡å¼ï¼Œç›´æ¥è¿”å›ç©ºç»“æœ
            if not pattern:
                return False, []
            
            # è·å–é­”æ³•æ­£åˆ™å¤„ç†åçš„çœŸå®è§„åˆ™
            pattern, replace = self.magic_regex_func(pattern, replace, task["taskname"])
            
            # è·å–ç›®å½•æ–‡ä»¶åˆ—è¡¨
            savepath = re.sub(r"/{2,}", "/", f"/{task['savepath']}{subdir_path}")
            if not self.savepath_fid.get(savepath):
                # è·¯å¾„ä¸å­˜åœ¨ï¼Œåˆ›å»ºæˆ–è·å–fid
                savepath_fids = self.get_fids([savepath])
                if not savepath_fids:
                    # print(f"ä¿å­˜è·¯å¾„ä¸å­˜åœ¨ï¼Œå‡†å¤‡æ–°å»ºï¼š{savepath}")
                    mkdir_result = self.mkdir(savepath)
                    if mkdir_result["code"] == 0:
                        self.savepath_fid[savepath] = mkdir_result["data"]["fid"]
                        # print(f"ä¿å­˜è·¯å¾„æ–°å»ºæˆåŠŸï¼š{savepath}")
                    else:
                        # print(f"ä¿å­˜è·¯å¾„æ–°å»ºå¤±è´¥ï¼š{mkdir_result['message']}")
                        return False, []
                else:
                    self.savepath_fid[savepath] = savepath_fids[0]["fid"]
            
            # è·å–ç›®å½•ä¸­çš„æ–‡ä»¶åˆ—è¡¨
            dir_file_list = self.ls_dir(self.savepath_fid[savepath])
            
            # åº”ç”¨è¿‡æ»¤è¯è¿‡æ»¤ï¼ˆä¿®å¤bugï¼šä¸ºæœ¬åœ°æ–‡ä»¶é‡å‘½åæ·»åŠ è¿‡æ»¤è§„åˆ™ï¼‰
            if task.get("filterwords"):
                # è®°å½•è¿‡æ»¤å‰çš„æ–‡ä»¶æ€»æ•°
                original_total_count = len(dir_file_list)
                
                # ä½¿ç”¨é«˜çº§è¿‡æ»¤å‡½æ•°å¤„ç†ä¿ç•™è¯å’Œè¿‡æ»¤è¯
                dir_file_list = advanced_filter_files(dir_file_list, task["filterwords"])
            
            # ä½¿ç”¨ä¸€ä¸ªåˆ—è¡¨æ”¶é›†æ‰€æœ‰éœ€è¦é‡å‘½åçš„æ“ä½œ
            rename_operations = []
            rename_logs = []  # æ”¶é›†é‡å‘½åæ—¥å¿—
            is_rename_count = 0
            
            # éå†ç›®å½•ä¸­çš„æ–‡ä»¶ï¼Œæ‰¾å‡ºç¬¦åˆæ­£åˆ™æ¡ä»¶çš„
            for dir_file in dir_file_list:
                if dir_file["dir"]:
                    continue  # è·³è¿‡æ–‡ä»¶å¤¹
                
                # åº”ç”¨æ­£åˆ™è¡¨è¾¾å¼
                try:
                    # åœ¨åº”ç”¨æ­£åˆ™è¡¨è¾¾å¼å‰ï¼Œå…ˆæ£€æŸ¥æ–‡ä»¶åæ˜¯å¦å·²ç»æ˜¯ç¬¦åˆç›®æ ‡æ ¼å¼çš„
                    orig_name = dir_file["file_name"]
                    
                    # åº”ç”¨æ­£åˆ™è¡¨è¾¾å¼è·å–ç›®æ ‡æ–‡ä»¶å
                    new_name = re.sub(pattern, replace, orig_name)
                    
                    # åº”ç”¨å­—å¹•å‘½åè§„åˆ™
                    new_name = apply_subtitle_naming_rule(new_name, task)
                    
                    # å¦‚æœæ›¿æ¢åçš„æ–‡ä»¶åæ²¡æœ‰å˜åŒ–ï¼Œè·³è¿‡
                    if new_name == orig_name:
                        continue
                    
                    # å¦‚æœæ›¿æ¢åçš„æ–‡ä»¶åæ˜¯ä»»åŠ¡åçš„é‡å¤åµŒå¥—ï¼Œè·³è¿‡
                    # ä¾‹å¦‚ï¼šå¯¹äº"ä½ å¥½ï¼Œæ˜ŸæœŸå…­ - 2025-04-05.mp4" -> "ä½ å¥½ï¼Œæ˜ŸæœŸå…­ - ä½ å¥½ï¼Œæ˜ŸæœŸå…­ - 2025-04-05.mp4"
                    if " - " in new_name:
                        parts = new_name.split(" - ")
                        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤çš„éƒ¨åˆ†
                        if len(parts) >= 2 and parts[0] == parts[1]:
                            continue
                        
                        # å¦ä¸€ç§æƒ…å†µï¼šæ£€æŸ¥å‰ç¼€æ˜¯å¦å·²å­˜åœ¨äºæ–‡ä»¶åä¸­
                        prefix = replace.split(" - ")[0] if " - " in replace else ""
                        if prefix and prefix in orig_name:
                            # å¦‚æœåŸå§‹æ–‡ä»¶åå·²ç»åŒ…å«äº†éœ€è¦æ·»åŠ çš„å‰ç¼€ï¼Œè·³è¿‡é‡å‘½å
                            continue
                            
                    # å¦‚æœæ–‡ä»¶åå‘ç”Ÿå˜åŒ–ï¼Œéœ€è¦é‡å‘½å
                    if new_name != orig_name:
                        rename_operations.append((dir_file, new_name))
                except Exception as e:
                    print(f"æ­£åˆ™æ›¿æ¢å‡ºé”™: {dir_file['file_name']}ï¼Œé”™è¯¯: {str(e)}")
            
            # æŒ‰åŸå§‹æ–‡ä»¶åå­—æ¯é¡ºåºæ’åºï¼Œä½¿é‡å‘½åæ“ä½œæœ‰åºè¿›è¡Œ
            # rename_operations.sort(key=lambda x: x[0]["file_name"])
            
            # ä¿®æ”¹ä¸ºæŒ‰æ—¥æœŸæˆ–æ•°å­—æ’åºï¼ˆå¤ç”¨ä¸æ–‡ä»¶æ ‘ç›¸åŒçš„æ’åºé€»è¾‘ï¼‰
            def extract_sort_value(file_name):
                # ä½¿ç”¨å…¨å±€æ’åºå‡½æ•°
                return sort_file_by_name(file_name)
            
            # æŒ‰ç›®æ ‡æ–‡ä»¶åä¸­çš„æ—¥æœŸæˆ–æ•°å­—è¿›è¡Œæ’åºï¼Œä¸é¡ºåºå‘½åå’Œå‰§é›†å‘½åæ¨¡å¼ä¿æŒä¸€è‡´
            rename_operations.sort(key=lambda x: extract_sort_value(x[1]))
            
            # æ‰§è¡Œé‡å‘½åæ“ä½œï¼Œå¹¶æ”¶é›†æ—¥å¿—
            already_renamed_files = set()  # ç”¨äºé˜²æ­¢é‡å¤é‡å‘½å
            for dir_file, new_name in rename_operations:
                # æ£€æŸ¥æ˜¯å¦ä¼šå¯¼è‡´é‡åï¼Œæ”¯æŒå¿½ç•¥åç¼€é€‰é¡¹
                name_conflict = False
                if task.get("ignore_extension", False):
                    # å¿½ç•¥åç¼€æ¨¡å¼ï¼šåªæ¯”è¾ƒæ–‡ä»¶åéƒ¨åˆ†ï¼Œä¸æ¯”è¾ƒæ‰©å±•å
                    new_name_base = os.path.splitext(new_name)[0]
                    name_conflict = any(
                        os.path.splitext(f["file_name"])[0] == new_name_base for f in dir_file_list
                    ) or any(
                        os.path.splitext(existing_name)[0] == new_name_base for existing_name in already_renamed_files
                    )
                else:
                    # ä¸å¿½ç•¥åç¼€æ¨¡å¼ï¼šå®Œæ•´æ–‡ä»¶åå¿…é¡»åŒ¹é…
                    name_conflict = new_name in [f["file_name"] for f in dir_file_list] or new_name in already_renamed_files

                if not name_conflict:
                    try:
                        rename_return = self.rename(dir_file["fid"], new_name)
                        if rename_return["code"] == 0:
                            # æ”¶é›†æ—¥å¿—ä½†ä¸æ‰“å°
                            log_message = f"é‡å‘½å: {dir_file['file_name']} â†’ {new_name}"
                            rename_logs.append(log_message)
                            is_rename_count += 1
                            # æ›´æ–°dir_file_listä¸­çš„æ–‡ä»¶åï¼Œé˜²æ­¢åç»­é‡ååˆ¤æ–­å‡ºé”™
                            for df in dir_file_list:
                                if df["fid"] == dir_file["fid"]:
                                    df["file_name"] = new_name
                                    break
                            # è®°å½•å·²é‡å‘½åçš„æ–‡ä»¶
                            already_renamed_files.add(new_name)
                        else:
                            # æ”¶é›†é”™è¯¯æ—¥å¿—ä½†ä¸æ‰“å°
                            error_msg = rename_return.get("message", "æœªçŸ¥é”™è¯¯")
                            error_log = f"é‡å‘½å: {dir_file['file_name']} â†’ {new_name} å¤±è´¥ï¼Œ{error_msg}"
                            rename_logs.append(error_log)
                    except Exception as e:
                        # æ”¶é›†é”™è¯¯æ—¥å¿—ä½†ä¸æ‰“å°
                        error_log = f"é‡å‘½åå‡ºé”™: {dir_file['file_name']} â†’ {new_name}ï¼Œé”™è¯¯: {str(e)}"
                        rename_logs.append(error_log)
                else:
                    # é‡åè­¦å‘Šä½†ä¸æ‰“å°
                    warning_log = f"é‡å‘½å: {dir_file['file_name']} â†’ {new_name} å¤±è´¥ï¼Œç›®æ ‡æ–‡ä»¶åå·²å­˜åœ¨"
                    rename_logs.append(warning_log)
            
            # è¿”å›é‡å‘½åæ—¥å¿—å’ŒæˆåŠŸæ ‡å¿—
            return (is_rename_count > 0), rename_logs


def verify_account(account):
    # éªŒè¯è´¦å·
    print(f"â–¶ï¸ éªŒè¯ç¬¬ {account.index} ä¸ªè´¦å·")
    if "__uid" not in account.cookie:
        return False
    else:
        account_info = account.init()
        if not account_info:
            add_notify(f"ğŸ‘¤ ç¬¬ {account.index} ä¸ªè´¦å·ç™»å½•å¤±è´¥ï¼Œcookie æ— æ•ˆ âŒ")
            return False
        else:
            print(f"ğŸ‘¤ è´¦å·æ˜µç§°: {account_info['nickname']} âœ…")
            return True


def format_bytes(size_bytes: int) -> str:
    units = ("B", "KB", "MB", "GB", "TB", "PB", "EB", "ZB", "YB")
    i = 0
    while size_bytes >= 1024 and i < len(units) - 1:
        size_bytes /= 1024
        i += 1
    return f"{size_bytes:.2f} {units[i]}"


def do_sign(account):
    if not account.mparam:
        print("â­ï¸ ç§»åŠ¨ç«¯å‚æ•°æœªè®¾ç½®ï¼Œè·³è¿‡ç­¾åˆ°")
        print()
        return
    # æ¯æ—¥é¢†ç©ºé—´
    growth_info = account.get_growth_info()
    if growth_info:
        growth_message = f"ğŸ’¾ {'88VIP' if growth_info['88VIP'] else 'æ™®é€šç”¨æˆ·'}: æ€»ç©ºé—´ {format_bytes(growth_info['total_capacity'])}ï¼Œç­¾åˆ°ç´¯è®¡è·å¾— {format_bytes(growth_info['cap_composition'].get('sign_reward', 0))}"
        if growth_info["cap_sign"]["sign_daily"]:
            sign_message = f"ğŸ“… ç­¾åˆ°è®°å½•: ä»Šæ—¥å·²ç­¾åˆ° +{int(growth_info['cap_sign']['sign_daily_reward']/1024/1024)}MBï¼Œè¿ç­¾è¿›åº¦ï¼ˆ{growth_info['cap_sign']['sign_progress']}/{growth_info['cap_sign']['sign_target']}ï¼‰âœ…"
            message = f"{sign_message}\n{growth_message}"
            print(message)
        else:
            sign, sign_return = account.get_growth_sign()
            if sign:
                sign_message = f"ğŸ“… æ‰§è¡Œç­¾åˆ°: ä»Šæ—¥ç­¾åˆ° +{int(sign_return/1024/1024)}MBï¼Œè¿ç­¾è¿›åº¦ï¼ˆ{growth_info['cap_sign']['sign_progress']+1}/{growth_info['cap_sign']['sign_target']}ï¼‰âœ…"
                message = f"{sign_message}\n{growth_message}"
                if (
                    str(
                        CONFIG_DATA.get("push_config", {}).get("QUARK_SIGN_NOTIFY")
                    ).lower()
                    == "false"
                    or os.environ.get("QUARK_SIGN_NOTIFY") == "false"
                ):
                    print(message)
                else:
                    if account.nickname:
                        message = message.replace("ä»Šæ—¥", f"{account.nickname} ä»Šæ—¥")
                    add_notify(message)
            else:
                print(f"ğŸ“… ç­¾åˆ°å¼‚å¸¸: {sign_return}")
    print()


def do_save(account, tasklist=[], ignore_execution_rules=False):
    print(f"ğŸ§© è½½å…¥æ’ä»¶")
    plugins, CONFIG_DATA["plugins"], task_plugins_config = Config.load_plugins(
        CONFIG_DATA.get("plugins", {})
    )
    print(f"è½¬å­˜è´¦å·: {account.nickname}")
    # è·å–å…¨éƒ¨ä¿å­˜ç›®å½•fid
    account.update_savepath_fid(tasklist)
    
    # åˆ›å»ºå·²å‘é€é€šçŸ¥è·Ÿè¸ªé›†åˆï¼Œé¿å…é‡å¤æ˜¾ç¤ºé€šçŸ¥
    sent_notices = set()

    def is_time(task):
        # è‹¥ä¸ºæ‰‹åŠ¨å•ä»»åŠ¡è¿è¡Œå¹¶æ˜ç¡®è¦æ±‚å¿½ç•¥æ‰§è¡Œå‘¨æœŸ/è¿›åº¦é™åˆ¶ï¼Œåˆ™å§‹ç»ˆæ‰§è¡Œ
        if ignore_execution_rules:
            return True
        # è·å–ä»»åŠ¡çš„æ‰§è¡Œå‘¨æœŸæ¨¡å¼ï¼Œä¼˜å…ˆä½¿ç”¨ä»»åŠ¡è‡ªèº«çš„execution_modeï¼Œå¦åˆ™ä½¿ç”¨ç³»ç»Ÿé…ç½®çš„execution_mode
        execution_mode = task.get("execution_mode") or CONFIG_DATA.get("execution_mode", "manual")
        
        # æŒ‰ä»»åŠ¡è¿›åº¦æ‰§è¡Œï¼ˆè‡ªåŠ¨ï¼‰
        if execution_mode == "auto":
            try:
                # ä»task_metricsè¡¨è·å–ä»»åŠ¡è¿›åº¦
                cal_db = CalendarDB()
                task_name = task.get("taskname") or task.get("task_name") or ""
                if task_name:
                    metrics = cal_db.get_task_metrics(task_name)
                    if metrics and metrics.get("progress_pct") is not None:
                        progress_pct = int(metrics.get("progress_pct", 0))
                        # å¦‚æœä»»åŠ¡è¿›åº¦100%ï¼Œåˆ™è·³è¿‡
                        if progress_pct >= 100:
                            return False
                        # å¦‚æœä»»åŠ¡è¿›åº¦ä¸æ˜¯100%ï¼Œåˆ™éœ€è¦è¿è¡Œ
                        return True
                    else:
                        # æ²¡æœ‰ä»»åŠ¡è¿›åº¦æ•°æ®ï¼Œé€€å›æŒ‰è‡ªé€‰å‘¨æœŸæ‰§è¡Œçš„é€»è¾‘
                        execution_mode = "manual"
            except Exception as e:
                # è·å–ä»»åŠ¡è¿›åº¦å¤±è´¥ï¼Œé€€å›æŒ‰è‡ªé€‰å‘¨æœŸæ‰§è¡Œçš„é€»è¾‘
                execution_mode = "manual"
        
        # æŒ‰è‡ªé€‰å‘¨æœŸæ‰§è¡Œï¼ˆè‡ªé€‰ï¼‰- åŸæœ‰é€»è¾‘
        if execution_mode == "manual":
            return (
                not task.get("enddate")
                or (
                    datetime.now().date()
                    <= datetime.strptime(task["enddate"], "%Y-%m-%d").date()
                )
            ) and (
                "runweek" not in task
                # æ˜ŸæœŸä¸€ä¸º0ï¼Œæ˜ŸæœŸæ—¥ä¸º6
                or (datetime.today().weekday() + 1 in task.get("runweek"))
            )
        
        # é»˜è®¤è¿”å›Trueï¼ˆå…¼å®¹æœªçŸ¥æ¨¡å¼ï¼‰
        return True

    # æ‰§è¡Œä»»åŠ¡
    for index, task in enumerate(tasklist):
        # æ£€æŸ¥ç¯å¢ƒå˜é‡è·å–çœŸå®çš„ä»»åŠ¡ç´¢å¼•ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        if len(tasklist) == 1 and os.environ.get("ORIGINAL_TASK_INDEX"):
            try:
                display_index = int(os.environ.get("ORIGINAL_TASK_INDEX"))
            except (ValueError, TypeError):
                display_index = index + 1
        else:
            display_index = index + 1
            
        print()
        print(f"#{str(display_index).zfill(2)}------------------")
        print(f"ä»»åŠ¡åç§°: {task['taskname']}")
        print(f"åˆ†äº«é“¾æ¥: {task['shareurl']}")
        print(f"ä¿å­˜è·¯å¾„: {task['savepath']}")
        # æ ¹æ®å‘½åæ¨¡å¼æ˜¾ç¤ºä¸åŒä¿¡æ¯
        if task.get("use_sequence_naming") and task.get("sequence_naming"):
            print(f"é¡ºåºå‘½å: {task['sequence_naming']}")
        elif task.get("use_episode_naming") and task.get("episode_naming"):
            print(f"å‰§é›†å‘½å: {task['episode_naming']}")
        else:
            # æ­£åˆ™å‘½åæ¨¡å¼
            if task.get("pattern") is not None:  # ä¿®æ”¹ä¸ºåˆ¤æ–­æ˜¯å¦ä¸ºNoneï¼Œè€Œéæ˜¯å¦ä¸ºçœŸå€¼
                print(f"æ­£åˆ™åŒ¹é…: {task['pattern']}")
            if task.get("replace") is not None:  # æ˜¾ç¤ºæ›¿æ¢è§„åˆ™ï¼Œå³ä½¿ä¸ºç©ºå­—ç¬¦ä¸²
                print(f"æ­£åˆ™æ›¿æ¢: {task['replace']}")
        if task.get("update_subdir"):
            print(f"æ›´æ–°ç›®å½•: {task['update_subdir']}")
        # è·å–ä»»åŠ¡çš„æ‰§è¡Œå‘¨æœŸæ¨¡å¼ï¼Œä¼˜å…ˆä½¿ç”¨ä»»åŠ¡è‡ªèº«çš„execution_modeï¼Œå¦åˆ™ä½¿ç”¨ç³»ç»Ÿé…ç½®çš„execution_mode
        execution_mode = task.get("execution_mode") or CONFIG_DATA.get("execution_mode", "manual")
        
        # æ ¹æ®æ‰§è¡Œå‘¨æœŸæ¨¡å¼æ˜¾ç¤ºæ—¥å¿—
        if execution_mode == "auto":
            # æŒ‰ä»»åŠ¡è¿›åº¦æ‰§è¡Œï¼ˆè‡ªåŠ¨ï¼‰
            try:
                # æ£€æŸ¥æ˜¯å¦æœ‰ä»»åŠ¡è¿›åº¦æ•°æ®
                cal_db = CalendarDB()
                task_name = task.get("taskname") or task.get("task_name") or ""
                if task_name:
                    metrics = cal_db.get_task_metrics(task_name)
                    if metrics and metrics.get("progress_pct") is not None:
                        # æœ‰ä»»åŠ¡è¿›åº¦æ•°æ®ï¼Œæ˜¾ç¤ºè‡ªåŠ¨æ¨¡å¼
                        print(f"æ‰§è¡Œå‘¨æœŸ: è‡ªåŠ¨")
                    else:
                        # æ²¡æœ‰ä»»åŠ¡è¿›åº¦æ•°æ®ï¼Œé€€å›æŒ‰è‡ªé€‰å‘¨æœŸæ‰§è¡Œï¼Œæ˜¾ç¤ºè‡ªé€‰å‘¨æœŸä¿¡æ¯
                        if task.get("runweek") or task.get("enddate"):
                            print(
                                f"æ‰§è¡Œå‘¨æœŸ: WK{task.get('runweek',[])} ~ {task.get('enddate','forever')} (è‡ªåŠ¨æ¨¡å¼ï¼Œæ— è¿›åº¦æ•°æ®ï¼Œé€€å›è‡ªé€‰å‘¨æœŸ)"
                            )
                        else:
                            print(f"æ‰§è¡Œå‘¨æœŸ: è‡ªåŠ¨ (æ— è¿›åº¦æ•°æ®ï¼Œé€€å›è‡ªé€‰å‘¨æœŸ)")
                else:
                    # æ²¡æœ‰ä»»åŠ¡åç§°ï¼Œé€€å›æŒ‰è‡ªé€‰å‘¨æœŸæ‰§è¡Œ
                    if task.get("runweek") or task.get("enddate"):
                        print(
                            f"æ‰§è¡Œå‘¨æœŸ: WK{task.get('runweek',[])} ~ {task.get('enddate','forever')} (è‡ªåŠ¨æ¨¡å¼ï¼Œæ— ä»»åŠ¡åç§°ï¼Œé€€å›è‡ªé€‰å‘¨æœŸ)"
                        )
                    else:
                        print(f"æ‰§è¡Œå‘¨æœŸ: è‡ªåŠ¨ (æ— ä»»åŠ¡åç§°ï¼Œé€€å›è‡ªé€‰å‘¨æœŸ)")
            except Exception:
                # è·å–ä»»åŠ¡è¿›åº¦å¤±è´¥ï¼Œé€€å›æŒ‰è‡ªé€‰å‘¨æœŸæ‰§è¡Œ
                if task.get("runweek") or task.get("enddate"):
                    print(
                        f"æ‰§è¡Œå‘¨æœŸ: WK{task.get('runweek',[])} ~ {task.get('enddate','forever')} (è‡ªåŠ¨æ¨¡å¼ï¼Œè·å–è¿›åº¦å¤±è´¥ï¼Œé€€å›è‡ªé€‰å‘¨æœŸ)"
                    )
                else:
                    print(f"æ‰§è¡Œå‘¨æœŸ: è‡ªåŠ¨ (è·å–è¿›åº¦å¤±è´¥ï¼Œé€€å›è‡ªé€‰å‘¨æœŸ)")
        else:
            # æŒ‰è‡ªé€‰å‘¨æœŸæ‰§è¡Œï¼ˆè‡ªé€‰ï¼‰- åŸæœ‰é€»è¾‘
            if task.get("runweek") or task.get("enddate"):
                print(
                    f"æ‰§è¡Œå‘¨æœŸ: WK{task.get('runweek',[])} ~ {task.get('enddate','forever')}"
                )
        
        print()
        # åˆ¤æ–­ä»»åŠ¡å‘¨æœŸ
        if not is_time(task):
            if execution_mode == "auto":
                # æŒ‰ä»»åŠ¡è¿›åº¦æ‰§è¡Œæ—¶çš„è·³è¿‡æç¤º
                try:
                    cal_db = CalendarDB()
                    task_name = task.get("taskname") or task.get("task_name") or ""
                    if task_name:
                        metrics = cal_db.get_task_metrics(task_name)
                        if metrics and metrics.get("progress_pct") is not None:
                            progress_pct = int(metrics.get("progress_pct", 0))
                            print(f"ä»»åŠ¡è¿›åº¦å·²è¾¾ {progress_pct}%ï¼Œè·³è¿‡")
                        else:
                            print(f"ä»»åŠ¡ä¸åœ¨æ‰§è¡Œå‘¨æœŸå†…ï¼Œè·³è¿‡")
                    else:
                        print(f"ä»»åŠ¡ä¸åœ¨æ‰§è¡Œå‘¨æœŸå†…ï¼Œè·³è¿‡")
                except Exception:
                    print(f"ä»»åŠ¡ä¸åœ¨æ‰§è¡Œå‘¨æœŸå†…ï¼Œè·³è¿‡")
            else:
                # æŒ‰è‡ªé€‰å‘¨æœŸæ‰§è¡Œæ—¶çš„è·³è¿‡æç¤ºï¼ˆåŸæœ‰é€»è¾‘ï¼‰
                print(f"ä»»åŠ¡ä¸åœ¨æ‰§è¡Œå‘¨æœŸå†…ï¼Œè·³è¿‡")
        else:
            # ä¿å­˜ä¹‹å‰çš„é€šçŸ¥ä¿¡æ¯
            global NOTIFYS
            notifys_before = NOTIFYS.copy()
            
            # å°†å…¨å±€çš„è‡ªåŠ¨è§£å‹è®¾ç½®æ·»åŠ åˆ°ä»»åŠ¡ä¸­
            task_settings = CONFIG_DATA.get("task_settings", {})
            if "auto_extract_archive" not in task:
                task["auto_extract_archive"] = task_settings.get("auto_extract_archive", "disabled")
            
            # æ‰§è¡Œä¿å­˜ä»»åŠ¡
            is_new_tree = account.do_save_task(task)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…é™¤é‡å¤çš„é€šçŸ¥
            # ç”±äºåœ¨ä¿®æ”¹é¡ºåºï¼Œç°åœ¨ä¸éœ€è¦ç‰¹æ®Šå¤„ç†é€šçŸ¥
            is_special_sequence = (task.get("use_sequence_naming") and task.get("sequence_naming")) or (task.get("use_episode_naming") and task.get("episode_naming"))
            # å¯¹äºæ­£åˆ™å‘½åæ¨¡å¼ï¼Œä¹Ÿå°†å…¶è§†ä¸ºç‰¹æ®Šåºåˆ—
            is_regex_mode = not is_special_sequence and task.get("pattern") is not None
            
            # æ‰§è¡Œé‡å‘½åä»»åŠ¡ï¼Œä½†æ”¶é›†æ—¥å¿—è€Œä¸æ˜¯ç«‹å³æ‰“å°
            is_rename, rename_logs = account.do_rename_task(task)

            
            # å¤„ç†å­ç›®å½•é‡å‘½å - å¦‚æœé…ç½®äº†æ›´æ–°ç›®å½•ä¸”ä½¿ç”¨æ­£åˆ™å‘½åæ¨¡å¼
            if task.get("update_subdir") and task.get("pattern") is not None:
                # è·å–ä¿å­˜è·¯å¾„
                savepath = re.sub(r"/{2,}", "/", f"/{task['savepath']}")
                if account.savepath_fid.get(savepath):
                    # é€’å½’å¤„ç†æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„å­ç›®å½•
                    def process_subdirs(current_path, relative_path=""):
                        # è·å–å½“å‰ç›®å½•çš„æ–‡ä»¶åˆ—è¡¨
                        current_fid = account.savepath_fid.get(current_path)
                        if not current_fid:
                            # å°è¯•è·å–ç›®å½•çš„fid
                            path_fids = account.get_fids([current_path])
                            if path_fids:
                                current_fid = path_fids[0]["fid"]
                                account.savepath_fid[current_path] = current_fid
                            else:
                                print(f"æ— æ³•è·å–ç›®å½•fid: {current_path}")
                                return
                        
                        current_dir_files = account.ls_dir(current_fid)
                        
                        # å¤„ç†å½“å‰ç›®å½•
                        if relative_path:
                            # å¯¹å½“å‰ç›®å½•æ‰§è¡Œé‡å‘½åæ“ä½œ
                            subtask = task.copy()
                            if not subtask.get("pattern"):
                                subtask["pattern"] = ".*"
                                subtask["replace"] = ""
                            
                            subdir_is_rename, subdir_rename_logs = account.do_rename_task(subtask, relative_path)
                            
                            # åˆå¹¶æ—¥å¿—
                            if subdir_is_rename and subdir_rename_logs:
                                clean_logs = []
                                for log in subdir_rename_logs:
                                    if "å¤±è´¥" not in log:
                                        clean_logs.append(log)
                                
                                rename_logs.extend(clean_logs)
                                nonlocal is_rename
                                is_rename = is_rename or subdir_is_rename
                        
                        # æ‰¾å‡ºç¬¦åˆæ›´æ–°ç›®å½•è§„åˆ™çš„å­ç›®å½•
                        subdirs = []
                        for file in current_dir_files:
                            if file["dir"]:
                                # å¦‚æœæ˜¯æ ¹ç›®å½•ï¼Œæ£€æŸ¥æ˜¯å¦ç¬¦åˆæ›´æ–°ç›®å½•çš„è§„åˆ™
                                if not relative_path and re.search(task["update_subdir"], file["file_name"]):
                                    subdirs.append(file)
                                # å¦‚æœå·²ç»åœ¨æŸä¸ªæ›´æ–°ç›®å½•å†…ï¼Œåˆ™æ‰€æœ‰å­ç›®å½•éƒ½éœ€è¦å¤„ç†
                                elif relative_path:
                                    subdirs.append(file)
                        
                        # å¯¹æ¯ä¸ªå­ç›®å½•é€’å½’è°ƒç”¨
                        for subdir in subdirs:
                            # æ„å»ºå­ç›®å½•å®Œæ•´è·¯å¾„
                            subdir_full_path = f"{current_path}/{subdir['file_name']}"
                            subdir_relative_path = f"{relative_path}/{subdir['file_name']}"
                            
                            # é€’å½’å¤„ç†å­ç›®å½•
                            process_subdirs(subdir_full_path, subdir_relative_path)
                    
                    # ä»æ ¹ç›®å½•å¼€å§‹é€’å½’å¤„ç†
                    process_subdirs(savepath)
            
            # å¤„ç†äº‘è§£å‹åâ€œä¿æŒåŸç›®å½•ç»“æ„â€çš„å­ç›®å½•é‡å‘½å
            # ä¸é¡¶å±‚ç›®å½•ä½¿ç”¨ç›¸åŒçš„é‡å‘½åè§„åˆ™
            auto_extract_subdirs = task.get("_auto_extract_subdirs") or []
            for subdir_path in auto_extract_subdirs:
                try:
                    subtask = task.copy()
                    subdir_is_rename, subdir_rename_logs = account.do_rename_task(subtask, subdir_path)
                    if subdir_is_rename and subdir_rename_logs:
                        # è¿‡æ»¤æ‰å¤±è´¥æ—¥å¿—ï¼Œåªä¿ç•™æˆåŠŸçš„
                        clean_logs = []
                        for log in subdir_rename_logs:
                            if "å¤±è´¥" not in log:
                                clean_logs.append(log)
                        rename_logs.extend(clean_logs)
                        is_rename = is_rename or subdir_is_rename
                except Exception as e:
                    # é˜²å¾¡æ€§å¤„ç†ï¼Œé¿å…å­ç›®å½•å¼‚å¸¸å½±å“ä¸»æµç¨‹
                    print(f"âš ï¸ è‡ªåŠ¨è§£å‹å­ç›®å½•é‡å‘½åå‡ºé”™ï¼ˆ{subdir_path}ï¼‰: {e}")
            
            # ç®€åŒ–æ—¥å¿—å¤„ç† - åªä¿ç•™æˆåŠŸçš„é‡å‘½åæ¶ˆæ¯
            if rename_logs:
                success_logs = []
                for log in rename_logs:
                    if "å¤±è´¥" not in log:
                        success_logs.append(log)
                # å®Œå…¨æ›¿æ¢æ—¥å¿—ï¼Œåªæ˜¾ç¤ºæˆåŠŸéƒ¨åˆ†
                rename_logs = success_logs
                
            # å¯¹äºé¡ºåºå‘½åæ¨¡å¼ï¼Œéœ€è¦é‡æ–°åˆ›å»ºæ–‡ä»¶æ ‘ä»¥æ˜¾ç¤ºå®é™…çš„æ–‡ä»¶å
            # è¿™ç¡®ä¿æ˜¾ç¤ºçš„æ˜¯å®é™…å­˜åœ¨çš„æ–‡ä»¶åï¼Œè€Œä¸æ˜¯é¢„æœŸçš„æ–‡ä»¶å
            # æ£€æŸ¥æ˜¯å¦æ˜¯ä¿æŒåŸç›®å½•ç»“æ„æ¨¡å¼
            auto_extract_mode_check = task.get("auto_extract_archive", "disabled")
            keep_structure_check = "keep_structure" in auto_extract_mode_check if auto_extract_mode_check != "disabled" else False
            auto_extract_subdirs_check = task.get("_auto_extract_subdirs") or []
            
            # å¦‚æœæ˜¯ä¿æŒåŸç›®å½•ç»“æ„æ¨¡å¼ä¸”æœ‰è‡ªåŠ¨è§£å‹çš„å­ç›®å½•ï¼Œè·³è¿‡é‡æ–°åˆ›å»ºæ–‡ä»¶æ ‘
            # å› ä¸ºæ–‡ä»¶å·²ç»åœ¨å­ç›®å½•ä¸­ï¼Œæ–‡ä»¶æ ‘ä¼šé€šè¿‡ _auto_extract_subdirs çš„é€»è¾‘æ¥æ˜¾ç¤º
            if keep_structure_check and auto_extract_subdirs_check:
                # è·³è¿‡é‡æ–°åˆ›å»ºæ–‡ä»¶æ ‘ï¼Œä½¿ç”¨åŸæ¥çš„æ–‡ä»¶æ ‘
                pass
            elif task.get("shareurl") and rename_logs and is_rename and (task.get("use_sequence_naming") or task.get("use_episode_naming")):
                # è·å–å½“å‰ç›®å½•
                savepath = re.sub(r"/{2,}", "/", f"/{task['savepath']}")
                if account.savepath_fid.get(savepath):
                    # åˆ›å»ºæ–°çš„Treeå¯¹è±¡
                    new_tree = Tree()
                    # åˆ›å»ºæ ¹èŠ‚ç‚¹
                    new_tree.create_node(
                        savepath,
                        "root",
                        data={
                            "is_dir": True,
                        },
                    )
                    
                    # è·å–å®é™…çš„æ–‡ä»¶åæ˜ å°„
                    actual_file_names = account.get_actual_file_names_from_directory(task, rename_logs)

                    # ä»é‡å‘½åæ—¥å¿—ä¸­æå–é¢„æœŸçš„æ–‡ä»¶åæ˜ å°„
                    expected_renamed_files = {}
                    for log in rename_logs:
                        # æ ¼å¼ï¼šé‡å‘½å: æ—§å â†’ æ–°å
                        match = re.search(r'é‡å‘½å: (.*?) â†’ (.+?)($|\s|ï¼Œ|å¤±è´¥)', log)
                        if match:
                            old_name = match.group(1).strip()
                            expected_new_name = match.group(2).strip()
                            expected_renamed_files[old_name] = expected_new_name

                    # è·å–æ–‡ä»¶åˆ—è¡¨ï¼Œåªæ·»åŠ é‡å‘½åçš„æ–‡ä»¶
                    fresh_dir_file_list = account.ls_dir(account.savepath_fid[savepath])

                    # æ£€æŸ¥æ˜¯å¦æ˜¯ä¿æŒåŸç›®å½•ç»“æ„æ¨¡å¼
                    auto_extract_mode = task.get("auto_extract_archive", "disabled")
                    keep_structure = "keep_structure" in auto_extract_mode if auto_extract_mode != "disabled" else False
                    # è·å–è‡ªåŠ¨è§£å‹çš„å­ç›®å½•åˆ—è¡¨ï¼Œç”¨äºè¿‡æ»¤æ ¹ç›®å½•ä¸­çš„æ–‡ä»¶
                    auto_extract_subdirs = task.get("_auto_extract_subdirs") or []
                    auto_extract_subdir_names = set()
                    for subdir_path in auto_extract_subdirs:
                        subdir_name = subdir_path.lstrip("/")
                        auto_extract_subdir_names.add(subdir_name)
                    
                    # å¦‚æœæ˜¯ä¿æŒåŸç›®å½•ç»“æ„æ¨¡å¼ï¼Œè·å–å­ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶fidå’Œæ–‡ä»¶åï¼Œç”¨äºè¿‡æ»¤
                    subdir_file_fids = set()
                    subdir_file_names = set()  # åŒæ—¶è®°å½•æ–‡ä»¶åï¼Œç”¨äºåŒé‡æ£€æŸ¥
                    # é€’å½’è·å–æ‰€æœ‰å­ç›®å½•ä¸­çš„æ–‡ä»¶ï¼ˆåŒ…æ‹¬åµŒå¥—å­ç›®å½•ï¼‰
                    def get_all_subdir_files(subdir_fid, subdir_name):
                        """é€’å½’è·å–å­ç›®å½•åŠå…¶æ‰€æœ‰å­ç›®å½•ä¸­çš„æ–‡ä»¶"""
                        all_files = []
                        try:
                            subdir_files = account.ls_dir(subdir_fid)
                            for subdir_file in subdir_files:
                                if subdir_file.get("dir", False):
                                    # é€’å½’å¤„ç†å­ç›®å½•
                                    sub_subdir_path = f"{subdir_name}/{subdir_file['file_name']}"
                                    sub_subdir_full_path = f"{savepath}/{sub_subdir_path}"
                                    if sub_subdir_full_path in account.savepath_fid:
                                        sub_subdir_fid = account.savepath_fid[sub_subdir_full_path]
                                        all_files.extend(get_all_subdir_files(sub_subdir_fid, sub_subdir_path))
                                else:
                                    all_files.append(subdir_file)
                        except Exception:
                            pass
                        return all_files
                    
                    if keep_structure and auto_extract_subdir_names:
                        for subdir_name in auto_extract_subdir_names:
                            subdir_full_path = f"{savepath}/{subdir_name}"
                            if subdir_full_path in account.savepath_fid:
                                subdir_fid = account.savepath_fid[subdir_full_path]
                                try:
                                    all_subdir_files = get_all_subdir_files(subdir_fid, subdir_name)
                                    for subdir_file in all_subdir_files:
                                        subdir_file_fids.add(subdir_file["fid"])
                                        subdir_file_names.add(subdir_file["file_name"])
                                except Exception:
                                    pass
                    
                    # æ‰å¹³åŒ–æ¨¡å¼ä¸‹ï¼Œéœ€è¦è¯†åˆ«æ‰€æœ‰è½¬å­˜çš„æ–‡ä»¶ï¼ˆåŒ…æ‹¬æœªé‡å‘½åçš„ï¼‰
                    flat_mode = not keep_structure and auto_extract_mode != "disabled"
                    current_time = int(time.time())
                    time_threshold = 600  # 10åˆ†é’Ÿ = 600ç§’

                    # æ·»åŠ å®é™…å­˜åœ¨çš„æ–‡ä»¶åˆ°æ ‘ä¸­
                    for file in fresh_dir_file_list:
                        if not file["dir"]:  # åªå¤„ç†æ–‡ä»¶
                            # å¦‚æœæ˜¯ä¿æŒåŸç›®å½•ç»“æ„æ¨¡å¼ï¼Œæ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨å­ç›®å½•ä¸­
                            # ä½¿ç”¨åŒé‡æ£€æŸ¥ï¼šfidåŒ¹é…å’Œæ–‡ä»¶ååŒ¹é…
                            if keep_structure:
                                file_in_subdir = False
                                if file.get("fid") in subdir_file_fids:
                                    file_in_subdir = True
                                elif file["file_name"] in subdir_file_names:
                                    # å³ä½¿fidä¸åŒ¹é…ï¼Œå¦‚æœæ–‡ä»¶ååœ¨å­ç›®å½•ä¸­ï¼Œä¹Ÿå¯èƒ½æ˜¯åŒä¸€ä¸ªæ–‡ä»¶ï¼ˆé‡å‘½ååï¼‰
                                    file_in_subdir = True
                                
                                if file_in_subdir:
                                    # æ–‡ä»¶åœ¨å­ç›®å½•ä¸­ï¼Œä¸åº”è¯¥æ·»åŠ åˆ°æ ¹ç›®å½•
                                    continue
                            
                            # æ£€æŸ¥è¿™ä¸ªæ–‡ä»¶æ˜¯å¦æ˜¯å½“æ¬¡è½¬å­˜çš„æ–‡ä»¶
                            is_transferred_file = False
                            check_method = None

                            # æ–¹æ³•1ï¼šæ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åœ¨å®é™…é‡å‘½åç»“æœä¸­
                            if file["file_name"] in actual_file_names.values():
                                is_transferred_file = True
                                check_method = "method1_actual_names"

                            # æ–¹æ³•2ï¼šæ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åœ¨é¢„æœŸé‡å‘½åç»“æœä¸­ï¼ˆç”¨äºé‡å‘½åå¤±è´¥çš„æƒ…å†µï¼‰
                            elif file["file_name"] in expected_renamed_files.values():
                                is_transferred_file = True
                                check_method = "method2_expected_values"

                            # æ–¹æ³•3ï¼šæ£€æŸ¥æ–‡ä»¶åæ˜¯å¦æ˜¯åŸå§‹æ–‡ä»¶åï¼ˆé‡å‘½åå¤±è´¥ä¿æŒåŸåï¼‰
                            elif file["file_name"] in expected_renamed_files.keys():
                                is_transferred_file = True
                                check_method = "method3_expected_keys"
                            
                            # æ–¹æ³•4ï¼šæ‰å¹³åŒ–æ¨¡å¼ä¸‹ï¼Œæ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ˜¯æœ€è¿‘åˆ›å»ºçš„ï¼ˆå¯èƒ½æ˜¯è½¬å­˜çš„æ–‡ä»¶ï¼‰
                            elif flat_mode:
                                file_updated_at = file.get("updated_at", 0)
                                # å¤„ç†æ¯«ç§’çº§æ—¶é—´æˆ³
                                if file_updated_at > 4102444800:  # 2100å¹´çš„æ—¶é—´æˆ³
                                    file_updated_at = file_updated_at / 1000
                                if file_updated_at > 0:
                                    time_diff = current_time - int(file_updated_at)
                                    if time_diff < time_threshold:
                                        is_transferred_file = True
                                        check_method = "method4_recent_file"

                            if is_transferred_file:
                                new_tree.create_node(
                                    file["file_name"],  # ä½¿ç”¨å®é™…å­˜åœ¨çš„æ–‡ä»¶å
                                    file["fid"],
                                    parent="root",
                                    data={
                                        "is_dir": False,
                                        "path": f"{savepath}/{file['file_name']}",
                                    },
                                )
                    
                    # å¦‚æœæ ‘çš„å¤§å°å¤§äº1ï¼ˆæœ‰æ–‡ä»¶ï¼‰ï¼Œåˆ™è®¾ç½®ä¸ºæ–°çš„Treeå¯¹è±¡
                    if new_tree.size() > 1:
                        is_new_tree = new_tree
            
            # æ·»åŠ ç”Ÿæˆæ–‡ä»¶æ ‘çš„åŠŸèƒ½ï¼ˆæ— è®ºæ˜¯å¦æ˜¯é¡ºåºå‘½åæ¨¡å¼ï¼‰
            # å¦‚æœis_new_treeè¿”å›äº†Treeå¯¹è±¡ï¼Œåˆ™æ‰“å°æ–‡ä»¶æ ‘
            if is_new_tree and isinstance(is_new_tree, Tree) and is_new_tree.size() > 1:
                # è·å–æ‰€æœ‰æ–‡ä»¶ï¼ˆéç›®å½•ï¼‰èŠ‚ç‚¹
                file_nodes = [node for node in is_new_tree.all_nodes_itr() if node.data.get("is_dir") == False]
                
                # å¦‚æœæ˜¯ä¿æŒåŸç›®å½•ç»“æ„æ¨¡å¼ï¼Œåœ¨å¼€å§‹å¤„ç†æ–‡ä»¶èŠ‚ç‚¹ä¹‹å‰ï¼Œå…ˆè¿‡æ»¤æ‰å­ç›®å½•ä¸­çš„æ–‡ä»¶
                auto_extract_mode_prefilter = task.get("auto_extract_archive", "disabled")
                keep_structure_prefilter = "keep_structure" in auto_extract_mode_prefilter if auto_extract_mode_prefilter != "disabled" else False
                auto_extract_subdirs_prefilter = task.get("_auto_extract_subdirs") or []
                
                if keep_structure_prefilter and auto_extract_subdirs_prefilter:
                    # è·å–æ‰€æœ‰å­ç›®å½•ä¸­çš„æ–‡ä»¶åï¼ˆé€’å½’ï¼‰
                    savepath_prefilter = re.sub(r"/{2,}", "/", f"/{task['savepath']}")
                    subdir_file_names_prefilter = set()
                    
                    def get_all_subdir_files_prefilter(subdir_fid, subdir_name):
                        """é€’å½’è·å–å­ç›®å½•åŠå…¶æ‰€æœ‰å­ç›®å½•ä¸­çš„æ–‡ä»¶"""
                        all_files = []
                        try:
                            subdir_files = account.ls_dir(subdir_fid)
                            for subdir_file in subdir_files:
                                if subdir_file.get("dir", False):
                                    sub_subdir_path = f"{subdir_name}/{subdir_file['file_name']}"
                                    sub_subdir_full_path = f"{savepath_prefilter}/{sub_subdir_path}"
                                    if sub_subdir_full_path in account.savepath_fid:
                                        sub_subdir_fid = account.savepath_fid[sub_subdir_full_path]
                                        all_files.extend(get_all_subdir_files_prefilter(sub_subdir_fid, sub_subdir_path))
                                else:
                                    all_files.append(subdir_file)
                        except Exception:
                            pass
                        return all_files
                    
                    for subdir_path in auto_extract_subdirs_prefilter:
                        subdir_name = subdir_path.lstrip("/")
                        subdir_full_path = f"{savepath_prefilter}/{subdir_name}"
                        if subdir_full_path in account.savepath_fid:
                            subdir_fid = account.savepath_fid[subdir_full_path]
                            try:
                                all_subdir_files = get_all_subdir_files_prefilter(subdir_fid, subdir_name)
                                for subdir_file in all_subdir_files:
                                    subdir_file_names_prefilter.add(subdir_file["file_name"])
                            except Exception:
                                pass
                    
                    # è¿‡æ»¤æ‰å­ç›®å½•ä¸­çš„æ–‡ä»¶
                    filtered_file_nodes = []
                    
                    for node in file_nodes:
                        file_name = remove_file_icons(node.tag)
                        if file_name not in subdir_file_names_prefilter:
                            filtered_file_nodes.append(node)
                    
                    file_nodes = filtered_file_nodes
                
                # åˆ›å»ºä¸€ä¸ªæ˜ å°„åˆ—è¡¨ï¼ŒåŒ…å«éœ€è¦æ˜¾ç¤ºçš„æ–‡ä»¶å
                display_files = []
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ›´æ–°ç›®å½•ï¼Œå¹¶è·å–ç›®å½•ä¸‹çš„æ–‡ä»¶
                update_subdir = task.get("update_subdir")
                
                # å¦‚æœæœ‰è®¾ç½®æ›´æ–°ç›®å½•ï¼ŒæŸ¥æ‰¾å¯¹åº”ç›®å½•ä¸‹çš„æ–‡ä»¶
                if update_subdir:
                    # æ£€æŸ¥æ–‡ä»¶æ ‘ä¸­æ˜¯å¦æœ‰æ›´æ–°ç›®å½•çš„èŠ‚ç‚¹
                    update_dir_nodes = []
                    update_subdir_files = []
                    
                    # éå†æ‰€æœ‰èŠ‚ç‚¹ï¼ŒæŸ¥æ‰¾å¯¹åº”çš„ç›®å½•èŠ‚ç‚¹
                    for node in is_new_tree.all_nodes_itr():
                        if node.data.get("is_dir", False) and node.tag.lstrip("ğŸ“") == update_subdir:
                            update_dir_nodes.append(node)
                    
                    # å¦‚æœæ‰¾åˆ°æ›´æ–°ç›®å½•èŠ‚ç‚¹ï¼Œæ”¶é›†å…¶å­èŠ‚ç‚¹
                    if update_dir_nodes:
                        for dir_node in update_dir_nodes:
                            # è·å–ç›®å½•èŠ‚ç‚¹ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å­èŠ‚ç‚¹
                            for node in is_new_tree.all_nodes_itr():
                                if (not node.data.get("is_dir", False) and 
                                    node.predecessor == dir_node.identifier):
                                    update_subdir_files.append(node)
                
                # æŒ‰æ–‡ä»¶åæ’åº
                if is_special_sequence:
                    # å¯¹äºé¡ºåºå‘½åæ¨¡å¼ï¼Œç›´æ¥ä½¿ç”¨æ–‡ä»¶æ ‘ä¸­çš„å®é™…æ–‡ä»¶å
                    if rename_logs:
                        # ç›´æ¥æ˜¾ç¤ºæ–‡ä»¶æ ‘ä¸­çš„å®é™…æ–‡ä»¶åï¼ˆå·²ç»æ˜¯é‡å‘½ååçš„ç»“æœï¼‰
                        # æŒ‰ç…§æ–‡ä»¶åä¸­çš„åºå·è¿›è¡Œæ’åº
                        def extract_sequence_number(node):
                            filename = remove_file_icons(node.tag)
                            # å°è¯•ä»æ–‡ä»¶åä¸­æå–åºå·ï¼Œå¦‚ "ä¹˜é£2025 - S06E01.flac" -> 1
                            import re
                            match = re.search(r'E(\d+)', filename)
                            if match:
                                return int(match.group(1))
                            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°Eåºå·ï¼Œå°è¯•å…¶ä»–æ¨¡å¼
                            match = re.search(r'(\d+)', filename)
                            if match:
                                return int(match.group(1))
                            return 0

                        # æŒ‰åºå·æ’åº
                        sorted_nodes = sorted(file_nodes, key=extract_sequence_number)

                        for node in sorted_nodes:
                            # è·å–å®é™…æ–‡ä»¶åï¼ˆå»é™¤å·²æœ‰å›¾æ ‡ï¼‰
                            actual_filename = remove_file_icons(node.tag)
                            # è·å–é€‚å½“çš„å›¾æ ‡
                            icon = get_file_icon(actual_filename, is_dir=node.data.get("is_dir", False))
                            # æ·»åŠ åˆ°æ˜¾ç¤ºåˆ—è¡¨
                            display_files.append((f"{icon} {actual_filename}", node))
                    else:
                        # å¦‚æœæ²¡æœ‰é‡å‘½åæ—¥å¿—ï¼Œä½¿ç”¨åŸæ¥çš„é¡ºåºå‘½åé€»è¾‘
                        if task.get("use_sequence_naming") and task.get("sequence_naming"):
                            # é¡ºåºå‘½åæ¨¡å¼é¢„è§ˆ
                            sequence_pattern = task["sequence_naming"]
                            
                            # å¯¹äºæ¯ä¸ªæ–‡ä»¶ï¼Œç”Ÿæˆå…¶é‡å‘½ååçš„åç§°
                            for i, node in enumerate(file_nodes):
                                # æå–åºå·ï¼ˆä»1å¼€å§‹ï¼‰
                                file_num = i + 1
                                # è·å–åŸå§‹æ–‡ä»¶çš„æ‰©å±•å
                                orig_filename = remove_file_icons(node.tag)
                                file_ext = os.path.splitext(orig_filename)[1]
                                # ç”Ÿæˆæ–°çš„æ–‡ä»¶åï¼ˆä½¿ç”¨é¡ºåºå‘½åæ¨¡å¼ï¼‰
                                if sequence_pattern == "{}":
                                    # å¯¹äºå•ç‹¬çš„{}ï¼Œç›´æ¥ä½¿ç”¨æ•°å­—åºå·ä½œä¸ºæ–‡ä»¶å
                                    new_filename = f"{file_num:02d}{file_ext}"
                                else:
                                    new_filename = sequence_pattern.replace("{}", f"{file_num:02d}") + file_ext
                                # è·å–é€‚å½“çš„å›¾æ ‡
                                icon = get_file_icon(orig_filename, is_dir=node.data.get("is_dir", False))
                                # æ·»åŠ åˆ°æ˜¾ç¤ºåˆ—è¡¨
                                display_files.append((f"{icon} {new_filename}", node))
                            
                            # æŒ‰æ•°å­—æ’åº
                            display_files.sort(key=lambda x: int(os.path.splitext(remove_file_icons(x[0]))[0]) if os.path.splitext(remove_file_icons(x[0]))[0].isdigit() else float('inf'))
                        # å¯¹äºå‰§é›†å‘½åæ¨¡å¼
                        elif task.get("use_episode_naming") and task.get("episode_naming"):
                            # ä»é‡å‘½åæ—¥å¿—æå–æ–°æ—§æ–‡ä»¶å (å¤‡ç”¨)
                            renamed_files = {}
                            for log in rename_logs:
                                # æ ¼å¼ï¼šé‡å‘½å: æ—§å â†’ æ–°å
                                match = re.search(r'é‡å‘½å: (.*?) â†’ (.+?)($|\s|ï¼Œ|å¤±è´¥)', log)
                                if match:
                                    old_name = match.group(1).strip()
                                    new_name = match.group(2).strip()
                                    renamed_files[old_name] = new_name
                            
                            # ä½¿ç”¨å·²çŸ¥çš„å‰§é›†å‘½åæ¨¡å¼æ¥ç”Ÿæˆæ–°æ–‡ä»¶å
                            episode_pattern = task["episode_naming"]
                            
                            # åˆ›å»ºå‰§é›†å·æå–å‡½æ•°
                            def extract_episode_number_local(filename):
                                # ä½¿ç”¨å…¨å±€çš„ç»Ÿä¸€æå–å‡½æ•°
                                return extract_episode_number(filename, episode_patterns=account.episode_patterns)
                            
                            # åªæ˜¾ç¤ºé‡å‘½åçš„æ–‡ä»¶
                            for node in file_nodes:
                                # è·å–åŸå§‹æ–‡ä»¶åï¼ˆå»é™¤å·²æœ‰å›¾æ ‡ï¼‰
                                orig_filename = remove_file_icons(node.tag)
                                # æ£€æŸ¥æ­¤æ–‡ä»¶æ˜¯å¦åœ¨é‡å‘½åæ—¥å¿—ä¸­
                                if orig_filename in renamed_files:
                                    # ä½¿ç”¨é‡å‘½ååçš„æ–‡ä»¶å
                                    new_filename = renamed_files[orig_filename]
                                    # è·å–é€‚å½“çš„å›¾æ ‡
                                    icon = get_file_icon(new_filename, is_dir=node.data.get("is_dir", False))
                                    # æ·»åŠ åˆ°æ˜¾ç¤ºåˆ—è¡¨
                                    display_files.append((f"{icon} {new_filename}", node))
                    
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ–‡ä»¶è¦æ˜¾ç¤ºï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶å
                    if not display_files:
                        for node in sorted(file_nodes, key=lambda node: node.tag):
                            # è·å–åŸå§‹æ–‡ä»¶åï¼ˆå»é™¤å·²æœ‰å›¾æ ‡ï¼‰
                            orig_filename = remove_file_icons(node.tag)
                            # ä¼˜å…ˆä½¿ç”¨å­˜å‚¨åœ¨dataä¸­çš„å›¾æ ‡ï¼Œå¦åˆ™é‡æ–°è®¡ç®—
                            icon = node.data.get("icon") if node.data else get_file_icon(orig_filename, is_dir=node.data.get("is_dir", False) if node.data else False)
                            display_files.append((f"{icon} {orig_filename}", node))
                else:
                    # å…¶ä»–æ¨¡å¼ï¼šæ˜¾ç¤ºåŸå§‹æ–‡ä»¶å
                    display_files = []
                    # è·å–æ‰€æœ‰èŠ‚ç‚¹ï¼ˆåŒ…æ‹¬ç›®å½•èŠ‚ç‚¹ï¼‰
                    all_nodes = [node for node in is_new_tree.all_nodes_itr()]
                    
                    # è·å–ä¿å­˜è·¯å¾„çš„æœ€åä¸€éƒ¨åˆ†ç›®å½•åï¼ˆå¦‚"/æµ‹è¯•/é­”æ³•"å–"é­”æ³•"ï¼‰
                    save_path_basename = os.path.basename(task.get("savepath", "").rstrip("/"))
                    
                    # åˆ›å»ºä¸€ä¸ªä¿å­˜ç›®å½•ç»“æ„çš„å­—å…¸
                    dir_structure = {"root": []}
                    
                    # é¦–å…ˆå¤„ç†æ‰€æœ‰ç›®å½•èŠ‚ç‚¹ï¼Œæ„å»ºç›®å½•ç»“æ„
                    dir_nodes = [node for node in all_nodes if node.data and node.data.get("is_dir", False) and node.identifier != "root"]
                    
                    # å¦‚æœæœ‰è®¾ç½®æ›´æ–°ç›®å½•ä½†åœ¨æ ‘ä¸­æ²¡æ‰¾åˆ°ï¼Œå°è¯•æŸ¥æ‰¾ç›®å½•
                    update_dir_node = None
                    if update_subdir:
                        for node in dir_nodes:
                            name = node.tag.lstrip("ğŸ“")
                            if name == update_subdir:
                                update_dir_node = node
                                break
                        
                        # å¦‚æœæ ‘ä¸­æ²¡æœ‰æ‰¾åˆ°æ›´æ–°ç›®å½•èŠ‚ç‚¹ï¼Œä½†è®¾ç½®äº†æ›´æ–°ç›®å½•ï¼Œå°è¯•å•ç‹¬å¤„ç†
                        if not update_dir_node:
                            savepath = re.sub(r"/{2,}", "/", f"/{task['savepath']}")
                            update_subdir_path = f"{savepath}/{update_subdir}"
                            
                            # æ£€æŸ¥æ›´æ–°ç›®å½•æ˜¯å¦å­˜åœ¨äºè´¦æˆ·çš„ç›®å½•ç¼“å­˜ä¸­
                            if update_subdir_path in account.savepath_fid:
                                # è·å–æ­¤ç›®å½•ä¸‹çš„æ–‡ä»¶ï¼Œå•ç‹¬å¤„ç†æ˜¾ç¤º
                                try:
                                    update_subdir_fid = account.savepath_fid[update_subdir_path]
                                    update_subdir_files = account.ls_dir(update_subdir_fid)
                                    
                                    # å¦‚æœç›®å½•å­˜åœ¨ä½†æ²¡æœ‰åœ¨æ–‡ä»¶æ ‘ä¸­ï¼Œè¿™å¯èƒ½æ˜¯é¦–æ¬¡æ‰§è¡Œçš„æƒ…å†µ
                                    # æ·»åŠ ä¸€ä¸ªè™šæ‹Ÿç›®å½•èŠ‚ç‚¹åˆ°æ ‘ä¸­
                                    class VirtualDirNode:
                                        def __init__(self, name, dir_id):
                                            self.tag = f"ğŸ“{name}"
                                            self.identifier = dir_id
                                            self.data = {"is_dir": True}
                                    
                                    # åˆ›å»ºè™šæ‹Ÿç›®å½•èŠ‚ç‚¹
                                    update_dir_node = VirtualDirNode(update_subdir, f"virtual_{update_subdir}")
                                    dir_nodes.append(update_dir_node)
                                    
                                    # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºè™šæ‹ŸèŠ‚ç‚¹
                                    virtual_file_nodes = []
                                    for file in update_subdir_files:
                                        if not file.get("dir", False):
                                            class VirtualFileNode:
                                                def __init__(self, name, file_id, dir_id):
                                                    self.tag = name
                                                    self.identifier = file_id
                                                    self.predecessor = dir_id
                                                    self.data = {"is_dir": False}
                                            
                                            # åˆ›å»ºè™šæ‹Ÿæ–‡ä»¶èŠ‚ç‚¹ï¼Œå…³è”åˆ°è™šæ‹Ÿç›®å½•
                                            virtual_node = VirtualFileNode(
                                                file["file_name"], 
                                                f"virtual_file_{file['fid']}", 
                                                update_dir_node.identifier
                                            )
                                            virtual_file_nodes.append(virtual_node)
                                    
                                    # å°†è™šæ‹Ÿæ–‡ä»¶èŠ‚ç‚¹æ·»åŠ åˆ°all_nodes
                                    if virtual_file_nodes:
                                        all_nodes.extend(virtual_file_nodes)
                                except Exception as e:
                                    print(f"è·å–æ›´æ–°ç›®å½•ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")
                    
                    # æ¢å¤ç›®å½•ç»“æ„æ„å»º
                    for node in sorted(dir_nodes, key=lambda node: node.tag):
                        # è·å–åŸå§‹æ–‡ä»¶åï¼ˆå»é™¤å·²æœ‰å›¾æ ‡ï¼‰
                        orig_filename = node.tag.lstrip("ğŸ“")
                        
                        # ç¡®ä¿åªæ˜¾ç¤ºç›®å½•åï¼Œè€Œä¸æ˜¯å®Œæ•´è·¯å¾„
                        if "/" in orig_filename:
                            # åªå–è·¯å¾„çš„æœ€åä¸€éƒ¨åˆ†ä½œä¸ºæ˜¾ç¤ºå
                            orig_filename = orig_filename.split("/")[-1]
                        
                        # è·³è¿‡ä¸ä¿å­˜è·¯å¾„ç›®å½•åç›¸åŒçš„ç›®å½•
                        if orig_filename == save_path_basename:
                            continue
                        
                        # è·å–çˆ¶èŠ‚ç‚¹ID
                        parent_id = node.predecessor if hasattr(node, 'predecessor') and node.predecessor != "root" else "root"
                        
                        # ç¡®ä¿çˆ¶èŠ‚ç‚¹é”®å­˜åœ¨äºå­—å…¸ä¸­
                        if parent_id not in dir_structure:
                            dir_structure[parent_id] = []
                        
                        # æ·»åŠ ç›®å½•èŠ‚ç‚¹åˆ°ç»“æ„ä¸­
                        dir_structure[parent_id].append({
                            "id": node.identifier,
                            "name": f"ğŸ“{orig_filename}",
                            "is_dir": True
                        })
                        
                        # ä¸ºè¯¥ç›®å½•åˆ›å»ºä¸€ä¸ªç©ºåˆ—è¡¨ï¼Œç”¨äºå­˜æ”¾å…¶å­é¡¹
                        dir_structure[node.identifier] = []
                    
                    # ç„¶åå¤„ç†æ‰€æœ‰æ–‡ä»¶èŠ‚ç‚¹å’Œè™šæ‹Ÿæ–‡ä»¶èŠ‚ç‚¹
                    all_file_nodes = [node for node in all_nodes if hasattr(node, 'data') and not node.data.get("is_dir", False)]
                    
                    for node in sorted(all_file_nodes, key=lambda node: node.tag):
                        # è·å–åŸå§‹æ–‡ä»¶åï¼ˆå»é™¤å·²æœ‰å›¾æ ‡ï¼‰
                        orig_filename = remove_file_icons(node.tag)
                        # æ·»åŠ é€‚å½“çš„å›¾æ ‡
                        icon = get_file_icon(orig_filename, is_dir=False)
                        
                        # è·å–çˆ¶èŠ‚ç‚¹ID
                        parent_id = node.predecessor if hasattr(node, 'predecessor') and node.predecessor != "root" else "root"
                        
                        # ç¡®ä¿çˆ¶èŠ‚ç‚¹é”®å­˜åœ¨äºå­—å…¸ä¸­
                        if parent_id not in dir_structure:
                            dir_structure[parent_id] = []
                        
                        # æ·»åŠ æ–‡ä»¶èŠ‚ç‚¹åˆ°ç»“æ„ä¸­
                        dir_structure[parent_id].append({
                            "id": node.identifier,
                            "name": f"{icon} {orig_filename}",
                            "is_dir": False
                        })
                
                # æ·»åŠ æˆåŠŸé€šçŸ¥ï¼Œå¸¦æ–‡ä»¶æ•°é‡å›¾æ ‡
                # è¿™ä¸ªé€šçŸ¥ä¼šåœ¨ä¸‹é¢çš„æ–°é€»è¾‘ä¸­æ·»åŠ ï¼Œè¿™é‡Œæ³¨é‡Šæ‰
                # add_notify(f"âœ…ã€Š{task['taskname']}ã€‹æ–°å¢æ–‡ä»¶:")
                # add_notify(f"/{task['savepath']}")
                
                # ç§»é™¤è°ƒè¯•ä¿¡æ¯
                # è·å–æ›´æ–°ç›®å½•åç§°
                update_subdir = task.get("update_subdir")
                
                # åˆ›å»ºä¸€ä¸ªåˆ—è¡¨æ¥å­˜å‚¨æ‰€æœ‰åŒ¹é…çš„æ›´æ–°ç›®å½•èŠ‚ç‚¹åŠå…¶æ–‡ä»¶
                update_dir_nodes = []
                files_by_dir = {}
                # é»˜è®¤æ ¹ç›®å½•
                files_by_dir["root"] = []
                
                # æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„æ›´æ–°ç›®å½•èŠ‚ç‚¹
                dir_nodes = [node for node in is_new_tree.all_nodes_itr() if node.data.get("is_dir") == True and node.identifier != "root"]
                if update_subdir:
                    for node in dir_nodes:
                        dir_name = node.tag.lstrip("ğŸ“")
                        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ç›®å½•å
                        if re.search(update_subdir, dir_name):
                            update_dir_nodes.append(node)
                            # ä¸ºæ¯ä¸ªåŒ¹é…çš„ç›®å½•åˆ›å»ºç©ºæ–‡ä»¶åˆ—è¡¨
                            files_by_dir[node.identifier] = []
                
                # å¦‚æœæ˜¯ä¿æŒåŸç›®å½•ç»“æ„æ¨¡å¼ï¼Œè·å–å­ç›®å½•æ–‡ä»¶åˆ—è¡¨ç”¨äºè¿‡æ»¤ï¼ˆé€’å½’è·å–æ‰€æœ‰å­ç›®å½•ï¼‰
                auto_extract_mode_display = task.get("auto_extract_archive", "disabled")
                keep_structure_display = "keep_structure" in auto_extract_mode_display if auto_extract_mode_display != "disabled" else False
                auto_extract_subdirs_display = task.get("_auto_extract_subdirs") or []
                subdir_file_names_display = set()
                # é€’å½’è·å–æ‰€æœ‰å­ç›®å½•ä¸­çš„æ–‡ä»¶ï¼ˆåŒ…æ‹¬åµŒå¥—å­ç›®å½•ï¼‰
                def get_all_subdir_files_display(subdir_fid, subdir_name):
                    """é€’å½’è·å–å­ç›®å½•åŠå…¶æ‰€æœ‰å­ç›®å½•ä¸­çš„æ–‡ä»¶"""
                    all_files = []
                    try:
                        subdir_files = account.ls_dir(subdir_fid)
                        for subdir_file in subdir_files:
                            if subdir_file.get("dir", False):
                                # é€’å½’å¤„ç†å­ç›®å½•
                                sub_subdir_path = f"{subdir_name}/{subdir_file['file_name']}"
                                sub_subdir_full_path = f"{savepath_display}/{sub_subdir_path}"
                                if sub_subdir_full_path in account.savepath_fid:
                                    sub_subdir_fid = account.savepath_fid[sub_subdir_full_path]
                                    all_files.extend(get_all_subdir_files_display(sub_subdir_fid, sub_subdir_path))
                            else:
                                all_files.append(subdir_file)
                    except Exception:
                        pass
                    return all_files
                
                if keep_structure_display and auto_extract_subdirs_display:
                    savepath_display = re.sub(r"/{2,}", "/", f"/{task['savepath']}")
                    for subdir_path in auto_extract_subdirs_display:
                        subdir_name = subdir_path.lstrip("/")
                        subdir_full_path = f"{savepath_display}/{subdir_name}"
                        if subdir_full_path in account.savepath_fid:
                            subdir_fid = account.savepath_fid[subdir_full_path]
                            try:
                                all_subdir_files = get_all_subdir_files_display(subdir_fid, subdir_name)
                                for subdir_file in all_subdir_files:
                                    subdir_file_names_display.add(subdir_file["file_name"])
                            except Exception:
                                pass
                
                # ä»æ–‡ä»¶çš„è·¯å¾„ä¿¡æ¯ä¸­æå–çˆ¶ç›®å½•
                for node in file_nodes:
                    # å¦‚æœæ˜¯ä¿æŒåŸç›®å½•ç»“æ„æ¨¡å¼ï¼Œæ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨å­ç›®å½•ä¸­
                    if keep_structure_display:
                        file_name = remove_file_icons(node.tag)
                        if file_name in subdir_file_names_display:
                            # æ–‡ä»¶åœ¨å­ç›®å½•ä¸­ï¼Œä¸åº”è¯¥æ·»åŠ åˆ°æ ¹ç›®å½•ï¼Œè·³è¿‡
                            continue
                    
                    if hasattr(node, 'data') and node.data and 'path' in node.data:
                        path = node.data['path']
                        path_parts = path.strip('/').split('/')
                        
                        # ç¡®å®šæ–‡ä»¶åº”è¯¥å±äºå“ªä¸ªç›®å½•
                        if len(path_parts) > 1 and update_subdir:
                            # è·å–ä¿å­˜è·¯å¾„
                            save_path = task.get("savepath", "").rstrip("/")
                            save_path_parts = save_path.split("/")
                            save_path_basename = save_path_parts[-1] if save_path_parts else ""
                            
                            # å»é™¤è·¯å¾„ä¸­çš„ä¿å­˜è·¯å¾„éƒ¨åˆ†ï¼Œåªä¿ç•™ç›¸å¯¹è·¯å¾„
                            # é¦–å…ˆæŸ¥æ‰¾ä¿å­˜è·¯å¾„åœ¨å®Œæ•´è·¯å¾„ä¸­çš„ä½ç½®
                            relative_path_start = 0
                            for i, part in enumerate(path_parts):
                                if i < len(path_parts) - 1 and part == save_path_basename:
                                    relative_path_start = i + 1
                                    break
                            
                            # æå–ç›¸å¯¹è·¯å¾„éƒ¨åˆ†ï¼Œä¸å«æ–‡ä»¶å
                            relative_path_parts = path_parts[relative_path_start:-1]
                            
                            # å¦‚æœæ²¡æœ‰ç›¸å¯¹è·¯å¾„éƒ¨åˆ†ï¼ˆç›´æ¥åœ¨æ ¹ç›®å½•ä¸‹çš„æ–‡ä»¶ï¼‰
                            if not relative_path_parts:
                                # å¦‚æœæ˜¯ä¿æŒåŸç›®å½•ç»“æ„æ¨¡å¼ï¼Œæ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨å­ç›®å½•ä¸­
                                if keep_structure_display:
                                    file_name_check = remove_file_icons(node.tag)
                                    if file_name_check in subdir_file_names_display:
                                        # æ–‡ä»¶åœ¨å­ç›®å½•ä¸­ï¼Œä¸åº”è¯¥æ·»åŠ åˆ°æ ¹ç›®å½•ï¼Œè·³è¿‡
                                        continue
                                files_by_dir["root"].append(node)
                                continue
                                
                            # æ£€æŸ¥ç¬¬ä¸€çº§å­ç›®å½•æ˜¯å¦æ˜¯æ›´æ–°ç›®å½•ä¹‹ä¸€
                            first_level_dir = relative_path_parts[0]
                            parent_found = False
                            
                            for dir_node in update_dir_nodes:
                                dir_name = dir_node.tag.lstrip("ğŸ“")
                                # åªçœ‹ç¬¬ä¸€çº§ç›®å½•æ˜¯å¦åŒ¹é…æ›´æ–°ç›®å½•è§„åˆ™
                                if dir_name == first_level_dir:
                                    # æ–‡ä»¶å±äºæ­¤æ›´æ–°ç›®å½•ï¼Œç›´æ¥æ·»åŠ åˆ°å¯¹åº”ç›®å½•ä¸‹
                                    files_by_dir[dir_node.identifier].append(node)
                                    parent_found = True
                                    
                                    # ä¸ºäº†åœ¨æ ‘æ˜¾ç¤ºä¸­å®šä½è¯¥æ–‡ä»¶ï¼Œè®¾ç½®å®Œæ•´è·¯å¾„ä¿¡æ¯
                                    if len(relative_path_parts) > 1:
                                        # å¦‚æœæ˜¯å¤šçº§åµŒå¥—ç›®å½•ï¼Œè®¾ç½®åµŒå¥—è·¯å¾„æ ‡è®°
                                        node.nested_path = "/".join(relative_path_parts[1:])
                                    break
                            
                            if not parent_found:
                                # å°è¯•æ£€æŸ¥æ–‡ä»¶çš„ç›´æ¥çˆ¶ç›®å½•
                                parent_dir_name = path_parts[-2]
                                for dir_node in update_dir_nodes:
                                    dir_name = dir_node.tag.lstrip("ğŸ“")
                                    if parent_dir_name == dir_name:
                                        files_by_dir[dir_node.identifier].append(node)
                                        parent_found = True
                                        break
                                
                                if not parent_found:
                                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„çˆ¶ç›®å½•ï¼Œå°†æ–‡ä»¶æ·»åŠ åˆ°æ ¹ç›®å½•
                                    # å¦‚æœæ˜¯ä¿æŒåŸç›®å½•ç»“æ„æ¨¡å¼ï¼Œæ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨å­ç›®å½•ä¸­
                                    if keep_structure_display:
                                        file_name_check = remove_file_icons(node.tag)
                                        if file_name_check in subdir_file_names_display:
                                            # æ–‡ä»¶åœ¨å­ç›®å½•ä¸­ï¼Œä¸åº”è¯¥æ·»åŠ åˆ°æ ¹ç›®å½•ï¼Œè·³è¿‡
                                            continue
                                    files_by_dir["root"].append(node)
                        else:
                            # æ–‡ä»¶å±äºæ ¹ç›®å½•
                            # å¦‚æœæ˜¯ä¿æŒåŸç›®å½•ç»“æ„æ¨¡å¼ï¼Œæ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨å­ç›®å½•ä¸­
                            if keep_structure_display:
                                file_name_check = remove_file_icons(node.tag)
                                if file_name_check in subdir_file_names_display:
                                    # æ–‡ä»¶åœ¨å­ç›®å½•ä¸­ï¼Œä¸åº”è¯¥æ·»åŠ åˆ°æ ¹ç›®å½•ï¼Œè·³è¿‡
                                    continue
                            files_by_dir["root"].append(node)
                    else:
                        # æ²¡æœ‰è·¯å¾„ä¿¡æ¯ï¼Œé»˜è®¤æ·»åŠ åˆ°æ ¹ç›®å½•
                        # å¦‚æœæ˜¯ä¿æŒåŸç›®å½•ç»“æ„æ¨¡å¼ï¼Œæ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨å­ç›®å½•ä¸­
                        if keep_structure_display:
                            file_name_check = remove_file_icons(node.tag)
                            if file_name_check in subdir_file_names_display:
                                # æ–‡ä»¶åœ¨å­ç›®å½•ä¸­ï¼Œä¸åº”è¯¥æ·»åŠ åˆ°æ ¹ç›®å½•ï¼Œè·³è¿‡
                                continue
                        files_by_dir["root"].append(node)
                
                # å¤„ç†è‡ªåŠ¨è§£å‹çš„æ–‡ä»¶å¤¹ï¼ˆä¿æŒåŸç›®å½•ç»“æ„æ¨¡å¼ï¼‰
                # æ£€æŸ¥æ˜¯å¦æœ‰è‡ªåŠ¨è§£å‹çš„æ–‡ä»¶å¤¹éœ€è¦æ·»åŠ åˆ°æ–‡ä»¶æ ‘ä¸­
                auto_extract_subdirs = task.get("_auto_extract_subdirs") or []
                if auto_extract_subdirs:
                    savepath = re.sub(r"/{2,}", "/", f"/{task['savepath']}")
                    if savepath in account.savepath_fid:
                        savepath_fid = account.savepath_fid[savepath]
                        
                        # é€’å½’è·å–æ–‡ä»¶å¤¹å†…å®¹çš„è¾…åŠ©å‡½æ•°
                        def get_extracted_folder_contents(folder_fid, folder_name, relative_path=""):
                            """é€’å½’è·å–è§£å‹æ–‡ä»¶å¤¹å†…çš„æ‰€æœ‰æ–‡ä»¶å’Œå­ç›®å½•"""
                            try:
                                folder_contents = account.ls_dir(folder_fid)
                                files = []
                                dirs = []
                                
                                for item in folder_contents:
                                    item_name = item["file_name"]
                                    item_fid = item["fid"]
                                    item_is_dir = item.get("dir", False)
                                    
                                    # æ„å»ºç›¸å¯¹è·¯å¾„
                                    if relative_path:
                                        item_relative_path = f"{relative_path}/{item_name}"
                                    else:
                                        item_relative_path = item_name
                                    
                                    if item_is_dir:
                                        # é€’å½’è·å–å­ç›®å½•å†…å®¹
                                        sub_contents = get_extracted_folder_contents(item_fid, item_name, item_relative_path)
                                        dirs.append({
                                            "name": item_name,
                                            "fid": item_fid,
                                            "relative_path": item_relative_path,
                                            "contents": sub_contents
                                        })
                                    else:
                                        # æ·»åŠ æ–‡ä»¶
                                        files.append({
                                            "name": item_name,
                                            "fid": item_fid,
                                            "relative_path": item_relative_path,
                                            "size": item.get("size", 0),
                                            "obj_category": item.get("obj_category", "default")
                                        })
                                
                                return {"files": files, "dirs": dirs}
                            except Exception as e:
                                print(f"âš ï¸ è·å–è§£å‹æ–‡ä»¶å¤¹å†…å®¹å¤±è´¥ï¼ˆ{folder_name}ï¼‰: {e}")
                                return {"files": [], "dirs": []}
                        
                        # ä¸ºæ¯ä¸ªè§£å‹æ–‡ä»¶å¤¹åˆ›å»ºè™šæ‹ŸèŠ‚ç‚¹å¹¶æ·»åŠ åˆ°æ–‡ä»¶æ ‘
                        for subdir_path in auto_extract_subdirs:
                            try:
                                # subdir_path æ ¼å¼ä¸º "/æ–‡ä»¶å¤¹å"
                                subdir_name = subdir_path.lstrip("/")
                                subdir_full_path = f"{savepath}/{subdir_name}"
                                
                                # è·å–æ–‡ä»¶å¤¹çš„ fid
                                if subdir_full_path in account.savepath_fid:
                                    subdir_fid = account.savepath_fid[subdir_full_path]
                                    
                                    # åˆ›å»ºè™šæ‹Ÿç›®å½•èŠ‚ç‚¹
                                    class VirtualExtractedDirNode:
                                        def __init__(self, name, dir_id, relative_path=""):
                                            self.tag = f"ğŸ“{name}"
                                            self.identifier = f"extracted_dir_{dir_id}"
                                            self.data = {
                                                "is_dir": True,
                                                "fid": dir_id,
                                                "relative_path": relative_path
                                            }
                                    
                                    # åˆ›å»ºè§£å‹æ–‡ä»¶å¤¹çš„è™šæ‹ŸèŠ‚ç‚¹
                                    extracted_dir_node = VirtualExtractedDirNode(subdir_name, subdir_fid, subdir_name)
                                    
                                    # å¦‚æœè®¾ç½®äº† update_subdirï¼Œæ£€æŸ¥æ˜¯å¦åŒ¹é…
                                    if update_subdir:
                                        if re.search(update_subdir, subdir_name):
                                            # åŒ¹é…æ›´æ–°ç›®å½•è§„åˆ™ï¼Œæ·»åŠ åˆ°æ›´æ–°ç›®å½•åˆ—è¡¨
                                            if extracted_dir_node.identifier not in [n.identifier for n in update_dir_nodes]:
                                                update_dir_nodes.append(extracted_dir_node)
                                                files_by_dir[extracted_dir_node.identifier] = []
                                    else:
                                        # æ²¡æœ‰è®¾ç½® update_subdirï¼Œæ·»åŠ åˆ°æ›´æ–°ç›®å½•åˆ—è¡¨
                                        if extracted_dir_node.identifier not in [n.identifier for n in update_dir_nodes]:
                                            update_dir_nodes.append(extracted_dir_node)
                                            files_by_dir[extracted_dir_node.identifier] = []
                                    
                                    # é€’å½’è·å–æ–‡ä»¶å¤¹å†…å®¹
                                    folder_contents = get_extracted_folder_contents(subdir_fid, subdir_name, subdir_name)
                                    
                                    # åˆ›å»ºè™šæ‹Ÿæ–‡ä»¶èŠ‚ç‚¹çš„è¾…åŠ©å‡½æ•°
                                    def create_virtual_file_node(file_info, parent_dir_id, relative_path=""):
                                        """åˆ›å»ºè™šæ‹Ÿæ–‡ä»¶èŠ‚ç‚¹"""
                                        class VirtualExtractedFileNode:
                                            def __init__(self, name, file_id, parent_dir_id_param, relative_path=""):
                                                file_icon = get_file_icon(name, is_dir=False)
                                                self.tag = f"{file_icon} {name}"
                                                self.identifier = f"extracted_file_{file_id}"
                                                self.predecessor = parent_dir_id_param
                                                # æ„å»ºå®Œæ•´è·¯å¾„
                                                if relative_path:
                                                    full_path = f"{savepath}/{relative_path}"
                                                else:
                                                    full_path = f"{savepath}/{name}"
                                                self.data = {
                                                    "is_dir": False,
                                                    "fid": file_id,
                                                    "path": full_path,
                                                    "relative_path": relative_path
                                                }
                                                # å¦‚æœç›¸å¯¹è·¯å¾„åŒ…å«å¤šçº§ç›®å½•ï¼Œè®¾ç½®åµŒå¥—è·¯å¾„
                                                if relative_path and "/" in relative_path:
                                                    path_parts = relative_path.split("/")
                                                    if len(path_parts) > 1:
                                                        # åµŒå¥—è·¯å¾„æ˜¯é™¤äº†æœ€åä¸€å±‚ï¼ˆæ–‡ä»¶åï¼‰ä¹‹å¤–çš„æ‰€æœ‰è·¯å¾„
                                                        self.nested_path = "/".join(path_parts[:-1])
                                        
                                        return VirtualExtractedFileNode(
                                            file_info["name"],
                                            file_info["fid"],
                                            parent_dir_id,  # ä½¿ç”¨å¤–å±‚å‡½æ•°çš„å‚æ•°
                                            relative_path
                                        )
                                    
                                    # é€’å½’æ·»åŠ æ–‡ä»¶å’Œå­ç›®å½•åˆ°æ–‡ä»¶æ ‘
                                    def add_extracted_contents_to_tree(contents, parent_dir_id, current_relative_path=""):
                                        """é€’å½’æ·»åŠ è§£å‹å†…å®¹åˆ°æ–‡ä»¶æ ‘"""
                                        # æ·»åŠ æ–‡ä»¶
                                        for file_info in contents["files"]:
                                            # æ„å»ºæ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„
                                            if current_relative_path:
                                                file_relative_path = f"{current_relative_path}/{file_info['name']}"
                                            else:
                                                file_relative_path = file_info["name"]
                                            
                                            file_node = create_virtual_file_node(
                                                file_info,
                                                parent_dir_id,
                                                file_relative_path
                                            )
                                            files_by_dir[parent_dir_id].append(file_node)
                                        
                                        # é€’å½’å¤„ç†å­ç›®å½•
                                        for dir_info in contents["dirs"]:
                                            # åˆ›å»ºå­ç›®å½•çš„è™šæ‹ŸèŠ‚ç‚¹
                                            subdir_node = VirtualExtractedDirNode(
                                                dir_info["name"],
                                                dir_info["fid"],
                                                dir_info["relative_path"]
                                            )
                                            
                                            # å¿…é¡»å…ˆåˆå§‹åŒ– files_by_dirï¼Œå¦åˆ™é€’å½’å†… append ä¼š KeyError
                                            if subdir_node.identifier not in files_by_dir:
                                                files_by_dir[subdir_node.identifier] = []
                                            
                                            # å¦‚æœè®¾ç½®äº† update_subdirï¼Œæ£€æŸ¥å­ç›®å½•æ˜¯å¦åŒ¹é…
                                            if update_subdir:
                                                if re.search(update_subdir, dir_info["name"]):
                                                    # åŒ¹é…æ›´æ–°ç›®å½•è§„åˆ™ï¼Œæ·»åŠ åˆ°æ›´æ–°ç›®å½•åˆ—è¡¨
                                                    if subdir_node.identifier not in [n.identifier for n in update_dir_nodes]:
                                                        update_dir_nodes.append(subdir_node)
                                            
                                            # é€’å½’æ·»åŠ å­ç›®å½•å†…å®¹
                                            add_extracted_contents_to_tree(
                                                dir_info["contents"],
                                                subdir_node.identifier,
                                                dir_info["relative_path"]
                                            )
                                    
                                    # æ·»åŠ è§£å‹æ–‡ä»¶å¤¹çš„å†…å®¹åˆ°æ–‡ä»¶æ ‘
                                    add_extracted_contents_to_tree(folder_contents, extracted_dir_node.identifier)
                                    
                            except Exception as e:
                                print(f"âš ï¸ å¤„ç†è§£å‹æ–‡ä»¶å¤¹å¤±è´¥ï¼ˆ{subdir_path}ï¼‰: {e}")
                
                # æ’åºå‡½æ•°ï¼Œä½¿ç”¨æ–‡ä»¶èŠ‚ç‚¹ä½œä¸ºè¾“å…¥
                def sort_nodes(nodes):
                    return sorted(nodes, key=lambda node: sort_file_by_name(remove_file_icons(node.tag)))
                
                # åˆå§‹åŒ–æœ€ç»ˆæ˜¾ç¤ºæ–‡ä»¶çš„å­—å…¸
                final_display_files = {
                    "root": [],
                    "subdirs": {}
                }
                
                # åˆ›å»ºé›†åˆæ¥è·Ÿè¸ªå½“æ¬¡æ–°å¢çš„æ–‡ä»¶å’Œæ–‡ä»¶å¤¹
                current_added_files = set()
                current_added_dirs = set()
                
                # è·Ÿè¸ªå­ç›®å½•å’Œæ ¹ç›®å½•æ˜¯å¦æœ‰æ–°å¢æ–‡ä»¶
                has_update_in_root = False
                has_update_in_subdir = False
                
                # è®°å½•æ˜¯å¦æ˜¯é¦–æ¬¡æ‰§è¡Œ
                is_first_run = True
                if task.get("last_run_time"):
                    is_first_run = False
                
                # å…ˆæ£€æŸ¥æ˜¯å¦æœ‰æ–°å¢çš„ç›®å½•
                for dir_node in dir_nodes:
                    dir_name = dir_node.tag.lstrip("ğŸ“")
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯è§£å‹æ–‡ä»¶å¤¹çš„è™šæ‹Ÿç›®å½•èŠ‚ç‚¹ï¼ˆä»¥ extracted_dir_ å¼€å¤´ï¼‰
                    if dir_node.identifier.startswith("extracted_dir_"):
                        current_added_dirs.add(dir_name)
                        has_update_in_subdir = True
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æŒ‡å®šçš„æ›´æ–°ç›®å½•
                    elif update_subdir and re.search(update_subdir, dir_name):
                        current_added_dirs.add(dir_name)
                        has_update_in_subdir = True
                
                # æ£€æŸ¥æ ¹ç›®å½•æ˜¯å¦æœ‰æ–°å¢æ–‡ä»¶
                root_new_files = []
                for node in files_by_dir["root"]:
                    file_name = remove_file_icons(node.tag)
                    # åˆ¤æ–­æ˜¯å¦ä¸ºæ–°å¢æ–‡ä»¶
                    is_new_file = False

                    # å¦‚æœæ˜¯ä¿æŒåŸç›®å½•ç»“æ„æ¨¡å¼ä¸”è¯¥æ–‡ä»¶æ¥è‡ªè§£å‹ï¼Œåˆ™ä¸è§†ä¸ºâ€œæ ¹ç›®å½•æ–°å¢æ–‡ä»¶â€
                    auto_extract_mode_root = task.get("auto_extract_archive", "disabled")
                    keep_structure_root = "keep_structure" in auto_extract_mode_root if auto_extract_mode_root != "disabled" else False
                    if keep_structure_root and getattr(node, "data", None) and node.data.get("from_extraction"):
                        # è¿™ç±»æ–‡ä»¶å·²ç»é€šè¿‡è§£å‹ç›®å½•ç»“æ„å±•ç¤ºï¼Œä¸åº”å†æ¬¡ä½œä¸ºæ ¹ç›®å½•æ–‡ä»¶æ˜¾ç¤º
                        continue
                    
                    # 1. æ£€æŸ¥æ˜¯å¦æ˜¯è§£å‹æ–‡ä»¶å¤¹çš„è™šæ‹ŸèŠ‚ç‚¹ï¼ˆä»¥ extracted_ å¼€å¤´ï¼‰
                    if node.identifier.startswith("extracted_"):
                        is_new_file = True
                    
                    # 2. æ£€æŸ¥æ˜¯å¦åœ¨å½“å‰è½¬å­˜çš„æ–‡ä»¶åˆ—è¡¨ä¸­
                    elif hasattr(node, 'data') and 'created_at' in node.data:
                        current_time = int(time.time())
                        time_threshold = 600  # 10åˆ†é’Ÿ = 600ç§’
                        if current_time - node.data['created_at'] < time_threshold:
                            is_new_file = True
                    
                    # 3. èŠ‚ç‚¹æœ¬èº«æ˜¯ä»å½“æ¬¡è½¬å­˜çš„æ–‡ä»¶æ ‘ä¸­è·å–çš„
                    elif hasattr(is_new_tree, 'nodes') and node.identifier in is_new_tree.nodes:
                        is_new_file = True
                    
                    # 4. é¦–æ¬¡è¿è¡Œä»»åŠ¡æ—¶ï¼Œè§†ä¸ºæ‰€æœ‰æ–‡ä»¶éƒ½æ˜¯æ–°å¢çš„
                    elif is_first_run:
                        is_new_file = True
                    
                    if is_new_file:
                        # å¦‚æœæ˜¯ä¿æŒåŸç›®å½•ç»“æ„æ¨¡å¼ï¼Œå†æ¬¡æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨å­ç›®å½•ä¸­
                        auto_extract_mode_final = task.get("auto_extract_archive", "disabled")
                        keep_structure_final = "keep_structure" in auto_extract_mode_final if auto_extract_mode_final != "disabled" else False
                        auto_extract_subdirs_final = task.get("_auto_extract_subdirs") or []
                        
                        if keep_structure_final and auto_extract_subdirs_final:
                            # è·å–æ‰€æœ‰å­ç›®å½•ä¸­çš„æ–‡ä»¶åï¼ˆé€’å½’ï¼‰
                            savepath_final = re.sub(r"/{2,}", "/", f"/{task['savepath']}")
                            subdir_file_names_final = set()
                            
                            def get_all_subdir_files_final(subdir_fid, subdir_name):
                                """é€’å½’è·å–å­ç›®å½•åŠå…¶æ‰€æœ‰å­ç›®å½•ä¸­çš„æ–‡ä»¶"""
                                all_files = []
                                try:
                                    subdir_files = account.ls_dir(subdir_fid)
                                    for subdir_file in subdir_files:
                                        if subdir_file.get("dir", False):
                                            sub_subdir_path = f"{subdir_name}/{subdir_file['file_name']}"
                                            sub_subdir_full_path = f"{savepath_final}/{sub_subdir_path}"
                                            if sub_subdir_full_path in account.savepath_fid:
                                                sub_subdir_fid = account.savepath_fid[sub_subdir_full_path]
                                                all_files.extend(get_all_subdir_files_final(sub_subdir_fid, sub_subdir_path))
                                        else:
                                            all_files.append(subdir_file)
                                except Exception:
                                    pass
                                return all_files
                            
                            for subdir_path in auto_extract_subdirs_final:
                                subdir_name = subdir_path.lstrip("/")
                                subdir_full_path = f"{savepath_final}/{subdir_name}"
                                if subdir_full_path in account.savepath_fid:
                                    subdir_fid = account.savepath_fid[subdir_full_path]
                                    try:
                                        all_subdir_files = get_all_subdir_files_final(subdir_fid, subdir_name)
                                        for subdir_file in all_subdir_files:
                                            subdir_file_names_final.add(subdir_file["file_name"])
                                    except Exception:
                                        pass
                            
                            # å¦‚æœæ–‡ä»¶åœ¨å­ç›®å½•ä¸­ï¼Œè·³è¿‡æ·»åŠ åˆ°æ ¹ç›®å½•
                            if file_name in subdir_file_names_final:
                                continue
                        
                        root_new_files.append(node)
                        current_added_files.add(file_name)
                        has_update_in_root = True
                        
                        # è®°å½•åˆ°æœ€ç»ˆæ˜¾ç¤ºçš„æ–‡ä»¶åˆ—è¡¨ä¸­
                        final_display_files["root"].append(node)
                
                # åˆ›å»ºå¤šç›®å½•ä¸‹çš„æ›´æ–°æ–‡ä»¶å­—å…¸
                subdir_new_files = {}
                
                # é¦–æ¬¡è¿è¡Œæ—¶ï¼Œè®°å½•å“ªäº›å­ç›®å½•æ˜¯æ–°æ·»åŠ çš„
                new_added_dirs = set()
                
                # å¯¹æ¯ä¸ªå·²è¯†åˆ«çš„æ›´æ–°ç›®å½•ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ–°æ–‡ä»¶
                for dir_node in update_dir_nodes:
                    dir_name = dir_node.tag.lstrip("ğŸ“")
                    dir_id = dir_node.identifier
                    dir_files = files_by_dir.get(dir_id, [])
                    
                    # åˆå§‹åŒ–è¯¥ç›®å½•çš„æ–°æ–‡ä»¶åˆ—è¡¨
                    subdir_new_files[dir_id] = []
                    
                    # é¦–æ¬¡è¿è¡Œæ—¶ï¼Œè®°å½•æ‰€æœ‰ç¬¦åˆæ›´æ–°ç›®å½•è§„åˆ™çš„ç›®å½•
                    if is_first_run:
                        new_added_dirs.add(dir_name)
                        has_update_in_subdir = True
                    
                    # æ£€æŸ¥è¯¥ç›®å½•ä¸‹çš„æ–‡ä»¶æ˜¯å¦æ˜¯æ–°æ–‡ä»¶
                    for file_node in dir_files:
                        file_name = remove_file_icons(file_node.tag)
                        # åˆ¤æ–­æ˜¯å¦ä¸ºæ–°å¢æ–‡ä»¶
                        is_new_file = False
                        
                        # 1. æ£€æŸ¥æ˜¯å¦æ˜¯è§£å‹æ–‡ä»¶å¤¹çš„è™šæ‹ŸèŠ‚ç‚¹ï¼ˆä»¥ extracted_ å¼€å¤´ï¼‰
                        if file_node.identifier.startswith("extracted_"):
                            is_new_file = True
                        
                        # 2. æ£€æŸ¥æ˜¯å¦åœ¨å½“å‰è½¬å­˜çš„æ–‡ä»¶åˆ—è¡¨ä¸­
                        elif hasattr(file_node, 'data') and 'created_at' in file_node.data:
                            current_time = int(time.time())
                            time_threshold = 600  # 10åˆ†é’Ÿ = 600ç§’
                            if current_time - file_node.data['created_at'] < time_threshold:
                                is_new_file = True
                        
                        # 3. èŠ‚ç‚¹æœ¬èº«æ˜¯ä»å½“æ¬¡è½¬å­˜çš„æ–‡ä»¶æ ‘ä¸­è·å–çš„
                        elif hasattr(is_new_tree, 'nodes') and file_node.identifier in is_new_tree.nodes:
                            is_new_file = True
                        
                        # 4. é¦–æ¬¡è¿è¡Œä»»åŠ¡æ—¶ï¼Œè§†ä¸ºæ‰€æœ‰æ–‡ä»¶éƒ½æ˜¯æ–°å¢çš„
                        elif is_first_run:
                            is_new_file = True
                        
                        if is_new_file:
                            subdir_new_files[dir_id].append(file_node)
                            current_added_files.add(file_name)
                            has_update_in_subdir = True
                            
                            # è®°å½•åˆ°æœ€ç»ˆæ˜¾ç¤ºçš„æ–‡ä»¶åˆ—è¡¨ä¸­
                            if dir_id not in final_display_files["subdirs"]:
                                final_display_files["subdirs"][dir_id] = []
                            final_display_files["subdirs"][dir_id].append(file_node)
                
                # å¦‚æœå·²è¯†åˆ«çš„ç›®å½•ä¸­æ²¡æœ‰æ–°å¢æ–‡ä»¶ï¼Œå°è¯•è¿›ä¸€æ­¥æŸ¥æ‰¾ç¬¦åˆupdate_subdirè§„åˆ™çš„ç›®å½•
                if update_subdir and not has_update_in_subdir:
                    savepath = re.sub(r"/{2,}", "/", f"/{task['savepath']}")
                    
                    # è·å–ä¿å­˜è·¯å¾„ä¸‹çš„æ‰€æœ‰ç›®å½•
                    try:
                        all_dirs = account.ls_dir(account.savepath_fid[savepath])
                        
                        # ç­›é€‰å‡ºç¬¦åˆæ›´æ–°è§„åˆ™çš„ç›®å½•
                        for dir_item in all_dirs:
                            if dir_item.get("dir", False):
                                dir_name = dir_item["file_name"]
                                if re.search(update_subdir, dir_name):
                                    # æ£€æŸ¥è¯¥ç›®å½•æ˜¯å¦å·²ç»å¤„ç†è¿‡
                                    if not any(node.tag.lstrip("ğŸ“") == dir_name for node in update_dir_nodes):
                                        # è·å–ç›®å½•çš„æ–‡ä»¶åˆ—è¡¨
                                        update_subdir_path = f"{savepath}/{dir_name}"
                                        if update_subdir_path in account.savepath_fid:
                                            try:
                                                update_subdir_fid = account.savepath_fid[update_subdir_path]
                                                update_subdir_files = account.ls_dir(update_subdir_fid)
                                                
                                                # åˆ›å»ºè™šæ‹Ÿç›®å½•èŠ‚ç‚¹
                                                class VirtualDirNode:
                                                    def __init__(self, name, dir_id):
                                                        self.tag = f"ğŸ“{name}"
                                                        self.identifier = dir_id
                                                        self.data = {"is_dir": True}
                                                
                                                # åˆ›å»ºè™šæ‹Ÿç›®å½•èŠ‚ç‚¹
                                                virtual_dir_node = VirtualDirNode(dir_name, f"virtual_{dir_name}")
                                                update_dir_nodes.append(virtual_dir_node)
                                                
                                                # åˆå§‹åŒ–æ–°æ–‡ä»¶åˆ—è¡¨
                                                subdir_new_files[virtual_dir_node.identifier] = []
                                                
                                                # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºè™šæ‹ŸèŠ‚ç‚¹
                                                for file in update_subdir_files:
                                                    if not file.get("dir", False):
                                                        class VirtualFileNode:
                                                            def __init__(self, name, file_id, dir_id):
                                                                self.tag = name
                                                                self.identifier = file_id
                                                                self.predecessor = dir_id
                                                                self.data = {"is_dir": False}
                                                        
                                                        # åˆ›å»ºè™šæ‹Ÿæ–‡ä»¶èŠ‚ç‚¹ï¼Œå…³è”åˆ°è™šæ‹Ÿç›®å½•
                                                        virtual_node = VirtualFileNode(
                                                            file["file_name"], 
                                                            f"virtual_file_{file['fid']}", 
                                                            virtual_dir_node.identifier
                                                        )
                                                        
                                                        # é¦–æ¬¡è¿è¡Œæ—¶ï¼Œå°†æ‰€æœ‰æ–‡ä»¶è§†ä¸ºæ–°æ–‡ä»¶
                                                        if is_first_run:
                                                            subdir_new_files[virtual_dir_node.identifier].append(virtual_node)
                                                            has_update_in_subdir = True
                                            except Exception as e:
                                                print(f"è·å–ç›®å½• {dir_name} æ–‡ä»¶åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}")
                    except Exception as e:
                        print(f"è·å–ç›®å½•åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}")
                
                # å¯¹æ‰€æœ‰ç›®å½•ä¸­çš„æ–‡ä»¶è¿›è¡Œæ’åº
                for dir_id in subdir_new_files:
                    if subdir_new_files[dir_id]:
                        subdir_new_files[dir_id] = sort_nodes(subdir_new_files[dir_id])
                
                # è®°å½•æœ¬æ¬¡æ‰§è¡Œæ—¶é—´
                task["last_run_time"] = int(time.time())
                
                # æ˜¾ç¤ºæ–‡ä»¶æ ‘è§„åˆ™:
                # 1. åªæœ‰æ ¹ç›®å½•æœ‰æ›´æ–°ï¼šåªæ˜¾ç¤ºæ ¹ç›®å½•
                # 2. åªæœ‰å­ç›®å½•æœ‰æ›´æ–°ï¼šåªæ˜¾ç¤ºå­ç›®å½•
                # 3. æ ¹ç›®å½•å’Œå­ç›®å½•éƒ½æœ‰æ›´æ–°ï¼šæ˜¾ç¤ºä¸¤è€…
                # 4. éƒ½æ²¡æœ‰æ›´æ–°ï¼šä¸æ˜¾ç¤ºä»»ä½•å†…å®¹
                
                # å¦‚æœæ²¡æœ‰ä»»ä½•æ›´æ–°ï¼Œä¸æ˜¾ç¤ºä»»ä½•å†…å®¹
                if not has_update_in_root and not has_update_in_subdir:
                    # ä¸æ·»åŠ ä»»ä½•é€šçŸ¥
                    pass
                else:
                    # æ·»åŠ åŸºæœ¬é€šçŸ¥
                    add_notify(f"âœ…ã€Š{task['taskname']}ã€‹æ–°å¢æ–‡ä»¶:")
                    savepath = task['savepath']
                    add_notify(f"{re.sub(r'/{2,}', '/', f'/{savepath}')}")
                    
                    # ä¿®æ­£é¦–æ¬¡è¿è¡Œæ—¶å¯¹å­ç›®å½•çš„å¤„ç† - åªæœ‰åœ¨é¦–æ¬¡è¿è¡Œä¸”æœ‰æ–°å¢çš„å­ç›®å½•æ—¶æ‰æ˜¾ç¤ºå­ç›®å½•å†…å®¹
                    if has_update_in_root and has_update_in_subdir and is_first_run and len(new_added_dirs) == 0:
                        # è™½ç„¶æ ‡è®°ä¸ºé¦–æ¬¡è¿è¡Œï¼Œä½†æ²¡æœ‰æ–°å¢å­ç›®å½•ï¼Œä¸åº”å±•ç¤ºå­ç›®å½•å†…å®¹
                        has_update_in_subdir = False
                    
                    # æ„å»ºé‡å‘½åæ˜ å°„ï¼ˆç”¨äºæ›´æ–°æ–‡ä»¶æ ‘ä¸­çš„æ–‡ä»¶åï¼‰
                    rename_mapping = {}
                    if rename_logs:
                        for log in rename_logs:
                            # æ ¼å¼ï¼šé‡å‘½å: æ—§å â†’ æ–°å
                            match = re.search(r'é‡å‘½å: (.*?) â†’ (.+?)($|\s|ï¼Œ|å¤±è´¥)', log)
                            if match:
                                old_name = match.group(1).strip()
                                new_name = match.group(2).strip()
                                rename_mapping[old_name] = new_name
                    
                    # æ„å»ºå®Œæ•´çš„ç›®å½•æ ‘ç»“æ„ï¼ˆæ”¯æŒå¤šå±‚çº§åµŒå¥—ï¼‰
                    def build_directory_tree():
                        # åˆ›å»ºç›®å½•æ ‘ç»“æ„
                        dir_tree = {"root": {"dirs": {}, "files": []}}
                        
                        # è·å–ä¿å­˜è·¯å¾„çš„æœ€åä¸€éƒ¨åˆ†ç›®å½•åï¼ˆç”¨äºè¿‡æ»¤ï¼‰
                        save_path = task.get("savepath", "").rstrip("/")
                        save_path_parts = save_path.split("/")
                        save_path_basename = save_path_parts[-1] if save_path_parts else ""
                        
                        # å¤„ç†æ‰€æœ‰ç›®å½•èŠ‚ç‚¹
                        for dir_node in update_dir_nodes:
                            dir_id = dir_node.identifier
                            dir_name = dir_node.tag.lstrip("ğŸ“")
                            
                            # è·³è¿‡ä¸ä¿å­˜è·¯å¾„ç›¸åŒçš„ç›®å½•
                            if dir_name == save_path_basename or dir_name == save_path:
                                continue
                                
                            # å¦‚æœç›®å½•ååŒ…å«å®Œæ•´è·¯å¾„ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ä¿å­˜è·¯å¾„ç›¸å…³
                            if "/" in dir_name:
                                # æ£€æŸ¥æ˜¯å¦ä»¥è·¯å¾„å¼€å¤´
                                if dir_name.startswith("/"):
                                    continue
                                
                                # æ£€æŸ¥æ˜¯å¦æ˜¯ä¿å­˜è·¯å¾„æˆ–å…¶å­è·¯å¾„
                                path_parts = dir_name.split("/")
                                # è·³è¿‡åŒ…å«ä¿å­˜è·¯å¾„çš„å®Œæ•´è·¯å¾„
                                if any(part == save_path_basename for part in path_parts):
                                    continue
                            
                            # åˆ†å‰²è·¯å¾„ï¼Œå¤„ç†å¯èƒ½çš„å¤šçº§ç›®å½•
                            path_parts = dir_name.split("/")
                            
                            # ä»æ ¹èŠ‚ç‚¹å¼€å§‹æ„å»ºè·¯å¾„
                            current = dir_tree["root"]
                            
                            for i, part in enumerate(path_parts):
                                # è·³è¿‡ç©ºéƒ¨åˆ†å’Œä¿å­˜è·¯å¾„éƒ¨åˆ†
                                if not part or part == save_path_basename:
                                    continue
                                    
                                if part not in current["dirs"]:
                                    # åˆ›å»ºæ–°çš„ç›®å½•èŠ‚ç‚¹
                                    current["dirs"][part] = {
                                        "dirs": {},
                                        "files": [],
                                        "dir_id": dir_id if i == len(path_parts) - 1 else None
                                    }
                                current = current["dirs"][part]
                            
                            # æ·»åŠ è¯¥ç›®å½•çš„æ–‡ä»¶
                            if dir_id in subdir_new_files:
                                # å¤„ç†åµŒå¥—ç›®å½•ä¸‹çš„æ–‡ä»¶
                                non_nested_files = []
                                
                                for file_node in subdir_new_files[dir_id]:
                                    file_name = remove_file_icons(file_node.tag)
                                    if hasattr(file_node, 'nested_path') and file_node.nested_path:
                                        # å¤„ç†åµŒå¥—æ–‡ä»¶
                                        nested_path_parts = file_node.nested_path.split('/')
                                        
                                        # åˆ›å»ºæˆ–è·å–å­ç›®å½•ç»“æ„
                                        sub_current = current
                                        for i, part in enumerate(nested_path_parts):
                                            if part not in sub_current["dirs"]:
                                                # åˆ›å»ºæ–°çš„å­ç›®å½•ç»“æ„
                                                sub_current["dirs"][part] = {
                                                    "dirs": {},
                                                    "files": [],
                                                    "dir_id": None  # è™šæ‹Ÿç›®å½•æš‚æ—¶æ²¡æœ‰ID
                                                }
                                            sub_current = sub_current["dirs"][part]
                                        
                                        # æ·»åŠ æ–‡ä»¶åˆ°åµŒå¥—ç›®å½•
                                        sub_current["files"].append(file_node)
                                    else:
                                        # ä¸æ˜¯åµŒå¥—çš„æ–‡ä»¶ï¼Œç›´æ¥æ·»åŠ åˆ°å½“å‰ç›®å½•
                                        non_nested_files.append(file_node)
                                
                                # è®¾ç½®å½“å‰ç›®å½•çš„éåµŒå¥—æ–‡ä»¶
                                current["files"] = non_nested_files
                        
                        # æ·»åŠ æ ¹ç›®å½•æ–‡ä»¶
                        if has_update_in_root and final_display_files["root"]:
                            dir_tree["root"]["files"] = final_display_files["root"]
                        
                        return dir_tree
                    
                    # é€’å½’æ˜¾ç¤ºç›®å½•æ ‘
                    def display_tree(node, prefix="", depth=0):
                        # è·å–ç›®å½•å’Œæ–‡ä»¶åˆ—è¡¨
                        dirs = sorted(node["dirs"].items())
                        files = node.get("files", [])
                        
                        # æ ¹ç›®å½•æ–‡ä»¶ç‰¹æ®Šå¤„ç†ï¼ˆå¦‚æœè·¯å¾„ä»¥"/"å¼€å¤´ï¼Œæ£€æŸ¥æ˜¯å¦å’Œå½“å‰ä¿å­˜è·¯å¾„ç›¸å…³ï¼‰
                        save_path = task.get("savepath", "").rstrip("/")
                        save_path_parts = save_path.split("/")
                        save_path_basename = save_path_parts[-1] if save_path else ""
                        
                        # è¿‡æ»¤ç›®å½• - å¦‚æœåªæœ‰æ ¹ç›®å½•æœ‰æ›´æ–°ï¼Œä¸”ä¸æ˜¯é¦–æ¬¡è¿è¡Œæˆ–æ²¡æœ‰æ–°å¢ç›®å½•ï¼Œåˆ™ä¸æ˜¾ç¤ºå­ç›®å½•
                        if depth == 0 and has_update_in_root and (not has_update_in_subdir or (is_first_run and len(new_added_dirs) == 0)):
                            # åœ¨æ ¹ç›®å½•çº§åˆ«ï¼Œå¦‚æœåªæœ‰æ ¹ç›®å½•æœ‰æ›´æ–°ï¼Œåˆ™è¿‡æ»¤æ‰æ‰€æœ‰å­ç›®å½•
                            dirs = []
                        
                        # å…ˆè¿‡æ»¤æ‰ç©ºçš„ç›®å½•ï¼Œé¿å…å½±å“åç»­è®¡ç®—
                        valid_dirs = []
                        for dir_name, dir_data in dirs:
                            dir_files = dir_data.get("files", [])
                            dir_subdirs = dir_data.get("dirs", {})
                            # å¦‚æœç›®å½•æ—¢æ²¡æœ‰æ–‡ä»¶ä¹Ÿæ²¡æœ‰å­ç›®å½•ï¼Œè·³è¿‡
                            if len(dir_files) == 0 and len(dir_subdirs) == 0:
                                continue
                            # æ£€æŸ¥ç›®å½•æ˜¯å¦åœ¨æ–°å¢ç›®å½•åˆ—è¡¨ä¸­æˆ–æœ‰å­æ–‡ä»¶æ›´æ–°
                            if is_first_run and dir_name not in new_added_dirs and len(dir_files) == 0:
                                continue
                            valid_dirs.append((dir_name, dir_data))
                        
                        # è®¡ç®—æ€»é¡¹æ•°ï¼ˆæœ‰æ•ˆç›®å½•+æ–‡ä»¶ï¼‰
                        total_items = len(valid_dirs) + len(files)
                        current_item = 0
                        
                        # å¤„ç†ç›®å½•
                        for i, (dir_name, dir_data) in enumerate(valid_dirs):
                            current_item += 1
                            is_dir_last = current_item == total_items
                            
                            # è¿‡æ»¤æ¡ä»¶ï¼š
                            # 1. ç›®å½•åä¸ä¸ºç©º
                            # 2. ä¸æ˜¯ä¿å­˜è·¯å¾„æœ¬èº«
                            # 3. ä¸æ˜¯ä»¥"/"å¼€å¤´çš„å®Œæ•´è·¯å¾„
                            # 4. ä¸æ˜¯ä¿å­˜è·¯å¾„çš„åŸºæœ¬åç§°
                            if (dir_name and 
                                dir_name != save_path and
                                not dir_name.startswith("/") and
                                dir_name != save_path_basename):
                                
                                dir_prefix = prefix + ("â””â”€â”€ " if is_dir_last else "â”œâ”€â”€ ")
                                add_notify(format_file_display(dir_prefix, "ğŸ“", dir_name))
                                
                                # è®¡ç®—å­é¡¹çš„å‰ç¼€ï¼Œä¿æŒæ ‘å½¢ç»“æ„æ¸…æ™°
                                # ç¬¬ä¸€ä¸ªç¼©è¿›æ ‡è®°ä½¿ç”¨ç‚¹å·ï¼Œåç»­ä½¿ç”¨ç©ºæ ¼
                                if prefix == "":
                                    # ç¬¬ä¸€å±‚ç¼©è¿›ä½¿ç”¨ç‚¹å·å¼€å¤´
                                    new_prefix = "Â·   " if is_dir_last else "â”‚   "
                                else:
                                    # åç»­å±‚çº§å¼€å¤´ä¿æŒå‰ç¼€ä¸å˜ï¼Œå°¾éƒ¨æ·»åŠ æ–°çš„ç¼©è¿›æ ‡è®°
                                    if is_dir_last:
                                        new_prefix = prefix + "    "  # æœ€åä¸€é¡¹ï¼Œç©ºæ ¼ç¼©è¿›
                                    else:
                                        new_prefix = prefix + "â”‚   "  # éæœ€åä¸€é¡¹ï¼Œä½¿ç”¨ç«–çº¿
                                
                                # é€’å½’æ˜¾ç¤ºå­ç›®å½•
                                display_tree(dir_data, new_prefix, depth + 1)
                        
                        # å¤„ç†æ–‡ä»¶
                        sorted_files = sort_nodes(files) if files else []

                        for j, file_node in enumerate(sorted_files):
                            current_item += 1
                            is_file_last = current_item == total_items
                            
                            # æ˜¾ç¤ºæ–‡ä»¶
                            file_prefix = prefix + ("â””â”€â”€ " if is_file_last else "â”œâ”€â”€ ")
                            file_name = remove_file_icons(file_node.tag)
                            # å…³é”®ä¿®å¤ï¼šå¦‚æœæ–‡ä»¶è¢«é‡å‘½åäº†ï¼Œä½¿ç”¨é‡å‘½ååçš„æ–‡ä»¶å
                            if file_name in rename_mapping:
                                file_name = rename_mapping[file_name]
                            icon = get_file_icon(file_name, is_dir=False)
                            notify_text = format_file_display(file_prefix, icon, file_name)
                            add_notify(notify_text)
                    
                    # æ„å»ºå¹¶æ˜¾ç¤ºç›®å½•æ ‘
                    if has_update_in_root or has_update_in_subdir:
                        directory_tree = build_directory_tree()
                        display_tree(directory_tree["root"])
                        add_notify("")
                        
                    # å¤„ç†é‡å‘½åæ—¥å¿—ï¼Œé¿å…æ˜¾ç¤ºä¸å¿…è¦çš„è·¯å¾„ä¿¡æ¯
                    # æ³¨æ„ï¼šé‡å‘½åæ—¥å¿—å°†åœ¨æ–‡ä»¶æ ‘æ˜¾ç¤ºåç»Ÿä¸€å¤„ç†å’Œæ‰“å°
                
                add_notify("")
            
            
            
            # å¦‚æœæ˜¯å‰§é›†å‘½åæ¨¡å¼å¹¶ä¸”æˆåŠŸè¿›è¡Œäº†é‡å‘½åï¼Œå•ç‹¬æ˜¾ç¤ºæ’åºå¥½çš„æ–‡ä»¶åˆ—è¡¨
            elif is_rename and task.get("use_episode_naming") and task.get("episode_naming"):
                # é‡æ–°è·å–æ–‡ä»¶åˆ—è¡¨
                savepath = re.sub(r"/{2,}", "/", f"/{task['savepath']}")
                dir_file_list = account.ls_dir(account.savepath_fid[savepath])

                # è¿‡æ»¤å‡ºéç›®å½•çš„æ–‡ä»¶
                file_nodes = [f for f in dir_file_list if not f["dir"]]

                # è·å–å®é™…çš„æ–‡ä»¶åæ˜ å°„
                actual_file_names = account.get_actual_file_names_from_directory(task, rename_logs)

                # ä»é‡å‘½åæ—¥å¿—æå–é¢„æœŸçš„æ–°æ—§æ–‡ä»¶åæ˜ å°„
                expected_renamed_files = {}
                for log in rename_logs:
                    # æ ¼å¼ï¼šé‡å‘½å: æ—§å â†’ æ–°å
                    if "é‡å‘½å:" in log and " â†’ " in log:
                        # å…ˆåˆ†å‰²å‡º"é‡å‘½å:"åé¢çš„éƒ¨åˆ†
                        parts = log.split("é‡å‘½å:", 1)[1].strip()
                        # å†æŒ‰ç®­å¤´åˆ†å‰²
                        if " â†’ " in parts:
                            old_name, expected_new_name = parts.split(" â†’ ", 1)
                            # åªå¤„ç†å¤±è´¥ä¿¡æ¯ï¼Œä¸æˆªæ–­æ­£å¸¸æ–‡ä»¶å
                            if " å¤±è´¥ï¼Œ" in expected_new_name:
                                expected_new_name = expected_new_name.split(" å¤±è´¥ï¼Œ")[0]
                            # å»é™¤é¦–å°¾ç©ºæ ¼
                            old_name = old_name.strip()
                            expected_new_name = expected_new_name.strip()
                            expected_renamed_files[old_name] = expected_new_name
                    
                # ç¡®ä¿è‡³å°‘æ˜¾ç¤ºå®é™…å­˜åœ¨çš„æ–‡ä»¶
                display_files = []

                # æ·»åŠ æ‰€æœ‰å®é™…å­˜åœ¨çš„è½¬å­˜æ–‡ä»¶
                for old_name in expected_renamed_files.keys():
                    # è·å–å®é™…çš„æ–‡ä»¶å
                    actual_name = actual_file_names.get(old_name, expected_renamed_files[old_name])

                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å®é™…å­˜åœ¨äºç›®å½•ä¸­
                    if any(f["file_name"] == actual_name for f in file_nodes):
                        if actual_name not in display_files:
                            display_files.append(actual_name)
                
                # æ­¤å¤–ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„æ–‡ä»¶èŠ‚ç‚¹ï¼ˆæ¯”è¾ƒèŠ‚ç‚¹æ—¶é—´ï¼‰
                if not display_files and is_new_tree and hasattr(is_new_tree, 'nodes'):
                    # å¦‚æœæœ‰è½¬å­˜æ–‡ä»¶æ ‘ï¼Œä»ä¸­æå–æ–‡ä»¶
                    tree_nodes = is_new_tree.nodes.values()
                    for node in tree_nodes:
                        if hasattr(node, 'data') and not node.data.get('is_dir', False):
                            file_path = node.data.get('path', '')
                            if file_path:
                                file_name = os.path.basename(file_path)
                                if file_name not in display_files:
                                    display_files.append(file_name)
                
                # è¿˜éœ€è¦æ£€æŸ¥æ˜¯å¦æœ‰æ‰“å°åˆ°æ§åˆ¶å°çš„è½¬å­˜æ–‡ä»¶ä¿¡æ¯ï¼ˆæƒ…å†µï¼šè½¬å­˜åç«‹å³é‡å‘½åï¼‰
                # æ— è®ºdisplay_filesæ˜¯å¦ä¸ºç©ºéƒ½æ‰§è¡Œæ­¤ä»£ç ï¼Œç¡®ä¿èƒ½æå–åˆ°é‡å‘½åçš„æ–‡ä»¶
                for log in rename_logs:
                    if "é‡å‘½å:" in log and " â†’ " in log:
                        parts = log.split(" â†’ ", 1)
                        if len(parts) > 1:
                            new_name = parts[1].strip()
                            # è¿‡æ»¤æ‰å¯èƒ½çš„ç»“æŸæ ‡è®°ï¼Œä½†è¦ç¡®ä¿å®Œæ•´ä¿ç•™æ–‡ä»¶å
                            if "\n" in new_name:
                                new_name = new_name.split("\n")[0].strip()
                            
                            # åªæœ‰å½“æ–‡ä»¶ååŒ…å«æ˜ç¡®çš„åˆ†éš”ç¬¦æ—¶æ‰è¿›è¡Œåˆ†å‰²
                            # ä¾‹å¦‚"é»‘é•œ - S07E02.mkv"ä¸åº”è¯¥è¢«åˆ†å‰²
                            if "ï¼Œ" in new_name:
                                new_name = new_name.split("ï¼Œ")[0].strip()
                                
                            # ç¡®ä¿ä¸è¦é”™è¯¯åœ°åªæå–æ–‡ä»¶åçš„ä¸€éƒ¨åˆ†ï¼ˆå¦‚"é»‘é•œ"ï¼‰
                            if " " in new_name and "." in new_name:  # å¦‚æœåŒ…å«ç©ºæ ¼å’Œæ‰©å±•å
                                # æ£€æŸ¥è¿™æ˜¯ä¸æ˜¯ä¸€ä¸ªå®Œæ•´æ–‡ä»¶å
                                if re.search(r'\.\w+$', new_name):  # æ£€æŸ¥æ˜¯å¦ä»¥æ‰©å±•åç»“å°¾
                                    # è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„æ–‡ä»¶åï¼Œä¸åšè¿›ä¸€æ­¥åˆ†å‰²
                                    pass
                                else:
                                    # ä¸æ˜¯ä»¥æ‰©å±•åç»“å°¾ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥å¤„ç†
                                    new_name = new_name.split(" ")[0].strip()
                            
                            if new_name and new_name not in display_files:
                                # é¢å¤–æ£€æŸ¥ï¼Œç¡®ä¿æå–çš„æ˜¯å®Œæ•´æ–‡ä»¶å
                                if "." in new_name:  # é€šå¸¸æ–‡ä»¶ååº”åŒ…å«æ‰©å±•å
                                    display_files.append(new_name)
                
                # å¦‚æœé€šè¿‡é‡å‘½åå’Œæ–‡ä»¶æ ‘éƒ½æ²¡æ‰¾åˆ°æ–‡ä»¶ï¼Œä½¿ç”¨æœ€æ–°æ—¶é—´æ’åºçš„æ–‡ä»¶
                if not display_files and file_nodes:
                    # æŸ¥æ‰¾ç›®å½•ä¸­ä¿®æ”¹æ—¶é—´æœ€æ–°çš„æ–‡ä»¶ï¼ˆå¯èƒ½æ˜¯åˆšåˆšè½¬å­˜çš„ï¼‰
                    today = datetime.now().strftime('%Y-%m-%d')
                    recent_files = []  # å®šä¹‰å¹¶åˆå§‹åŒ–recent_fileså˜é‡
                    
                    # é¦–å…ˆå°è¯•é€šè¿‡ä¿®æ”¹æ—¥æœŸè¿‡æ»¤å½“å¤©çš„æ–‡ä»¶
                    for file in file_nodes:
                        # å¦‚æœæœ‰æ—¶é—´æˆ³ï¼Œè½¬æ¢ä¸ºæ—¥æœŸå­—ç¬¦ä¸²
                        if 'updated_at' in file and file['updated_at']:
                            try:
                                # æ£€æŸ¥æ—¶é—´æˆ³æ˜¯å¦åœ¨åˆç†èŒƒå›´å†… (1970-2100å¹´)
                                timestamp = file['updated_at']
                                if timestamp > 4102444800:  # 2100å¹´çš„æ—¶é—´æˆ³
                                    # å¯èƒ½æ˜¯æ¯«ç§’çº§æ—¶é—´æˆ³ï¼Œå°è¯•è½¬æ¢ä¸ºç§’çº§
                                    timestamp = timestamp / 1000
                                
                                # å†æ¬¡æ£€æŸ¥æ—¶é—´æˆ³æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
                                if 0 < timestamp < 4102444800:
                                    update_time = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d')
                                    if update_time == today:
                                        recent_files.append(file)
                                else:
                                    print(f"è­¦å‘Š: æ–‡ä»¶ {file.get('file_name', 'æœªçŸ¥')} çš„æ—¶é—´æˆ³ {file['updated_at']} è¶…å‡ºèŒƒå›´")
                            except (ValueError, OSError, OverflowError) as e:
                                print(f"è­¦å‘Š: å¤„ç†æ–‡ä»¶ {file.get('file_name', 'æœªçŸ¥')} çš„æ—¶é—´æˆ³æ—¶å‡ºé”™: {e}")
                    
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å½“å¤©çš„æ–‡ä»¶ï¼Œè‡³å°‘æ˜¾ç¤ºä¸€ä¸ªæœ€æ–°çš„æ–‡ä»¶
                    if not recent_files and file_nodes:
                        # å®šä¹‰å®‰å…¨çš„æ’åºé”®å‡½æ•°
                        def safe_timestamp_key(x):
                            try:
                                timestamp = x.get('updated_at', 0)
                                # å¦‚æœæ—¶é—´æˆ³å¤ªå¤§ï¼Œå¯èƒ½æ˜¯æ¯«ç§’çº§æ—¶é—´æˆ³
                                if timestamp > 4102444800:  # 2100å¹´çš„æ—¶é—´æˆ³
                                    timestamp = timestamp / 1000
                                # å†æ¬¡æ£€æŸ¥èŒƒå›´
                                if timestamp < 0 or timestamp > 4102444800:
                                    return 0  # æ— æ•ˆæ—¶é—´æˆ³è¿”å›0
                                return timestamp
                            except (ValueError, TypeError):
                                return 0  # æ— æ•ˆè¿”å›0
                        
                        try:
                            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œä½¿ç”¨å®‰å…¨çš„æ’åºå‡½æ•°
                            recent_files = sorted(file_nodes, key=safe_timestamp_key, reverse=True)
                        except Exception as e:
                            print(f"è­¦å‘Š: æ–‡ä»¶æ’åºæ—¶å‡ºé”™: {e}")
                            # å¦‚æœæ’åºå‡ºé”™ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹åˆ—è¡¨
                            recent_files = file_nodes
                    
                    # åªå–ç¬¬ä¸€ä¸ªä½œä¸ºæ˜¾ç¤º
                    if recent_files:
                        try:
                            display_files.append(recent_files[0]['file_name'])
                        except (IndexError, KeyError) as e:
                            print(f"è­¦å‘Š: è·å–æ–‡ä»¶åæ—¶å‡ºé”™: {e}")
                            # å¦‚æœå‡ºé”™ï¼Œå°è¯•æ·»åŠ ç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼ˆå¦‚æœæœ‰ï¼‰
                            if file_nodes:
                                try:
                                    display_files.append(file_nodes[0]['file_name'])
                                except (KeyError, IndexError):
                                    print("è­¦å‘Š: æ— æ³•è·å–æœ‰æ•ˆçš„æ–‡ä»¶å")
                
                # æ·»åŠ æˆåŠŸé€šçŸ¥ - ä¿®å¤é—®é¢˜ï¼šç¡®ä¿åœ¨æœ‰æ–‡ä»¶æ—¶æ·»åŠ é€šçŸ¥
                if display_files:
                    add_notify(f"âœ…ã€Š{task['taskname']}ã€‹æ–°å¢æ–‡ä»¶:")
                    savepath = task['savepath']
                    add_notify(f"{re.sub(r'/{2,}', '/', f'/{savepath}')}")
                
                
                # åˆ›å»ºepisode_patternå‡½æ•°ç”¨äºæ’åº
                def extract_episode_number_local(filename):
                    # ä½¿ç”¨å…¨å±€çš„ç»Ÿä¸€æå–å‡½æ•°ï¼Œä½†ä¼˜å…ˆå°è¯•ä»episode_namingæ¨¡å¼ä¸­æå–
                    episode_pattern = task["episode_naming"]
                    
                    # ä¼˜å…ˆå°è¯•å…¨å±€å‡½æ•°æå–
                    ep_num = extract_episode_number(filename)
                    if ep_num is not None:
                        return ep_num
                    
                    # å¦‚æœå…¨å±€å‡½æ•°æ— æ³•æå–ï¼Œå°è¯•ä»episode_namingæ¨¡å¼ä¸­æå–
                    if "[]" in episode_pattern:
                        pattern_parts = episode_pattern.split("[]")
                        if len(pattern_parts) == 2:
                            prefix, suffix = pattern_parts
                            if prefix and filename.startswith(prefix):
                                number_part = filename[len(prefix):].split(suffix)[0] if suffix else filename[len(prefix):]
                                if number_part.isdigit():
                                    return int(number_part)
                                # å°è¯•è½¬æ¢ä¸­æ–‡æ•°å­—
                                else:
                                    arabic_num = chinese_to_arabic(number_part)
                                    if arabic_num is not None:
                                        return arabic_num
                    
                    # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›float('inf')
                    return float('inf')
                
                # æŒ‰å‰§é›†å·æ’åº
                display_files.sort(key=extract_episode_number_local)
                
                # æ‰“å°æ–‡ä»¶åˆ—è¡¨
                for idx, file_name in enumerate(display_files):
                    prefix = "â”œâ”€â”€ " if idx < len(display_files) - 1 else "â””â”€â”€ "
                    # æŸ¥æ‰¾æ–‡ä»¶ä¿¡æ¯ç”¨äºè·å–å›¾æ ‡
                    file_info = next((f for f in file_nodes if f["file_name"] == file_name or 
                                    (f["file_name"] in renamed_files and renamed_files[f["file_name"]] == file_name)), None)
                    if file_info is None:
                        # å¦‚æœæ‰¾ä¸åˆ°å¯¹åº”ä¿¡æ¯ï¼Œå¯èƒ½æ˜¯å·²é‡å‘½åæ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤å›¾æ ‡
                        icon = get_file_icon(file_name, is_dir=False)
                    else:
                        icon = get_file_icon(file_name, is_dir=file_info.get("dir", False))
                    add_notify(format_file_display(prefix, icon, file_name))
                
                # ç¡®ä¿åªæœ‰åœ¨æœ‰æ–‡ä»¶æ—¶æ‰æ·»åŠ ç©ºè¡Œ
                if display_files:
                    add_notify("")
            # æ·»åŠ æ­£åˆ™å‘½åæ¨¡å¼çš„æ–‡ä»¶æ ‘æ˜¾ç¤ºé€»è¾‘
            elif is_rename and not is_special_sequence and task.get("pattern") is not None:
                # é‡æ–°è·å–æ–‡ä»¶åˆ—è¡¨
                savepath = re.sub(r"/{2,}", "/", f"/{task['savepath']}")
                dir_file_list = account.ls_dir(account.savepath_fid[savepath])

                # è¿‡æ»¤å‡ºéç›®å½•çš„æ–‡ä»¶
                file_nodes = [f for f in dir_file_list if not f["dir"]]

                # è·å–å®é™…çš„æ–‡ä»¶åæ˜ å°„
                actual_file_names = account.get_actual_file_names_from_directory(task, rename_logs)

                # ä»é‡å‘½åæ—¥å¿—æå–é¢„æœŸçš„æ–°æ—§æ–‡ä»¶åæ˜ å°„
                expected_renamed_files = {}
                for log in rename_logs:
                    # æ ¼å¼ï¼šé‡å‘½å: æ—§å â†’ æ–°å
                    match = re.search(r'é‡å‘½å: (.*?) â†’ (.+?)($|\s|ï¼Œ|å¤±è´¥)', log)
                    if match:
                        old_name = match.group(1).strip()
                        expected_new_name = match.group(2).strip()
                        expected_renamed_files[old_name] = expected_new_name

                # åªæ˜¾ç¤ºå®é™…å­˜åœ¨çš„è½¬å­˜æ–‡ä»¶
                display_files = []
                for old_name in expected_renamed_files.keys():
                    # è·å–å®é™…çš„æ–‡ä»¶å
                    actual_name = actual_file_names.get(old_name, expected_renamed_files[old_name])

                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å®é™…å­˜åœ¨äºç›®å½•ä¸­
                    if any(f["file_name"] == actual_name for f in file_nodes):
                        if actual_name not in display_files:
                            display_files.append(actual_name)
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ–‡ä»¶è¦æ˜¾ç¤ºï¼Œä½¿ç”¨åŸå§‹é€»è¾‘
                if not display_files:
                    # åˆ›å»ºä¸€ä¸ªæ˜ å°„åˆ—è¡¨ï¼ŒåŒ…å«æ‰€æœ‰æ–‡ä»¶
                    display_files = [file["file_name"] for file in file_nodes]
                
                # æ·»åŠ æˆåŠŸé€šçŸ¥
                add_notify(f"âœ…ã€Š{task['taskname']}ã€‹æ–°å¢æ–‡ä»¶:")
                savepath = task['savepath']
                add_notify(f"{re.sub(r'/{2,}', '/', f'/{savepath}')}")
                
                # æ‰“å°æ–‡ä»¶åˆ—è¡¨
                for idx, file_name in enumerate(display_files):
                    prefix = "â”œâ”€â”€ " if idx < len(display_files) - 1 else "â””â”€â”€ "
                    file_info = file_nodes[next((i for i, f in enumerate(file_nodes) if f["file_name"] == file_name), 0)]
                    icon = get_file_icon(file_name, is_dir=file_info.get("dir", False))
                    add_notify(format_file_display(prefix, icon, file_name))
                add_notify("")
            
            # æ‰“å°é‡å‘½åæ—¥å¿—ï¼ˆæ–‡ä»¶æ ‘ä¹‹åï¼‰
            if rename_logs:
                # å¤„ç†é‡å‘½åæ—¥å¿—ï¼Œæ›´æ–°æ•°æ®åº“è®°å½•
                account.process_rename_logs(task, rename_logs)
                
                # æ§åˆ¶å°è§†è§‰åˆ†éš”ï¼šè‹¥å‰é¢æœªé€šè¿‡ add_notify("") æ‰“å°è¿‡ç©ºè¡Œï¼Œåˆ™è¡¥æ‰“ä¸€è¡Œç©ºè¡Œ
                try:
                    if not (NOTIFYS and NOTIFYS[-1] == ""):
                        print()
                except Exception:
                    # å…œåº•ï¼šè‹¥ NOTIFYS å¼‚å¸¸ï¼Œä»ä¿è¯æœ‰ä¸€è¡Œç©ºè¡Œ
                    print()
                
                # å¯¹å‰§é›†å‘½åæ¨¡å¼å’Œå…¶ä»–æ¨¡å¼ç»Ÿä¸€å¤„ç†é‡å‘½åæ—¥å¿—
                # æŒ‰sort_file_by_nameå‡½æ•°çš„å¤šçº§æ’åºé€»è¾‘æ’åºé‡å‘½åæ—¥å¿—
                sorted_rename_logs = []
                
                for log in rename_logs:
                    # æå–æ–°æ–‡ä»¶åï¼ˆæ ¼å¼ï¼šé‡å‘½å: æ—§å â†’ æ–°åï¼‰
                    # ä½¿ç”¨æ›´ç²¾ç¡®çš„å­—ç¬¦ä¸²åˆ†å‰²æ–¹æ³•ï¼Œç¡®ä¿èƒ½æ•è·å®Œæ•´çš„æ–‡ä»¶å
                    if "é‡å‘½å:" in log and " â†’ " in log:
                        parts = log.split("é‡å‘½å:", 1)[1].strip()
                        if " â†’ " in parts:
                            _, new_name = parts.split(" â†’ ", 1)
                            
                            # åªå¤„ç†å¤±è´¥ä¿¡æ¯ï¼Œä¸æˆªæ–­æ­£å¸¸æ–‡ä»¶å
                            if " å¤±è´¥ï¼Œ" in new_name:
                                new_name = new_name.split(" å¤±è´¥ï¼Œ")[0]
                            
                            # å»é™¤é¦–å°¾ç©ºæ ¼
                            new_name = new_name.strip()
                            
                            # ä½¿ç”¨sort_file_by_nameå‡½æ•°è·å–æ’åºå€¼
                            sort_tuple = sort_file_by_name(new_name)
                            sorted_rename_logs.append((sort_tuple, log))
                    else:
                        # æ²¡æ‰¾åˆ°ç®­å¤´æˆ–æ ¼å¼ä¸ç¬¦çš„æ—¥å¿—æ”¾åœ¨æœ€å
                        sorted_rename_logs.append(((float('inf'), float('inf'), float('inf'), 0), log))
                
                # æŒ‰sort_file_by_nameè¿”å›çš„æ’åºå…ƒç»„æ’åº
                sorted_rename_logs.sort(key=lambda x: x[0])
                
                # æ‰“å°æ’åºåçš„æ—¥å¿—
                for _, log in sorted_rename_logs:
                    print(log)
            
            # è¡¥å……ä»»åŠ¡çš„æ’ä»¶é…ç½®
            def merge_dicts(a, b):
                result = a.copy()
                for key, value in b.items():
                    if (
                        key in result
                        and isinstance(result[key], dict)
                        and isinstance(value, dict)
                    ):
                        result[key] = merge_dicts(result[key], value)
                    elif key not in result:
                        result[key] = value
                return result

            task["addition"] = merge_dicts(
                task.get("addition", {}), task_plugins_config
            )
            
            # ä¸ºä»»åŠ¡æ·»åŠ å‰§é›†æ¨¡å¼é…ç½®
            if task.get("use_episode_naming") and task.get("episode_naming"):
                task["config_data"] = {
                    "episode_patterns": CONFIG_DATA.get("episode_patterns", [])
                }
            # è°ƒç”¨æ’ä»¶
            if is_new_tree or is_rename:
                print()
                print(f"ğŸ§© è°ƒç”¨æ’ä»¶")
                for plugin_name, plugin in plugins.items():
                    if plugin.is_active and (is_new_tree or is_rename):
                        task = (
                            plugin.run(task, account=account, tree=is_new_tree, rename_logs=rename_logs) or task
                        )
            elif is_new_tree is False:  # æ˜ç¡®æ²¡æœ‰æ–°æ–‡ä»¶
                print(f"ä»»åŠ¡å®Œæˆ: æ²¡æœ‰æ–°çš„æ–‡ä»¶éœ€è¦è½¬å­˜")
    print()


def main():
    global CONFIG_DATA
    start_time = datetime.now()
    print(f"===============ç¨‹åºå¼€å§‹===============")
    print(f"â° æ‰§è¡Œæ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    # è¯»å–å¯åŠ¨å‚æ•°
    config_path = sys.argv[1] if len(sys.argv) > 1 else "quark_config.json"
    # ä»ç¯å¢ƒå˜é‡ä¸­è·å– TASKLIST
    tasklist_from_env = []
    if tasklist_json := os.environ.get("TASKLIST"):
        try:
            tasklist_from_env = json.loads(tasklist_json)
        except Exception as e:
            print(f"ä»ç¯å¢ƒå˜é‡è§£æä»»åŠ¡åˆ—è¡¨å¤±è´¥ {e}")
    # æ£€æŸ¥æœ¬åœ°æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨å°±ä¸‹è½½
    if not os.path.exists(config_path):
        if os.environ.get("QUARK_COOKIE"):
            print(
                f"âš™ï¸ è¯»å–åˆ° QUARK_COOKIE ç¯å¢ƒå˜é‡ï¼Œä»…ç­¾åˆ°é¢†ç©ºé—´ã€‚å¦‚éœ€æ‰§è¡Œè½¬å­˜ï¼Œè¯·åˆ é™¤è¯¥ç¯å¢ƒå˜é‡åé…ç½® {config_path} æ–‡ä»¶"
            )
            cookie_val = os.environ.get("QUARK_COOKIE")
            cookie_form_file = False
        else:
            print(f"âš™ï¸ é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨âŒï¼Œæ­£è¿œç¨‹ä»ä¸‹è½½é…ç½®æ¨¡ç‰ˆ")
            config_url = f"{GH_PROXY}https://raw.githubusercontent.com/Cp0204/quark_auto_save/main/quark_config.json"
            if Config.download_file(config_url, config_path):
                print("âš™ï¸ é…ç½®æ¨¡ç‰ˆä¸‹è½½æˆåŠŸâœ…ï¼Œè¯·åˆ°ç¨‹åºç›®å½•ä¸­æ‰‹åŠ¨é…ç½®")
            return
    else:
        print(f"âš™ï¸ æ­£ä» {config_path} æ–‡ä»¶ä¸­è¯»å–é…ç½®")
        CONFIG_DATA = Config.read_json(config_path)
        Config.breaking_change_update(CONFIG_DATA)
        cookie_val = CONFIG_DATA.get("cookie")
        if not CONFIG_DATA.get("magic_regex"):
            CONFIG_DATA["magic_regex"] = MAGIC_REGEX
        cookie_form_file = True
    # è·å–cookie
    cookies = Config.get_cookies(cookie_val)
    if not cookies:
        print("âŒ cookie æœªé…ç½®")
        return
    accounts = [Quark(cookie, index) for index, cookie in enumerate(cookies)]
    # ç­¾åˆ°
    print()
    print(f"===============ç­¾åˆ°ä»»åŠ¡===============")
    if tasklist_from_env:
        verify_account(accounts[0])
    else:
        for account in accounts:
            verify_account(account)
            do_sign(account)
    print()
    # è½¬å­˜
    if accounts[0].is_active and cookie_form_file:
        print(f"===============è½¬å­˜ä»»åŠ¡===============")
        # ä»»åŠ¡åˆ—è¡¨
        if tasklist_from_env:
            # è‹¥é€šè¿‡ç¯å¢ƒå˜é‡ä¼ å…¥ä»»åŠ¡åˆ—è¡¨ï¼Œè§†ä¸ºæ‰‹åŠ¨è¿è¡Œï¼Œå¯ç”±å¤–å±‚æ§åˆ¶æ˜¯å¦å¿½ç•¥æ‰§è¡Œå‘¨æœŸ/è¿›åº¦é™åˆ¶
            ignore_execution_rules = os.environ.get("IGNORE_EXECUTION_RULES", "").lower() in ["1", "true", "yes"]
            do_save(accounts[0], tasklist_from_env, ignore_execution_rules=ignore_execution_rules)
        else:
            # å®šæ—¶ä»»åŠ¡æˆ–å‘½ä»¤è¡Œå…¨é‡è¿è¡Œï¼Œå§‹ç»ˆéµå¾ªæ‰§è¡Œå‘¨æœŸ/è¿›åº¦è§„åˆ™
            do_save(accounts[0], CONFIG_DATA.get("tasklist", []), ignore_execution_rules=False)
        print()
    # é€šçŸ¥
    if NOTIFYS:
        # ä¸ºæ¨é€é€šçŸ¥åšä¸€æ¬¡è½»é‡æ¸…æ´—ï¼Œé¿å…æ–‡ä»¶æ ‘ä¸­å‡ºç°å¤šä½™ç©ºè¡Œ
        def _clean_notify_lines(lines):
            """
            è½»é‡æ¸…æ´—é€šçŸ¥è¡Œï¼Œé¿å…æ¨é€æ­£æ–‡ä¸­çš„æ–‡ä»¶æ ‘å‡ºç°å¤šä½™ç©ºè¡Œã€‚
            
            è¯´æ˜ï¼š
            - ç»ˆç«¯æ—¥å¿—ä¸­çš„ç©ºè¡Œä¿ç•™ä¸å˜ï¼Œä»ç„¶ç”± add_notify æ‰“å°ï¼›
            - è¿™é‡Œåªåœ¨æ¨é€å‰å¯¹ NOTIFYS åšä¸€æ¬¡åªè¯»æ¸…æ´—ã€‚
            """
            cleaned = []
            total = len(lines)
            for i, line in enumerate(lines):
                # è·³è¿‡ä»…ç”¨äºåˆ†éš”çš„ç©ºè¡Œï¼ˆä¾‹å¦‚å‡ºç°åœ¨æ ‘å½¢æ–‡ä»¶é¡¹ä¹‹é—´ï¼‰
                if not line.strip():
                    prev_line = lines[i - 1] if i > 0 else ""
                    next_line = lines[i + 1] if i + 1 < total else ""
                    
                    # åˆ¤æ–­ä¸€è¡Œæ˜¯å¦ä¸ºâ€œæ ‘å½¢æ–‡ä»¶è¡Œâ€ï¼ˆæ”¯æŒå‰ç¼€æœ‰ â”‚ / Â· ç­‰ç¬¦å·ï¼‰
                    def is_tree_line(text: str) -> bool:
                        stripped = text.strip()
                        # ç›´æ¥ä»¥æ ‘å½¢å‰ç¼€å¼€å¤´
                        if stripped.startswith(("â”œâ”€â”€", "â””â”€â”€")):
                            return True
                        # æˆ–è€…ä¸­é—´åŒ…å«æ ‘å½¢å‰ç¼€ï¼ˆä¾‹å¦‚ "â”‚   â”œâ”€â”€", "Â·   â””â”€â”€"ï¼‰
                        return "â”œâ”€â”€" in stripped or "â””â”€â”€" in stripped
                    
                    # å¦‚æœå‰åéƒ½æ˜¯æ ‘å½¢æ–‡ä»¶è¡Œï¼Œåˆ™è®¤ä¸ºè¿™æ˜¯å¤šä½™çš„ç©ºè¡Œï¼Œåªåœ¨ç»ˆç«¯æ˜¾ç¤ºï¼Œä¸è¿›å…¥æ¨é€æ­£æ–‡
                    if is_tree_line(prev_line) and is_tree_line(next_line):
                        continue
                cleaned.append(line)
            return cleaned

        notify_lines = _clean_notify_lines(NOTIFYS)
        notify_body = "\n".join(notify_lines)
        print(f"===============æ¨é€é€šçŸ¥===============")
        send_ql_notify("ã€å¤¸å…‹è‡ªåŠ¨è½¬å­˜ã€‘", notify_body)
        print()
    else:
        # å¦‚æœæ²¡æœ‰é€šçŸ¥å†…å®¹ï¼Œæ˜¾ç¤ºç»Ÿä¸€æç¤º
        print(f"===============æ¨é€é€šçŸ¥===============")
        print("ğŸ“­ æœ¬æ¬¡è¿è¡Œæ²¡æœ‰æ–°çš„è½¬å­˜ï¼Œæœªæ¨é€é€šçŸ¥")
        print()
    if cookie_form_file:
        # æ›´æ–°é…ç½®
        Config.write_json(config_path, CONFIG_DATA)

    print(f"===============ç¨‹åºç»“æŸ===============")
    duration = datetime.now() - start_time
    print(f"ğŸ˜ƒ è¿è¡Œæ—¶é•¿: {round(duration.total_seconds(), 2)}s")
    print()


if __name__ == "__main__":
    main()
