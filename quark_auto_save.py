# !/usr/bin/env python3
# -*- coding: utf-8 -*-
# Modify: 2024-01-31
# Repo: https://github.com/Cp0204/quark_auto_save
# ConfigFile: quark_config.json
"""
new Env('å¤¸å…‹è‡ªåŠ¨è¿½æ›´');
0 8,18,20 * * * quark_auto_save.py
"""
import os
import re
import sys
import json
import random
import requests
from datetime import datetime

config_data = {}
notifys = []

magic_regex = {
    "$TV": {
        "pattern": ".*?(S\\d{1,2}E)?P?(\\d{1,3}).*?\\.(mp4|mkv)",
        "replace": "\\1\\2.\\3",
    },
}


# é­”æ³•æ­£åˆ™åŒ¹é…
def magic_regex_func(pattern, replace):
    keyword = pattern
    if keyword in magic_regex:
        pattern = magic_regex[keyword]["pattern"]
        if replace == "":
            replace = magic_regex[keyword]["replace"]
    return pattern, replace


# å‘é€é€šçŸ¥æ¶ˆæ¯
def send_ql_notify(title, body):
    try:
        # å¯¼å…¥é€šçŸ¥æ¨¡å—
        import sendNotify

        # å¦‚æœªé…ç½® push_config åˆ™ä½¿ç”¨é’é¾™ç¯å¢ƒé€šçŸ¥è®¾ç½®
        if config_data.get("push_config"):
            sendNotify.push_config = config_data["push_config"]
        sendNotify.send(title, body)
    except Exception as e:
        if e:
            print("å‘é€é€šçŸ¥æ¶ˆæ¯å¤±è´¥ï¼")


# æ·»åŠ æ¶ˆæ¯
def add_notify(text):
    global notifys
    notifys.append(text)
    print("ğŸ“¢", text)
    return text


def common_headers():
    global config_data
    return {
        "cookie": config_data["cookie"],
        "content-type": "application/json",
    }


def get_growth_info():
    url = "https://drive-m.quark.cn/1/clouddrive/capacity/growth/info"
    querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
    headers = common_headers()
    response = requests.request("GET", url, headers=headers, params=querystring).json()
    if response.get("data"):
        return response["data"]
    else:
        return False


def get_growth_sign():
    url = "https://drive-m.quark.cn/1/clouddrive/capacity/growth/sign"
    querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
    payload = {
        "sign_cyclic": True,
    }
    headers = common_headers()
    response = requests.request(
        "POST", url, json=payload, headers=headers, params=querystring
    ).json()
    if response.get("data"):
        return True, response["data"]["sign_daily_reward"]
    else:
        return False, response["message"]


def get_id_from_url(url):
    pattern = r"/s/(\w+)(#/list/share.*/(\w+))?"
    match = re.search(pattern, url)
    if match:
        pwd_id = match.group(1)
        if match.group(2):
            pdir_fid = match.group(3)
        else:
            pdir_fid = 0
        return pwd_id, pdir_fid
    else:
        return None


def get_account_info():
    url = "https://pan.quark.cn/account/info"
    querystring = {"fr": "pc", "platform": "pc"}
    headers = common_headers()
    response = requests.request("GET", url, headers=headers, params=querystring).json()
    if response.get("data"):
        return response["data"]
    else:
        return False


# å¯éªŒè¯èµ„æºæ˜¯å¦å¤±æ•ˆ
def get_stoken(pwd_id):
    url = "https://pan.quark.cn/1/clouddrive/share/sharepage/token"
    querystring = {"pr": "ucpro", "fr": "h5"}
    payload = {"pwd_id": pwd_id, "passcode": ""}
    headers = common_headers()
    response = requests.request(
        "POST", url, json=payload, headers=headers, params=querystring
    ).json()
    if response.get("data"):
        return True, response["data"]["stoken"]
    else:
        return False, response["message"]


def get_detail(pwd_id, stoken, pdir_fid):
    file_list = []
    page = 1
    while True:
        url = "https://pan.quark.cn/1/clouddrive/share/sharepage/detail"
        querystring = {
            "pr": "ucpro",
            "fr": "pc",
            "pwd_id": pwd_id,
            "stoken": stoken,
            "pdir_fid": pdir_fid,
            "force": "0",
            "_page": page,
            "_size": "50",
            "_fetch_banner": "0",
            "_fetch_share": "0",
            "_fetch_total": "1",
            "_sort": "file_type:asc,updated_at:desc",
        }
        headers = common_headers()
        response = requests.request(
            "GET", url, headers=headers, params=querystring
        ).json()
        if response["data"]["list"]:
            file_list += response["data"]["list"]
            page += 1
        else:
            break
        if len(file_list) >= response["metadata"]["_total"]:
            break
    return file_list


def get_fids(file_paths):
    url = "https://drive.quark.cn/1/clouddrive/file/info/path_list"
    querystring = {"pr": "ucpro", "fr": "pc"}
    payload = {"file_path": file_paths, "namespace": "0"}
    headers = common_headers()
    response = requests.request(
        "POST", url, json=payload, headers=headers, params=querystring
    ).json()
    # print(response)
    return response["data"]


def ls_dir(pdir_fid):
    file_list = []
    page = 1
    while True:
        url = "https://drive.quark.cn/1/clouddrive/file/sort"
        querystring = {
            "pr": "ucpro",
            "fr": "pc",
            "uc_param_str": "",
            "pdir_fid": pdir_fid,
            "_page": page,
            "_size": "50",
            "_fetch_total": "1",
            "_fetch_sub_dirs": "0",
            "_sort": "file_type:asc,updated_at:desc",
        }
        headers = common_headers()
        response = requests.request(
            "GET", url, headers=headers, params=querystring
        ).json()
        if response["data"]["list"]:
            file_list += response["data"]["list"]
            page += 1
        else:
            break
        if len(file_list) >= response["metadata"]["_total"]:
            break
    return file_list


def save_file(fid_list, fid_token_list, to_pdir_fid, pwd_id, stoken):
    url = "https://drive.quark.cn/1/clouddrive/share/sharepage/save"
    querystring = {
        "pr": "ucpro",
        "fr": "pc",
        "uc_param_str": "",
        "__dt": int(random.uniform(1, 5) * 60 * 1000),
        "__t": datetime.now().timestamp(),
    }
    payload = {
        "fid_list": fid_list,
        "fid_token_list": fid_token_list,
        "to_pdir_fid": to_pdir_fid,
        "pwd_id": pwd_id,
        "stoken": stoken,
        "pdir_fid": "0",
        "scene": "link",
    }
    headers = common_headers()
    response = requests.request(
        "POST", url, json=payload, headers=headers, params=querystring
    ).json()
    return response


def mkdir(dir_path):
    url = "https://drive-pc.quark.cn/1/clouddrive/file"
    querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
    payload = {
        "pdir_fid": "0",
        "file_name": "",
        "dir_path": dir_path,
        "dir_init_lock": False,
    }
    headers = common_headers()
    response = requests.request(
        "POST", url, json=payload, headers=headers, params=querystring
    ).json()
    return response["data"]


def rename(fid, file_name):
    url = "https://drive-pc.quark.cn/1/clouddrive/file/rename"
    querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
    payload = {"fid": fid, "file_name": file_name}
    headers = common_headers()
    response = requests.request(
        "POST", url, json=payload, headers=headers, params=querystring
    ).json()
    return response["data"]


def update_savepath_fid(tasklist):
    dir_paths = [item["savepath"] for item in tasklist]
    dir_paths_exist_arr = get_fids(dir_paths)
    dir_paths_exist = [item["file_path"] for item in dir_paths_exist_arr]
    # æ¯”è¾ƒåˆ›å»ºä¸å­˜åœ¨çš„
    dir_paths_unexist = list(set(dir_paths) - set(dir_paths_exist))
    for dir_path in dir_paths_unexist:
        new_dir = mkdir(dir_path)
        dir_paths_exist_arr.append({"file_path": dir_path, "fid": new_dir["fid"]})
        print("åˆ›å»ºæ–‡ä»¶å¤¹: ", dir_path)
    # æ›´æ–°åˆ°é…ç½®
    for task in tasklist:
        for dir_path in dir_paths_exist_arr:
            if task["savepath"] == dir_path["file_path"]:
                task["savepath_fid"] = dir_path["fid"]
    # print(dir_paths_exist_arr)


def save_task(task):
    # åˆ¤æ–­èµ„æºå¤±æ•ˆè®°å½•
    if task.get("shareurl_ban"):
        print(f"ã€Š{task['taskname']}ã€‹ï¼š{task['shareurl_ban']}")
        return

    # é“¾æ¥è½¬æ¢æ‰€éœ€å‚æ•°
    pwd_id, pdir_fid = get_id_from_url(task["shareurl"])
    # print("match: ", pwd_id, pdir_fid)

    # è·å–stokenï¼ŒåŒæ—¶å¯éªŒè¯èµ„æºæ˜¯å¦å¤±æ•ˆ
    is_sharing, stoken = get_stoken(pwd_id)
    if not is_sharing:
        add_notify(f"ã€Š{task['taskname']}ã€‹ï¼š{stoken}")
        task["shareurl_ban"] = stoken
        return
    # print("stoken: ", stoken)

    # è·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨
    share_file_list = get_detail(pwd_id, stoken, pdir_fid)
    if not share_file_list:
        add_notify(f"ã€Š{task['taskname']}ã€‹ï¼šåˆ†äº«ç›®å½•ä¸ºç©º")
        return
    # print("share_file_list: ", share_file_list)

    # è·å–ç›®æ ‡ç›®å½•æ–‡ä»¶åˆ—è¡¨
    task["savepath_fid"] = (
        task.get("savepath_fid")
        if task.get("savepath_fid")
        else get_fids([task["savepath"]])[0]["fid"]
    )
    to_pdir_fid = task["savepath_fid"]
    dir_file_list = ls_dir(to_pdir_fid)
    # print("dir_file_list: ", dir_file_list)

    # éœ€ä¿å­˜çš„æ–‡ä»¶æ¸…å•
    need_save_list = []
    # æ·»åŠ ç¬¦åˆçš„
    for share_file in share_file_list:
        # æ­£åˆ™æ–‡ä»¶ååŒ¹é…
        pattern, replace = magic_regex_func(task["pattern"], task["replace"])
        if re.search(pattern, share_file["file_name"]):
            # æ›¿æ¢åçš„æ–‡ä»¶å
            save_name = (
                re.sub(pattern, replace, share_file["file_name"])
                if replace != ""
                else share_file["file_name"]
            )
            # åˆ¤æ–­ç›®æ ‡ç›®å½•æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¯é€‰å¿½ç•¥åç¼€
            if task.get("ignore_extension"):
                compare_func = lambda a, b1, b2: (
                    os.path.splitext(a)[0] == os.path.splitext(b1)[0]
                    or os.path.splitext(a)[0] == os.path.splitext(b2)[0]
                )
            else:
                compare_func = lambda a, b1, b2: (a == b1 or a == b2)
            file_exists = any(
                compare_func(dir_file["file_name"], share_file["file_name"], save_name)
                for dir_file in dir_file_list
            )
            if not file_exists:
                share_file["save_name"] = save_name
                need_save_list.append(share_file)

    fid_list = [item["fid"] for item in need_save_list]
    fid_token_list = [item["share_fid_token"] for item in need_save_list]
    save_name_list = [item["save_name"] for item in need_save_list]
    if fid_list:
        save_name_list.sort()
        add_notify(f"ã€Š{task['taskname']}ã€‹æ·»åŠ è¿½æ›´ï¼š{', '.join(save_name_list)}")
        task = save_file(fid_list, fid_token_list, to_pdir_fid, pwd_id, stoken)
        return True
    else:
        print("è¿è¡Œç»“æœï¼šæ²¡æœ‰æ–°çš„è½¬å­˜ä»»åŠ¡")
        return False


def rename_task(task):
    dir_file_list = ls_dir(task["savepath_fid"])
    is_rename = False
    for dir_file in dir_file_list:
        pattern, replace = magic_regex_func(task["pattern"], task["replace"])
        if re.search(pattern, dir_file["file_name"]):
            save_name = (
                re.sub(pattern, replace, dir_file["file_name"])
                if replace != ""
                else dir_file["file_name"]
            )
            if save_name != dir_file["file_name"]:
                rename(dir_file["fid"], save_name)
                print("é‡å‘½åï¼š", dir_file["file_name"], "â†’", save_name)
                is_rename = True
    return is_rename


def emby_refresh(emby_id):
    global config_data
    emby_url = config_data.get("emby").get("url")
    emby_apikey = config_data.get("emby").get("apikey")
    if emby_url and emby_apikey and emby_id:
        url = f"{emby_url}/emby/Items/{emby_id}/Refresh"
        querystring = {
            "Recursive": "true",
            "MetadataRefreshMode": "FullRefresh",
            "ImageRefreshMode": "FullRefresh",
            "ReplaceAllMetadata": "false",
            "ReplaceAllImages": "false",
            "api_key": emby_apikey,
        }
        response = requests.request("POST", url, headers=None, params=querystring)
        if response.text == "":
            print(f"ğŸ åˆ·æ–°Embyåª’ä½“åº“ï¼šæˆåŠŸâœ…")
            return True
        else:
            print(f"ğŸ åˆ·æ–°Embyåª’ä½“åº“ï¼š{response.text}âŒ")
            return False


def download_file(url, save_path):
    response = requests.get(url)
    if response.status_code == 200:
        with open(save_path, "wb") as file:
            file.write(response.content)
        return True
    else:
        return False


def main():
    global config_data
    formatted_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"============================")
    print(f"â° æ‰§è¡Œæ—¶é—´: {formatted_time}")
    # å¯åŠ¨å‚æ•°
    arguments = sys.argv
    if len(arguments) > 1:
        config_path = arguments[1]
    else:
        config_path = "quark_config.json"
    # æ£€æŸ¥æœ¬åœ°æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨å°±ä¸‹è½½
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨ï¼Œæ­£è¿œç¨‹ä»ä¸‹è½½é…ç½®æ¨¡ç‰ˆ")
        config_url = "https://mirror.ghproxy.com/https://raw.githubusercontent.com/Cp0204/quark_auto_save/main/quark_config.json"
        if download_file(config_url, config_path):
            print("âœ… é…ç½®æ¨¡ç‰ˆä¸‹è½½æˆåŠŸï¼Œè¯·åˆ°ç¨‹åºç›®å½•ä¸­æ‰‹åŠ¨é…ç½®")
        return
    else:
        with open(config_path, "r", encoding="utf-8") as file:
            config_data = json.load(file)
    # æ¨é€æµ‹è¯•
    # add_notify("æ¶ˆæ¯æµ‹è¯•")
    # send_ql_notify("ã€å¤¸å…‹è‡ªåŠ¨è¿½æ›´ã€‘", "\n".join(notifys))
    # return
    # è·å–cookie
    if not config_data.get("cookie"):
        print("âŒ cookieæœªé…ç½®")
        return
    # éªŒè¯è´¦å·
    account_info = get_account_info()
    if not account_info:
        add_notify("ğŸ‘¤ éªŒè¯è´¦å·: ç™»å½•å¤±è´¥ï¼Œcookieæ— æ•ˆâŒ")
    else:
        print(f"ğŸ‘¤ éªŒè¯è´¦å·: {account_info['nickname']}âœ…")
        # æ¯æ—¥é¢†ç©ºé—´
        growth_info = get_growth_info()
        if growth_info:
            if growth_info["cap_sign"]["sign_daily"]:
                print(f"ğŸ“… ç­¾åˆ°ä»»åŠ¡: ä»Šæ—¥å·²ç­¾åˆ°+{growth_info['cap_sign']['sign_daily_reward']/1024/1024}MBï¼Œè¿ç­¾è¿›åº¦({growth_info['cap_sign']['sign_progress']}/{growth_info['cap_sign']['sign_target']})âœ…")
            else:
                sign, sign_return = get_growth_sign()
                if sign:
                    print(f"ğŸ“… ç­¾åˆ°ä»»åŠ¡: ä»Šæ—¥ç­¾åˆ°+{sign_return/1024/1024}MBï¼Œè¿ç­¾è¿›åº¦({growth_info['cap_sign']['sign_progress']+1}/{growth_info['cap_sign']['sign_target']})âœ…")
                else:
                    print(f"ğŸ“… ç­¾åˆ°ä»»åŠ¡: {sign_return}")
        # ä»»åŠ¡åˆ—è¡¨
        tasklist = config_data.get("tasklist", [])
        # è·å–å…¨éƒ¨ä¿å­˜ç›®å½•fid
        if tasklist:
            update_savepath_fid(tasklist)
        # æ‰§è¡Œä»»åŠ¡
        for task in tasklist:
            # åˆ¤æ–­ä»»åŠ¡æœŸé™
            if not task.get("enddate") or (
                datetime.now().date()
                <= datetime.strptime(task["enddate"], "%Y-%m-%d").date()
            ):
                print(f"============================")
                print(f"å½“å‰ä»»åŠ¡: {task['taskname']}")
                print(f"åˆ†äº«é“¾æ¥: {task['shareurl']}")
                print(f"ç›®æ ‡ç›®å½•: {task['savepath']}")
                print(f"æ­£åˆ™åŒ¹é…: {task['pattern']}")
                print(f"æ­£åˆ™æ›¿æ¢: {task['replace']}")
                if task.get("enddate"):
                    print(f"ä»»åŠ¡æˆªæ­¢: {task['enddate']}")
                if task.get("emby_id"):
                    print(f"åˆ·åª’ä½“åº“: {task['emby_id']}")
                if task.get("ignore_extension"):
                    print(f"å¿½ç•¥åç¼€: {task['ignore_extension']}")
                print()
                is_new = save_task(task)
                is_rename = rename_task(task)
                if (is_new or is_rename) and task.get("emby_id"):
                    emby_refresh(task["emby_id"])
                print(f"============================")
    # è·å–cookie
    if notifys:
        notify_body = "\n".join(notifys)
        print(f"\n\næ¨é€é€šçŸ¥ï¼š\n{notify_body}\n\n")
        send_ql_notify("ã€å¤¸å…‹è‡ªåŠ¨è¿½æ›´ã€‘", notify_body)
    # æ›´æ–°é…ç½®
    with open(config_path, "w", encoding="utf-8") as file:
        json.dump(config_data, file, ensure_ascii=False, indent=2)


if __name__ == "__main__":
    main()
