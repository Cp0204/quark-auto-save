# !/usr/bin/env python3
# -*- coding: utf-8 -*-
# Modify: 2026-02-04
# Repo: https://github.com/Cp0204/quark_auto_save
# ConfigFile: quark_config.json
"""
new Env('å¤¸å…‹è‡ªåŠ¨è¿½æ›´');
0 8,18,20 * * * quark_auto_save.py
"""
import os
import re
import sys
import json
import time
import random
import platform
import requests
import importlib
import traceback
import urllib.parse
from datetime import datetime
from natsort import natsorted

# å…¼å®¹é’é¾™
try:
    from treelib import Tree
except:
    print("æ­£åœ¨å°è¯•è‡ªåŠ¨å®‰è£…ä¾èµ–...")
    os.system("pip3 install treelib &> /dev/null")
    from treelib import Tree


CONFIG_DATA = {}
NOTIFYS = []
GH_PROXY = os.environ.get("GH_PROXY", "https://ghproxy.net/")


# å‘é€é€šçŸ¥æ¶ˆæ¯
def send_ql_notify(title, body):
    try:
        # å¯¼å…¥é€šçŸ¥æ¨¡å—
        import notify

        # å¦‚æœªé…ç½® push_config åˆ™ä½¿ç”¨é’é¾™ç¯å¢ƒé€šçŸ¥è®¾ç½®
        if CONFIG_DATA.get("push_config"):
            notify.push_config.update(CONFIG_DATA["push_config"])
            notify.push_config["CONSOLE"] = notify.push_config.get("CONSOLE", True)
        notify.send(title, body)
    except Exception as e:
        if e:
            print("å‘é€é€šçŸ¥æ¶ˆæ¯å¤±è´¥ï¼")


# æ·»åŠ æ¶ˆæ¯
def add_notify(text):
    global NOTIFYS
    NOTIFYS.append(text)
    print("ğŸ“¢", text)
    return text


class Config:
    # ä¸‹è½½é…ç½®
    def download_file(url, save_path):
        response = requests.get(url)
        if response.status_code == 200:
            with open(save_path, "wb") as file:
                file.write(response.content)
            return True
        else:
            return False

    # è¯»å– JSON æ–‡ä»¶å†…å®¹
    def read_json(config_path):
        with open(config_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        return data

    # å°†æ•°æ®å†™å…¥ JSON æ–‡ä»¶
    def write_json(config_path, data):
        with open(config_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, sort_keys=False, indent=2)

    # è¯»å–CK
    def get_cookies(cookie_val):
        if isinstance(cookie_val, list):
            return cookie_val
        elif cookie_val:
            if "\n" in cookie_val:
                return cookie_val.split("\n")
            else:
                return [cookie_val]
        else:
            return False

    def load_plugins(plugins_config={}, plugins_dir="plugins"):
        PLUGIN_FLAGS = os.environ.get("PsLUGIN_FLAGS", "").split(",")
        plugins_available = {}
        task_plugins_config = {}
        # è·å–æ‰€æœ‰æ¨¡å—
        sys_ext = "pyd" if platform.system() == "Windows" else "so"
        module_ext = [".py", f".{sys_ext}"]
        all_modules = [
            f.replace(ext, "")
            for f in os.listdir(plugins_dir)
            for ext in module_ext
            if f.endswith(ext)
        ]
        # è°ƒæ•´æ¨¡å—ä¼˜å…ˆçº§
        priority_path = os.path.join(plugins_dir, "_priority.json")
        try:
            with open(priority_path, encoding="utf-8") as f:
                priority_modules = json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            priority_modules = []
        if priority_modules:
            all_modules = [
                module for module in priority_modules if module in all_modules
            ] + [module for module in all_modules if module not in priority_modules]
        # åŠ è½½æ¨¡å—
        for module_name in all_modules:
            if f"-{module_name}" in PLUGIN_FLAGS:
                continue
            try:
                module = importlib.import_module(f"{plugins_dir}.{module_name}")
                ServerClass = getattr(module, module_name.capitalize())
                # æ£€æŸ¥é…ç½®ä¸­æ˜¯å¦å­˜åœ¨è¯¥æ¨¡å—çš„é…ç½®
                if module_name in plugins_config:
                    plugin = ServerClass(**plugins_config[module_name])
                    plugins_available[module_name] = plugin
                else:
                    plugin = ServerClass()
                    plugins_config[module_name] = plugin.default_config
                # æ£€æŸ¥æ’ä»¶æ˜¯å¦æ”¯æŒå•ç‹¬ä»»åŠ¡é…ç½®
                if hasattr(plugin, "default_task_config"):
                    task_plugins_config[module_name] = plugin.default_task_config
            except (ImportError, AttributeError) as e:
                print(f"è½½å…¥æ¨¡å— {module_name} å¤±è´¥: {e}")
        return plugins_available, plugins_config, task_plugins_config

    def breaking_change_update(config_data):
        # ğŸ”¼ Update config v0.5.x to 0.6.0
        for task in config_data.get("tasklist", []):
            if "$TASKNAME" in task.get("replace", ""):
                task["replace"] = task["replace"].replace("$TASKNAME", "{TASKNAME}")


class MagicRename:

    magic_regex = {
        "$TV": {
            "pattern": r".*?([Ss]\d{1,2})?(?:[ç¬¬EePpXx\.\-\_\( ]{1,2}|^)(\d{1,3})(?!\d).*?\.(mp4|mkv)",
            "replace": r"\1E\2.\3",
        },
        "$BLACK_WORD": {
            "pattern": r"^(?!.*çº¯äº«)(?!.*åŠ æ›´)(?!.*è¶…å‰ä¼åˆ’)(?!.*è®­ç»ƒå®¤)(?!.*è’¸è’¸æ—¥ä¸Š).*",
            "replace": "",
        },
    }

    magic_variable = {
        "{TASKNAME}": "",
        "{I}": 1,
        "{EXT}": [r"(?<=\.)\w+$"],
        "{CHINESE}": [r"[\u4e00-\u9fa5]{2,}"],
        "{DATE}": [
            r"(18|19|20)?\d{2}[\.\-/å¹´]\d{1,2}[\.\-/æœˆ]\d{1,2}",
            r"(?<!\d)[12]\d{3}[01]?\d[0123]?\d",
            r"(?<!\d)[01]?\d[\.\-/æœˆ][0123]?\d",
        ],
        "{YEAR}": [r"(?<!\d)(18|19|20)\d{2}(?!\d)"],
        "{S}": [r"(?<=[Ss])\d{1,2}(?=[EeXx])", r"(?<=[Ss])\d{1,2}"],
        "{SXX}": [r"[Ss]\d{1,2}(?=[EeXx])", r"[Ss]\d{1,2}"],
        "{E}": [
            r"(?<=[Ss]\d\d[Ee])\d{1,3}",
            r"(?<=[Ee])\d{1,3}",
            r"(?<=[Ee][Pp])\d{1,3}",
            r"(?<=ç¬¬)\d{1,3}(?=[é›†æœŸè¯éƒ¨ç¯‡])",
            r"(?<!\d)\d{1,3}(?=[é›†æœŸè¯éƒ¨ç¯‡])",
            r"(?!.*19)(?!.*20)(?<=[\._])\d{1,3}(?=[\._])",
            r"^\d{1,3}(?=\.\w+)",
            r"(?<!\d)\d{1,3}(?!\d)(?!$)",
        ],
        "{PART}": [
            r"(?<=[é›†æœŸè¯éƒ¨ç¯‡ç¬¬])[ä¸Šä¸­ä¸‹ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]",
            r"[ä¸Šä¸­ä¸‹ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]",
        ],
        "{VER}": [r"[\u4e00-\u9fa5]+ç‰ˆ"],
    }

    priority_list = [
        "ä¸Š",
        "ä¸­",
        "ä¸‹",
        "ä¸€",
        "äºŒ",
        "ä¸‰",
        "å››",
        "äº”",
        "å…­",
        "ä¸ƒ",
        "å…«",
        "ä¹",
        "å",
        "ç™¾",
        "åƒ",
        "ä¸‡",
    ]

    def __init__(self, magic_regex={}, magic_variable={}):
        self.magic_regex.update(magic_regex)
        self.magic_variable.update(magic_variable)
        self.dir_filename_dict = {}

    def set_taskname(self, taskname):
        """è®¾ç½®ä»»åŠ¡åç§°"""
        self.magic_variable["{TASKNAME}"] = taskname

    def magic_regex_conv(self, pattern, replace):
        """é­”æ³•æ­£åˆ™åŒ¹é…"""
        keyword = pattern
        if keyword in self.magic_regex:
            pattern = self.magic_regex[keyword]["pattern"]
            if replace == "":
                replace = self.magic_regex[keyword]["replace"]
        return pattern, replace

    def sub(self, pattern, replace, file_name):
        """é­”æ³•æ­£åˆ™ã€å˜é‡æ›¿æ¢"""
        if not replace:
            return file_name
        # é¢„å¤„ç†æ›¿æ¢å˜é‡
        for key, p_list in self.magic_variable.items():
            if key in replace:
                # æ­£åˆ™ç±»æ›¿æ¢å˜é‡
                if p_list and isinstance(p_list, list):
                    for p in p_list:
                        match = re.search(p, file_name)
                        if match:
                            # åŒ¹é…æˆåŠŸï¼Œæ›¿æ¢ä¸ºåŒ¹é…åˆ°çš„å€¼
                            value = match.group()
                            # æ—¥æœŸæ ¼å¼å¤„ç†ï¼šè¡¥å…¨ã€æ ¼å¼åŒ–
                            if key == "{DATE}":
                                value = "".join(
                                    [char for char in value if char.isdigit()]
                                )
                                value = (
                                    str(datetime.now().year)[: (8 - len(value))] + value
                                )
                            replace = replace.replace(key, value)
                            break
                # éæ­£åˆ™ç±»æ›¿æ¢å˜é‡
                if key == "{TASKNAME}":
                    replace = replace.replace(key, self.magic_variable["{TASKNAME}"])
                elif key == "{SXX}" and not match:
                    replace = replace.replace(key, "S01")
                elif key == "{I}":
                    continue
                else:
                    # æ¸…ç†æœªåŒ¹é…çš„ magic_variable key
                    replace = replace.replace(key, "")
        if pattern and replace:
            file_name = re.sub(pattern, replace, file_name)
        else:
            file_name = replace
        return file_name

    def _custom_sort_key(self, name):
        """è‡ªå®šä¹‰æ’åºé”®"""
        for i, keyword in enumerate(self.priority_list):
            if keyword in name:
                name = name.replace(keyword, f"_{i:02d}_")  # æ›¿æ¢ä¸ºæ•°å­—ï¼Œæ–¹ä¾¿æ’åº
        return name

    def sort_file_list(self, file_list, dir_filename_dict={}):
        """æ–‡ä»¶åˆ—è¡¨ç»Ÿä¸€æ’åºï¼Œç»™{I+}èµ‹å€¼"""
        filename_list = [
            # å¼ºåˆ¶åŠ å…¥`æ–‡ä»¶ä¿®æ”¹æ—¶é—´`å­—æ®µä¾›æ’åºï¼Œæ•ˆæœï¼š1æ— å¯æ’åºå­—ç¬¦æ—¶åˆ™æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œ2å’Œç›®å½•å·²æœ‰æ–‡ä»¶é‡åæ—¶å§‹ç»ˆåœ¨å…¶å
            f"{f['file_name_re']}_{f['updated_at']}"
            for f in file_list
            if f.get("file_name_re") and not f["dir"]
        ]
        # print(f"filename_list_before: {filename_list}")
        dir_filename_dict = dir_filename_dict or self.dir_filename_dict
        # print(f"dir_filename_list: {dir_filename_list}")
        # åˆå¹¶ç›®å½•æ–‡ä»¶åˆ—è¡¨
        filename_list = list(set(filename_list) | set(dir_filename_dict.values()))
        filename_list = natsorted(filename_list, key=self._custom_sort_key)
        filename_index = {}
        for name in filename_list:
            if name in dir_filename_dict.values():
                continue
            i = filename_list.index(name) + 1
            while i in dir_filename_dict.keys():
                i += 1
            dir_filename_dict[i] = name
            filename_index[name] = i
        for file in file_list:
            if file.get("file_name_re"):
                if match := re.search(r"\{I+\}", file["file_name_re"]):
                    i = filename_index.get(
                        f"{file['file_name_re']}_{file['updated_at']}", 0
                    )
                    file["file_name_re"] = re.sub(
                        match.group(),
                        str(i).zfill(match.group().count("I")),
                        file["file_name_re"],
                    )

    def set_dir_file_list(self, file_list, replace):
        """è®¾ç½®ç›®å½•æ–‡ä»¶åˆ—è¡¨"""
        self.dir_filename_dict = {}
        filename_list = [f["file_name"] for f in file_list if not f["dir"]]
        filename_list.sort()
        if not filename_list:
            return
        if match := re.search(r"\{I+\}", replace):
            # ç”±æ›¿æ¢å¼è½¬æ¢åŒ¹é…å¼
            magic_i = match.group()
            pattern_i = r"\d" * magic_i.count("I")
            pattern = replace.replace(match.group(), "ğŸ”¢")
            for key, _ in self.magic_variable.items():
                if key in pattern:
                    pattern = pattern.replace(key, "ğŸ”£")
            pattern = re.sub(r"\\[0-9]+", "ğŸ”£", pattern)  # \1 \2 \3
            pattern = f"({re.escape(pattern).replace('ğŸ”£', '.*?').replace('ğŸ”¢', f')({pattern_i})(')})"
            # print(f"pattern: {pattern}")
            # è·å–èµ·å§‹ç¼–å·
            if match := re.match(pattern, filename_list[-1]):
                self.magic_variable["{I}"] = int(match.group(2))
            # ç›®å½•æ–‡ä»¶åˆ—è¡¨
            for filename in filename_list:
                if match := re.match(pattern, filename):
                    self.dir_filename_dict[int(match.group(2))] = (
                        match.group(1) + magic_i + match.group(3)
                    )
            # print(f"filename_list: {self.filename_list}")

    def is_exists(self, filename, filename_list, ignore_ext=False):
        """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¤„ç†å¿½ç•¥æ‰©å±•å"""
        # print(f"filename: {filename} filename_list: {filename_list}")
        if ignore_ext:
            filename = os.path.splitext(filename)[0]
            filename_list = [os.path.splitext(f)[0] for f in filename_list]
        # {I+} æ¨¡å¼ï¼Œç”¨Ié€šé…æ•°å­—åºå·
        if match := re.search(r"\{I+\}", filename):
            magic_i = match.group()
            pattern_i = r"\d" * magic_i.count("I")
            pattern = re.escape(filename).replace(re.escape(magic_i), pattern_i)
            for filename in filename_list:
                if re.match(pattern, filename):
                    return filename
            return None
        else:
            return filename if filename in filename_list else None


class Quark:
    BASE_URL = "https://drive-pc.quark.cn"
    BASE_URL_APP = "https://drive-m.quark.cn"
    USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) quark-cloud-drive/3.14.2 Chrome/112.0.5615.165 Electron/24.1.3.8 Safari/537.36 Channel/pckk_other_ch"

    def __init__(self, cookie="", index=0):
        self.cookie = cookie.strip()
        self.index = index + 1
        self.is_active = False
        self.nickname = ""
        self.mparam = self._match_mparam_form_cookie(cookie)
        self.savepath_fid = {"/": "0"}

    def _match_mparam_form_cookie(self, cookie):
        mparam = {}
        kps_match = re.search(r"(?<!\w)kps=([a-zA-Z0-9%+/=]+)[;&]?", cookie)
        sign_match = re.search(r"(?<!\w)sign=([a-zA-Z0-9%+/=]+)[;&]?", cookie)
        vcode_match = re.search(r"(?<!\w)vcode=([a-zA-Z0-9%+/=]+)[;&]?", cookie)
        if kps_match and sign_match and vcode_match:
            mparam = {
                "kps": kps_match.group(1).replace("%25", "%"),
                "sign": sign_match.group(1).replace("%25", "%"),
                "vcode": vcode_match.group(1).replace("%25", "%"),
            }
        return mparam

    def _send_request(self, method, url, **kwargs):
        headers = {
            "cookie": self.cookie,
            "content-type": "application/json",
            "user-agent": self.USER_AGENT,
        }
        if "headers" in kwargs:
            headers = kwargs["headers"]
            del kwargs["headers"]
        if self.mparam and "share" in url and self.BASE_URL in url:
            url = url.replace(self.BASE_URL, self.BASE_URL_APP)
            kwargs["params"].update(
                {
                    "device_model": "M2011K2C",
                    "entry": "default_clouddrive",
                    "_t_group": "0%3A_s_vp%3A1",
                    "dmn": "Mi%2B11",
                    "fr": "android",
                    "pf": "3300",
                    "bi": "35937",
                    "ve": "7.4.5.680",
                    "ss": "411x875",
                    "mi": "M2011K2C",
                    "nt": "5",
                    "nw": "0",
                    "kt": "4",
                    "pr": "ucpro",
                    "sv": "release",
                    "dt": "phone",
                    "data_from": "ucapi",
                    "kps": self.mparam.get("kps"),
                    "sign": self.mparam.get("sign"),
                    "vcode": self.mparam.get("vcode"),
                    "app": "clouddrive",
                    "kkkk": "1",
                }
            )
            del headers["cookie"]
        try:
            response = requests.request(method, url, headers=headers, **kwargs)
            # print(f"{response.text}")
            # response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸï¼Œä½†è¿”å›é200ä¹Ÿä¼šæŠ›å‡ºå¼‚å¸¸
            return response
        except Exception as e:
            print(f"_send_request error:\n{e}")
            fake_response = requests.Response()
            fake_response.status_code = 500
            fake_response._content = (
                b'{"status": 500, "code": 1, "message": "request error"}'
            )
            return fake_response

    def init(self):
        account_info = self.get_account_info()
        if account_info:
            self.is_active = True
            self.nickname = account_info["nickname"]
            return account_info
        else:
            return False

    def get_account_info(self):
        url = "https://pan.quark.cn/account/info"
        querystring = {"fr": "pc", "platform": "pc"}
        response = self._send_request("GET", url, params=querystring).json()
        if response.get("data"):
            return response["data"]
        else:
            return False

    def get_growth_info(self):
        url = f"{self.BASE_URL_APP}/1/clouddrive/capacity/growth/info"
        querystring = {
            "pr": "ucpro",
            "fr": "android",
            "kps": self.mparam.get("kps"),
            "sign": self.mparam.get("sign"),
            "vcode": self.mparam.get("vcode"),
        }
        headers = {
            "content-type": "application/json",
        }
        response = self._send_request(
            "GET", url, headers=headers, params=querystring
        ).json()
        if response.get("data"):
            return response["data"]
        else:
            return False

    def get_growth_sign(self):
        url = f"{self.BASE_URL_APP}/1/clouddrive/capacity/growth/sign"
        querystring = {
            "pr": "ucpro",
            "fr": "android",
            "kps": self.mparam.get("kps"),
            "sign": self.mparam.get("sign"),
            "vcode": self.mparam.get("vcode"),
        }
        payload = {
            "sign_cyclic": True,
        }
        headers = {
            "content-type": "application/json",
        }
        response = self._send_request(
            "POST", url, json=payload, headers=headers, params=querystring
        ).json()
        if response.get("data"):
            return True, response["data"]["sign_daily_reward"]
        else:
            return False, response["message"]

    # å¯éªŒè¯èµ„æºæ˜¯å¦å¤±æ•ˆ
    def get_stoken(self, pwd_id, passcode=""):
        url = f"{self.BASE_URL}/1/clouddrive/share/sharepage/token"
        querystring = {"pr": "ucpro", "fr": "pc"}
        payload = {"pwd_id": pwd_id, "passcode": passcode}
        response = self._send_request(
            "POST", url, json=payload, params=querystring
        ).json()
        return response

    def get_detail(
        self, pwd_id, stoken, pdir_fid, _fetch_share=0, fetch_share_full_path=0
    ):
        list_merge = []
        page = 1
        while True:
            url = f"{self.BASE_URL}/1/clouddrive/share/sharepage/detail"
            querystring = {
                "pr": "ucpro",
                "fr": "pc",
                "pwd_id": pwd_id,
                "stoken": stoken,
                "pdir_fid": pdir_fid,
                "force": "0",
                "_page": page,
                "_size": "50",
                "_fetch_banner": "0",
                "_fetch_share": _fetch_share,
                "_fetch_total": "1",
                "_sort": "file_type:asc,updated_at:desc",
                "ver": "2",
                "fetch_share_full_path": fetch_share_full_path,
            }
            response = self._send_request("GET", url, params=querystring).json()
            if response["code"] != 0:
                return response
            if response["data"]["list"]:
                list_merge += response["data"]["list"]
                page += 1
            else:
                break
            if len(list_merge) >= response["metadata"]["_total"]:
                break
        response["data"]["list"] = list_merge
        return response

    def get_fids(self, file_paths):
        fids = []
        while True:
            url = f"{self.BASE_URL}/1/clouddrive/file/info/path_list"
            querystring = {"pr": "ucpro", "fr": "pc"}
            payload = {"file_path": file_paths[:50], "namespace": "0"}
            response = self._send_request(
                "POST", url, json=payload, params=querystring
            ).json()
            if response["code"] == 0:
                fids += response["data"]
                file_paths = file_paths[50:]
            else:
                print(f"è·å–ç›®å½•IDï¼šå¤±è´¥, {response['message']}")
                break
            if len(file_paths) == 0:
                break
        return fids

    def ls_dir(self, pdir_fid, **kwargs):
        list_merge = []
        page = 1
        while True:
            url = f"{self.BASE_URL}/1/clouddrive/file/sort"
            querystring = {
                "pr": "ucpro",
                "fr": "pc",
                "uc_param_str": "",
                "pdir_fid": pdir_fid,
                "_page": page,
                "_size": "50",
                "_fetch_total": "1",
                "_fetch_sub_dirs": "0",
                "_sort": "file_type:asc,updated_at:desc",
                "_fetch_full_path": kwargs.get("fetch_full_path", 0),
                "fetch_all_file": 1,  # è·ŸéšWebç«¯ï¼Œä½œç”¨æœªçŸ¥
                "fetch_risk_file_name": 1,  # å¦‚æ— æ­¤å‚æ•°ï¼Œè¿è§„æ–‡ä»¶åä¼šè¢«å˜ ***
            }
            response = self._send_request("GET", url, params=querystring).json()
            if response["code"] != 0:
                return response
            if response["data"]["list"]:
                list_merge += response["data"]["list"]
                page += 1
            else:
                break
            if len(list_merge) >= response["metadata"]["_total"]:
                break
        response["data"]["list"] = list_merge
        return response

    def save_file(self, fid_list, fid_token_list, to_pdir_fid, pwd_id, stoken):
        url = f"{self.BASE_URL}/1/clouddrive/share/sharepage/save"
        querystring = {
            "pr": "ucpro",
            "fr": "pc",
            "uc_param_str": "",
            "app": "clouddrive",
            "__dt": int(random.uniform(1, 5) * 60 * 1000),
            "__t": datetime.now().timestamp(),
        }
        payload = {
            "fid_list": fid_list,
            "fid_token_list": fid_token_list,
            "to_pdir_fid": to_pdir_fid,
            "pwd_id": pwd_id,
            "stoken": stoken,
            "pdir_fid": "0",
            "scene": "link",
        }
        response = self._send_request(
            "POST", url, json=payload, params=querystring
        ).json()
        return response

    def query_task(self, task_id):
        retry_index = 0
        while True:
            url = f"{self.BASE_URL}/1/clouddrive/task"
            querystring = {
                "pr": "ucpro",
                "fr": "pc",
                "uc_param_str": "",
                "task_id": task_id,
                "retry_index": retry_index,
                "__dt": int(random.uniform(1, 5) * 60 * 1000),
                "__t": datetime.now().timestamp(),
            }
            response = self._send_request("GET", url, params=querystring).json()
            if response["status"] != 200:
                return response
            if response["data"]["status"] == 2:
                if retry_index > 0:
                    print()
                break
            else:
                if retry_index == 0:
                    print(
                        f"æ­£åœ¨ç­‰å¾…[{response['data']['task_title']}]æ‰§è¡Œç»“æœ",
                        end="",
                        flush=True,
                    )
                else:
                    print(".", end="", flush=True)
                retry_index += 1
                time.sleep(0.500)
        return response

    def download(self, fids):
        url = f"{self.BASE_URL}/1/clouddrive/file/download"
        querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
        payload = {"fids": fids}
        response = self._send_request("POST", url, json=payload, params=querystring)
        set_cookie = response.cookies.get_dict()
        cookie_str = "; ".join([f"{key}={value}" for key, value in set_cookie.items()])
        return response.json(), cookie_str

    def mkdir(self, dir_path):
        url = f"{self.BASE_URL}/1/clouddrive/file"
        querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
        payload = {
            "pdir_fid": "0",
            "file_name": "",
            "dir_path": dir_path,
            "dir_init_lock": False,
        }
        response = self._send_request(
            "POST", url, json=payload, params=querystring
        ).json()
        return response

    def rename(self, fid, file_name):
        url = f"{self.BASE_URL}/1/clouddrive/file/rename"
        querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
        payload = {"fid": fid, "file_name": file_name}
        response = self._send_request(
            "POST", url, json=payload, params=querystring
        ).json()
        return response

    def delete(self, filelist):
        url = f"{self.BASE_URL}/1/clouddrive/file/delete"
        querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
        payload = {"action_type": 2, "filelist": filelist, "exclude_fids": []}
        response = self._send_request(
            "POST", url, json=payload, params=querystring
        ).json()
        return response

    def recycle_list(self, page=1, size=30):
        url = f"{self.BASE_URL}/1/clouddrive/file/recycle/list"
        querystring = {
            "_page": page,
            "_size": size,
            "pr": "ucpro",
            "fr": "pc",
            "uc_param_str": "",
        }
        response = self._send_request("GET", url, params=querystring).json()
        return response["data"]["list"]

    def recycle_remove(self, record_list):
        url = f"{self.BASE_URL}/1/clouddrive/file/recycle/remove"
        querystring = {"uc_param_str": "", "fr": "pc", "pr": "ucpro"}
        payload = {
            "select_mode": 2,
            "record_list": record_list,
        }
        response = self._send_request(
            "POST", url, json=payload, params=querystring
        ).json()
        return response

    # â†‘ è¯·æ±‚å‡½æ•°
    # â†“ æ“ä½œå‡½æ•°

    def extract_url(self, url):
        # pwd_id
        match_id = re.search(r"/s/(\w+)", url)
        pwd_id = match_id.group(1) if match_id else None
        # passcode
        match_pwd = re.search(r"pwd=(\w+)", url)
        passcode = match_pwd.group(1) if match_pwd else ""
        # path: fid-name
        # Legacy 20250905
        paths = []
        matches = re.findall(r"/(\w{32})-?([^/]+)?", url)
        for match in matches:
            fid = match[0]
            name = urllib.parse.unquote(match[1]).replace("*101", "-")
            paths.append({"fid": fid, "name": name})
        pdir_fid = paths[-1]["fid"] if matches else 0
        return pwd_id, passcode, pdir_fid, paths

    def update_savepath_fid(self, tasklist):
        dir_paths = [
            re.sub(r"/{2,}", "/", f"/{item['savepath']}")
            for item in tasklist
            if not item.get("enddate")
            or (
                datetime.now().date()
                <= datetime.strptime(item["enddate"], "%Y-%m-%d").date()
            )
        ]
        if not dir_paths:
            return False
        dir_paths_exist_arr = self.get_fids(dir_paths)
        dir_paths_exist = [item["file_path"] for item in dir_paths_exist_arr]
        # æ¯”è¾ƒåˆ›å»ºä¸å­˜åœ¨çš„
        dir_paths_unexist = list(set(dir_paths) - set(dir_paths_exist) - set(["/"]))
        for dir_path in dir_paths_unexist:
            mkdir_return = self.mkdir(dir_path)
            if mkdir_return["code"] == 0:
                new_dir = mkdir_return["data"]
                dir_paths_exist_arr.append(
                    {"file_path": dir_path, "fid": new_dir["fid"]}
                )
                print(f"åˆ›å»ºæ–‡ä»¶å¤¹ï¼š{dir_path}")
            else:
                print(f"åˆ›å»ºæ–‡ä»¶å¤¹ï¼š{dir_path} å¤±è´¥, {mkdir_return['message']}")
        # å‚¨å­˜ç›®æ ‡ç›®å½•çš„fid
        for dir_path in dir_paths_exist_arr:
            self.savepath_fid[dir_path["file_path"]] = dir_path["fid"]
        # print(dir_paths_exist_arr)

    def do_save_check(self, shareurl, savepath):
        try:
            pwd_id, passcode, pdir_fid, _ = self.extract_url(shareurl)
            stoken = self.get_stoken(pwd_id, passcode)["data"]["stoken"]
            share_file_list = self.get_detail(pwd_id, stoken, pdir_fid)["data"]["list"]
            print(f"è·å–åˆ†äº«: {share_file_list}")
            fid_list = [item["fid"] for item in share_file_list]
            fid_token_list = [item["share_fid_token"] for item in share_file_list]
            get_fids = self.get_fids([savepath])
            to_pdir_fid = (
                get_fids[0]["fid"] if get_fids else self.mkdir(savepath)["data"]["fid"]
            )
            save_file = self.save_file(
                fid_list, fid_token_list, to_pdir_fid, pwd_id, stoken
            )
            print(f"è½¬å­˜æ–‡ä»¶: {save_file}")
            if save_file["code"] == 0:
                task_id = save_file["data"]["task_id"]
                query_task = self.query_task(task_id)
                print(f"æŸ¥è¯¢è½¬å­˜: {query_task}")
                if query_task["code"] == 0:
                    del_list = query_task["data"]["save_as"]["save_as_top_fids"]
                    if del_list:
                        delete_return = self.delete(del_list)
                        print(f"åˆ é™¤è½¬å­˜: {delete_return}")
                        recycle_list = self.recycle_list()
                        record_id_list = [
                            item["record_id"]
                            for item in recycle_list
                            if item["fid"] in del_list
                        ]
                        recycle_remove = self.recycle_remove(record_id_list)
                        print(f"æ¸…ç†è½¬å­˜: {recycle_remove}")
                        print(f"âœ… è½¬å­˜æµ‹è¯•æˆåŠŸ")
                        return True
            print(f"âŒ è½¬å­˜æµ‹è¯•å¤±è´¥: ä¸­æ–­")
            return False
        except Exception as e:
            print(f"âŒ è½¬å­˜æµ‹è¯•å¤±è´¥: {str(e)}")
            traceback.print_exc()

    def do_save_task(self, task):
        # åˆ¤æ–­èµ„æºå¤±æ•ˆè®°å½•
        if task.get("shareurl_ban"):
            print(f"ã€Š{task['taskname']}ã€‹ï¼š{task['shareurl_ban']}")
            return

        # é“¾æ¥è½¬æ¢æ‰€éœ€å‚æ•°
        pwd_id, passcode, pdir_fid, _ = self.extract_url(task["shareurl"])

        # è·å–stokenï¼ŒåŒæ—¶å¯éªŒè¯èµ„æºæ˜¯å¦å¤±æ•ˆ
        get_stoken = self.get_stoken(pwd_id, passcode)
        if get_stoken.get("status") == 200:
            stoken = get_stoken["data"]["stoken"]
        elif get_stoken.get("status") == 500:
            print(f"è·³è¿‡ä»»åŠ¡ï¼šç½‘ç»œå¼‚å¸¸ {get_stoken.get('message')}")
            return
        else:
            message = get_stoken.get("message")
            add_notify(f"âŒã€Š{task['taskname']}ã€‹ï¼š{message}\n")
            task["shareurl_ban"] = message
            return
        # print("stoken: ", stoken)

        updated_tree = self.dir_check_and_save(task, pwd_id, stoken, pdir_fid)
        if updated_tree.size(1) > 0:
            self.do_rename(updated_tree)
            print()
            add_notify(f"âœ…ã€Š{task['taskname']}ã€‹æ·»åŠ è¿½æ›´ï¼š\n{updated_tree}")
            return updated_tree
        else:
            print(f"ä»»åŠ¡ç»“æŸï¼šæ²¡æœ‰æ–°çš„è½¬å­˜ä»»åŠ¡")
            return False

    def dir_check_and_save(self, task, pwd_id, stoken, pdir_fid="", subdir_path=""):
        tree = Tree()
        # è·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨
        share_file_list = self.get_detail(pwd_id, stoken, pdir_fid)["data"]["list"]
        # print("share_file_list: ", share_file_list)

        if not share_file_list:
            if subdir_path == "":
                task["shareurl_ban"] = "åˆ†äº«ä¸ºç©ºï¼Œæ–‡ä»¶å·²è¢«åˆ†äº«è€…åˆ é™¤"
                add_notify(f"âŒã€Š{task['taskname']}ã€‹ï¼š{task['shareurl_ban']}\n")
            return tree
        elif (
            len(share_file_list) == 1
            and share_file_list[0]["dir"]
            and subdir_path == ""
        ):  # ä»…æœ‰ä¸€ä¸ªæ–‡ä»¶å¤¹
            print("ğŸ§  è¯¥åˆ†äº«æ˜¯ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œè¯»å–æ–‡ä»¶å¤¹å†…åˆ—è¡¨")
            share_file_list = self.get_detail(
                pwd_id, stoken, share_file_list[0]["fid"]
            )["data"]["list"]

        # è·å–ç›®æ ‡ç›®å½•æ–‡ä»¶åˆ—è¡¨
        savepath = re.sub(r"/{2,}", "/", f"/{task['savepath']}{subdir_path}")
        if not self.savepath_fid.get(savepath):
            if get_fids := self.get_fids([savepath]):
                self.savepath_fid[savepath] = get_fids[0]["fid"]
            else:
                print(f"âŒ ç›®å½• {savepath} fidè·å–å¤±è´¥ï¼Œè·³è¿‡è½¬å­˜")
                return tree
        to_pdir_fid = self.savepath_fid[savepath]
        dir_file_list = self.ls_dir(to_pdir_fid)["data"]["list"]
        dir_filename_list = [dir_file["file_name"] for dir_file in dir_file_list]
        # print("dir_file_list: ", dir_file_list)

        tree.create_node(
            savepath,
            pdir_fid,
            data={
                "is_dir": True,
            },
        )

        # æ–‡ä»¶å‘½åç±»
        mr = MagicRename(CONFIG_DATA.get("magic_regex", {}))
        mr.set_taskname(task["taskname"])

        # é­”æ³•æ­£åˆ™è½¬æ¢
        pattern, replace = mr.magic_regex_conv(
            task.get("pattern", ""), task.get("replace", "")
        )
        # éœ€ä¿å­˜çš„æ–‡ä»¶æ¸…å•
        need_save_list = []
        # æ·»åŠ ç¬¦åˆçš„
        for share_file in share_file_list:
            search_pattern = (
                task["update_subdir"]
                if share_file["dir"] and task.get("update_subdir")
                else pattern
            )
            # æ­£åˆ™æ–‡ä»¶ååŒ¹é…
            if re.search(search_pattern, share_file["file_name"]):
                # åˆ¤æ–­åŸæ–‡ä»¶åæ˜¯å¦å­˜åœ¨ï¼Œå¤„ç†å¿½ç•¥æ‰©å±•å
                if not mr.is_exists(
                    share_file["file_name"],
                    dir_filename_list,
                    (task.get("ignore_extension") and not share_file["dir"]),
                ):
                    # æ–‡ä»¶å¤¹ã€å­ç›®å½•æ–‡ä»¶ä¸è¿›è¡Œé‡å‘½å
                    if share_file["dir"] or subdir_path:
                        share_file["file_name_re"] = share_file["file_name"]
                        need_save_list.append(share_file)
                    else:
                        # æ›¿æ¢åçš„æ–‡ä»¶å
                        file_name_re = mr.sub(pattern, replace, share_file["file_name"])
                        # åˆ¤æ–­æ›¿æ¢åçš„æ–‡ä»¶åæ˜¯å¦å­˜åœ¨
                        if not mr.is_exists(
                            file_name_re,
                            dir_filename_list,
                            task.get("ignore_extension"),
                        ):
                            share_file["file_name_re"] = file_name_re
                            need_save_list.append(share_file)
                elif share_file["dir"]:
                    # å­˜åœ¨å¹¶æ˜¯ä¸€ä¸ªç›®å½•ï¼Œå†éå­ç›®å½•
                    if task.get("update_subdir", False) and re.search(
                        task["update_subdir"], share_file["file_name"]
                    ):
                        if task.get("update_subdir_resave_mode", False):
                            # é‡å­˜æ¨¡å¼ï¼šåˆ é™¤è¯¥ç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶ï¼Œé‡æ–°è½¬å­˜
                            print(f"é‡å­˜å­ç›®å½•ï¼š{savepath}/{share_file['file_name']}")
                            # åˆ é™¤å­ç›®å½•ã€å›æ”¶ç«™ä¸­å½»åº•åˆ é™¤
                            subdir = next(
                                (
                                    f
                                    for f in dir_file_list
                                    if f["file_name"] == share_file["file_name"]
                                ),
                                None,
                            )
                            delete_return = self.delete([subdir["fid"]])
                            self.query_task(delete_return["data"]["task_id"])
                            recycle_list = self.recycle_list()
                            record_id_list = [
                                item["record_id"]
                                for item in recycle_list
                                if item["fid"] == subdir["fid"]
                            ]
                            self.recycle_remove(record_id_list)
                            # ä½œä¸ºæ–°æ–‡ä»¶æ·»åŠ åˆ°è½¬å­˜åˆ—è¡¨
                            share_file["file_name_re"] = share_file["file_name"]
                            need_save_list.append(share_file)
                        else:
                            # é€’å½’æ¨¡å¼
                            print(f"æ£€æŸ¥å­ç›®å½•ï¼š{savepath}/{share_file['file_name']}")
                            subdir_tree = self.dir_check_and_save(
                                task,
                                pwd_id,
                                stoken,
                                share_file["fid"],
                                f"{subdir_path}/{share_file['file_name']}",
                            )
                            if subdir_tree.size(1) > 0:
                                # åˆå¹¶å­ç›®å½•æ ‘
                                tree.create_node(
                                    "ğŸ“" + share_file["file_name"],
                                    share_file["fid"],
                                    parent=pdir_fid,
                                    data={
                                        "is_dir": share_file["dir"],
                                    },
                                )
                                tree.merge(share_file["fid"], subdir_tree, deep=False)
            # æŒ‡å®šæ–‡ä»¶å¼€å§‹è®¢é˜…/åˆ°è¾¾æŒ‡å®šæ–‡ä»¶ï¼ˆå«ï¼‰ç»“æŸå†é
            if share_file["fid"] == task.get("startfid", ""):
                break

        if re.search(r"\{I+\}", replace):
            mr.set_dir_file_list(dir_file_list, replace)
            mr.sort_file_list(need_save_list)

        # è½¬å­˜æ–‡ä»¶
        fid_list = [item["fid"] for item in need_save_list]
        fid_token_list = [item["share_fid_token"] for item in need_save_list]
        if fid_list:
            err_msg = None
            save_as_top_fids = []
            while fid_list:
                # åˆ†æ¬¡è½¬å­˜ï¼Œ100ä¸ª/æ¬¡ï¼Œå› query_taskè¿”å›save_as_top_fidsæœ€å¤š100
                save_file_return = self.save_file(
                    fid_list[:100], fid_token_list[:100], to_pdir_fid, pwd_id, stoken
                )
                fid_list = fid_list[100:]
                fid_token_list = fid_token_list[100:]
                if save_file_return["code"] == 0:
                    # è½¬å­˜æˆåŠŸï¼ŒæŸ¥è¯¢è½¬å­˜ç»“æœ
                    task_id = save_file_return["data"]["task_id"]
                    query_task_return = self.query_task(task_id)
                    if query_task_return["code"] == 0:
                        save_as_top_fids.extend(
                            query_task_return["data"]["save_as"]["save_as_top_fids"]
                        )
                    else:
                        err_msg = query_task_return["message"]
                else:
                    err_msg = save_file_return["message"]
                if err_msg:
                    add_notify(f"âŒã€Š{task['taskname']}ã€‹è½¬å­˜å¤±è´¥ï¼š{err_msg}\n")
            # å»ºç«‹ç›®å½•æ ‘
            if len(need_save_list) == len(save_as_top_fids):
                for index, item in enumerate(need_save_list):
                    icon = self._get_file_icon(item)
                    tree.create_node(
                        f"{icon}{item['file_name_re']}",
                        item["fid"],
                        parent=pdir_fid,
                        data={
                            "file_name": item["file_name"],
                            "file_name_re": item["file_name_re"],
                            "fid": f"{save_as_top_fids[index]}",
                            "path": f"{savepath}/{item['file_name_re']}",
                            "is_dir": item["dir"],
                            "obj_category": item.get("obj_category", ""),
                        },
                    )
        return tree

    def do_rename(self, tree, node_id=None):
        if node_id is None:
            node_id = tree.root
        for child in tree.children(node_id):
            file = child.data
            if file.get("is_dir"):
                # self.do_rename(tree, child.identifier)
                pass
            elif file.get("file_name_re") and file["file_name_re"] != file["file_name"]:
                rename_ret = self.rename(file["fid"], file["file_name_re"])
                print(f"é‡å‘½åï¼š{file['file_name']} â†’ {file['file_name_re']}")
                if rename_ret["code"] != 0:
                    print(f"      â†‘ å¤±è´¥ï¼Œ{rename_ret['message']}")

    def _get_file_icon(self, f):
        if f.get("dir"):
            return "ğŸ“"
        ico_maps = {
            "video": "ğŸï¸",
            "image": "ğŸ–¼ï¸",
            "audio": "ğŸµ",
            "doc": "ğŸ“„",
            "archive": "ğŸ“¦",
            "default": "",
        }
        return ico_maps.get(f.get("obj_category"), "")


def verify_account(account):
    # éªŒè¯è´¦å·
    print(f"â–¶ï¸ éªŒè¯ç¬¬{account.index}ä¸ªè´¦å·")
    if "__uid" not in account.cookie:
        print(f"ğŸ’¡ ä¸å­˜åœ¨cookieå¿…è¦å‚æ•°ï¼Œåˆ¤æ–­ä¸ºä»…ç­¾åˆ°")
        return False
    else:
        account_info = account.init()
        if not account_info:
            add_notify(f"ğŸ‘¤ ç¬¬{account.index}ä¸ªè´¦å·ç™»å½•å¤±è´¥ï¼Œcookieæ— æ•ˆâŒ")
            return False
        else:
            print(f"ğŸ‘¤ è´¦å·æ˜µç§°: {account_info['nickname']}âœ…")
            return True


def format_bytes(size_bytes: int) -> str:
    units = ("B", "KB", "MB", "GB", "TB", "PB", "EB", "ZB", "YB")
    i = 0
    while size_bytes >= 1024 and i < len(units) - 1:
        size_bytes /= 1024
        i += 1
    return f"{size_bytes:.2f} {units[i]}"


def do_sign(account):
    if not account.mparam:
        print("â­ï¸ ç§»åŠ¨ç«¯å‚æ•°æœªè®¾ç½®ï¼Œè·³è¿‡ç­¾åˆ°")
        print()
        return
    # æ¯æ—¥é¢†ç©ºé—´
    growth_info = account.get_growth_info()
    if growth_info:
        VIP_MAP = {
            "NORMAL": "æ™®é€šç”¨æˆ·",
            "EXP_SVIP": "88VIP",
            "SUPER_VIP": "SVIP",
            "Z_VIP": "SVIP+",
        }
        growth_message = f"ğŸ’¾ {VIP_MAP.get(growth_info['member_type'], growth_info['member_type'])} æ€»ç©ºé—´ï¼š{format_bytes(growth_info['total_capacity'])}ï¼Œç­¾åˆ°ç´¯è®¡è·å¾—ï¼š{format_bytes(growth_info['cap_composition'].get('sign_reward', 0))}"
        if growth_info["cap_sign"]["sign_daily"]:
            sign_message = f"ğŸ“… ç­¾åˆ°è®°å½•: ä»Šæ—¥å·²ç­¾åˆ°+{int(growth_info['cap_sign']['sign_daily_reward']/1024/1024)}MBï¼Œè¿ç­¾è¿›åº¦({growth_info['cap_sign']['sign_progress']}/{growth_info['cap_sign']['sign_target']})âœ…"
            message = f"{sign_message}\n{growth_message}"
            print(message)
        else:
            sign, sign_return = account.get_growth_sign()
            if sign:
                sign_message = f"ğŸ“… æ‰§è¡Œç­¾åˆ°: ä»Šæ—¥ç­¾åˆ°+{int(sign_return/1024/1024)}MBï¼Œè¿ç­¾è¿›åº¦({growth_info['cap_sign']['sign_progress']+1}/{growth_info['cap_sign']['sign_target']})âœ…"
                message = f"{sign_message}\n{growth_message}"
                if (
                    str(
                        CONFIG_DATA.get("push_config", {}).get("QUARK_SIGN_NOTIFY")
                    ).lower()
                    == "false"
                    or os.environ.get("QUARK_SIGN_NOTIFY") == "false"
                ):
                    print(message)
                else:
                    message = message.replace("ä»Šæ—¥", f"[{account.nickname}]ä»Šæ—¥")
                    add_notify(message)
            else:
                print(f"ğŸ“… ç­¾åˆ°å¼‚å¸¸: {sign_return}")
    else:
        print("â­ï¸ ç­¾åˆ°è¿›åº¦è¯»å–å¼‚å¸¸ï¼Œå¯èƒ½ç™»å½•å¤±æ•ˆï¼Œè·³è¿‡ç­¾åˆ°")
    print()


def do_save(account, tasklist=[]):
    print(f"ğŸ§© è½½å…¥æ’ä»¶")
    plugins, CONFIG_DATA["plugins"], task_plugins_config = Config.load_plugins(
        CONFIG_DATA.get("plugins", {})
    )
    print()
    print(f"è½¬å­˜è´¦å·: {account.nickname}")
    # è·å–å…¨éƒ¨ä¿å­˜ç›®å½•fid
    account.update_savepath_fid(tasklist)

    def is_time(task):
        return (
            not task.get("enddate")
            or (
                datetime.now().date()
                <= datetime.strptime(task["enddate"], "%Y-%m-%d").date()
            )
        ) and (
            "runweek" not in task
            # æ˜ŸæœŸä¸€ä¸º0ï¼Œæ˜ŸæœŸæ—¥ä¸º6
            or (datetime.today().weekday() + 1 in task.get("runweek"))
        )

    for plugin_name, plugin in plugins.items():
        if plugin.is_active and hasattr(plugin, "task_before"):
            tasklist = (
                plugin.task_before(tasklist=tasklist, account=account) or tasklist
            )

    # æ‰§è¡Œä»»åŠ¡
    for index, task in enumerate(tasklist):
        print()
        print(f"#{index+1}------------------")
        print(f"ä»»åŠ¡åç§°: {task['taskname']}")
        print(f"åˆ†äº«é“¾æ¥: {task['shareurl']}")
        print(f"ä¿å­˜è·¯å¾„: {task['savepath']}")
        if task.get("pattern"):
            print(f"æ­£åˆ™åŒ¹é…: {task['pattern']}")
        if task.get("replace"):
            print(f"æ­£åˆ™æ›¿æ¢: {task['replace']}")
        if task.get("update_subdir"):
            print(f"æ›´å­ç›®å½•: {task['update_subdir']}")
        if task.get("runweek") or task.get("enddate"):
            print(
                f"è¿è¡Œå‘¨æœŸ: WK{task.get('runweek',[])} ~ {task.get('enddate','forever')}"
            )
        print()
        # åˆ¤æ–­ä»»åŠ¡å‘¨æœŸ
        if not is_time(task):
            print(f"ä»»åŠ¡ä¸åœ¨è¿è¡Œå‘¨æœŸå†…ï¼Œè·³è¿‡")
        else:
            is_new_tree = account.do_save_task(task)

            # è¡¥å……ä»»åŠ¡çš„æ’ä»¶é…ç½®
            def merge_dicts(a, b):
                result = a.copy()
                for key, value in b.items():
                    if (
                        key in result
                        and isinstance(result[key], dict)
                        and isinstance(value, dict)
                    ):
                        result[key] = merge_dicts(result[key], value)
                    elif key not in result:
                        result[key] = value
                return result

            task["addition"] = merge_dicts(
                task.get("addition", {}), task_plugins_config
            )
            # è°ƒç”¨æ’ä»¶
            if is_new_tree:
                print(f"ğŸ§© è°ƒç”¨æ’ä»¶")
                for plugin_name, plugin in plugins.items():
                    if plugin.is_active and hasattr(plugin, "run"):
                        task = (
                            plugin.run(task, account=account, tree=is_new_tree) or task
                        )
    print()
    print(f"===============æ’ä»¶æ”¶å°¾===============")
    for plugin_name, plugin in plugins.items():
        if plugin.is_active and hasattr(plugin, "task_after"):
            data = plugin.task_after(tasklist=tasklist, account=account)
            if data.get("tasklist"):
                CONFIG_DATA["tasklist"] = data["tasklist"]
            if data.get("config"):
                CONFIG_DATA["plugins"][plugin_name] = data["config"]
    print()


def main():
    global CONFIG_DATA
    start_time = datetime.now()
    print(f"===============ç¨‹åºå¼€å§‹===============")
    print(f"â° æ‰§è¡Œæ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    # è¯»å–å¯åŠ¨å‚æ•°
    config_path = sys.argv[1] if len(sys.argv) > 1 else "quark_config.json"
    # æ¨é€æµ‹è¯•
    if os.environ.get("QUARK_TEST", "").lower() == "true":
        print(f"===============é€šçŸ¥æµ‹è¯•===============")
        CONFIG_DATA["push_config"] = json.loads(os.environ.get("PUSH_CONFIG"))
        send_ql_notify(
            "ã€å¤¸å…‹è‡ªåŠ¨è½¬å­˜ã€‘",
            f"é€šçŸ¥æµ‹è¯•\n\n{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        )
        print()
        if cookies := json.loads(os.environ.get("COOKIE", "[]")):
            print(f"===============è½¬å­˜æµ‹è¯•===============")
            accounts = Quark(cookies[0])
            accounts.do_save_check("https://pan.quark.cn/s/1ed94d530d63", "/æ¥è‡ªï¼šåˆ†äº«")
            print()
        return
    # ä»ç¯å¢ƒå˜é‡ä¸­è·å– TASKLIST
    tasklist_from_env = []
    if tasklist_json := os.environ.get("TASKLIST"):
        try:
            tasklist_from_env = json.loads(tasklist_json)
        except Exception as e:
            print(f"ä»ç¯å¢ƒå˜é‡è§£æä»»åŠ¡åˆ—è¡¨å¤±è´¥ {e}")
    # æ£€æŸ¥æœ¬åœ°æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨å°±ä¸‹è½½
    if not os.path.exists(config_path):
        if os.environ.get("QUARK_COOKIE"):
            print(
                f"âš™ï¸ è¯»å–åˆ° QUARK_COOKIE ç¯å¢ƒå˜é‡ï¼Œä»…ç­¾åˆ°é¢†ç©ºé—´ã€‚å¦‚éœ€æ‰§è¡Œè½¬å­˜ï¼Œè¯·åˆ é™¤è¯¥ç¯å¢ƒå˜é‡åé…ç½® {config_path} æ–‡ä»¶"
            )
            cookie_val = os.environ.get("QUARK_COOKIE")
            cookie_form_file = False
        else:
            print(f"âš™ï¸ é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨âŒï¼Œæ­£è¿œç¨‹ä»ä¸‹è½½é…ç½®æ¨¡ç‰ˆ")
            config_url = f"{GH_PROXY}https://raw.githubusercontent.com/Cp0204/quark_auto_save/main/quark_config.json"
            if Config.download_file(config_url, config_path):
                print("âš™ï¸ é…ç½®æ¨¡ç‰ˆä¸‹è½½æˆåŠŸâœ…ï¼Œè¯·åˆ°ç¨‹åºç›®å½•ä¸­æ‰‹åŠ¨é…ç½®")
            return
    else:
        print(f"âš™ï¸ æ­£ä» {config_path} æ–‡ä»¶ä¸­è¯»å–é…ç½®")
        CONFIG_DATA = Config.read_json(config_path)
        Config.breaking_change_update(CONFIG_DATA)
        cookie_val = CONFIG_DATA.get("cookie")
        cookie_form_file = True
    # è·å–cookie
    cookies = Config.get_cookies(cookie_val)
    if not cookies:
        print("âŒ cookie æœªé…ç½®")
        return
    accounts = [Quark(cookie, index) for index, cookie in enumerate(cookies)]
    # ç­¾åˆ°
    print(f"===============ç­¾åˆ°ä»»åŠ¡===============")
    if tasklist_from_env:
        verify_account(accounts[0])
    else:
        for account in accounts:
            verify_account(account)
            do_sign(account)
    print()
    # è½¬å­˜
    if accounts[0].is_active and cookie_form_file:
        print(f"===============è½¬å­˜ä»»åŠ¡===============")
        # ä»»åŠ¡åˆ—è¡¨
        if tasklist_from_env:
            do_save(accounts[0], tasklist_from_env)
        else:
            do_save(accounts[0], CONFIG_DATA.get("tasklist", []))
        print()
    # é€šçŸ¥
    if NOTIFYS:
        notify_body = "\n".join(NOTIFYS)
        print(f"===============æ¨é€é€šçŸ¥===============")
        send_ql_notify("ã€å¤¸å…‹è‡ªåŠ¨è½¬å­˜ã€‘", notify_body)
        print()
    if cookie_form_file:
        # æ›´æ–°é…ç½®
        Config.write_json(config_path, CONFIG_DATA)

    print(f"===============ç¨‹åºç»“æŸ===============")
    duration = datetime.now() - start_time
    print(f"ğŸ˜ƒ è¿è¡Œæ—¶é•¿: {round(duration.total_seconds(), 2)}s")
    print()


if __name__ == "__main__":
    main()
