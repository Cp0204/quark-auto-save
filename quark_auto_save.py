# !/usr/bin/env python3
# -*- coding: utf-8 -*-
# Modify: 2024-02-29
# Repo: https://github.com/Cp0204/quark_auto_save
# ConfigFile: quark_config.json
"""
new Env('å¤¸å…‹è‡ªåŠ¨è¿½æ›´');
0 8,18,20 * * * quark_auto_save.py
"""
import os
import re
import sys
import json
import random
import requests
from datetime import datetime

config_data = {}
notifys = []
first_account = {}

magic_regex = {
    "$TV": {
        "pattern": ".*?(S\\d{1,2}E)?P?(\\d{1,3}).*?\\.(mp4|mkv)",
        "replace": "\\1\\2.\\3",
    },
}


# é­”æ³•æ­£åˆ™åŒ¹é…
def magic_regex_func(pattern, replace):
    keyword = pattern
    if keyword in magic_regex:
        pattern = magic_regex[keyword]["pattern"]
        if replace == "":
            replace = magic_regex[keyword]["replace"]
    return pattern, replace


# å‘é€é€šçŸ¥æ¶ˆæ¯
def send_ql_notify(title, body):
    try:
        # å¯¼å…¥é€šçŸ¥æ¨¡å—
        import sendNotify

        # å¦‚æœªé…ç½® push_config åˆ™ä½¿ç”¨é’é¾™ç¯å¢ƒé€šçŸ¥è®¾ç½®
        if config_data.get("push_config"):
            config_data["push_config"]["CONSOLE"] = True
            sendNotify.push_config = config_data["push_config"]
        sendNotify.send(title, body)
    except Exception as e:
        if e:
            print("å‘é€é€šçŸ¥æ¶ˆæ¯å¤±è´¥ï¼")


# æ·»åŠ æ¶ˆæ¯
def add_notify(text):
    global notifys
    notifys.append(text)
    print("ğŸ“¢", text)
    return text


def common_headers():
    return {
        "cookie": first_account["cookie"],
        "content-type": "application/json",
    }


def get_growth_info(cookie):
    url = "https://drive-m.quark.cn/1/clouddrive/capacity/growth/info"
    querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
    headers = {
        "cookie": cookie,
        "content-type": "application/json",
    }
    response = requests.request("GET", url, headers=headers, params=querystring).json()
    if response.get("data"):
        return response["data"]
    else:
        return False


def get_growth_sign(cookie):
    url = "https://drive-m.quark.cn/1/clouddrive/capacity/growth/sign"
    querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
    payload = {
        "sign_cyclic": True,
    }
    headers = {
        "cookie": cookie,
        "content-type": "application/json",
    }
    response = requests.request(
        "POST", url, json=payload, headers=headers, params=querystring
    ).json()
    if response.get("data"):
        return True, response["data"]["sign_daily_reward"]
    else:
        return False, response["message"]


def get_id_from_url(url):
    pattern = r"/s/(\w+)(#/list/share.*/(\w+))?"
    match = re.search(pattern, url)
    if match:
        pwd_id = match.group(1)
        if match.group(2):
            pdir_fid = match.group(3)
        else:
            pdir_fid = 0
        return pwd_id, pdir_fid
    else:
        return None


def get_account_info(cookie):
    url = "https://pan.quark.cn/account/info"
    querystring = {"fr": "pc", "platform": "pc"}
    headers = {
        "cookie": cookie,
        "content-type": "application/json",
    }
    response = requests.request("GET", url, headers=headers, params=querystring).json()
    if response.get("data"):
        return response["data"]
    else:
        return False


# å¯éªŒè¯èµ„æºæ˜¯å¦å¤±æ•ˆ
def get_stoken(pwd_id):
    url = "https://pan.quark.cn/1/clouddrive/share/sharepage/token"
    querystring = {"pr": "ucpro", "fr": "h5"}
    payload = {"pwd_id": pwd_id, "passcode": ""}
    headers = common_headers()
    response = requests.request(
        "POST", url, json=payload, headers=headers, params=querystring
    ).json()
    if response.get("data"):
        return True, response["data"]["stoken"]
    else:
        return False, response["message"]


def get_detail(pwd_id, stoken, pdir_fid):
    file_list = []
    page = 1
    while True:
        url = "https://pan.quark.cn/1/clouddrive/share/sharepage/detail"
        querystring = {
            "pr": "ucpro",
            "fr": "pc",
            "pwd_id": pwd_id,
            "stoken": stoken,
            "pdir_fid": pdir_fid,
            "force": "0",
            "_page": page,
            "_size": "50",
            "_fetch_banner": "0",
            "_fetch_share": "0",
            "_fetch_total": "1",
            "_sort": "file_type:asc,updated_at:desc",
        }
        headers = common_headers()
        response = requests.request(
            "GET", url, headers=headers, params=querystring
        ).json()
        if response["data"]["list"]:
            file_list += response["data"]["list"]
            page += 1
        else:
            break
        if len(file_list) >= response["metadata"]["_total"]:
            break
    # ä»…æœ‰ä¸€ä¸ªæ–‡ä»¶å¤¹
    if len(file_list) == 1 and file_list[0]["file_type"] == 0:
        print("ğŸ§  è¯¥åˆ†äº«æ˜¯ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œè¯»å–æ–‡ä»¶å¤¹å†…åˆ—è¡¨")
        file_list = get_detail(pwd_id, stoken, file_list[0]["fid"])
    return file_list


def get_fids(file_paths):
    url = "https://drive.quark.cn/1/clouddrive/file/info/path_list"
    querystring = {"pr": "ucpro", "fr": "pc"}
    payload = {"file_path": file_paths, "namespace": "0"}
    headers = common_headers()
    response = requests.request(
        "POST", url, json=payload, headers=headers, params=querystring
    ).json()
    # print(response)
    return response["data"]


def ls_dir(pdir_fid):
    file_list = []
    page = 1
    while True:
        url = "https://drive.quark.cn/1/clouddrive/file/sort"
        querystring = {
            "pr": "ucpro",
            "fr": "pc",
            "uc_param_str": "",
            "pdir_fid": pdir_fid,
            "_page": page,
            "_size": "50",
            "_fetch_total": "1",
            "_fetch_sub_dirs": "0",
            "_sort": "file_type:asc,updated_at:desc",
        }
        headers = common_headers()
        response = requests.request(
            "GET", url, headers=headers, params=querystring
        ).json()
        if response["data"]["list"]:
            file_list += response["data"]["list"]
            page += 1
        else:
            break
        if len(file_list) >= response["metadata"]["_total"]:
            break
    return file_list


def save_file(fid_list, fid_token_list, to_pdir_fid, pwd_id, stoken):
    url = "https://drive.quark.cn/1/clouddrive/share/sharepage/save"
    querystring = {
        "pr": "ucpro",
        "fr": "pc",
        "uc_param_str": "",
        "__dt": int(random.uniform(1, 5) * 60 * 1000),
        "__t": datetime.now().timestamp(),
    }
    payload = {
        "fid_list": fid_list,
        "fid_token_list": fid_token_list,
        "to_pdir_fid": to_pdir_fid,
        "pwd_id": pwd_id,
        "stoken": stoken,
        "pdir_fid": "0",
        "scene": "link",
    }
    headers = common_headers()
    response = requests.request(
        "POST", url, json=payload, headers=headers, params=querystring
    ).json()
    return response


def mkdir(dir_path):
    url = "https://drive-pc.quark.cn/1/clouddrive/file"
    querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
    payload = {
        "pdir_fid": "0",
        "file_name": "",
        "dir_path": dir_path,
        "dir_init_lock": False,
    }
    headers = common_headers()
    response = requests.request(
        "POST", url, json=payload, headers=headers, params=querystring
    ).json()
    return response


def rename(fid, file_name):
    url = "https://drive-pc.quark.cn/1/clouddrive/file/rename"
    querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
    payload = {"fid": fid, "file_name": file_name}
    headers = common_headers()
    response = requests.request(
        "POST", url, json=payload, headers=headers, params=querystring
    ).json()
    return response


def update_savepath_fid(tasklist):
    dir_paths = [
        item["savepath"]
        for item in tasklist
        if not item.get("enddate")
        or (
            datetime.now().date()
            <= datetime.strptime(item["enddate"], "%Y-%m-%d").date()
        )
    ]
    if not dir_paths:
        return False
    dir_paths_exist_arr = get_fids(dir_paths)
    dir_paths_exist = [item["file_path"] for item in dir_paths_exist_arr]
    # æ¯”è¾ƒåˆ›å»ºä¸å­˜åœ¨çš„
    dir_paths_unexist = list(set(dir_paths) - set(dir_paths_exist))
    for dir_path in dir_paths_unexist:
        mkdir_return = mkdir(dir_path)
        if mkdir_return["code"] == 0:
            new_dir = mkdir_return["data"]
            dir_paths_exist_arr.append({"file_path": dir_path, "fid": new_dir["fid"]})
            print(f"åˆ›å»ºæ–‡ä»¶å¤¹: {dir_path}")
        else:
            print(f"åˆ›å»ºæ–‡ä»¶å¤¹: {dir_path} å¤±è´¥, {mkdir_return['message']}")
    # æ›´æ–°åˆ°é…ç½®
    for task in tasklist:
        for dir_path in dir_paths_exist_arr:
            if task["savepath"] == dir_path["file_path"]:
                task["savepath_fid"] = dir_path["fid"]
    # print(dir_paths_exist_arr)


def do_save_task(task):
    # åˆ¤æ–­èµ„æºå¤±æ•ˆè®°å½•
    if task.get("shareurl_ban"):
        print(f"ã€Š{task['taskname']}ã€‹ï¼š{task['shareurl_ban']}")
        return

    # é“¾æ¥è½¬æ¢æ‰€éœ€å‚æ•°
    pwd_id, pdir_fid = get_id_from_url(task["shareurl"])
    # print("match: ", pwd_id, pdir_fid)

    # è·å–stokenï¼ŒåŒæ—¶å¯éªŒè¯èµ„æºæ˜¯å¦å¤±æ•ˆ
    is_sharing, stoken = get_stoken(pwd_id)
    if not is_sharing:
        add_notify(f"ã€Š{task['taskname']}ã€‹ï¼š{stoken}")
        task["shareurl_ban"] = stoken
        return
    # print("stoken: ", stoken)

    # è·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨
    share_file_list = get_detail(pwd_id, stoken, pdir_fid)
    if not share_file_list:
        add_notify(f"ã€Š{task['taskname']}ã€‹ï¼šåˆ†äº«ç›®å½•ä¸ºç©º")
        return
    # print("share_file_list: ", share_file_list)

    # è·å–ç›®æ ‡ç›®å½•æ–‡ä»¶åˆ—è¡¨
    task["savepath_fid"] = (
        task.get("savepath_fid")
        if task.get("savepath_fid")
        else get_fids([task["savepath"]])[0]["fid"]
    )
    to_pdir_fid = task["savepath_fid"]
    dir_file_list = ls_dir(to_pdir_fid)
    # print("dir_file_list: ", dir_file_list)

    # éœ€ä¿å­˜çš„æ–‡ä»¶æ¸…å•
    need_save_list = []
    # æ·»åŠ ç¬¦åˆçš„
    for share_file in share_file_list:
        # æ­£åˆ™æ–‡ä»¶ååŒ¹é…
        pattern, replace = magic_regex_func(task["pattern"], task["replace"])
        if re.search(pattern, share_file["file_name"]):
            # æ›¿æ¢åçš„æ–‡ä»¶å
            save_name = (
                re.sub(pattern, replace, share_file["file_name"])
                if replace != ""
                else share_file["file_name"]
            )
            # åˆ¤æ–­ç›®æ ‡ç›®å½•æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¯é€‰å¿½ç•¥åç¼€
            if task.get("ignore_extension"):
                compare_func = lambda a, b1, b2: (
                    os.path.splitext(a)[0] == os.path.splitext(b1)[0]
                    or os.path.splitext(a)[0] == os.path.splitext(b2)[0]
                )
            else:
                compare_func = lambda a, b1, b2: (a == b1 or a == b2)
            file_exists = any(
                compare_func(dir_file["file_name"], share_file["file_name"], save_name)
                for dir_file in dir_file_list
            )
            if not file_exists:
                share_file["save_name"] = save_name
                need_save_list.append(share_file)

    fid_list = [item["fid"] for item in need_save_list]
    fid_token_list = [item["share_fid_token"] for item in need_save_list]
    save_name_list = [item["save_name"] for item in need_save_list]
    if fid_list:
        save_file_return = save_file(
            fid_list, fid_token_list, to_pdir_fid, pwd_id, stoken
        )
        if save_file_return["code"] == 0:
            task_id = save_file_return["data"]["task_id"]
            query_task_return = query_task(task_id)
            if query_task_return["code"] == 0:
                save_name_list.sort()
                add_notify(
                    f"ã€Š{task['taskname']}ã€‹æ·»åŠ è¿½æ›´ï¼š{', '.join(save_name_list)}"
                )
                return True
            else:
                err_msg = query_task_return["message"]
        else:
            err_msg = save_file_return["message"]
        add_notify(f"ã€Š{task['taskname']}ã€‹è½¬å­˜å¤±è´¥ï¼š{err_msg}")
        return False
    else:
        print("ä»»åŠ¡ç»“æŸï¼šæ²¡æœ‰æ–°çš„è½¬å­˜ä»»åŠ¡")
        return False


def query_task(task_id):
    url = "https://drive-pc.quark.cn/1/clouddrive/task"
    querystring = {
        "pr": "ucpro",
        "fr": "pc",
        "uc_param_str": "",
        "task_id": task_id,
        "retry_index": "1",
        "__dt": int(random.uniform(1, 5) * 60 * 1000),
        "__t": datetime.now().timestamp(),
    }
    headers = common_headers()
    response = requests.request("GET", url, headers=headers, params=querystring).json()
    if response["code"] == 32003:
        response["message"] = "å®¹é‡é™åˆ¶"
    return response


def do_rename_task(task):
    dir_file_list = ls_dir(task["savepath_fid"])
    is_rename = False
    for dir_file in dir_file_list:
        pattern, replace = magic_regex_func(task["pattern"], task["replace"])
        if re.search(pattern, dir_file["file_name"]):
            save_name = (
                re.sub(pattern, replace, dir_file["file_name"])
                if replace != ""
                else dir_file["file_name"]
            )
            if save_name != dir_file["file_name"]:
                rename_return = rename(dir_file["fid"], save_name)
                if rename_return["code"] == 0:
                    print(f"é‡å‘½åï¼š{dir_file['file_name']} â†’ {save_name}")
                    is_rename = True
                else:
                    print(
                        f"é‡å‘½åï¼š{dir_file['file_name']} â†’ {save_name} å¤±è´¥ï¼Œ{rename_return['message']}"
                    )
    return is_rename


def emby_refresh(emby_id):
    emby_url = config_data.get("emby").get("url")
    emby_apikey = config_data.get("emby").get("apikey")
    if emby_url and emby_apikey and emby_id:
        url = f"{emby_url}/emby/Items/{emby_id}/Refresh"
        headers = {"X-Emby-Token": emby_apikey}
        querystring = {
            "Recursive": "true",
            "MetadataRefreshMode": "FullRefresh",
            "ImageRefreshMode": "FullRefresh",
            "ReplaceAllMetadata": "false",
            "ReplaceAllImages": "false",
        }
        response = requests.request("POST", url, headers=headers, params=querystring)
        if response.text == "":
            print(f"ğŸ åˆ·æ–°Embyåª’ä½“åº“ï¼šæˆåŠŸâœ…")
            return True
        else:
            print(f"ğŸ åˆ·æ–°Embyåª’ä½“åº“ï¼š{response.text}âŒ")
            return False


def emby_search(media_name):
    emby_url = config_data.get("emby").get("url")
    emby_apikey = config_data.get("emby").get("apikey")
    if emby_url and emby_apikey and media_name:
        url = f"{emby_url}/emby/Items"
        headers = {"X-Emby-Token": emby_apikey}
        querystring = {
            "IncludeItemTypes": "Series",
            "StartIndex": 0,
            "SortBy": "SortName",
            "SortOrder": "Ascending",
            "ImageTypeLimit": 0,
            "Recursive": "true",
            "SearchTerm": media_name,
            "Limit": 10,
            "IncludeSearchTypes": "false",
        }
        response = requests.request("GET", url, headers=headers, params=querystring)
        if "application/json" in response.headers["Content-Type"]:
            response = response.json()
            if response.get("Items"):
                for item in response["Items"]:
                    if item["IsFolder"]:
                        print(f"ğŸ ã€Š{item['Name']}ã€‹åŒ¹é…åˆ°Embyåª’ä½“åº“IDï¼š{item['Id']}")
                        return item["Id"]
        else:
            print(f"ğŸ æœç´¢Embyåª’ä½“åº“ï¼š{response.text}âŒ")
    return False


def download_file(url, save_path):
    response = requests.get(url)
    if response.status_code == 200:
        with open(save_path, "wb") as file:
            file.write(response.content)
        return True
    else:
        return False


def get_cookies(cookie_val):
    if isinstance(cookie_val, list):
        return cookie_val
    elif cookie_val:
        if "\n" in cookie_val:
            return cookie_val.split("\n")
        else:
            return [cookie_val]
    else:
        return False


def do_sign(cookies):
    first_account = {}
    print(f"===============ç­¾åˆ°ä»»åŠ¡===============")
    for index, cookie in enumerate(cookies):
        # éªŒè¯è´¦å·
        account_info = get_account_info(cookie)
        print(f"â–¶ï¸ éªŒè¯ç¬¬{index+1}ä¸ªè´¦å·")
        if not account_info:
            add_notify(f"ğŸ‘¤ ç¬¬{index+1}ä¸ªè´¦å·ç™»å½•å¤±è´¥ï¼Œcookieæ— æ•ˆâŒ")
        else:
            if index == 0:
                first_account = account_info
                first_account["cookie"] = cookie
            print(f"ğŸ‘¤ è´¦å·æ˜µç§°: {account_info['nickname']}âœ…")
            # æ¯æ—¥é¢†ç©ºé—´
            growth_info = get_growth_info(cookie)
            if growth_info:
                if growth_info["cap_sign"]["sign_daily"]:
                    print(
                        f"ğŸ“… æ‰§è¡Œç­¾åˆ°: ä»Šæ—¥å·²ç­¾åˆ°+{int(growth_info['cap_sign']['sign_daily_reward']/1024/1024)}MBï¼Œè¿ç­¾è¿›åº¦({growth_info['cap_sign']['sign_progress']}/{growth_info['cap_sign']['sign_target']})âœ…"
                    )
                else:
                    sign, sign_return = get_growth_sign(cookie)
                    if sign:
                        message = f"ğŸ“… æ‰§è¡Œç­¾åˆ°: ä»Šæ—¥ç­¾åˆ°+{int(sign_return/1024/1024)}MBï¼Œè¿ç­¾è¿›åº¦({growth_info['cap_sign']['sign_progress']+1}/{growth_info['cap_sign']['sign_target']})âœ…"
                        if (
                            config_data.get("push_config").get("QUARK_SIGN_NOTIFY")
                            == False
                            or os.environ.get("QUARK_SIGN_NOTIFY") == False
                        ):
                            print(message)
                        else:
                            message = message.replace(
                                "ä»Šæ—¥", f"[{account_info['nickname']}]ä»Šæ—¥"
                            )
                            add_notify(message)
                    else:
                        print(f"ğŸ“… æ‰§è¡Œç­¾åˆ°: {sign_return}")
        print(f"")
    print(f"")
    return first_account


def do_save():
    print(f"===============è½¬å­˜ä»»åŠ¡===============")
    print(f"è½¬å­˜è´¦å·: {first_account['nickname']}")
    # ä»»åŠ¡åˆ—è¡¨
    tasklist = config_data.get("tasklist", [])
    # è·å–å…¨éƒ¨ä¿å­˜ç›®å½•fid
    update_savepath_fid(tasklist)

    def check_date(task):
        return (
            not task.get("enddate")
            or (
                datetime.now().date()
                <= datetime.strptime(task["enddate"], "%Y-%m-%d").date()
            )
        ) and (
            not task.get("runweek")
            # æ˜ŸæœŸä¸€ä¸º0ï¼Œæ˜ŸæœŸæ—¥ä¸º6
            or (datetime.today().weekday() + 1 in task.get("runweek"))
        )

    # æ‰§è¡Œä»»åŠ¡
    for index, task in enumerate(tasklist):
        # åˆ¤æ–­ä»»åŠ¡æœŸé™
        if check_date(task):
            print(f"")
            print(f"#{index+1}------------------")
            print(f"ä»»åŠ¡åç§°: {task['taskname']}")
            print(f"åˆ†äº«é“¾æ¥: {task['shareurl']}")
            print(f"ç›®æ ‡ç›®å½•: {task['savepath']}")
            print(f"æ­£åˆ™åŒ¹é…: {task['pattern']}")
            print(f"æ­£åˆ™æ›¿æ¢: {task['replace']}")
            if task.get("enddate"):
                print(f"ä»»åŠ¡æˆªæ­¢: {task['enddate']}")
            if task.get("emby_id"):
                print(f"åˆ·åª’ä½“åº“: {task['emby_id']}")
            if task.get("ignore_extension"):
                print(f"å¿½ç•¥åç¼€: {task['ignore_extension']}")
            print()
            is_new = do_save_task(task)
            is_rename = do_rename_task(task)
            if (is_new or is_rename) and task.get("emby_id") != "0":
                if task.get("emby_id"):
                    emby_refresh(task["emby_id"])
                else:
                    match_emby_id = emby_search(task["taskname"])
                    if match_emby_id:
                        task["emby_id"] = match_emby_id
                        emby_refresh(match_emby_id)
    print(f"")


def main():
    global config_data, first_account
    formatted_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"===============ç¨‹åºå¼€å§‹===============")
    print(f"â° æ‰§è¡Œæ—¶é—´: {formatted_time}")
    print(f"")
    # å¯åŠ¨å‚æ•°
    arguments = sys.argv
    if len(arguments) > 1:
        config_path = arguments[1]
    else:
        config_path = "quark_config.json"
    # æ£€æŸ¥æœ¬åœ°æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨å°±ä¸‹è½½
    if not os.path.exists(config_path):
        if os.environ.get("QUARK_COOKIE"):
            print(
                f"âš™ï¸ è¯»å–åˆ° QUARK_COOKIE ç¯å¢ƒå˜é‡ï¼Œä»…ç­¾åˆ°é¢†ç©ºé—´ã€‚å¦‚éœ€æ‰§è¡Œè½¬å­˜ï¼Œè¯·åˆ é™¤è¯¥ç¯å¢ƒå˜é‡åé…ç½® {config_path} æ–‡ä»¶"
            )
            cookie_val = os.environ.get("QUARK_COOKIE")
            cookie_form_file = False
        else:
            print(f"âš™ï¸ é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨âŒï¼Œæ­£è¿œç¨‹ä»ä¸‹è½½é…ç½®æ¨¡ç‰ˆ")
            config_url = "https://mirror.ghproxy.com/https://raw.githubusercontent.com/Cp0204/quark_auto_save/main/quark_config.json"
            if download_file(config_url, config_path):
                print("âš™ï¸ é…ç½®æ¨¡ç‰ˆä¸‹è½½æˆåŠŸâœ…ï¼Œè¯·åˆ°ç¨‹åºç›®å½•ä¸­æ‰‹åŠ¨é…ç½®")
            return
    else:
        print(f"âš™ï¸ æ­£ä» {config_path} æ–‡ä»¶ä¸­è¯»å–é…ç½®")
        with open(config_path, "r", encoding="utf-8") as file:
            config_data = json.load(file)
        cookie_val = config_data.get("cookie")
        cookie_form_file = True
    # è·å–cookie
    cookies = get_cookies(cookie_val)
    if not cookies:
        print("âŒ cookie æœªé…ç½®")
        return
    # ç­¾åˆ°
    first_account = do_sign(cookies)
    # è½¬å­˜
    if first_account and cookie_form_file:
        do_save()
    # é€šçŸ¥
    if notifys:
        notify_body = "\n".join(notifys)
        print(f"===============æ¨é€é€šçŸ¥===============")
        send_ql_notify("ã€å¤¸å…‹è‡ªåŠ¨è¿½æ›´ã€‘", notify_body)
        print(f"")
    if cookie_form_file:
        # æ›´æ–°é…ç½®
        with open(config_path, "w", encoding="utf-8") as file:
            json.dump(config_data, file, ensure_ascii=False, indent=2)
    print(f"======================================")


if __name__ == "__main__":
    main()
