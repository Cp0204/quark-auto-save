# !/usr/bin/env python3
# -*- coding: utf-8 -*-
# Modify: 2024-11-13
# Repo: https://github.com/Cp0204/quark_auto_save
# ConfigFile: quark_config.json
"""
new Env('å¤¸å…‹è‡ªåŠ¨è¿½æ›´');
0 8,18,20 * * * quark_auto_save.py
"""
import os
import re
import sys
import json
import time
import random
import requests
import importlib
import urllib.parse
from datetime import datetime

# å…¨å±€å˜é‡
VERSION = "2.9.0"
CONFIG_PATH = "quark_config.json"
COOKIE_PATH = "quark_cookie.txt"
CONFIG_DATA = {}
LOG_LIST = []
NOTIFYS = []

def is_date_format(number_str):
    """
    åˆ¤æ–­ä¸€ä¸ªçº¯æ•°å­—å­—ç¬¦ä¸²æ˜¯å¦å¯èƒ½æ˜¯æ—¥æœŸæ ¼å¼
    æ”¯æŒçš„æ ¼å¼ï¼šYYYYMMDD, MMDD
    """
    # åˆ¤æ–­YYYYMMDDæ ¼å¼ (8ä½æ•°å­—)
    if len(number_str) == 8 and number_str.startswith('20'):
        year = int(number_str[:4])
        month = int(number_str[4:6])
        day = int(number_str[6:8])
        
        # ç®€å•æ£€æŸ¥æœˆä»½å’Œæ—¥æœŸæ˜¯å¦æœ‰æ•ˆ
        if 1 <= month <= 12 and 1 <= day <= 31:
            # å¯èƒ½æ˜¯æ—¥æœŸæ ¼å¼
            return True
    
    # åˆ¤æ–­MMDDæ ¼å¼ (4ä½æ•°å­—)
    elif len(number_str) == 4:
        month = int(number_str[:2])
        day = int(number_str[2:4])
        
        # ç®€å•æ£€æŸ¥æœˆä»½å’Œæ—¥æœŸæ˜¯å¦æœ‰æ•ˆ
        if 1 <= month <= 12 and 1 <= day <= 31:
            # å¯èƒ½æ˜¯æ—¥æœŸæ ¼å¼
            return True
            
    # å…¶ä»–é•¿åº¦çš„çº¯æ•°å­—ä¸è§†ä¸ºæ—¥æœŸæ ¼å¼
    return False

# å…¼å®¹é’é¾™
try:
    from treelib import Tree
except:
    print("æ­£åœ¨å°è¯•è‡ªåŠ¨å®‰è£…ä¾èµ–...")
    os.system("pip3 install treelib &> /dev/null")
    from treelib import Tree


MAGIC_REGEX = {
    "$TV": {
        "pattern": r".*?([Ss]\d{1,2})?(?:[ç¬¬EePpXx\.\-\_\( ]{1,2}|^)(\d{1,3})(?!\d).*?\.(mp4|mkv)",
        "replace": r"\1E\2.\3",
    },
    "$BLACK_WORD": {
        "pattern": r"^(?!.*çº¯äº«)(?!.*åŠ æ›´)(?!.*è¶…å‰ä¼åˆ’)(?!.*è®­ç»ƒå®¤)(?!.*è’¸è’¸æ—¥ä¸Š).*",
        "replace": "",
    },
}


# å‘é€é€šçŸ¥æ¶ˆæ¯
def send_ql_notify(title, body):
    try:
        # å¯¼å…¥é€šçŸ¥æ¨¡å—
        import notify

        # å¦‚æœªé…ç½® push_config åˆ™ä½¿ç”¨é’é¾™ç¯å¢ƒé€šçŸ¥è®¾ç½®
        if CONFIG_DATA.get("push_config"):
            notify.push_config = CONFIG_DATA["push_config"].copy()
            notify.push_config["CONSOLE"] = notify.push_config.get("CONSOLE", True)
        notify.send(title, body)
    except Exception as e:
        if e:
            print("å‘é€é€šçŸ¥æ¶ˆæ¯å¤±è´¥ï¼")


# æ·»åŠ æ¶ˆæ¯
def add_notify(text):
    global NOTIFYS
    NOTIFYS.append(text)
    print(text)
    return text


# å®šä¹‰ä¸€ä¸ªé€šç”¨çš„æ–‡ä»¶ç±»å‹å›¾æ ‡é€‰æ‹©å‡½æ•°
def get_file_icon(file_name, is_dir=False):
    """æ ¹æ®æ–‡ä»¶æ‰©å±•åè¿”å›å¯¹åº”çš„å›¾æ ‡"""
    # å¦‚æœæ˜¯æ–‡ä»¶å¤¹ï¼Œç›´æ¥è¿”å›æ–‡ä»¶å¤¹å›¾æ ‡
    if is_dir:
        return "ğŸ“"
    
    # æ–‡ä»¶åè½¬å°å†™ä¾¿äºåŒ¹é…
    lower_name = file_name.lower()
    
    # è§†é¢‘æ–‡ä»¶
    if any(lower_name.endswith(ext) for ext in ['.mp4', '.mkv', '.avi', '.mov', '.rmvb', '.flv', '.wmv', '.m4v', '.ts']):
        return "ğŸï¸"
    
    # å›¾ç‰‡æ–‡ä»¶
    if any(lower_name.endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp', '.tiff', '.svg']):
        return "ğŸ–¼ï¸"
    
    # éŸ³é¢‘æ–‡ä»¶
    if any(lower_name.endswith(ext) for ext in ['.mp3', '.wav', '.flac', '.aac', '.ogg', '.m4a', '.wma']):
        return "ğŸµ"
    
    # æ–‡æ¡£æ–‡ä»¶
    if any(lower_name.endswith(ext) for ext in ['.pdf', '.doc', '.docx', '.xls', '.xlsx', '.ppt', '.pptx', '.txt', '.md', '.csv']):
        return "ğŸ“„"
    
    # å‹ç¼©æ–‡ä»¶
    if any(lower_name.endswith(ext) for ext in ['.zip', '.rar', '.7z', '.tar', '.gz', '.bz2']):
        return "ğŸ“¦"
    
    # ä»£ç æ–‡ä»¶
    if any(lower_name.endswith(ext) for ext in ['.py', '.js', '.html', '.css', '.java', '.c', '.cpp', '.php', '.go', '.json']):
        return "ğŸ“"
    
    # å­—å¹•æ–‡ä»¶
    if any(lower_name.endswith(ext) for ext in ['.srt', '.ass', '.ssa', '.vtt']):
        return "ğŸ’¬"
    
    # é»˜è®¤å›¾æ ‡ï¼ˆå…¶ä»–æ–‡ä»¶ç±»å‹ï¼‰
    return ""


class Config:
    # ä¸‹è½½é…ç½®
    def download_file(url, save_path):
        response = requests.get(url)
        if response.status_code == 200:
            with open(save_path, "wb") as file:
                file.write(response.content)
            return True
        else:
            return False

    # è¯»å– JSON æ–‡ä»¶å†…å®¹
    def read_json(config_path):
        with open(config_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        return data

    # å°†æ•°æ®å†™å…¥ JSON æ–‡ä»¶
    def write_json(config_path, data):
        with open(config_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, sort_keys=False, indent=2)

    # è¯»å–CK
    def get_cookies(cookie_val):
        if isinstance(cookie_val, list):
            return cookie_val
        elif cookie_val:
            if "\n" in cookie_val:
                return cookie_val.split("\n")
            else:
                return [cookie_val]
        else:
            return False

    def load_plugins(plugins_config={}, plugins_dir="plugins"):
        PLUGIN_FLAGS = os.environ.get("PLUGIN_FLAGS", "").split(",")
        plugins_available = {}
        task_plugins_config = {}
        all_modules = [
            f.replace(".py", "") for f in os.listdir(plugins_dir) if f.endswith(".py")
        ]
        # è°ƒæ•´æ¨¡å—ä¼˜å…ˆçº§
        priority_path = os.path.join(plugins_dir, "_priority.json")
        try:
            with open(priority_path, encoding="utf-8") as f:
                priority_modules = json.load(f)
            if priority_modules:
                all_modules = [
                    module for module in priority_modules if module in all_modules
                ] + [module for module in all_modules if module not in priority_modules]
        except (FileNotFoundError, json.JSONDecodeError):
            priority_modules = []
        for module_name in all_modules:
            if f"-{module_name}" in PLUGIN_FLAGS:
                continue
            try:
                module = importlib.import_module(f"{plugins_dir}.{module_name}")
                ServerClass = getattr(module, module_name.capitalize())
                # æ£€æŸ¥é…ç½®ä¸­æ˜¯å¦å­˜åœ¨è¯¥æ¨¡å—çš„é…ç½®
                if module_name in plugins_config:
                    plugin = ServerClass(**plugins_config[module_name])
                    plugins_available[module_name] = plugin
                else:
                    plugin = ServerClass()
                    plugins_config[module_name] = plugin.default_config
                # æ£€æŸ¥æ’ä»¶æ˜¯å¦æ”¯æŒå•ç‹¬ä»»åŠ¡é…ç½®
                if hasattr(plugin, "default_task_config"):
                    task_plugins_config[module_name] = plugin.default_task_config
            except (ImportError, AttributeError) as e:
                print(f"è½½å…¥æ¨¡å— {module_name} å¤±è´¥: {e}")
        print()
        return plugins_available, plugins_config, task_plugins_config

    def breaking_change_update(config_data):
        if config_data.get("emby"):
            print("ğŸ”¼ Update config v0.3.6.1 to 0.3.7")
            config_data.setdefault("media_servers", {})["emby"] = {
                "url": config_data["emby"]["url"],
                "token": config_data["emby"]["apikey"],
            }
            del config_data["emby"]
            for task in config_data.get("tasklist", {}):
                task["media_id"] = task.get("emby_id", "")
                if task.get("emby_id"):
                    del task["emby_id"]
        if config_data.get("media_servers"):
            print("ğŸ”¼ Update config v0.3.8 to 0.3.9")
            config_data["plugins"] = config_data.get("media_servers")
            del config_data["media_servers"]
            for task in config_data.get("tasklist", {}):
                task["addition"] = {
                    "emby": {
                        "media_id": task.get("media_id", ""),
                    }
                }
                if task.get("media_id"):
                    del task["media_id"]
                    
        # æ·»åŠ å‰§é›†è¯†åˆ«æ¨¡å¼é…ç½®
        if not config_data.get("episode_patterns"):
            print("ğŸ”¼ æ·»åŠ å‰§é›†è¯†åˆ«æ¨¡å¼é…ç½®")
            config_data["episode_patterns"] = [
                {"description": "[]", "regex": "(\\d+)"},
                {"description": "[]-4K", "regex": "(\\d+)[-_\\s]*4[Kk]"},
                {"description": "[]è¯", "regex": "(\\d+)è¯"},
                {"description": "E[]", "regex": "[Ee](\\d+)"},
                {"description": "EP[]", "regex": "[Ee][Pp](\\d+)"},
                {"description": "ç¬¬[]è¯", "regex": "ç¬¬(\\d+)è¯"},
                {"description": "ç¬¬[]é›†", "regex": "ç¬¬(\\d+)é›†"},
                {"description": "ç¬¬[]æœŸ", "regex": "ç¬¬(\\d+)æœŸ"},
                {"description": "[] 4K", "regex": "(\\d+)\\s+4[Kk]"},
                {"description": "[]_4K", "regex": "(\\d+)[_\\s]4[Kk]"},
                {"description": "ã€[]ã€‘", "regex": "ã€(\\d+)ã€‘"},
                {"description": "[[]", "regex": "\\[(\\d+)\\]"},
                {"description": "_[]_", "regex": "_?(\\d+)_"}
            ]


class Quark:
    BASE_URL = "https://drive-pc.quark.cn"
    BASE_URL_APP = "https://drive-m.quark.cn"
    USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) quark-cloud-drive/3.14.2 Chrome/112.0.5615.165 Electron/24.1.3.8 Safari/537.36 Channel/pckk_other_ch"

    def __init__(self, cookie, index=None):
        self.cookie = cookie.strip()
        self.index = index + 1
        self.is_active = False
        self.nickname = ""
        self.mparam = self._match_mparam_form_cookie(cookie)
        self.savepath_fid = {"/": "0"}

    def _match_mparam_form_cookie(self, cookie):
        mparam = {}
        kps_match = re.search(r"(?<!\w)kps=([a-zA-Z0-9%+/=]+)[;&]?", cookie)
        sign_match = re.search(r"(?<!\w)sign=([a-zA-Z0-9%+/=]+)[;&]?", cookie)
        vcode_match = re.search(r"(?<!\w)vcode=([a-zA-Z0-9%+/=]+)[;&]?", cookie)
        if kps_match and sign_match and vcode_match:
            mparam = {
                "kps": kps_match.group(1).replace("%25", "%"),
                "sign": sign_match.group(1).replace("%25", "%"),
                "vcode": vcode_match.group(1).replace("%25", "%"),
            }
        return mparam

    def _send_request(self, method, url, **kwargs):
        headers = {
            "cookie": self.cookie,
            "content-type": "application/json",
            "user-agent": self.USER_AGENT,
        }
        if "headers" in kwargs:
            headers = kwargs["headers"]
            del kwargs["headers"]
        if self.mparam and "share" in url and self.BASE_URL in url:
            url = url.replace(self.BASE_URL, self.BASE_URL_APP)
            kwargs["params"].update(
                {
                    "device_model": "M2011K2C",
                    "entry": "default_clouddrive",
                    "_t_group": "0%3A_s_vp%3A1",
                    "dmn": "Mi%2B11",
                    "fr": "android",
                    "pf": "3300",
                    "bi": "35937",
                    "ve": "7.4.5.680",
                    "ss": "411x875",
                    "mi": "M2011K2C",
                    "nt": "5",
                    "nw": "0",
                    "kt": "4",
                    "pr": "ucpro",
                    "sv": "release",
                    "dt": "phone",
                    "data_from": "ucapi",
                    "kps": self.mparam.get("kps"),
                    "sign": self.mparam.get("sign"),
                    "vcode": self.mparam.get("vcode"),
                    "app": "clouddrive",
                    "kkkk": "1",
                }
            )
            del headers["cookie"]
        try:
            response = requests.request(method, url, headers=headers, **kwargs)
            # print(f"{response.text}")
            # response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸï¼Œä½†è¿”å›é200ä¹Ÿä¼šæŠ›å‡ºå¼‚å¸¸
            return response
        except Exception as e:
            print(f"_send_request error:\n{e}")
            fake_response = requests.Response()
            fake_response.status_code = 500
            fake_response._content = b'{"status": 500, "message": "request error"}'
            return fake_response

    def init(self):
        account_info = self.get_account_info()
        if account_info:
            self.is_active = True
            self.nickname = account_info["nickname"]
            return account_info
        else:
            return False

    def get_account_info(self):
        url = "https://pan.quark.cn/account/info"
        querystring = {"fr": "pc", "platform": "pc"}
        response = self._send_request("GET", url, params=querystring).json()
        if response.get("data"):
            return response["data"]
        else:
            return False

    def get_growth_info(self):
        url = f"{self.BASE_URL_APP}/1/clouddrive/capacity/growth/info"
        querystring = {
            "pr": "ucpro",
            "fr": "android",
            "kps": self.mparam.get("kps"),
            "sign": self.mparam.get("sign"),
            "vcode": self.mparam.get("vcode"),
        }
        headers = {
            "content-type": "application/json",
        }
        response = self._send_request(
            "GET", url, headers=headers, params=querystring
        ).json()
        if response.get("data"):
            return response["data"]
        else:
            return False

    def get_growth_sign(self):
        url = f"{self.BASE_URL_APP}/1/clouddrive/capacity/growth/sign"
        querystring = {
            "pr": "ucpro",
            "fr": "android",
            "kps": self.mparam.get("kps"),
            "sign": self.mparam.get("sign"),
            "vcode": self.mparam.get("vcode"),
        }
        payload = {
            "sign_cyclic": True,
        }
        headers = {
            "content-type": "application/json",
        }
        response = self._send_request(
            "POST", url, json=payload, headers=headers, params=querystring
        ).json()
        if response.get("data"):
            return True, response["data"]["sign_daily_reward"]
        else:
            return False, response["message"]

    # å¯éªŒè¯èµ„æºæ˜¯å¦å¤±æ•ˆ
    def get_stoken(self, pwd_id, passcode=""):
        url = f"{self.BASE_URL}/1/clouddrive/share/sharepage/token"
        querystring = {"pr": "ucpro", "fr": "pc"}
        payload = {"pwd_id": pwd_id, "passcode": passcode}
        response = self._send_request(
            "POST", url, json=payload, params=querystring
        ).json()
        if response.get("status") == 200:
            return True, response["data"]["stoken"]
        else:
            return False, response["message"]

    def get_detail(self, pwd_id, stoken, pdir_fid, _fetch_share=0):
        list_merge = []
        page = 1
        while True:
            url = f"{self.BASE_URL}/1/clouddrive/share/sharepage/detail"
            querystring = {
                "pr": "ucpro",
                "fr": "pc",
                "pwd_id": pwd_id,
                "stoken": stoken,
                "pdir_fid": pdir_fid,
                "force": "0",
                "_page": page,
                "_size": "50",
                "_fetch_banner": "0",
                "_fetch_share": _fetch_share,
                "_fetch_total": "1",
                "_sort": "file_type:asc,updated_at:desc",
            }
            response = self._send_request("GET", url, params=querystring).json()
            if response["code"] != 0:
                return {"error": response["message"]}
            if response["data"]["list"]:
                list_merge += response["data"]["list"]
                page += 1
            else:
                break
            if len(list_merge) >= response["metadata"]["_total"]:
                break
        response["data"]["list"] = list_merge
        return response["data"]

    def get_fids(self, file_paths):
        fids = []
        while True:
            url = f"{self.BASE_URL}/1/clouddrive/file/info/path_list"
            querystring = {"pr": "ucpro", "fr": "pc"}
            payload = {"file_path": file_paths[:50], "namespace": "0"}
            response = self._send_request(
                "POST", url, json=payload, params=querystring
            ).json()
            if response["code"] == 0:
                fids += response["data"]
                file_paths = file_paths[50:]
            else:
                print(f"è·å–ç›®å½•IDï¼šå¤±è´¥, {response['message']}")
                break
            if len(file_paths) == 0:
                break
        return fids

    def ls_dir(self, pdir_fid, **kwargs):
        file_list = []
        page = 1
        while True:
            url = f"{self.BASE_URL}/1/clouddrive/file/sort"
            querystring = {
                "pr": "ucpro",
                "fr": "pc",
                "uc_param_str": "",
                "pdir_fid": pdir_fid,
                "_page": page,
                "_size": "50",
                "_fetch_total": "1",
                "_fetch_sub_dirs": "0",
                "_sort": "file_type:asc,updated_at:desc",
                "_fetch_full_path": kwargs.get("fetch_full_path", 0),
            }
            response = self._send_request("GET", url, params=querystring).json()
            if response["code"] != 0:
                return {"error": response["message"]}
            if response["data"]["list"]:
                file_list += response["data"]["list"]
                page += 1
            else:
                break
            if len(file_list) >= response["metadata"]["_total"]:
                break
        return file_list

    def save_file(self, fid_list, fid_token_list, to_pdir_fid, pwd_id, stoken):
        url = f"{self.BASE_URL}/1/clouddrive/share/sharepage/save"
        querystring = {
            "pr": "ucpro",
            "fr": "pc",
            "uc_param_str": "",
            "app": "clouddrive",
            "__dt": int(random.uniform(1, 5) * 60 * 1000),
            "__t": datetime.now().timestamp(),
        }
        payload = {
            "fid_list": fid_list,
            "fid_token_list": fid_token_list,
            "to_pdir_fid": to_pdir_fid,
            "pwd_id": pwd_id,
            "stoken": stoken,
            "pdir_fid": "0",
            "scene": "link",
        }
        response = self._send_request(
            "POST", url, json=payload, params=querystring
        ).json()
        return response

    def query_task(self, task_id):
        retry_index = 0
        while True:
            url = f"{self.BASE_URL}/1/clouddrive/task"
            querystring = {
                "pr": "ucpro",
                "fr": "pc",
                "uc_param_str": "",
                "task_id": task_id,
                "retry_index": retry_index,
                "__dt": int(random.uniform(1, 5) * 60 * 1000),
                "__t": datetime.now().timestamp(),
            }
            response = self._send_request("GET", url, params=querystring).json()
            if response["data"]["status"] != 0:
                if retry_index > 0:
                    print()
                break
            else:
                if retry_index == 0:
                    print(
                        f"æ­£åœ¨ç­‰å¾…[{response['data']['task_title']}]æ‰§è¡Œç»“æœ",
                        end="",
                        flush=True,
                    )
                else:
                    print(".", end="", flush=True)
                retry_index += 1
                time.sleep(0.500)
        return response

    def download(self, fids):
        url = f"{self.BASE_URL}/1/clouddrive/file/download"
        querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
        payload = {"fids": fids}
        response = self._send_request("POST", url, json=payload, params=querystring)
        set_cookie = response.cookies.get_dict()
        cookie_str = "; ".join([f"{key}={value}" for key, value in set_cookie.items()])
        return response.json(), cookie_str

    def mkdir(self, dir_path):
        url = f"{self.BASE_URL}/1/clouddrive/file"
        querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
        payload = {
            "pdir_fid": "0",
            "file_name": "",
            "dir_path": dir_path,
            "dir_init_lock": False,
        }
        response = self._send_request(
            "POST", url, json=payload, params=querystring
        ).json()
        return response

    def rename(self, fid, file_name):
        url = f"{self.BASE_URL}/1/clouddrive/file/rename"
        querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
        payload = {"fid": fid, "file_name": file_name}
        response = self._send_request(
            "POST", url, json=payload, params=querystring
        ).json()
        return response

    def delete(self, filelist):
        url = f"{self.BASE_URL}/1/clouddrive/file/delete"
        querystring = {"pr": "ucpro", "fr": "pc", "uc_param_str": ""}
        payload = {"action_type": 2, "filelist": filelist, "exclude_fids": []}
        response = self._send_request(
            "POST", url, json=payload, params=querystring
        ).json()
        return response

    def recycle_list(self, page=1, size=30):
        url = f"{self.BASE_URL}/1/clouddrive/file/recycle/list"
        querystring = {
            "_page": page,
            "_size": size,
            "pr": "ucpro",
            "fr": "pc",
            "uc_param_str": "",
        }
        response = self._send_request("GET", url, params=querystring).json()
        return response["data"]["list"]

    def recycle_remove(self, record_list):
        url = f"{self.BASE_URL}/1/clouddrive/file/recycle/remove"
        querystring = {"uc_param_str": "", "fr": "pc", "pr": "ucpro"}
        payload = {
            "select_mode": 2,
            "record_list": record_list,
        }
        response = self._send_request(
            "POST", url, json=payload, params=querystring
        ).json()
        return response

    # â†‘ è¯·æ±‚å‡½æ•°
    # â†“ æ“ä½œå‡½æ•°

    # é­”æ³•æ­£åˆ™åŒ¹é…
    def magic_regex_func(self, pattern, replace, taskname=None, magic_regex={}):
        magic_regex = magic_regex or CONFIG_DATA.get("magic_regex") or MAGIC_REGEX
        keyword = pattern
        if keyword in magic_regex:
            pattern = magic_regex[keyword]["pattern"]
            if replace == "":
                replace = magic_regex[keyword]["replace"]
        if taskname:
            replace = replace.replace("$TASKNAME", taskname)
        return pattern, replace

    # def get_id_from_url(self, url):
    #     url = url.replace("https://pan.quark.cn/s/", "")
    #     pattern = r"(\w+)(\?pwd=(\w+))?(#/list/share.*/(\w+))?"
    #     match = re.search(pattern, url)
    #     if match:
    #         pwd_id = match.group(1)
    #         passcode = match.group(3) if match.group(3) else ""
    #         pdir_fid = match.group(5) if match.group(5) else 0
    #         return pwd_id, passcode, pdir_fid
    #     else:
    #         return None

    def extract_url(self, url):
        # pwd_id
        match_id = re.search(r"/s/(\w+)", url)
        pwd_id = match_id.group(1) if match_id else None
        # passcode
        match_pwd = re.search(r"pwd=(\w+)", url)
        passcode = match_pwd.group(1) if match_pwd else ""
        # path: fid-name
        paths = []
        matches = re.findall(r"/(\w{32})-?([^/]+)?", url)
        for match in matches:
            fid = match[0]
            name = urllib.parse.unquote(match[1])
            paths.append({"fid": fid, "name": name})
        pdir_fid = paths[-1]["fid"] if matches else 0
        return pwd_id, passcode, pdir_fid, paths

    def update_savepath_fid(self, tasklist):
        dir_paths = [
            re.sub(r"/{2,}", "/", f"/{item['savepath']}")
            for item in tasklist
            if not item.get("enddate")
            or (
                datetime.now().date()
                <= datetime.strptime(item["enddate"], "%Y-%m-%d").date()
            )
        ]
        if not dir_paths:
            return False
        dir_paths_exist_arr = self.get_fids(dir_paths)
        dir_paths_exist = [item["file_path"] for item in dir_paths_exist_arr]
        # æ¯”è¾ƒåˆ›å»ºä¸å­˜åœ¨çš„
        dir_paths_unexist = list(set(dir_paths) - set(dir_paths_exist) - set(["/"]))
        for dir_path in dir_paths_unexist:
            mkdir_return = self.mkdir(dir_path)
            if mkdir_return["code"] == 0:
                new_dir = mkdir_return["data"]
                dir_paths_exist_arr.append(
                    {"file_path": dir_path, "fid": new_dir["fid"]}
                )
                print(f"åˆ›å»ºæ–‡ä»¶å¤¹ï¼š{dir_path}")
            else:
                print(f"åˆ›å»ºæ–‡ä»¶å¤¹ï¼š{dir_path} å¤±è´¥, {mkdir_return['message']}")
        # å‚¨å­˜ç›®æ ‡ç›®å½•çš„fid
        for dir_path in dir_paths_exist_arr:
            self.savepath_fid[dir_path["file_path"]] = dir_path["fid"]
        # print(dir_paths_exist_arr)

    def do_save_check(self, shareurl, savepath):
        try:
            pwd_id, passcode, pdir_fid, _ = self.extract_url(shareurl)
            _, stoken = self.get_stoken(pwd_id, passcode)
            share_file_list = self.get_detail(pwd_id, stoken, pdir_fid)["list"]
            fid_list = [item["fid"] for item in share_file_list]
            fid_token_list = [item["share_fid_token"] for item in share_file_list]
            file_name_list = [item["file_name"] for item in share_file_list]
            if not fid_list:
                return
            get_fids = self.get_fids([savepath])
            to_pdir_fid = (
                get_fids[0]["fid"] if get_fids else self.mkdir(savepath)["data"]["fid"]
            )
            save_file = self.save_file(
                fid_list, fid_token_list, to_pdir_fid, pwd_id, stoken
            )
            if save_file["code"] == 41017:
                return
            elif save_file["code"] == 0:
                dir_file_list = self.ls_dir(to_pdir_fid)
                del_list = [
                    item["fid"]
                    for item in dir_file_list
                    if (item["file_name"] in file_name_list)
                    and ((datetime.now().timestamp() - item["created_at"]) < 60)
                ]
                if del_list:
                    self.delete(del_list)
                    recycle_list = self.recycle_list()
                    record_id_list = [
                        item["record_id"]
                        for item in recycle_list
                        if item["fid"] in del_list
                    ]
                    self.recycle_remove(record_id_list)
                return save_file
            else:
                return False
        except Exception as e:
            print(f"è½¬å­˜æµ‹è¯•å¤±è´¥: {str(e)}")

    def do_save_task(self, task):
        # åˆ¤æ–­èµ„æºå¤±æ•ˆè®°å½•
        if task.get("shareurl_ban"):
            print(f"åˆ†äº«èµ„æºå·²å¤±æ•ˆï¼š{task['shareurl_ban']}")
            add_notify(f"â—ã€Š{task['taskname']}ã€‹åˆ†äº«èµ„æºå·²å¤±æ•ˆï¼š{task['shareurl_ban']}\n")
            return
        # æå–é“¾æ¥å‚æ•°
        pwd_id, passcode, pdir_fid, paths = self.extract_url(task["shareurl"])
        if not pwd_id:
            task["shareurl_ban"] = f"æå–é“¾æ¥å‚æ•°å¤±è´¥ï¼Œè¯·æ£€æŸ¥åˆ†äº«é“¾æ¥æ˜¯å¦æœ‰æ•ˆ"
            print(f"æå–é“¾æ¥å‚æ•°å¤±è´¥ï¼Œè¯·æ£€æŸ¥åˆ†äº«é“¾æ¥æ˜¯å¦æœ‰æ•ˆ")
            return
        # è·å–åˆ†äº«è¯¦æƒ…
        is_sharing, stoken = self.get_stoken(pwd_id, passcode)
        if not is_sharing:
            task["shareurl_ban"] = stoken
            print(f"åˆ†äº«è¯¦æƒ…è·å–å¤±è´¥ï¼š{stoken}")
            add_notify(f"â—ã€Š{task['taskname']}ã€‹åˆ†äº«è¯¦æƒ…è·å–å¤±è´¥ï¼š{stoken}\n")
            return
        share_detail = self.get_detail(pwd_id, stoken, pdir_fid, _fetch_share=1)
        # è·å–ä¿å­˜è·¯å¾„fid
        savepath = task["savepath"]
        if not self.savepath_fid.get(savepath):
            # æ£€æŸ¥è§„èŒƒåŒ–è·¯å¾„æ˜¯å¦å·²åœ¨å­—å…¸ä¸­
            norm_savepath = re.sub(r"/{2,}", "/", f"/{savepath}")
            if norm_savepath != savepath and self.savepath_fid.get(norm_savepath):
                self.savepath_fid[savepath] = self.savepath_fid[norm_savepath]
            else:
                savepath_fids = self.get_fids([savepath])
                if not savepath_fids:
                    print(f"ä¿å­˜è·¯å¾„ä¸å­˜åœ¨ï¼Œå‡†å¤‡æ–°å»ºï¼š{savepath}")
                    mkdir_result = self.mkdir(savepath)
                    if mkdir_result["code"] == 0:
                        self.savepath_fid[savepath] = mkdir_result["data"]["fid"]
                        print(f"ä¿å­˜è·¯å¾„æ–°å»ºæˆåŠŸï¼š{savepath}")
                    else:
                        print(f"ä¿å­˜è·¯å¾„æ–°å»ºå¤±è´¥ï¼š{mkdir_result['message']}")
                        return
                else:
                    # è·¯å¾„å·²å­˜åœ¨ï¼Œç›´æ¥è®¾ç½®fid
                    self.savepath_fid[savepath] = savepath_fids[0]["fid"]

        # æ”¯æŒé¡ºåºå‘½åæ¨¡å¼
        if task.get("use_sequence_naming") and task.get("sequence_naming"):
            # é¡ºåºå‘½åæ¨¡å¼ä¸‹å·²ç»åœ¨do_saveä¸­æ‰“å°äº†é¡ºåºå‘½åä¿¡æ¯ï¼Œè¿™é‡Œä¸å†é‡å¤æ‰“å°
            # è®¾ç½®æ­£åˆ™æ¨¡å¼ä¸ºç©º
            task["regex_pattern"] = None
            # æ„å»ºé¡ºåºå‘½åçš„æ­£åˆ™è¡¨è¾¾å¼
            sequence_pattern = task["sequence_naming"]
            # å°†{}æ›¿æ¢ä¸º(\d+)ç”¨äºåŒ¹é…
            if sequence_pattern == "{}":
                # å¯¹äºå•ç‹¬çš„{}ï¼Œä½¿ç”¨ç‰¹æ®ŠåŒ¹é…
                regex_pattern = "(\\d+)"
            else:
                regex_pattern = re.escape(sequence_pattern).replace('\\{\\}', '(\\d+)')
            task["regex_pattern"] = regex_pattern
        # æ”¯æŒå‰§é›†å‘½åæ¨¡å¼
        elif task.get("use_episode_naming") and task.get("episode_naming"):
            # å‰§é›†å‘½åæ¨¡å¼ä¸‹å·²ç»åœ¨do_saveä¸­æ‰“å°äº†å‰§é›†å‘½åä¿¡æ¯ï¼Œè¿™é‡Œä¸å†é‡å¤æ‰“å°
            # è®¾ç½®æ­£åˆ™æ¨¡å¼ä¸ºç©º
            task["regex_pattern"] = None
            # æ„å»ºå‰§é›†å‘½åçš„æ­£åˆ™è¡¨è¾¾å¼
            episode_pattern = task["episode_naming"]
            # å…ˆæ£€æŸ¥æ˜¯å¦åŒ…å«åˆæ³•çš„[]å­—ç¬¦
            if "[]" in episode_pattern:
                # å°†[] æ›¿æ¢ä¸º (\d+)
                # å…ˆå°†æ¨¡å¼å­—ç¬¦ä¸²è¿›è¡Œè½¬ä¹‰ï¼Œç¡®ä¿å…¶ä»–ç‰¹æ®Šå­—ç¬¦ä¸ä¼šå¹²æ‰°
                escaped_pattern = re.escape(episode_pattern)
                # ç„¶åå°†è½¬ä¹‰åçš„ \[ \] æ›¿æ¢ä¸ºæ•è·ç»„ (\d+)
                regex_pattern = escaped_pattern.replace('\\[\\]', '(\\d+)')
            else:
                # å¦‚æœè¾“å…¥æ¨¡å¼ä¸åŒ…å«[]ï¼Œåˆ™ä½¿ç”¨ç®€å•åŒ¹é…æ¨¡å¼ï¼Œé¿å…æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯
                print(f"âš ï¸ å‰§é›†å‘½åæ¨¡å¼ä¸­æ²¡æœ‰æ‰¾åˆ° [] å ä½ç¬¦ï¼Œå°†ä½¿ç”¨ç®€å•åŒ¹é…")
                regex_pattern = "^" + re.escape(episode_pattern) + "(\\d+)$"
            
            task["regex_pattern"] = regex_pattern
        else:
            # æ­£åˆ™å‘½åæ¨¡å¼
            pattern, replace = self.magic_regex_func(
                task.get("pattern", ""), task.get("replace", ""), task["taskname"]
            )
            # æ³¨é‡Šæ‰è¿™é‡Œçš„æ­£åˆ™è¡¨è¾¾å¼æ‰“å°ï¼Œå› ä¸ºåœ¨do_saveå‡½æ•°ä¸­å·²ç»æ‰“å°äº†
            # åªæœ‰åœ¨éé­”æ³•å˜é‡æƒ…å†µä¸‹æ‰æ˜¾ç¤ºå±•å¼€åçš„æ­£åˆ™è¡¨è¾¾å¼
            # å¯¹äºé­”æ³•å˜é‡($TVç­‰)ï¼Œæ˜¾ç¤ºåŸå§‹è¾“å…¥
            # if pattern and task.get("pattern") and task.get("pattern") not in CONFIG_DATA.get("magic_regex", MAGIC_REGEX):
            #     print(f"æ­£åˆ™åŒ¹é…: {pattern}")
            #     print(f"æ­£åˆ™æ›¿æ¢: {replace}")
            
        # ä¿å­˜æ–‡ä»¶
        tree = self.dir_check_and_save(task, pwd_id, stoken, pdir_fid)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ–‡ä»¶è½¬å­˜
        if tree and tree.size() <= 1:  # åªæœ‰æ ¹èŠ‚ç‚¹æ„å‘³ç€æ²¡æœ‰æ–°æ–‡ä»¶
            return False
            
        return tree

    def dir_check_and_save(self, task, pwd_id, stoken, pdir_fid="", subdir_path=""):
        tree = Tree()
        # è·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨
        share_file_list = self.get_detail(pwd_id, stoken, pdir_fid)["list"]
        # print("share_file_list: ", share_file_list)

        if not share_file_list:
            if subdir_path == "":
                task["shareurl_ban"] = "åˆ†äº«ä¸ºç©ºï¼Œæ–‡ä»¶å·²è¢«åˆ†äº«è€…åˆ é™¤"
                add_notify(f"âŒã€Š{task['taskname']}ã€‹ï¼š{task['shareurl_ban']}\n")
            return tree
        elif (
            len(share_file_list) == 1
            and share_file_list[0]["dir"]
            and subdir_path == ""
        ):  # ä»…æœ‰ä¸€ä¸ªæ–‡ä»¶å¤¹
            print("ğŸ§  è¯¥åˆ†äº«æ˜¯ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œè¯»å–æ–‡ä»¶å¤¹å†…åˆ—è¡¨")
            share_file_list = self.get_detail(
                pwd_id, stoken, share_file_list[0]["fid"]
            )["list"]
            
        # åº”ç”¨è¿‡æ»¤è¯è¿‡æ»¤
        if task.get("filterwords"):
            # åŒæ—¶æ”¯æŒä¸­è‹±æ–‡é€—å·åˆ†éš”
            filterwords = task["filterwords"].replace("ï¼Œ", ",")
            filterwords_list = [word.strip().lower() for word in filterwords.split(',')]
            
            # æ”¹è¿›è¿‡æ»¤é€»è¾‘ï¼ŒåŒæ—¶æ£€æŸ¥æ–‡ä»¶åå’Œæ‰©å±•å
            filtered_files = []
            for file in share_file_list:
                file_name = file['file_name'].lower()
                # æå–æ–‡ä»¶æ‰©å±•åï¼ˆä¸å¸¦ç‚¹ï¼‰
                file_ext = os.path.splitext(file_name)[1].lower().lstrip('.')
                
                # æ£€æŸ¥è¿‡æ»¤è¯æ˜¯å¦å­˜åœ¨äºæ–‡ä»¶åä¸­ï¼Œæˆ–è€…è¿‡æ»¤è¯ç­‰äºæ‰©å±•å
                if not any(word in file_name for word in filterwords_list) and not any(word == file_ext for word in filterwords_list):
                    filtered_files.append(file)
                    
            share_file_list = filtered_files
            print(f"ğŸ“‘ åº”ç”¨è¿‡æ»¤è¯: {task['filterwords']}ï¼Œå‰©ä½™{len(share_file_list)}ä¸ªæ–‡ä»¶")
            print()

        # è·å–ç›®æ ‡ç›®å½•æ–‡ä»¶åˆ—è¡¨
        savepath = re.sub(r"/{2,}", "/", f"/{task['savepath']}{subdir_path}")
        if not self.savepath_fid.get(savepath):
            # æ£€æŸ¥è§„èŒƒåŒ–è·¯å¾„æ˜¯å¦å·²åœ¨å­—å…¸ä¸­
            norm_savepath = re.sub(r"/{2,}", "/", f"/{savepath}")
            if norm_savepath != savepath and self.savepath_fid.get(norm_savepath):
                self.savepath_fid[savepath] = self.savepath_fid[norm_savepath]
            else:
                savepath_fids = self.get_fids([savepath])
                if not savepath_fids:
                    print(f"ä¿å­˜è·¯å¾„ä¸å­˜åœ¨ï¼Œå‡†å¤‡æ–°å»ºï¼š{savepath}")
                    mkdir_result = self.mkdir(savepath)
                    if mkdir_result["code"] == 0:
                        self.savepath_fid[savepath] = mkdir_result["data"]["fid"]
                        print(f"ä¿å­˜è·¯å¾„æ–°å»ºæˆåŠŸï¼š{savepath}")
                    else:
                        print(f"ä¿å­˜è·¯å¾„æ–°å»ºå¤±è´¥ï¼š{mkdir_result['message']}")
                        return
                else:
                    # è·¯å¾„å·²å­˜åœ¨ï¼Œç›´æ¥è®¾ç½®fid
                    self.savepath_fid[savepath] = savepath_fids[0]["fid"]
        to_pdir_fid = self.savepath_fid[savepath]
        dir_file_list = self.ls_dir(to_pdir_fid)
        
        tree.create_node(
            savepath,
            pdir_fid,
            data={
                "is_dir": True,
            },
        )

        # å¤„ç†é¡ºåºå‘½åæ¨¡å¼
        if task.get("use_sequence_naming") and task.get("sequence_naming"):
            # é¡ºåºå‘½åæ¨¡å¼
            current_sequence = 1
            sequence_pattern = task["sequence_naming"]
            regex_pattern = task.get("regex_pattern")
            
            # æŸ¥æ‰¾ç›®å½•ä¸­ç°æœ‰çš„æœ€å¤§åºå·
            for dir_file in dir_file_list:
                if not dir_file["dir"]:  # åªæ£€æŸ¥æ–‡ä»¶
                    if sequence_pattern == "{}":
                        # å¯¹äºå•ç‹¬çš„{}ï¼Œç›´æ¥å°è¯•åŒ¹é…æ•´ä¸ªæ–‡ä»¶åæ˜¯å¦ä¸ºæ•°å­—
                        file_name_without_ext = os.path.splitext(dir_file["file_name"])[0]
                        if file_name_without_ext.isdigit():
                            try:
                                seq_num = int(file_name_without_ext)
                                current_sequence = max(current_sequence, seq_num + 1)
                            except (ValueError, IndexError):
                                pass
                    elif matches := re.match(regex_pattern, dir_file["file_name"]):
                        try:
                            seq_num = int(matches.group(1))
                            current_sequence = max(current_sequence, seq_num + 1)
                        except (ValueError, IndexError):
                            pass
            
            # æ„å»ºç›®æ ‡ç›®å½•ä¸­æ‰€æœ‰æ–‡ä»¶çš„æŸ¥é‡ç´¢å¼•ï¼ˆæŒ‰å¤§å°å’Œä¿®æ”¹æ—¶é—´ï¼‰
            dir_files_map = {}
            for dir_file in dir_file_list:
                if not dir_file["dir"]:  # ä»…å¤„ç†æ–‡ä»¶
                    file_size = dir_file.get("size", 0)
                    file_ext = os.path.splitext(dir_file["file_name"])[1].lower()
                    update_time = dir_file.get("updated_at", 0)
                    
                    # åˆ›å»ºå¤§å°+æ‰©å±•åçš„ç´¢å¼•ï¼Œç”¨äºå¿«é€ŸæŸ¥é‡
                    key = f"{file_size}_{file_ext}"
                    if key not in dir_files_map:
                        dir_files_map[key] = []
                    dir_files_map[key].append({
                        "file_name": dir_file["file_name"],
                        "updated_at": update_time,
                    })
            
            # é¢„å…ˆè¿‡æ»¤æ‰å·²ç»å­˜åœ¨çš„æ–‡ä»¶ï¼ˆæŒ‰å¤§å°å’Œæ‰©å±•åæ¯”å¯¹ï¼‰
            filtered_share_files = []
            for share_file in share_file_list:
                if share_file["dir"]:
                    # å¤„ç†å­ç›®å½•
                    if task.get("update_subdir") and re.search(task["update_subdir"], share_file["file_name"]):
                        filtered_share_files.append(share_file)
                    continue
                    
                file_size = share_file.get("size", 0)
                file_ext = os.path.splitext(share_file["file_name"])[1].lower()
                share_update_time = share_file.get("last_update_at", 0)
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒå¤§å°å’Œæ‰©å±•åçš„æ–‡ä»¶
                key = f"{file_size}_{file_ext}"
                is_duplicate = False
                
                if key in dir_files_map:
                    for existing_file in dir_files_map[key]:
                        existing_update_time = existing_file.get("updated_at", 0)
                        
                        # å¦‚æœä¿®æ”¹æ—¶é—´ç›¸è¿‘ï¼ˆ30å¤©å†…ï¼‰æˆ–è€…å·®è·ä¸å¤§ï¼ˆ10%ä»¥å†…ï¼‰ï¼Œè®¤ä¸ºæ˜¯åŒä¸€ä¸ªæ–‡ä»¶
                        if (abs(share_update_time - existing_update_time) < 2592000 or 
                            abs(1 - (share_update_time / existing_update_time if existing_update_time else 1)) < 0.1):
                            is_duplicate = True
                            break
                
                # åªæœ‰éé‡å¤æ–‡ä»¶æ‰è¿›è¡Œå¤„ç†
                if not is_duplicate:
                    filtered_share_files.append(share_file)
                    
                # æŒ‡å®šæ–‡ä»¶å¼€å§‹è®¢é˜…/åˆ°è¾¾æŒ‡å®šæ–‡ä»¶ï¼ˆå«ï¼‰ç»“æŸå†é
                if share_file["fid"] == task.get("startfid", ""):
                    break
            
            # å®ç°é«˜çº§æ’åºç®—æ³•
            def extract_sorting_value(file):
                if file.get("dir", False):  # è·³è¿‡æ–‡ä»¶å¤¹
                    return float('inf')
                
                filename = file["file_name"]
                
                # æå–æ–‡ä»¶åï¼Œä¸å«æ‰©å±•å
                file_name_without_ext = os.path.splitext(filename)[0]
                
                # 1. "ç¬¬XæœŸ/é›†/è¯" æ ¼å¼
                match_chinese = re.search(r'ç¬¬(\d+)[æœŸé›†è¯]', filename)
                episode_num = int(match_chinese.group(1)) if match_chinese else 0
                
                # 5. æ–‡ä»¶åå«"ä¸Šä¸­ä¸‹"ï¼ˆä¼˜å…ˆå¤„ç†ï¼Œå› ä¸ºå¯èƒ½ä¸å…¶ä»–æ ¼å¼åŒæ—¶å­˜åœ¨ï¼‰
                if match_chinese:
                    # å¦‚æœåŒæ—¶å­˜åœ¨é›†æ•°å’Œä¸Šä¸­ä¸‹ï¼Œåˆ™æŒ‰ç…§é›†æ•°*10+ä½ç½®æ’åº
                    if 'ä¸Š' in filename:
                        return episode_num * 10 + 1
                    elif 'ä¸­' in filename:
                        return episode_num * 10 + 2
                    elif 'ä¸‹' in filename:
                        return episode_num * 10 + 3
                    return episode_num * 10
                elif 'ä¸Š' in filename:
                    return 1
                elif 'ä¸­' in filename:
                    return 2
                elif 'ä¸‹' in filename:
                    return 3
                
                # 2.1 S01E01 æ ¼å¼ï¼Œæå–å­£æ•°å’Œé›†æ•°
                match_s_e = re.search(r'[Ss](\d+)[Ee](\d+)', filename)
                if match_s_e:
                    season = int(match_s_e.group(1))
                    episode = int(match_s_e.group(2))
                    return season * 1000 + episode
                
                # 2.2 E01 æ ¼å¼ï¼Œä»…æå–é›†æ•°
                match_e = re.search(r'[Ee][Pp]?(\d+)', filename)
                if match_e:
                    return int(match_e.group(1))
                
                # 2.3 1x01 æ ¼å¼ï¼Œæå–å­£æ•°å’Œé›†æ•°
                match_x = re.search(r'(\d+)[Xx](\d+)', filename)
                if match_x:
                    season = int(match_x.group(1))
                    episode = int(match_x.group(2))
                    return season * 1000 + episode
                
                # 3. æ—¥æœŸæ ¼å¼è¯†åˆ«ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
                
                # 3.1 å®Œæ•´çš„YYYYMMDDæ ¼å¼
                match_date_compact = re.search(r'(20\d{2})(\d{2})(\d{2})', filename)
                if match_date_compact:
                    year = int(match_date_compact.group(1))
                    month = int(match_date_compact.group(2))
                    day = int(match_date_compact.group(3))
                    return year * 10000 + month * 100 + day
                
                # 3.2 YYYY-MM-DD æˆ– YYYY.MM.DD æˆ– YYYY/MM/DD æ ¼å¼
                match_date_full = re.search(r'(20\d{2})[-./](\d{1,2})[-./](\d{1,2})', filename)
                if match_date_full:
                    year = int(match_date_full.group(1))
                    month = int(match_date_full.group(2))
                    day = int(match_date_full.group(3))
                    return year * 10000 + month * 100 + day
                
                # 3.3 MM/DD/YYYY æˆ– DD/MM/YYYY æ ¼å¼
                match_date_alt = re.search(r'(\d{1,2})[-./](\d{1,2})[-./](20\d{2})', filename)
                if match_date_alt:
                    # å‡è®¾ç¬¬ä¸€ä¸ªæ˜¯æœˆï¼Œç¬¬äºŒä¸ªæ˜¯æ—¥ï¼ˆç¾å¼æ—¥æœŸï¼‰
                    month = int(match_date_alt.group(1))
                    day = int(match_date_alt.group(2))
                    year = int(match_date_alt.group(3))
                    # æ£€æŸ¥æœˆä»½å€¼ï¼Œå¦‚æœå¤§äº12å¯èƒ½æ˜¯æ¬§å¼æ—¥æœŸæ ¼å¼ï¼ˆDD/MM/YYYYï¼‰
                    if month > 12:
                        month, day = day, month
                    return year * 10000 + month * 100 + day
                
                # 3.4 MM/DD æ ¼å¼ï¼ˆæ— å¹´ä»½ï¼‰ï¼Œå‡è®¾ä¸ºå½“å‰å¹´
                match_date_short = re.search(r'(\d{1,2})[-./](\d{1,2})', filename)
                if match_date_short:
                    # å‡è®¾ç¬¬ä¸€ä¸ªæ˜¯æœˆï¼Œç¬¬äºŒä¸ªæ˜¯æ—¥
                    month = int(match_date_short.group(1))
                    day = int(match_date_short.group(2))
                    # æ£€æŸ¥æœˆä»½å€¼ï¼Œå¦‚æœå¤§äº12å¯èƒ½æ˜¯æ¬§å¼æ—¥æœŸæ ¼å¼ï¼ˆDD/MMï¼‰
                    if month > 12:
                        month, day = day, month
                    # ç”±äºæ²¡æœ‰å¹´ä»½ï¼Œä½¿ç”¨ä¸€ä¸ªè¾ƒä½çš„åŸºæ•°ï¼Œç¡®ä¿ä»»ä½•æœ‰å¹´ä»½çš„æ—¥æœŸéƒ½æ’åœ¨åé¢
                    return month * 100 + day
                
                # 3.5 å¹´æœŸæ ¼å¼ï¼Œå¦‚"2025å¹´14æœŸ"
                match_year_issue = re.search(r'(20\d{2})[å¹´].*?(\d+)[æœŸ]', filename)
                if match_year_issue:
                    year = int(match_year_issue.group(1))
                    issue = int(match_year_issue.group(2))
                    return year * 1000 + issue
                
                # 3.6 æ—¥æœŸ+æœŸæ•°çš„å¤åˆæ ¼å¼ï¼Œä¾‹å¦‚ï¼š2025-04-18 ç¬¬5æœŸä¸Š
                match_date_episode = re.search(r'(20\d{2})[-./](\d{1,2})[-./](\d{1,2}).*?ç¬¬(\d+)[æœŸé›†è¯]', filename)
                if match_date_episode:
                    year = int(match_date_episode.group(1))
                    month = int(match_date_episode.group(2))
                    day = int(match_date_episode.group(3))
                    episode = int(match_date_episode.group(4))
                    date_val = year * 10000 + month * 100 + day
                    # å°†æ—¥æœŸå€¼ä½œä¸ºä¸»æ’åºï¼ŒæœŸæ•°ä¸ºæ¬¡è¦æ’åº
                    if 'ä¸Š' in filename:
                        return date_val * 100 + episode * 10 + 1
                    elif 'ä¸­' in filename:
                        return date_val * 100 + episode * 10 + 2
                    elif 'ä¸‹' in filename:
                        return date_val * 100 + episode * 10 + 3
                    return date_val * 100 + episode * 10
                
                # 4. çº¯æ•°å­—æ ¼å¼ï¼ˆæ–‡ä»¶åå¼€å¤´æ˜¯çº¯æ•°å­—ï¼‰
                match_num = re.match(r'^(\d+)', file_name_without_ext)
                if match_num:
                    return int(match_num.group(1))
                
                # 5. å°è¯•åŒ¹é…æ–‡ä»¶åä¸­çš„ä»»ä½•æ•°å­—
                any_num_match = re.search(r'(\d+)', filename)
                if any_num_match:
                    return int(any_num_match.group(1))
                
                # 6. é»˜è®¤ä½¿ç”¨æ›´æ–°æ—¶é—´
                return file.get("created_at", file.get("updated_at", file.get("last_update_at", 0)))
            
            # è¿‡æ»¤å‡ºéç›®å½•æ–‡ä»¶ï¼Œæ’é™¤å·²ç»æ’é™¤æ‰çš„é‡å¤æ–‡ä»¶ï¼Œç„¶åæ’åº
            files_to_process = []
            for f in filtered_share_files:
                if f["dir"]:
                    continue  # è·³è¿‡æ–‡ä»¶å¤¹
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç¬¦åˆå‘½åè§„åˆ™
                if sequence_pattern == "{}":
                    # å¯¹äºå•ç‹¬çš„{}ï¼Œæ£€æŸ¥æ–‡ä»¶åæ˜¯å¦ä¸ºçº¯æ•°å­—
                    file_name_without_ext = os.path.splitext(f["file_name"])[0]
                    if file_name_without_ext.isdigit():
                        # å¢åŠ åˆ¤æ–­ï¼šå¦‚æœæ˜¯æ—¥æœŸæ ¼å¼çš„çº¯æ•°å­—ï¼Œä¸è§†ä¸ºå·²å‘½å
                        if not is_date_format(file_name_without_ext):
                            continue  # è·³è¿‡å·²ç¬¦åˆå‘½åè§„åˆ™çš„æ–‡ä»¶
                elif re.match(regex_pattern, f["file_name"]):
                    continue  # è·³è¿‡å·²ç¬¦åˆå‘½åè§„åˆ™çš„æ–‡ä»¶
                
                # æ·»åŠ åˆ°å¾…å¤„ç†æ–‡ä»¶åˆ—è¡¨
                files_to_process.append(f)
            
            # æ ¹æ®æå–çš„æ’åºå€¼è¿›è¡Œæ’åº
            sorted_files = sorted(files_to_process, key=extract_sorting_value)
            
            # éœ€ä¿å­˜çš„æ–‡ä»¶æ¸…å•
            need_save_list = []
            
            # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ†é…åºå·
            for share_file in sorted_files:
                # è·å–æ–‡ä»¶æ‰©å±•å
                file_ext = os.path.splitext(share_file["file_name"])[1]
                # ç”Ÿæˆæ–°æ–‡ä»¶å
                save_name = sequence_pattern.replace("{}", f"{current_sequence:02d}") + file_ext
                
                # æ£€æŸ¥ç›®æ ‡ç›®å½•æ˜¯å¦å·²å­˜åœ¨æ­¤æ–‡ä»¶
                file_exists = any(
                    dir_file["file_name"] == save_name for dir_file in dir_file_list
                )
                
                if not file_exists:
                    # è®¾ç½®ä¿å­˜æ–‡ä»¶åï¼ˆå•ç‹¬çš„{}ä¸åœ¨è¿™é‡Œé‡å‘½åï¼Œè€Œæ˜¯åœ¨do_rename_taskä¸­å¤„ç†ï¼‰
                    if sequence_pattern == "{}":
                        share_file["save_name"] = share_file["file_name"]  # ä¿æŒåŸæ–‡ä»¶åï¼Œç¨ååœ¨do_rename_taskä¸­å¤„ç†
                    else:
                        share_file["save_name"] = save_name
                    share_file["original_name"] = share_file["file_name"]  # ä¿å­˜åŸæ–‡ä»¶åï¼Œç”¨äºæ’åº
                    need_save_list.append(share_file)
                    current_sequence += 1
                else:
                    # print(f"è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶: {save_name}")
                    pass
                
                # æŒ‡å®šæ–‡ä»¶å¼€å§‹è®¢é˜…/åˆ°è¾¾æŒ‡å®šæ–‡ä»¶ï¼ˆå«ï¼‰ç»“æŸå†é
                if share_file["fid"] == task.get("startfid", ""):
                    break
                    
            # å¤„ç†å­æ–‡ä»¶å¤¹
            for share_file in share_file_list:
                if share_file["dir"] and task.get("update_subdir", False):
                    if re.search(task["update_subdir"], share_file["file_name"]):
                        print(f"æ£€æŸ¥å­æ–‡ä»¶å¤¹: {savepath}/{share_file['file_name']}")
                        subdir_tree = self.dir_check_and_save(
                            task,
                            pwd_id,
                            stoken,
                            share_file["fid"],
                            f"{subdir_path}/{share_file['file_name']}",
                        )
                        if subdir_tree.size(1) > 0:
                            # åˆå¹¶å­ç›®å½•æ ‘
                            tree.create_node(
                                "ğŸ“" + share_file["file_name"],
                                share_file["fid"],
                                parent=pdir_fid,
                                data={
                                    "is_dir": share_file["dir"],
                                },
                            )
                            tree.merge(share_file["fid"], subdir_tree, deep=False)
                
        else:
            # æ­£åˆ™å‘½åæ¨¡å¼
            need_save_list = []
            # æ·»åŠ ç¬¦åˆçš„
            for share_file in share_file_list:
                if share_file["dir"] and task.get("update_subdir", False):
                    pattern, replace = task["update_subdir"], ""
                else:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å‰§é›†å‘½åæ¨¡å¼
                    if task.get("use_episode_naming") and task.get("regex_pattern"):
                        # ä½¿ç”¨é¢„å…ˆå‡†å¤‡å¥½çš„æ­£åˆ™è¡¨è¾¾å¼
                        pattern = task["regex_pattern"]
                        replace = ""
                    else:
                        # æ™®é€šæ­£åˆ™å‘½åæ¨¡å¼
                        pattern, replace = self.magic_regex_func(
                            task.get("pattern", ""), task.get("replace", ""), task["taskname"]
                        )
                
                # ç¡®ä¿patternä¸ä¸ºç©ºï¼Œé¿å…æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯
                if not pattern:
                    pattern = ".*"
                    
                # æ­£åˆ™æ–‡ä»¶ååŒ¹é…
                try:
                    if re.search(pattern, share_file["file_name"]):
                        # æ›¿æ¢åçš„æ–‡ä»¶å
                        save_name = (
                            re.sub(pattern, replace, share_file["file_name"])
                            if replace != ""
                            else share_file["file_name"]
                        )
                        # å¿½ç•¥åç¼€
                        if task.get("ignore_extension") and not share_file["dir"]:
                            compare_func = lambda a, b1, b2: (
                                os.path.splitext(a)[0] == os.path.splitext(b1)[0]
                                or os.path.splitext(a)[0] == os.path.splitext(b2)[0]
                            )
                        else:
                            compare_func = lambda a, b1, b2: (a == b1 or a == b2)
                        # åˆ¤æ–­ç›®æ ‡ç›®å½•æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                        file_exists = False
                        for dir_file in dir_file_list:
                            if compare_func(
                                dir_file["file_name"], share_file["file_name"], save_name
                            ):
                                file_exists = True
                                # print(f"è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶: {dir_file['file_name']}")
                                # åˆ é™¤å¯¹æ–‡ä»¶æ‰“å°éƒ¨åˆ†
                                break
                                
                        if not file_exists:
                            # ä¸æ‰“å°ä¿å­˜ä¿¡æ¯
                            share_file["save_name"] = save_name
                            share_file["original_name"] = share_file["file_name"]  # ä¿å­˜åŸæ–‡ä»¶åï¼Œç”¨äºæ’åº
                            need_save_list.append(share_file)
                        elif share_file["dir"]:
                            # å­˜åœ¨å¹¶æ˜¯ä¸€ä¸ªæ–‡ä»¶å¤¹
                            if task.get("update_subdir", False):
                                if re.search(task["update_subdir"], share_file["file_name"]):
                                    print(f"æ£€æŸ¥å­æ–‡ä»¶å¤¹: {savepath}/{share_file['file_name']}")
                                    subdir_tree = self.dir_check_and_save(
                                        task,
                                        pwd_id,
                                        stoken,
                                        share_file["fid"],
                                        f"{subdir_path}/{share_file['file_name']}",
                                    )
                                    if subdir_tree.size(1) > 0:
                                        # åˆå¹¶å­ç›®å½•æ ‘
                                        tree.create_node(
                                            "ğŸ“" + share_file["file_name"],
                                            share_file["fid"],
                                            parent=pdir_fid,
                                            data={
                                                "is_dir": share_file["dir"],
                                            },
                                        )
                                        tree.merge(share_file["fid"], subdir_tree, deep=False)
                except Exception as e:
                    print(f"âš ï¸ æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯: {str(e)}, pattern: {pattern}")
                    # ä½¿ç”¨å®‰å…¨çš„é»˜è®¤å€¼
                    share_file["save_name"] = share_file["file_name"]
                    share_file["original_name"] = share_file["file_name"]
                    need_save_list.append(share_file)
                # æŒ‡å®šæ–‡ä»¶å¼€å§‹è®¢é˜…/åˆ°è¾¾æŒ‡å®šæ–‡ä»¶ï¼ˆå«ï¼‰ç»“æŸå†é
                if share_file["fid"] == task.get("startfid", ""):
                    break

        fid_list = [item["fid"] for item in need_save_list]
        fid_token_list = [item["share_fid_token"] for item in need_save_list]
        if fid_list:
            # åªåœ¨æœ‰æ–°æ–‡ä»¶éœ€è¦è½¬å­˜æ—¶æ‰å¤„ç†
            save_file_return = self.save_file(
                fid_list, fid_token_list, to_pdir_fid, pwd_id, stoken
            )
            err_msg = None
            if save_file_return["code"] == 0:
                task_id = save_file_return["data"]["task_id"]
                query_task_return = self.query_task(task_id)
                if query_task_return["code"] == 0:
                    # å»ºç«‹ç›®å½•æ ‘
                    saved_files = []
                    for index, item in enumerate(need_save_list):
                        icon = (
                            "ğŸ“"
                            if item["dir"] == True
                            else "ğŸï¸" if item["obj_category"] == "video" else ""
                        )
                        saved_files.append(f"{icon}{item['save_name']}")
                        tree.create_node(
                            f"{icon}{item['save_name']}",
                            item["fid"],
                            parent=pdir_fid,
                            data={
                                "fid": f"{query_task_return['data']['save_as']['save_as_top_fids'][index]}",
                                "path": f"{savepath}/{item['save_name']}",
                                "is_dir": item["dir"],
                            },
                        )
                    
                    # ç§»é™¤é€šçŸ¥ç”Ÿæˆï¼Œç”±do_saveå‡½æ•°ç»Ÿä¸€å¤„ç†
                    # é¡ºåºå‘½åæ¨¡å¼å’Œå‰§é›†å‘½åæ¨¡å¼éƒ½ä¸åœ¨æ­¤å¤„ç”Ÿæˆé€šçŸ¥
                else:
                    err_msg = query_task_return["message"]
            else:
                err_msg = save_file_return["message"]
            if err_msg:
                add_notify(f"âŒã€Š{task['taskname']}ã€‹è½¬å­˜å¤±è´¥ï¼š{err_msg}\n")
        else:
            # æ²¡æœ‰æ–°æ–‡ä»¶éœ€è¦è½¬å­˜
            if not subdir_path:  # åªåœ¨é¡¶å±‚ï¼ˆéå­ç›®å½•ï¼‰æ‰“å°ä¸€æ¬¡æ¶ˆæ¯
                pass
        return tree

    def do_rename_task(self, task, subdir_path=""):
        # æ£€æŸ¥æ˜¯å¦ä¸ºé¡ºåºå‘½åæ¨¡å¼
        if task.get("use_sequence_naming") and task.get("sequence_naming"):
            # ä½¿ç”¨é¡ºåºå‘½åæ¨¡å¼
            sequence_pattern = task["sequence_naming"]
            # æ›¿æ¢å ä½ç¬¦ä¸ºæ­£åˆ™è¡¨è¾¾å¼æ•è·ç»„
            if sequence_pattern == "{}":
                # å¯¹äºå•ç‹¬çš„{}ï¼Œä½¿ç”¨ç‰¹æ®ŠåŒ¹é…
                regex_pattern = "(\\d+)"
            else:
                regex_pattern = re.escape(sequence_pattern).replace('\\{\\}', '(\\d+)')
            
            savepath = re.sub(r"/{2,}", "/", f"/{task['savepath']}{subdir_path}")
            if not self.savepath_fid.get(savepath):
                # è·¯å¾„å·²å­˜åœ¨ï¼Œç›´æ¥è®¾ç½®fid
                self.savepath_fid[savepath] = self.get_fids([savepath])[0]["fid"]
            dir_file_list = self.ls_dir(self.savepath_fid[savepath])
            dir_file_name_list = [item["file_name"] for item in dir_file_list]
            
            # åˆ¤æ–­ç›®å½•æ˜¯å¦ä¸ºç©ºï¼ˆåªåŒ…å«éç›®å½•æ–‡ä»¶ï¼‰
            non_dir_files = [f for f in dir_file_list if not f.get("dir", False)]
            is_empty_dir = len(non_dir_files) == 0
            
            # æ‰¾å‡ºå½“å‰æœ€å¤§åºå·
            max_sequence = 0
            if not is_empty_dir:  # åªæœ‰åœ¨ç›®å½•éç©ºæ—¶æ‰å¯»æ‰¾æœ€å¤§åºå·
                for dir_file in dir_file_list:
                    if sequence_pattern == "{}":
                        # å¯¹äºå•ç‹¬çš„{}ï¼Œç›´æ¥å°è¯•åŒ¹é…æ•´ä¸ªæ–‡ä»¶åæ˜¯å¦ä¸ºæ•°å­—
                        file_name_without_ext = os.path.splitext(dir_file["file_name"])[0]
                        if file_name_without_ext.isdigit():
                            # å¢åŠ åˆ¤æ–­ï¼šå¦‚æœæ˜¯æ—¥æœŸæ ¼å¼çš„çº¯æ•°å­—ï¼Œä¸åº”è¢«è§†ä¸ºåºå·
                            if not is_date_format(file_name_without_ext):
                                try:
                                    current_seq = int(file_name_without_ext)
                                    max_sequence = max(max_sequence, current_seq)
                                except (ValueError, IndexError):
                                    pass
                    elif matches := re.match(regex_pattern, dir_file["file_name"]):
                        try:
                            current_seq = int(matches.group(1))
                            max_sequence = max(max_sequence, current_seq)
                        except (IndexError, ValueError):
                            pass
            
            # å®ç°é«˜çº§æ’åºç®—æ³•
            def extract_sorting_value(file):
                if file.get("dir", False):  # è·³è¿‡æ–‡ä»¶å¤¹
                    return float('inf')
                
                filename = file["file_name"]
                
                # æå–æ–‡ä»¶åï¼Œä¸å«æ‰©å±•å
                file_name_without_ext = os.path.splitext(filename)[0]
                
                # 1. "ç¬¬XæœŸ/é›†/è¯" æ ¼å¼
                match_chinese = re.search(r'ç¬¬(\d+)[æœŸé›†è¯]', filename)
                episode_num = int(match_chinese.group(1)) if match_chinese else 0
                
                # 5. æ–‡ä»¶åå«"ä¸Šä¸­ä¸‹"ï¼ˆä¼˜å…ˆå¤„ç†ï¼Œå› ä¸ºå¯èƒ½ä¸å…¶ä»–æ ¼å¼åŒæ—¶å­˜åœ¨ï¼‰
                if match_chinese:
                    # å¦‚æœåŒæ—¶å­˜åœ¨é›†æ•°å’Œä¸Šä¸­ä¸‹ï¼Œåˆ™æŒ‰ç…§é›†æ•°*10+ä½ç½®æ’åº
                    if 'ä¸Š' in filename:
                        return episode_num * 10 + 1
                    elif 'ä¸­' in filename:
                        return episode_num * 10 + 2
                    elif 'ä¸‹' in filename:
                        return episode_num * 10 + 3
                    return episode_num * 10
                elif 'ä¸Š' in filename:
                    return 1
                elif 'ä¸­' in filename:
                    return 2
                elif 'ä¸‹' in filename:
                    return 3
                
                # 2.1 S01E01 æ ¼å¼ï¼Œæå–å­£æ•°å’Œé›†æ•°
                match_s_e = re.search(r'[Ss](\d+)[Ee](\d+)', filename)
                if match_s_e:
                    season = int(match_s_e.group(1))
                    episode = int(match_s_e.group(2))
                    return season * 1000 + episode
                
                # 2.2 E01 æ ¼å¼ï¼Œä»…æå–é›†æ•°
                match_e = re.search(r'[Ee][Pp]?(\d+)', filename)
                if match_e:
                    return int(match_e.group(1))
                
                # 2.3 1x01 æ ¼å¼ï¼Œæå–å­£æ•°å’Œé›†æ•°
                match_x = re.search(r'(\d+)[Xx](\d+)', filename)
                if match_x:
                    season = int(match_x.group(1))
                    episode = int(match_x.group(2))
                    return season * 1000 + episode
                
                # 3. æ—¥æœŸæ ¼å¼è¯†åˆ«ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
                
                # 3.1 å®Œæ•´çš„YYYYMMDDæ ¼å¼
                match_date_compact = re.search(r'(20\d{2})(\d{2})(\d{2})', filename)
                if match_date_compact:
                    year = int(match_date_compact.group(1))
                    month = int(match_date_compact.group(2))
                    day = int(match_date_compact.group(3))
                    return year * 10000 + month * 100 + day
                
                # 3.2 YYYY-MM-DD æˆ– YYYY.MM.DD æˆ– YYYY/MM/DD æ ¼å¼
                match_date_full = re.search(r'(20\d{2})[-./](\d{1,2})[-./](\d{1,2})', filename)
                if match_date_full:
                    year = int(match_date_full.group(1))
                    month = int(match_date_full.group(2))
                    day = int(match_date_full.group(3))
                    return year * 10000 + month * 100 + day
                
                # 3.3 MM/DD/YYYY æˆ– DD/MM/YYYY æ ¼å¼
                match_date_alt = re.search(r'(\d{1,2})[-./](\d{1,2})[-./](20\d{2})', filename)
                if match_date_alt:
                    # å‡è®¾ç¬¬ä¸€ä¸ªæ˜¯æœˆï¼Œç¬¬äºŒä¸ªæ˜¯æ—¥ï¼ˆç¾å¼æ—¥æœŸï¼‰
                    month = int(match_date_alt.group(1))
                    day = int(match_date_alt.group(2))
                    year = int(match_date_alt.group(3))
                    # æ£€æŸ¥æœˆä»½å€¼ï¼Œå¦‚æœå¤§äº12å¯èƒ½æ˜¯æ¬§å¼æ—¥æœŸæ ¼å¼ï¼ˆDD/MM/YYYYï¼‰
                    if month > 12:
                        month, day = day, month
                    return year * 10000 + month * 100 + day
                
                # 3.4 MM/DD æ ¼å¼ï¼ˆæ— å¹´ä»½ï¼‰ï¼Œå‡è®¾ä¸ºå½“å‰å¹´
                match_date_short = re.search(r'(\d{1,2})[-./](\d{1,2})', filename)
                if match_date_short:
                    # å‡è®¾ç¬¬ä¸€ä¸ªæ˜¯æœˆï¼Œç¬¬äºŒä¸ªæ˜¯æ—¥
                    month = int(match_date_short.group(1))
                    day = int(match_date_short.group(2))
                    # æ£€æŸ¥æœˆä»½å€¼ï¼Œå¦‚æœå¤§äº12å¯èƒ½æ˜¯æ¬§å¼æ—¥æœŸæ ¼å¼ï¼ˆDD/MMï¼‰
                    if month > 12:
                        month, day = day, month
                    # ç”±äºæ²¡æœ‰å¹´ä»½ï¼Œä½¿ç”¨ä¸€ä¸ªè¾ƒä½çš„åŸºæ•°ï¼Œç¡®ä¿ä»»ä½•æœ‰å¹´ä»½çš„æ—¥æœŸéƒ½æ’åœ¨åé¢
                    return month * 100 + day
                
                # 3.5 å¹´æœŸæ ¼å¼ï¼Œå¦‚"2025å¹´14æœŸ"
                match_year_issue = re.search(r'(20\d{2})[å¹´].*?(\d+)[æœŸ]', filename)
                if match_year_issue:
                    year = int(match_year_issue.group(1))
                    issue = int(match_year_issue.group(2))
                    return year * 1000 + issue
                
                # 3.6 æ—¥æœŸ+æœŸæ•°çš„å¤åˆæ ¼å¼ï¼Œä¾‹å¦‚ï¼š2025-04-18 ç¬¬5æœŸä¸Š
                match_date_episode = re.search(r'(20\d{2})[-./](\d{1,2})[-./](\d{1,2}).*?ç¬¬(\d+)[æœŸé›†è¯]', filename)
                if match_date_episode:
                    year = int(match_date_episode.group(1))
                    month = int(match_date_episode.group(2))
                    day = int(match_date_episode.group(3))
                    episode = int(match_date_episode.group(4))
                    date_val = year * 10000 + month * 100 + day
                    # å°†æ—¥æœŸå€¼ä½œä¸ºä¸»æ’åºï¼ŒæœŸæ•°ä¸ºæ¬¡è¦æ’åº
                    if 'ä¸Š' in filename:
                        return date_val * 100 + episode * 10 + 1
                    elif 'ä¸­' in filename:
                        return date_val * 100 + episode * 10 + 2
                    elif 'ä¸‹' in filename:
                        return date_val * 100 + episode * 10 + 3
                    return date_val * 100 + episode * 10
                
                # 4. çº¯æ•°å­—æ ¼å¼ï¼ˆæ–‡ä»¶åå¼€å¤´æ˜¯çº¯æ•°å­—ï¼‰
                match_num = re.match(r'^(\d+)', file_name_without_ext)
                if match_num:
                    return int(match_num.group(1))
                
                # 5. å°è¯•åŒ¹é…æ–‡ä»¶åä¸­çš„ä»»ä½•æ•°å­—
                any_num_match = re.search(r'(\d+)', filename)
                if any_num_match:
                    return int(any_num_match.group(1))
                
                # 6. é»˜è®¤ä½¿ç”¨æ›´æ–°æ—¶é—´
                return file.get("created_at", file.get("updated_at", file.get("last_update_at", 0)))
            
            # åˆå§‹åŒ–sorted_filesåˆ—è¡¨ï¼Œç”¨äºæ”¶é›†éœ€è¦é‡å‘½åçš„æ–‡ä»¶
            sorted_files = []
            
            # å¯¹äºå•ç‹¬çš„{}æ¨¡å¼ï¼Œå¢åŠ é¢å¤–æ£€æŸ¥
            if sequence_pattern == "{}":
                # æ”¶é›†æ‰€æœ‰ä¸æ˜¯çº¯æ•°å­—å‘½åçš„æ–‡ä»¶
                for dir_file in dir_file_list:
                    if dir_file["dir"]:
                        continue  # è·³è¿‡æ–‡ä»¶å¤¹
                    
                    file_name_without_ext = os.path.splitext(dir_file["file_name"])[0]
                    # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦ä¸ºçº¯æ•°å­—ï¼Œå¦‚æœæ˜¯åˆ™è·³è¿‡ï¼ˆå·²ç»å‘½åå¥½çš„ï¼‰
                    if file_name_without_ext.isdigit():
                        # å¢åŠ åˆ¤æ–­ï¼šå¦‚æœæ˜¯æ—¥æœŸæ ¼å¼çš„çº¯æ•°å­—ï¼Œä¸è§†ä¸ºå·²å‘½å
                        if not is_date_format(file_name_without_ext):
                            # ä¸æ˜¯æ—¥æœŸæ ¼å¼ï¼Œæ˜¯çº¯æ•°å­—åºå·ï¼Œè·³è¿‡
                            continue
                        # æ˜¯æ—¥æœŸæ ¼å¼ï¼Œéœ€è¦é‡å‘½åï¼Œæ‰€ä»¥ä¸è·³è¿‡
                    
                    # æ·»åŠ åˆ°éœ€è¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
                    sorted_files.append(dir_file)
            else:
                # å¯¹äºéå•ç‹¬{}çš„æ¨¡å¼ï¼Œæ”¶é›†æ‰€æœ‰ä¸ç¬¦åˆæ¨¡å¼çš„æ–‡ä»¶
                for dir_file in dir_file_list:
                    if dir_file["dir"]:
                        continue  # è·³è¿‡æ–‡ä»¶å¤¹
                    
                    # æ£€æŸ¥æ˜¯å¦å·²ç¬¦åˆå‘½åæ¨¡å¼
                    if re.match(regex_pattern, dir_file["file_name"]):
                        continue  # è·³è¿‡å·²ç»ç¬¦åˆå‘½åè§„åˆ™çš„æ–‡ä»¶
                    
                    # æ·»åŠ åˆ°éœ€è¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
                    sorted_files.append(dir_file)
            
            # ä½¿ç”¨extract_sorting_valueå‡½æ•°å¯¹æ‰€æœ‰éœ€è¦å¤„ç†çš„æ–‡ä»¶è¿›è¡Œæ’åº
            sorted_files = sorted(sorted_files, key=extract_sorting_value)
            
            # æ”¶é›†æ‰€æœ‰éœ€è¦é‡å‘½åçš„æ–‡ä»¶ï¼Œå¹¶æŒ‰é¡ºåºå¤„ç†
            renamed_pairs = []
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æœ€å¤§åºå·ï¼Œä»1å¼€å§‹å‘½å
            if max_sequence == 0:
                current_sequence = 0  # ä¼šç«‹å³åŠ 1ï¼Œæ‰€ä»¥ä»0å¼€å§‹
            else:
                current_sequence = max_sequence
            
            # å¯¹æ’åºå¥½çš„æ–‡ä»¶åº”ç”¨é¡ºåºå‘½å
            for dir_file in sorted_files:
                current_sequence += 1
                file_ext = os.path.splitext(dir_file["file_name"])[1]
                # æ ¹æ®é¡ºåºå‘½åæ¨¡å¼ç”Ÿæˆæ–°çš„æ–‡ä»¶å
                if sequence_pattern == "{}":
                    # å¯¹äºå•ç‹¬çš„{}ï¼Œç›´æ¥ä½¿ç”¨æ•°å­—åºå·ä½œä¸ºæ–‡ä»¶åï¼Œä¸å†ä½¿ç”¨æ—¥æœŸæ ¼å¼
                    save_name = f"{current_sequence:02d}{file_ext}"
                else:
                    save_name = sequence_pattern.replace("{}", f"{current_sequence:02d}") + file_ext
                
                if save_name != dir_file["file_name"] and save_name not in dir_file_name_list:
                    # æ”¶é›†é‡å‘½åå¯¹ï¼ŒåŒ…å«åŸå§‹æ–‡ä»¶ä¿¡æ¯ä»¥ä¾¿æ’åº
                    renamed_pairs.append((dir_file, save_name, current_sequence))
                    dir_file_name_list.append(save_name)
            
            # ç¡®ä¿æŒ‰ç…§åºå·é¡ºåºæ‰§è¡Œé‡å‘½åæ“ä½œ
            renamed_pairs.sort(key=lambda x: x[2])
            
            is_rename_count = 0
            rename_logs = []  # åˆå§‹åŒ–é‡å‘½åæ—¥å¿—åˆ—è¡¨
            # æ‰§è¡Œé‡å‘½åï¼Œå¹¶æŒ‰é¡ºåºæ‰“å°
            for dir_file, save_name, _ in renamed_pairs:
                try:
                    rename_return = self.rename(dir_file["fid"], save_name)
                    # é˜²æ­¢ç½‘ç»œé—®é¢˜å¯¼è‡´çš„é”™è¯¯
                    if isinstance(rename_return, dict) and rename_return.get("code") == 0:
                        rename_log = f"é‡å‘½å: {dir_file['file_name']} â†’ {save_name}"
                        rename_logs.append(rename_log)
                        # ç§»é™¤ç›´æ¥æ‰“å°çš„éƒ¨åˆ†ï¼Œç”±do_saveè´Ÿè´£æ‰“å°
                        # print(rename_log)
                        is_rename_count += 1
                    else:
                        error_msg = rename_return.get("message", "æœªçŸ¥é”™è¯¯")
                        rename_log = f"é‡å‘½å: {dir_file['file_name']} â†’ {save_name} å¤±è´¥ï¼Œ{error_msg}"
                        rename_logs.append(rename_log)
                        # ç§»é™¤ç›´æ¥æ‰“å°çš„éƒ¨åˆ†ï¼Œç”±do_saveè´Ÿè´£æ‰“å°
                        # print(rename_log)
                except Exception as e:
                    rename_log = f"é‡å‘½åå‡ºé”™: {dir_file['file_name']} â†’ {save_name}ï¼Œé”™è¯¯ï¼š{str(e)}"
                    rename_logs.append(rename_log)
                    # ç§»é™¤ç›´æ¥æ‰“å°çš„éƒ¨åˆ†ï¼Œç”±do_saveè´Ÿè´£æ‰“å°
                    # print(rename_log)
            
            return is_rename_count > 0, rename_logs

        # æ£€æŸ¥æ˜¯å¦ä¸ºå‰§é›†å‘½åæ¨¡å¼
        elif task.get("use_episode_naming") and task.get("episode_naming"):
            # ä½¿ç”¨å‰§é›†å‘½åæ¨¡å¼
            episode_pattern = task["episode_naming"]
            regex_pattern = task.get("regex_pattern")
            
            # è·å–ç›®å½•æ–‡ä»¶åˆ—è¡¨ - æ·»åŠ è¿™è¡Œä»£ç åˆå§‹åŒ–dir_file_list
            savepath = re.sub(r"/{2,}", "/", f"/{task['savepath']}{subdir_path}")
            if not self.savepath_fid.get(savepath):
                # è·¯å¾„å·²å­˜åœ¨ï¼Œç›´æ¥è®¾ç½®fid
                savepath_fids = self.get_fids([savepath])
                if not savepath_fids:
                    print(f"ä¿å­˜è·¯å¾„ä¸å­˜åœ¨ï¼Œå‡†å¤‡æ–°å»ºï¼š{savepath}")
                    mkdir_result = self.mkdir(savepath)
                    if mkdir_result["code"] == 0:
                        self.savepath_fid[savepath] = mkdir_result["data"]["fid"]
                        print(f"ä¿å­˜è·¯å¾„æ–°å»ºæˆåŠŸï¼š{savepath}")
                    else:
                        print(f"ä¿å­˜è·¯å¾„æ–°å»ºå¤±è´¥ï¼š{mkdir_result['message']}")
                        return False, []
                else:
                    self.savepath_fid[savepath] = savepath_fids[0]["fid"]
            
            dir_file_list = self.ls_dir(self.savepath_fid[savepath])
            
            # æ„å»ºç›®æ ‡ç›®å½•ä¸­æ‰€æœ‰æ–‡ä»¶çš„æŸ¥é‡ç´¢å¼•ï¼ˆæŒ‰å¤§å°å’Œä¿®æ”¹æ—¶é—´ï¼‰
            dir_files_map = {}
            for dir_file in dir_file_list:
                if not dir_file["dir"]:  # ä»…å¤„ç†æ–‡ä»¶
                    file_size = dir_file.get("size", 0)
                    file_ext = os.path.splitext(dir_file["file_name"])[1].lower()
                    update_time = dir_file.get("updated_at", 0)
                    
                    # åˆ›å»ºå¤§å°+æ‰©å±•åçš„ç´¢å¼•ï¼Œç”¨äºå¿«é€ŸæŸ¥é‡
                    key = f"{file_size}_{file_ext}"
                    if key not in dir_files_map:
                        dir_files_map[key] = []
                    dir_files_map[key].append({
                        "file_name": dir_file["file_name"],
                        "updated_at": update_time,
                    })
            
            # å®ç°åºå·æå–å‡½æ•°
            def extract_episode_number(filename):
                # ä¼˜å…ˆåŒ¹é…SxxExxæ ¼å¼
                match_s_e = re.search(r'[Ss](\d+)[Ee](\d+)', filename)
                if match_s_e:
                    # ç›´æ¥è¿”å›Eåé¢çš„é›†æ•°
                    return int(match_s_e.group(2))
                
                # å…¶æ¬¡åŒ¹é…E01æ ¼å¼
                match_e = re.search(r'[Ee][Pp]?(\d+)', filename)
                if match_e:
                    return int(match_e.group(1))
                
                # å°è¯•åŒ¹é…æ›´å¤šæ ¼å¼
                default_patterns = [
                    r'(\d+)',
                    r'(\d+)[-_\s]*4[Kk]',
                    r'(\d+)è¯',
                    r'ç¬¬(\d+)è¯',
                    r'ç¬¬(\d+)é›†',
                    r'ç¬¬(\d+)æœŸ',
                    r'(\d+)\s+4[Kk]',
                    r'(\d+)[_\s]4[Kk]',
                    r'ã€(\d+)ã€‘',
                    r'\[(\d+)\]',
                    r'_?(\d+)_'
                ]
                
                # å¦‚æœé…ç½®äº†è‡ªå®šä¹‰è§„åˆ™ï¼Œä¼˜å…ˆä½¿ç”¨
                if "config_data" in task and isinstance(task["config_data"].get("episode_patterns"), list) and task["config_data"]["episode_patterns"]:
                    patterns = [p.get("regex", "(\\d+)") for p in task["config_data"]["episode_patterns"]]
                else:
                    # å°è¯•ä»å…¨å±€é…ç½®è·å–
                    global CONFIG_DATA
                    if isinstance(CONFIG_DATA.get("episode_patterns"), list) and CONFIG_DATA["episode_patterns"]:
                        patterns = [p.get("regex", "(\\d+)") for p in CONFIG_DATA["episode_patterns"]]
                    else:
                        patterns = default_patterns
                
                # å°è¯•ä½¿ç”¨æ¯ä¸ªæ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ–‡ä»¶å
                for pattern_regex in patterns:
                    try:
                        match = re.search(pattern_regex, filename)
                        if match:
                            return int(match.group(1))
                    except:
                        continue
                return None
                
            # æ‰¾å‡ºå·²å‘½åçš„æ–‡ä»¶åˆ—è¡¨ï¼Œé¿å…é‡å¤è½¬å­˜
            existing_episode_numbers = set()
            for dir_file in dir_file_list:
                if not dir_file["dir"] and regex_pattern:
                    try:
                        matches = re.match(regex_pattern, dir_file["file_name"])
                        if matches:
                            episode_num = int(matches.group(1))
                            existing_episode_numbers.add(episode_num)
                    except:
                        pass
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ä»åˆ†äº«é“¾æ¥è·å–æ•°æ®
            if task.get("shareurl"):
                try:
                    # æå–é“¾æ¥å‚æ•°
                    pwd_id, passcode, pdir_fid, paths = self.extract_url(task["shareurl"])
                    if not pwd_id:
                        print(f"æå–é“¾æ¥å‚æ•°å¤±è´¥ï¼Œè¯·æ£€æŸ¥åˆ†äº«é“¾æ¥æ˜¯å¦æœ‰æ•ˆ")
                        return False, []
                    
                    # è·å–åˆ†äº«è¯¦æƒ…
                    is_sharing, stoken = self.get_stoken(pwd_id, passcode)
                    if not is_sharing:
                        print(f"åˆ†äº«è¯¦æƒ…è·å–å¤±è´¥ï¼š{stoken}")
                        return False, []
                    
                    # è·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨
                    share_file_list = self.get_detail(pwd_id, stoken, pdir_fid)["list"]
                    if not share_file_list:
                        print("åˆ†äº«ä¸ºç©ºï¼Œæ–‡ä»¶å·²è¢«åˆ†äº«è€…åˆ é™¤")
                        return False, []
                    
                    # é¢„å…ˆè¿‡æ»¤åˆ†äº«æ–‡ä»¶åˆ—è¡¨ï¼Œå»é™¤å·²å­˜åœ¨çš„æ–‡ä»¶
                    filtered_share_files = []
                    for share_file in share_file_list:
                        if share_file["dir"]:
                            # å¤„ç†å­ç›®å½•
                            if task.get("update_subdir") and re.search(task["update_subdir"], share_file["file_name"]):
                                filtered_share_files.append(share_file)
                            continue
                            
                        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆåŸºäºå¤§å°å’Œä¿®æ”¹æ—¶é—´ï¼‰
                        file_size = share_file.get("size", 0)
                        file_ext = os.path.splitext(share_file["file_name"])[1].lower()
                        share_update_time = share_file.get("last_update_at", 0)
                        
                        key = f"{file_size}_{file_ext}"
                        is_duplicate = False
                        
                        if key in dir_files_map:
                            for existing_file in dir_files_map[key]:
                                existing_update_time = existing_file.get("updated_at", 0)
                                if (abs(share_update_time - existing_update_time) < 2592000 or 
                                    abs(1 - (share_update_time / existing_update_time if existing_update_time else 1)) < 0.1):
                                    is_duplicate = True
                                    break
                        
                        # æ£€æŸ¥å‰§é›†å·æ˜¯å¦å·²ç»å­˜åœ¨
                        episode_num = extract_episode_number(share_file["file_name"])
                        if episode_num is not None and episode_num in existing_episode_numbers:
                            # print(f"è·³è¿‡å·²å­˜åœ¨çš„å‰§é›†å·: {episode_num} ({share_file['file_name']})")
                            is_duplicate = True
                        
                        # ç”Ÿæˆé¢„æœŸçš„ç›®æ ‡æ–‡ä»¶åå¹¶æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                        if episode_num is not None and not is_duplicate:
                            file_ext = os.path.splitext(share_file["file_name"])[1]
                            expected_name = episode_pattern.replace("[]", f"{episode_num:02d}") + file_ext
                            # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶åæ˜¯å¦å­˜åœ¨äºç›®å½•ä¸­
                            if any(dir_file["file_name"] == expected_name for dir_file in dir_file_list):
                                # print(f"è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶å: {expected_name}")
                                is_duplicate = True
                        
                        # åªå¤„ç†éé‡å¤æ–‡ä»¶
                        if not is_duplicate:
                            filtered_share_files.append(share_file)
                        
                        # æŒ‡å®šæ–‡ä»¶å¼€å§‹è®¢é˜…/åˆ°è¾¾æŒ‡å®šæ–‡ä»¶ï¼ˆå«ï¼‰ç»“æŸå†é
                        if share_file["fid"] == task.get("startfid", ""):
                            break
                    
                    # å®ç°é«˜çº§æ’åºç®—æ³•
                    def sort_by_episode(file):
                        if file["dir"]:
                            return (float('inf'), 0)
                        
                        filename = file["file_name"]
                        
                        # ä¼˜å…ˆåŒ¹é…S01E01æ ¼å¼
                        match_s_e = re.search(r'[Ss](\d+)[Ee](\d+)', filename)
                        if match_s_e:
                            season = int(match_s_e.group(1))
                            episode = int(match_s_e.group(2))
                            return (season * 1000 + episode, 0)
                            
                        # å…¶ä»–åŒ¹é…æ–¹å¼
                        episode_num = extract_episode_number(filename)
                        if episode_num is not None:
                            return (episode_num, 0)
                            
                        # æ— æ³•è¯†åˆ«ï¼Œä½¿ç”¨ä¿®æ”¹æ—¶é—´
                        return (float('inf'), file.get("last_update_at", 0))
                        
                    # è¿‡æ»¤å‡ºæ–‡ä»¶å¹¶æ’åº
                    files_to_process = [f for f in filtered_share_files if not f["dir"]]
                    sorted_files = sorted(files_to_process, key=sort_by_episode)
                    
                    # è¦ä¿å­˜çš„æ–‡ä»¶åˆ—è¡¨
                    need_save_list = []
                    
                    # ç”Ÿæˆæ–‡ä»¶åå¹¶æ·»åŠ åˆ°åˆ—è¡¨
                    for share_file in sorted_files:
                        episode_num = extract_episode_number(share_file["file_name"])
                        if episode_num is not None:
                            # ç”Ÿæˆæ–°æ–‡ä»¶å
                            file_ext = os.path.splitext(share_file["file_name"])[1]
                            save_name = episode_pattern.replace("[]", f"{episode_num:02d}") + file_ext
                            
                            # æ£€æŸ¥è¿‡æ»¤è¯
                            should_filter = False
                            if task.get("filterwords"):
                                # åŒæ—¶æ”¯æŒä¸­è‹±æ–‡é€—å·åˆ†éš”
                                filterwords = task["filterwords"].replace("ï¼Œ", ",")
                                filterwords_list = [word.strip().lower() for word in filterwords.split(',')]
                                
                                # æ£€æŸ¥åŸå§‹æ–‡ä»¶å
                                original_name_lower = share_file["file_name"].lower()
                                if any(word in original_name_lower for word in filterwords_list):
                                    should_filter = True
                                
                                # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶å
                                save_name_lower = save_name.lower()
                                if any(word in save_name_lower for word in filterwords_list):
                                    should_filter = True
                                
                                # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
                                file_ext_lower = file_ext.lower().lstrip('.')
                                if any(word == file_ext_lower for word in filterwords_list):
                                    should_filter = True
                            
                            # åªå¤„ç†ä¸éœ€è¦è¿‡æ»¤çš„æ–‡ä»¶
                            if not should_filter:
                                # æ·»åŠ åˆ°ä¿å­˜åˆ—è¡¨
                                share_file["save_name"] = save_name
                                share_file["original_name"] = share_file["file_name"]
                                need_save_list.append(share_file)
                        else:
                            # æ— æ³•æå–é›†å·ï¼Œä½¿ç”¨åŸæ–‡ä»¶åï¼ˆä»ç„¶æ£€æŸ¥è¿‡æ»¤è¯ï¼‰
                            # æ£€æŸ¥è¿‡æ»¤è¯
                            should_filter = False
                            if task.get("filterwords"):
                                # åŒæ—¶æ”¯æŒä¸­è‹±æ–‡é€—å·åˆ†éš”
                                filterwords = task["filterwords"].replace("ï¼Œ", ",")
                                filterwords_list = [word.strip().lower() for word in filterwords.split(',')]
                                
                                # æ£€æŸ¥åŸå§‹æ–‡ä»¶å
                                original_name_lower = share_file["file_name"].lower()
                                if any(word in original_name_lower for word in filterwords_list):
                                    should_filter = True
                                
                                # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
                                file_ext = os.path.splitext(share_file["file_name"])[1].lower()
                                file_ext_lower = file_ext.lstrip('.')
                                if any(word == file_ext_lower for word in filterwords_list):
                                    should_filter = True
                            
                            # åªå¤„ç†ä¸éœ€è¦è¿‡æ»¤çš„æ–‡ä»¶
                            if not should_filter:
                                share_file["save_name"] = share_file["file_name"]
                                share_file["original_name"] = share_file["file_name"]
                                need_save_list.append(share_file)
                    
                    # ä¿å­˜æ–‡ä»¶
                    if need_save_list:
                        fid_list = [item["fid"] for item in need_save_list]
                        fid_token_list = [item["share_fid_token"] for item in need_save_list]
                        save_file_return = self.save_file(
                            fid_list, fid_token_list, self.savepath_fid[savepath], pwd_id, stoken
                        )
                        if save_file_return["code"] == 0:
                            task_id = save_file_return["data"]["task_id"]
                            query_task_return = self.query_task(task_id)
                            
                            if query_task_return["code"] == 0:
                                # è¿›è¡Œé‡å‘½åæ“ä½œï¼Œç¡®ä¿æ–‡ä»¶æŒ‰ç…§é¢„è§ˆåç§°ä¿å­˜
                                time.sleep(1)  # ç­‰å¾…æ–‡ä»¶ä¿å­˜å®Œæˆ
                                
                                # åˆ·æ–°ç›®å½•åˆ—è¡¨ä»¥è·å–æ–°ä¿å­˜çš„æ–‡ä»¶
                                fresh_dir_file_list = self.ls_dir(self.savepath_fid[savepath])
                                
                                # åˆ›å»ºä¸€ä¸ªæ˜ å°„æ¥å­˜å‚¨åŸå§‹æ–‡ä»¶ååˆ°ä¿å­˜é¡¹çš„æ˜ å°„
                                original_name_to_item = {}
                                for saved_item in need_save_list:
                                    # ä½¿ç”¨æ–‡ä»¶åå‰ç¼€ä½œä¸ºé”®ï¼Œå¤„ç†å¯èƒ½çš„æ–‡ä»¶åå˜åŒ–
                                    file_prefix = saved_item["original_name"].split(".")[0]
                                    original_name_to_item[file_prefix] = saved_item
                                    # åŒæ—¶ä¿å­˜å®Œæ•´æ–‡ä»¶åçš„æ˜ å°„
                                    original_name_to_item[saved_item["original_name"]] = saved_item
                                
                                # åˆ›å»ºä¸€ä¸ªåˆ—è¡¨æ¥æ”¶é›†æ‰€æœ‰é‡å‘½åæ“ä½œ
                                rename_operations = []
                                
                                # é¦–å…ˆå°è¯•ä½¿ç”¨å‰§é›†å·è¿›è¡Œæ™ºèƒ½åŒ¹é…
                                for dir_file in fresh_dir_file_list:
                                    if dir_file["dir"]:
                                        continue
                                        
                                        # ä»æ–‡ä»¶åä¸­æå–å‰§é›†å·
                                        episode_num = extract_episode_number(dir_file["file_name"])
                                        if episode_num is None:
                                            continue
                                        
                                        # æŸ¥æ‰¾å¯¹åº”çš„ç›®æ ‡æ–‡ä»¶
                                        for saved_item in need_save_list:
                                            saved_episode_num = extract_episode_number(saved_item["original_name"])
                                            if saved_episode_num == episode_num:
                                                # åŒ¹é…åˆ°å¯¹åº”çš„å‰§é›†å·
                                                target_name = saved_item["save_name"]
                                                # ç¡®ä¿ç›®æ ‡åç§°ä¸é‡å¤
                                                if target_name not in [f["file_name"] for f in fresh_dir_file_list]:
                                                    # æ”¶é›†é‡å‘½åæ“ä½œè€Œä¸æ˜¯ç«‹å³æ‰§è¡Œ
                                                    rename_operations.append((dir_file, target_name, episode_num))
                                                    break
                                                else:
                                                    # å¦‚æœç›®æ ‡æ–‡ä»¶åå·²å­˜åœ¨ï¼Œå°è¯•åŠ ä¸Šåºå·
                                                    name_base, ext = os.path.splitext(target_name)
                                                    alt_name = f"{name_base} ({episode_num}){ext}"
                                                    if alt_name not in [f["file_name"] for f in fresh_dir_file_list]:
                                                        # æ”¶é›†é‡å‘½åæ“ä½œè€Œä¸æ˜¯ç«‹å³æ‰§è¡Œ
                                                        rename_operations.append((dir_file, alt_name, episode_num))
                                                        break
                                
                                # å¯¹äºæœªèƒ½é€šè¿‡å‰§é›†å·åŒ¹é…çš„æ–‡ä»¶ï¼Œå°è¯•ä½¿ç”¨æ–‡ä»¶ååŒ¹é…
                                for dir_file in fresh_dir_file_list:
                                    if dir_file["dir"]:
                                        continue
                                    
                                    # å¦‚æœå·²ç»æœ‰é‡å‘½åæ“ä½œï¼Œè·³è¿‡
                                    if any(op[0]["fid"] == dir_file["fid"] for op in rename_operations):
                                        continue
                                    
                                    # å°è¯•ç²¾ç¡®åŒ¹é…
                                    if dir_file["file_name"] in original_name_to_item:
                                        saved_item = original_name_to_item[dir_file["file_name"]]
                                        target_name = saved_item["save_name"]
                                        episode_num = extract_episode_number(saved_item["original_name"]) or 9999
                                        
                                        if target_name not in [f["file_name"] for f in fresh_dir_file_list]:
                                            # æ”¶é›†é‡å‘½åæ“ä½œ
                                            rename_operations.append((dir_file, target_name, episode_num))
                                        continue
                                    
                                    # å°è¯•æ¨¡ç³ŠåŒ¹é…ï¼ˆä½¿ç”¨æ–‡ä»¶åå‰ç¼€ï¼‰
                                    dir_file_prefix = dir_file["file_name"].split(".")[0]
                                    for prefix, saved_item in list(original_name_to_item.items()):
                                        if prefix in dir_file_prefix or dir_file_prefix in prefix:
                                            # æ‰¾åˆ°ç›¸ä¼¼çš„æ–‡ä»¶å
                                            target_name = saved_item["save_name"]
                                            episode_num = extract_episode_number(saved_item["original_name"]) or 9999
                                            if target_name not in [f["file_name"] for f in fresh_dir_file_list]:
                                                # æ”¶é›†é‡å‘½åæ“ä½œ
                                                rename_operations.append((dir_file, target_name, episode_num))
                                                original_name_to_item.pop(prefix, None)  # é¿å…é‡å¤ä½¿ç”¨
                                                break
                                
                                # æŒ‰å‰§é›†å·æ’åºé‡å‘½åæ“ä½œ
                                rename_operations.sort(key=lambda x: x[2])
                                
                                # æ‰§è¡Œæ’åºåçš„é‡å‘½åæ“ä½œï¼Œä½†ä¸ç«‹å³æ‰“å°æ—¥å¿—
                                renamed_count = 0
                                rename_logs = []  # æ”¶é›†é‡å‘½åæ—¥å¿—
                                for dir_file, target_name, _ in rename_operations:
                                    rename_result = self.rename(dir_file["fid"], target_name)
                                    if rename_result["code"] == 0:
                                        # æ”¶é›†æ—¥å¿—ä½†ä¸æ‰“å°
                                        rename_logs.append(f"é‡å‘½å: {dir_file['file_name']} â†’ {target_name}")
                                        renamed_count += 1
                                        # æ›´æ–°æ–‡ä»¶åˆ—è¡¨ä¸­çš„æ–‡ä»¶åï¼Œé˜²æ­¢é‡ååˆ¤æ–­å‡ºé”™
                                        for df in fresh_dir_file_list:
                                            if df["fid"] == dir_file["fid"]:
                                                df["file_name"] = target_name
                                                break
                                    else:
                                        # æ”¶é›†é”™è¯¯æ—¥å¿—ä½†ä¸æ‰“å°
                                        rename_logs.append(f"é‡å‘½å: {dir_file['file_name']} â†’ {target_name} å¤±è´¥ï¼Œ{rename_result['message']}")
                                
                                if renamed_count > 0:
                                    # print(f"âœ… æˆåŠŸé‡å‘½å {renamed_count} ä¸ªæ–‡ä»¶")
                                    pass
                                
                                # è¿”å›é‡å‘½åæ—¥å¿—å’ŒæˆåŠŸæ ‡å¿—
                                return True, rename_logs
                            else:
                                err_msg = query_task_return["message"]
                                add_notify(f"âŒã€Š{task['taskname']}ã€‹è½¬å­˜å¤±è´¥ï¼š{err_msg}\n")
                                return False, []
                        else:
                            print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {save_file_return['message']}")
                            add_notify(f"âŒã€Š{task['taskname']}ã€‹è½¬å­˜å¤±è´¥ï¼š{save_file_return['message']}\n")
                            return False, []
                    else:
                        # print("æ²¡æœ‰éœ€è¦ä¿å­˜çš„æ–°æ–‡ä»¶")
                        return False, []
                except Exception as e:
                    print(f"å¤„ç†åˆ†äº«é“¾æ¥æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                    add_notify(f"âŒã€Š{task['taskname']}ã€‹å¤„ç†åˆ†äº«é“¾æ¥æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}\n")
                    return False, []

            # å¯¹æœ¬åœ°å·²æœ‰æ–‡ä»¶è¿›è¡Œé‡å‘½åï¼ˆå³ä½¿æ²¡æœ‰åˆ†äº«é“¾æ¥æˆ–å¤„ç†å¤±è´¥ä¹Ÿæ‰§è¡Œï¼‰
            is_rename_count = 0
            renamed_files = []
            
            # ä½¿ç”¨ä¸€ä¸ªåˆ—è¡¨æ”¶é›†æ‰€æœ‰éœ€è¦é‡å‘½åçš„æ“ä½œ
            rename_operations = []
            rename_logs = []  # æ”¶é›†é‡å‘½åæ—¥å¿—
            
            # ç­›é€‰å‡ºéœ€è¦é‡å‘½åçš„æ–‡ä»¶
            for dir_file in dir_file_list:
                if dir_file["dir"]:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å‘½å
                episode_num = extract_episode_number(dir_file["file_name"])
                if episode_num is not None:
                    # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦ç¬¦åˆæŒ‡å®šçš„å‰§é›†å‘½åæ ¼å¼
                    if not re.match(regex_pattern, dir_file["file_name"]):
                        file_ext = os.path.splitext(dir_file["file_name"])[1]
                        new_name = episode_pattern.replace("[]", f"{episode_num:02d}") + file_ext
                        rename_operations.append((dir_file, new_name, episode_num))
            
            # æŒ‰å‰§é›†å·æ’åº
            rename_operations.sort(key=lambda x: x[2])
            
            # æ‰§è¡Œé‡å‘½åæ“ä½œï¼Œä½†ä¸ç«‹å³æ‰“å°æ—¥å¿—
            for dir_file, new_name, _ in rename_operations:
                # é˜²æ­¢é‡å
                if new_name not in [f["file_name"] for f in dir_file_list]:
                    try:
                        rename_return = self.rename(dir_file["fid"], new_name)
                        if rename_return["code"] == 0:
                            # æ”¶é›†æ—¥å¿—ä½†ä¸æ‰“å°
                            rename_logs.append(f"é‡å‘½å: {dir_file['file_name']} â†’ {new_name}")
                            is_rename_count += 1
                            # æ›´æ–°dir_file_listä¸­çš„æ–‡ä»¶åï¼Œé˜²æ­¢åç»­é‡ååˆ¤æ–­å‡ºé”™
                            for df in dir_file_list:
                                if df["fid"] == dir_file["fid"]:
                                    df["file_name"] = new_name
                                    break
                        else:
                            # æ”¶é›†é”™è¯¯æ—¥å¿—ä½†ä¸æ‰“å°
                            rename_logs.append(f"é‡å‘½å: {dir_file['file_name']} â†’ {new_name} å¤±è´¥ï¼Œ{rename_return['message']}")
                    except Exception as e:
                        # æ”¶é›†é”™è¯¯æ—¥å¿—ä½†ä¸æ‰“å°
                        rename_logs.append(f"é‡å‘½åå‡ºé”™: {dir_file['file_name']} â†’ {new_name}ï¼Œé”™è¯¯ï¼š{str(e)}")
            
            # è¿”å›é‡å‘½åæ—¥å¿—å’ŒæˆåŠŸæ ‡å¿—
            return (is_rename_count > 0), rename_logs

        # æ­£åˆ™æ¨¡å¼æˆ–æ— ç‰¹æ®Šå‘½åæ¨¡å¼ï¼Œç›´æ¥è¿”å›ç©ºç»“æœ
        else:
            # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åˆ™æ¨¡å¼çš„é…ç½®
            pattern = task.get("pattern", "")
            replace = task.get("replace", "")
            
            # å¦‚æœæ²¡æœ‰è®¾ç½®æ­£åˆ™åŒ¹é…æ¨¡å¼ï¼Œç›´æ¥è¿”å›ç©ºç»“æœ
            if not pattern:
                return False, []
            
            # è·å–é­”æ³•æ­£åˆ™å¤„ç†åçš„çœŸå®è§„åˆ™
            pattern, replace = self.magic_regex_func(pattern, replace, task["taskname"])
            
            # è·å–ç›®å½•æ–‡ä»¶åˆ—è¡¨
            savepath = re.sub(r"/{2,}", "/", f"/{task['savepath']}{subdir_path}")
            if not self.savepath_fid.get(savepath):
                # è·¯å¾„ä¸å­˜åœ¨ï¼Œåˆ›å»ºæˆ–è·å–fid
                savepath_fids = self.get_fids([savepath])
                if not savepath_fids:
                    print(f"ä¿å­˜è·¯å¾„ä¸å­˜åœ¨ï¼Œå‡†å¤‡æ–°å»ºï¼š{savepath}")
                    mkdir_result = self.mkdir(savepath)
                    if mkdir_result["code"] == 0:
                        self.savepath_fid[savepath] = mkdir_result["data"]["fid"]
                        print(f"ä¿å­˜è·¯å¾„æ–°å»ºæˆåŠŸï¼š{savepath}")
                    else:
                        print(f"ä¿å­˜è·¯å¾„æ–°å»ºå¤±è´¥ï¼š{mkdir_result['message']}")
                        return False, []
                else:
                    self.savepath_fid[savepath] = savepath_fids[0]["fid"]
            
            # è·å–ç›®å½•ä¸­çš„æ–‡ä»¶åˆ—è¡¨
            dir_file_list = self.ls_dir(self.savepath_fid[savepath])
            
            # ä½¿ç”¨ä¸€ä¸ªåˆ—è¡¨æ”¶é›†æ‰€æœ‰éœ€è¦é‡å‘½åçš„æ“ä½œ
            rename_operations = []
            rename_logs = []  # æ”¶é›†é‡å‘½åæ—¥å¿—
            is_rename_count = 0
            
            # éå†ç›®å½•ä¸­çš„æ–‡ä»¶ï¼Œæ‰¾å‡ºç¬¦åˆæ­£åˆ™æ¡ä»¶çš„
            for dir_file in dir_file_list:
                if dir_file["dir"]:
                    continue  # è·³è¿‡æ–‡ä»¶å¤¹
                
                # åº”ç”¨æ­£åˆ™è¡¨è¾¾å¼
                try:
                    new_name = re.sub(pattern, replace, dir_file["file_name"])
                    
                    # å¦‚æœæ–‡ä»¶åå‘ç”Ÿå˜åŒ–ï¼Œéœ€è¦é‡å‘½å
                    if new_name != dir_file["file_name"]:
                        rename_operations.append((dir_file, new_name))
                except Exception as e:
                    print(f"æ­£åˆ™æ›¿æ¢å‡ºé”™: {dir_file['file_name']}ï¼Œé”™è¯¯ï¼š{str(e)}")
            
            # æŒ‰åŸå§‹æ–‡ä»¶åå­—æ¯é¡ºåºæ’åºï¼Œä½¿é‡å‘½åæ“ä½œæœ‰åºè¿›è¡Œ
            rename_operations.sort(key=lambda x: x[0]["file_name"])
            
            # æ‰§è¡Œé‡å‘½åæ“ä½œï¼Œå¹¶æ”¶é›†æ—¥å¿—
            for dir_file, new_name in rename_operations:
                # æ£€æŸ¥æ˜¯å¦ä¼šå¯¼è‡´é‡å
                if new_name not in [f["file_name"] for f in dir_file_list]:
                    try:
                        rename_return = self.rename(dir_file["fid"], new_name)
                        if rename_return["code"] == 0:
                            # æ”¶é›†æ—¥å¿—ä½†ä¸æ‰“å°
                            rename_logs.append(f"é‡å‘½å: {dir_file['file_name']} â†’ {new_name}")
                            is_rename_count += 1
                            # æ›´æ–°dir_file_listä¸­çš„æ–‡ä»¶åï¼Œé˜²æ­¢åç»­é‡ååˆ¤æ–­å‡ºé”™
                            for df in dir_file_list:
                                if df["fid"] == dir_file["fid"]:
                                    df["file_name"] = new_name
                                    break
                        else:
                            # æ”¶é›†é”™è¯¯æ—¥å¿—ä½†ä¸æ‰“å°
                            error_msg = rename_return.get("message", "æœªçŸ¥é”™è¯¯")
                            rename_logs.append(f"é‡å‘½å: {dir_file['file_name']} â†’ {new_name} å¤±è´¥ï¼Œ{error_msg}")
                    except Exception as e:
                        # æ”¶é›†é”™è¯¯æ—¥å¿—ä½†ä¸æ‰“å°
                        rename_logs.append(f"é‡å‘½åå‡ºé”™: {dir_file['file_name']} â†’ {new_name}ï¼Œé”™è¯¯ï¼š{str(e)}")
                else:
                    # é‡åè­¦å‘Š
                    rename_logs.append(f"é‡å‘½å: {dir_file['file_name']} â†’ {new_name} å¤±è´¥ï¼Œç›®æ ‡æ–‡ä»¶åå·²å­˜åœ¨")
            
            # è¿”å›é‡å‘½åæ—¥å¿—å’ŒæˆåŠŸæ ‡å¿—
            return (is_rename_count > 0), rename_logs


def verify_account(account):
    # éªŒè¯è´¦å·
    print(f"â–¶ï¸ éªŒè¯ç¬¬{account.index}ä¸ªè´¦å·")
    if "__uid" not in account.cookie:
        print(f"ğŸ’¡ ä¸å­˜åœ¨cookieå¿…è¦å‚æ•°ï¼Œåˆ¤æ–­ä¸ºä»…ç­¾åˆ°")
        return False
    else:
        account_info = account.init()
        if not account_info:
            add_notify(f"ğŸ‘¤ ç¬¬{account.index}ä¸ªè´¦å·ç™»å½•å¤±è´¥ï¼Œcookieæ— æ•ˆâŒ")
            return False
        else:
            print(f"ğŸ‘¤ è´¦å·æ˜µç§°: {account_info['nickname']}âœ…")
            return True


def format_bytes(size_bytes: int) -> str:
    units = ("B", "KB", "MB", "GB", "TB", "PB", "EB", "ZB", "YB")
    i = 0
    while size_bytes >= 1024 and i < len(units) - 1:
        size_bytes /= 1024
        i += 1
    return f"{size_bytes:.2f} {units[i]}"


def do_sign(account):
    if not account.mparam:
        print("â­ï¸ ç§»åŠ¨ç«¯å‚æ•°æœªè®¾ç½®ï¼Œè·³è¿‡ç­¾åˆ°")
        print()
        return
    # æ¯æ—¥é¢†ç©ºé—´
    growth_info = account.get_growth_info()
    if growth_info:
        growth_message = f"ğŸ’¾ {'88VIP' if growth_info['88VIP'] else 'æ™®é€šç”¨æˆ·'} æ€»ç©ºé—´ï¼š{format_bytes(growth_info['total_capacity'])}ï¼Œç­¾åˆ°ç´¯è®¡è·å¾—ï¼š{format_bytes(growth_info['cap_composition'].get('sign_reward', 0))}"
        if growth_info["cap_sign"]["sign_daily"]:
            sign_message = f"ğŸ“… ç­¾åˆ°è®°å½•: ä»Šæ—¥å·²ç­¾åˆ°+{int(growth_info['cap_sign']['sign_daily_reward']/1024/1024)}MBï¼Œè¿ç­¾è¿›åº¦({growth_info['cap_sign']['sign_progress']}/{growth_info['cap_sign']['sign_target']})âœ…"
            message = f"{sign_message}\n{growth_message}"
            print(message)
        else:
            sign, sign_return = account.get_growth_sign()
            if sign:
                sign_message = f"ğŸ“… æ‰§è¡Œç­¾åˆ°: ä»Šæ—¥ç­¾åˆ°+{int(sign_return/1024/1024)}MBï¼Œè¿ç­¾è¿›åº¦({growth_info['cap_sign']['sign_progress']+1}/{growth_info['cap_sign']['sign_target']})âœ…"
                message = f"{sign_message}\n{growth_message}"
                if (
                    str(
                        CONFIG_DATA.get("push_config", {}).get("QUARK_SIGN_NOTIFY")
                    ).lower()
                    == "false"
                    or os.environ.get("QUARK_SIGN_NOTIFY") == "false"
                ):
                    print(message)
                else:
                    message = message.replace("ä»Šæ—¥", f"[{account.nickname}]ä»Šæ—¥")
                    add_notify(message)
            else:
                print(f"ğŸ“… ç­¾åˆ°å¼‚å¸¸: {sign_return}")
    print()


def do_save(account, tasklist=[]):
    print(f"ğŸ§© è½½å…¥æ’ä»¶")
    plugins, CONFIG_DATA["plugins"], task_plugins_config = Config.load_plugins(
        CONFIG_DATA.get("plugins", {})
    )
    print(f"è½¬å­˜è´¦å·: {account.nickname}")
    # è·å–å…¨éƒ¨ä¿å­˜ç›®å½•fid
    account.update_savepath_fid(tasklist)

    def is_time(task):
        return (
            not task.get("enddate")
            or (
                datetime.now().date()
                <= datetime.strptime(task["enddate"], "%Y-%m-%d").date()
            )
        ) and (
            "runweek" not in task
            # æ˜ŸæœŸä¸€ä¸º0ï¼Œæ˜ŸæœŸæ—¥ä¸º6
            or (datetime.today().weekday() + 1 in task.get("runweek"))
        )

    # æ‰§è¡Œä»»åŠ¡
    for index, task in enumerate(tasklist):
        print()
        print(f"#{index+1}------------------")
        print(f"ä»»åŠ¡åç§°: {task['taskname']}")
        print(f"åˆ†äº«é“¾æ¥: {task['shareurl']}")
        print(f"ä¿å­˜è·¯å¾„: {task['savepath']}")
        # æ ¹æ®å‘½åæ¨¡å¼æ˜¾ç¤ºä¸åŒä¿¡æ¯
        if task.get("use_sequence_naming") and task.get("sequence_naming"):
            print(f"é¡ºåºå‘½å: {task['sequence_naming']}")
        elif task.get("use_episode_naming") and task.get("episode_naming"):
            print(f"å‰§é›†å‘½å: {task['episode_naming']}")
        else:
            # æ­£åˆ™å‘½åæ¨¡å¼
            if task.get("pattern") is not None:  # ä¿®æ”¹ä¸ºåˆ¤æ–­æ˜¯å¦ä¸ºNoneï¼Œè€Œéæ˜¯å¦ä¸ºçœŸå€¼
                print(f"æ­£åˆ™åŒ¹é…: {task['pattern']}")
            if task.get("replace") is not None:  # æ˜¾ç¤ºæ›¿æ¢è§„åˆ™ï¼Œå³ä½¿ä¸ºç©ºå­—ç¬¦ä¸²
                print(f"æ­£åˆ™æ›¿æ¢: {task['replace']}")
        if task.get("update_subdir"):
            print(f"æ›´å­ç›®å½•: {task['update_subdir']}")
        if task.get("runweek") or task.get("enddate"):
            print(
                f"è¿è¡Œå‘¨æœŸ: WK{task.get('runweek',[])} ~ {task.get('enddate','forever')}"
            )
        print()
        # åˆ¤æ–­ä»»åŠ¡å‘¨æœŸ
        if not is_time(task):
            print(f"ä»»åŠ¡ä¸åœ¨è¿è¡Œå‘¨æœŸå†…ï¼Œè·³è¿‡")
        else:
            # ä¿å­˜ä¹‹å‰çš„é€šçŸ¥ä¿¡æ¯
            global NOTIFYS
            notifys_before = NOTIFYS.copy()
            
            # æ‰§è¡Œä¿å­˜ä»»åŠ¡
            is_new_tree = account.do_save_task(task)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…é™¤é‡å¤çš„é€šçŸ¥
            # ç”±äºåœ¨ä¿®æ”¹é¡ºåºï¼Œç°åœ¨ä¸éœ€è¦ç‰¹æ®Šå¤„ç†é€šçŸ¥
            is_special_sequence = (task.get("use_sequence_naming") and task.get("sequence_naming")) or (task.get("use_episode_naming") and task.get("episode_naming"))
            
            # æ‰§è¡Œé‡å‘½åä»»åŠ¡ï¼Œä½†æ”¶é›†æ—¥å¿—è€Œä¸æ˜¯ç«‹å³æ‰“å°
            is_rename, rename_logs = account.do_rename_task(task)
            
            # æ·»åŠ ç”Ÿæˆæ–‡ä»¶æ ‘çš„åŠŸèƒ½ï¼ˆæ— è®ºæ˜¯å¦æ˜¯é¡ºåºå‘½åæ¨¡å¼ï¼‰
            # å¦‚æœis_new_treeè¿”å›äº†Treeå¯¹è±¡ï¼Œåˆ™æ‰“å°æ–‡ä»¶æ ‘
            if is_new_tree and isinstance(is_new_tree, Tree) and is_new_tree.size() > 1:
                # è·å–æ‰€æœ‰æ–‡ä»¶ï¼ˆéç›®å½•ï¼‰èŠ‚ç‚¹
                file_nodes = [node for node in is_new_tree.all_nodes_itr() if node.data.get("is_dir") == False]
                
                # è®¡ç®—æ–‡ä»¶æ•°é‡
                file_count = len(file_nodes)
                
                # åˆ›å»ºä¸€ä¸ªæ˜ å°„åˆ—è¡¨ï¼ŒåŒ…å«éœ€è¦æ˜¾ç¤ºçš„æ–‡ä»¶å
                display_files = []
                
                # æŒ‰æ–‡ä»¶åæ’åº
                if is_special_sequence:
                    # å¦‚æœæ˜¯é¡ºåºå‘½åæ¨¡å¼ï¼Œç›´æ¥ä½¿ç”¨é¡ºåºå‘½åæ¨¡å¼çš„æ¨¡æ¿æ¥æ˜¾ç¤º
                    sequence_pattern = task["sequence_naming"]
                    
                    # å¯¹äºæ¯ä¸ªæ–‡ä»¶ï¼Œç”Ÿæˆå…¶é‡å‘½ååçš„åç§°
                    for i, node in enumerate(file_nodes):
                        # æå–åºå·ï¼ˆä»1å¼€å§‹ï¼‰
                        file_num = i + 1
                        # è·å–åŸå§‹æ–‡ä»¶çš„æ‰©å±•å
                        orig_filename = node.tag.lstrip("ğŸï¸")
                        file_ext = os.path.splitext(orig_filename)[1]
                        # ç”Ÿæˆæ–°çš„æ–‡ä»¶åï¼ˆä½¿ç”¨é¡ºåºå‘½åæ¨¡å¼ï¼‰
                        if sequence_pattern == "{}":
                            # å¯¹äºå•ç‹¬çš„{}ï¼Œç›´æ¥ä½¿ç”¨æ•°å­—åºå·ä½œä¸ºæ–‡ä»¶å
                            new_filename = f"{file_num:02d}{file_ext}"
                        else:
                            new_filename = sequence_pattern.replace("{}", f"{file_num:02d}") + file_ext
                        # è·å–é€‚å½“çš„å›¾æ ‡
                        icon = get_file_icon(orig_filename, is_dir=node.data.get("is_dir", False))
                        # æ·»åŠ åˆ°æ˜¾ç¤ºåˆ—è¡¨
                        display_files.append((f"{icon}{new_filename}", node))
                    
                    # æŒ‰æ•°å­—æ’åº
                    display_files.sort(key=lambda x: int(os.path.splitext(x[0].lstrip("ğŸï¸"))[0]) if os.path.splitext(x[0].lstrip("ğŸï¸"))[0].isdigit() else float('inf'))
                
                elif task.get("use_episode_naming") and task.get("episode_naming"):
                    # å‰§é›†å‘½åæ¨¡å¼
                    episode_pattern = task["episode_naming"]
                    
                    # æå–åºå·çš„å‡½æ•°
                    def extract_episode_number(filename):
                        # ä¼˜å…ˆåŒ¹é…SxxExxæ ¼å¼
                        match_s_e = re.search(r'[Ss](\d+)[Ee](\d+)', filename)
                        if match_s_e:
                            return int(match_s_e.group(2))
                        
                        # å…¶æ¬¡åŒ¹é…E01æ ¼å¼
                        match_e = re.search(r'[Ee][Pp]?(\d+)', filename)
                        if match_e:
                            return int(match_e.group(1))
                        
                        # å°è¯•åŒ¹é…æ›´å¤šæ ¼å¼
                        patterns = [
                            r'(\d+)',
                            r'(\d+)[-_\s]*4[Kk]',
                            r'(\d+)è¯',
                            r'ç¬¬(\d+)è¯',
                            r'ç¬¬(\d+)é›†',
                            r'ç¬¬(\d+)æœŸ',
                            r'(\d+)\s+4[Kk]',
                            r'(\d+)[_\s]4[Kk]',
                            r'ã€(\d+)ã€‘',
                            r'\[(\d+)\]',
                            r'_?(\d+)_'
                        ]
                        
                        for pattern_regex in patterns:
                            try:
                                match = re.search(pattern_regex, filename)
                                if match:
                                    return int(match.group(1))
                            except:
                                continue
                        return None
                    
                    # å¯¹äºæ¯ä¸ªæ–‡ä»¶èŠ‚ç‚¹ï¼Œç”Ÿæˆé¢„æœŸçš„å‰§é›†å‘½åæ ¼å¼
                    for node in file_nodes:
                        # è·å–åŸå§‹æ–‡ä»¶å
                        orig_filename = node.tag.lstrip("ğŸï¸")
                        # æå–å‰§é›†å·
                        episode_num = extract_episode_number(orig_filename)
                        if episode_num is not None:
                            # è·å–æ‰©å±•å
                            file_ext = os.path.splitext(orig_filename)[1]
                            # ç”Ÿæˆæ–°çš„æ–‡ä»¶åï¼ˆä½¿ç”¨å‰§é›†å‘½åæ¨¡å¼ï¼‰
                            new_filename = episode_pattern.replace("[]", f"{episode_num:02d}") + file_ext
                            # è·å–é€‚å½“çš„å›¾æ ‡
                            icon = get_file_icon(orig_filename, is_dir=node.data.get("is_dir", False))
                            # æ·»åŠ åˆ°æ˜¾ç¤ºåˆ—è¡¨
                            display_files.append((f"{icon}{new_filename}", node))
                        else:
                            # å¦‚æœæ— æ³•æå–å‰§é›†å·ï¼Œä¿ç•™åŸå§‹æ–‡ä»¶å
                            orig_filename = node.tag.lstrip("ğŸï¸")
                            icon = get_file_icon(orig_filename, is_dir=node.data.get("is_dir", False))
                            display_files.append((f"{icon}{orig_filename}", node))
                    
                    # æŒ‰å‰§é›†å·æ’åº
                    display_files.sort(
                        key=lambda x: extract_episode_number(x[0]) if extract_episode_number(x[0]) is not None else float('inf')
                    )
                
                else:
                    # æ­£åˆ™æ¨¡å¼æˆ–å…¶ä»–æ¨¡å¼ï¼šå°è¯•æ˜¾ç¤ºæ­£åˆ™æ›¿æ¢åçš„æ–‡ä»¶å
                    if task.get("pattern") and task.get("replace") is not None:
                        # è·å–æ­£åˆ™æ¨¡å¼
                        pattern, replace = account.magic_regex_func(
                            task.get("pattern", ""), task.get("replace", ""), task["taskname"]
                        )
                        
                        # å¯¹æ–‡ä»¶ååº”ç”¨æ­£åˆ™æ›¿æ¢
                        for node in file_nodes:
                            orig_filename = node.tag.lstrip("ğŸï¸")
                            try:
                                # åº”ç”¨æ­£åˆ™è¡¨è¾¾å¼
                                new_name = re.sub(pattern, replace, orig_filename)
                                # ä¸ºæ–‡ä»¶æ·»åŠ å›¾æ ‡
                                icon = get_file_icon(orig_filename, is_dir=node.data.get("is_dir", False))
                                display_files.append((f"{icon}{new_name}", node))
                            except Exception as e:
                                # å¦‚æœæ­£åˆ™æ›¿æ¢å¤±è´¥ï¼Œä½¿ç”¨åŸæ–‡ä»¶å
                                icon = get_file_icon(orig_filename, is_dir=node.data.get("is_dir", False))
                                display_files.append((f"{icon}{orig_filename}", node))
                    else:
                        # ä½¿ç”¨å­—æ¯é¡ºåºå’ŒåŸå§‹æ–‡ä»¶å
                        display_files = []
                        for node in sorted(file_nodes, key=lambda node: node.tag):
                            # è·å–åŸå§‹æ–‡ä»¶åï¼ˆå»é™¤å·²æœ‰å›¾æ ‡ï¼‰
                            orig_filename = node.tag.lstrip("ğŸï¸")
                            # æ·»åŠ é€‚å½“çš„å›¾æ ‡
                            icon = get_file_icon(orig_filename, is_dir=node.data.get("is_dir", False))
                            display_files.append((f"{icon}{orig_filename}", node))
                
                # æ·»åŠ æˆåŠŸé€šçŸ¥
                add_notify(f"âœ…ã€Š{task['taskname']}ã€‹ æ·»åŠ è¿½æ›´:")
                add_notify(f"/{task['savepath']}")
                
                # æ‰“å°ä¿å­˜æ–‡ä»¶åˆ—è¡¨
                for idx, (display_name, _) in enumerate(display_files):
                    prefix = "â”œâ”€â”€ " if idx < len(display_files) - 1 else "â””â”€â”€ "
                    add_notify(f"{prefix}{display_name}")
                add_notify("")
            
            # å¦‚æœæ˜¯å‰§é›†å‘½åæ¨¡å¼å¹¶ä¸”æˆåŠŸè¿›è¡Œäº†é‡å‘½åï¼Œå•ç‹¬æ˜¾ç¤ºæ’åºå¥½çš„æ–‡ä»¶åˆ—è¡¨
            elif is_rename and task.get("use_episode_naming") and task.get("episode_naming"):
                # é‡æ–°è·å–æ–‡ä»¶åˆ—è¡¨
                savepath = re.sub(r"/{2,}", "/", f"/{task['savepath']}")
                dir_file_list = account.ls_dir(account.savepath_fid[savepath])
                
                # è¿‡æ»¤å‡ºéç›®å½•çš„æ–‡ä»¶
                file_nodes = [f for f in dir_file_list if not f["dir"]]
                
                # è®¡ç®—æ–‡ä»¶æ•°é‡
                file_count = len(file_nodes)
                
                # æå–åºå·çš„å‡½æ•°
                def extract_episode_number(filename):
                    # ä¼˜å…ˆåŒ¹é…SxxExxæ ¼å¼
                    match_s_e = re.search(r'[Ss](\d+)[Ee](\d+)', filename)
                    if match_s_e:
                        return int(match_s_e.group(2))
                    
                    # å…¶æ¬¡åŒ¹é…E01æ ¼å¼
                    match_e = re.search(r'[Ee][Pp]?(\d+)', filename)
                    if match_e:
                        return int(match_e.group(1))
                    
                    # å°è¯•åŒ¹é…æ›´å¤šæ ¼å¼
                    patterns = [
                        r'(\d+)',
                        r'(\d+)[-_\s]*4[Kk]',
                        r'(\d+)è¯',
                        r'ç¬¬(\d+)è¯',
                        r'ç¬¬(\d+)é›†',
                        r'ç¬¬(\d+)æœŸ',
                        r'(\d+)\s+4[Kk]',
                        r'(\d+)[_\s]4[Kk]',
                        r'ã€(\d+)ã€‘',
                        r'\[(\d+)\]',
                        r'_?(\d+)_'
                    ]
                    
                    for pattern_regex in patterns:
                        try:
                            match = re.search(pattern_regex, filename)
                            if match:
                                return int(match.group(1))
                        except:
                            continue
                    return None
                
                # åˆ›å»ºä¸€ä¸ªæ˜ å°„åˆ—è¡¨ï¼ŒåŒ…å«æ’åºåçš„æ–‡ä»¶
                display_files = []
                episode_pattern = task["episode_naming"]
                regex_pattern = task.get("regex_pattern")
                
                # æ‰¾å‡ºç¬¦åˆå‰§é›†å‘½åæ ¼å¼çš„æ–‡ä»¶
                for file in file_nodes:
                    if re.match(regex_pattern, file["file_name"]):
                        display_files.append(file["file_name"])
                
                # æŒ‰å‰§é›†å·æ’åº
                display_files.sort(
                    key=lambda x: extract_episode_number(x) if extract_episode_number(x) is not None else float('inf')
                )
                
                # æ·»åŠ æˆåŠŸé€šçŸ¥
                add_notify(f"âœ…ã€Š{task['taskname']}ã€‹ æ·»åŠ è¿½æ›´:")
                if file_count > 0:
                    add_notify(f"/{task['savepath']}")
                    
                    # æ‰“å°æ–‡ä»¶åˆ—è¡¨
                    for idx, file_name in enumerate(display_files):
                        prefix = "â”œâ”€â”€ " if idx < len(display_files) - 1 else "â””â”€â”€ "
                        file_info = file_nodes[next((i for i, f in enumerate(file_nodes) if f["file_name"] == file_name), 0)]
                        icon = get_file_icon(file_name, is_dir=file_info.get("dir", False))
                        add_notify(f"{prefix}{icon}{file_name}")
                else:
                    add_notify(f"/{task['savepath']} (ç©ºç›®å½•)")
                add_notify("")
            
            # å¦‚æœæ˜¯æ­£åˆ™æ¨¡å¼ä¸”æˆåŠŸé‡å‘½åï¼Œæ˜¾ç¤ºé‡å‘½ååçš„æ–‡ä»¶åˆ—è¡¨
            elif is_rename and task.get("pattern") and task.get("replace") is not None:
                # é‡æ–°è·å–æ–‡ä»¶åˆ—è¡¨
                savepath = re.sub(r"/{2,}", "/", f"/{task['savepath']}")
                dir_file_list = account.ls_dir(account.savepath_fid[savepath])
                
                # è¿‡æ»¤å‡ºéç›®å½•çš„æ–‡ä»¶
                file_nodes = [f for f in dir_file_list if not f["dir"]]
                
                # è®¡ç®—æ–‡ä»¶æ•°é‡
                file_count = len(file_nodes)
                
                # è·å–æ­£åˆ™æ¨¡å¼å’Œæ›¿æ¢è§„åˆ™
                pattern, replace = account.magic_regex_func(
                    task.get("pattern", ""), task.get("replace", ""), task["taskname"]
                )
                
                # åˆ›å»ºæ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
                display_files = []
                for file in file_nodes:
                    # å°è¯•åº”ç”¨æ­£åˆ™æ›¿æ¢ï¼Œæ˜¾ç¤ºæ›¿æ¢åçš„åç§°
                    try:
                        new_name = re.sub(pattern, replace, file["file_name"])
                        # ä¸ºæ–‡ä»¶æ·»åŠ å›¾æ ‡
                        icon = get_file_icon(file["file_name"], is_dir=file.get("dir", False))
                        display_files.append((f"{icon}{new_name}", file))
                    except Exception as e:
                        # å¦‚æœæ­£åˆ™æ›¿æ¢å¤±è´¥ï¼Œä½¿ç”¨åŸå
                        icon = get_file_icon(file["file_name"], is_dir=file.get("dir", False))
                        display_files.append((f"{icon}{file['file_name']}", file))
                
                # æŒ‰æ–‡ä»¶åæ’åº
                display_files.sort(key=lambda x: x[0])
                
                # æ·»åŠ æˆåŠŸé€šçŸ¥ï¼Œå¸¦æ–‡ä»¶æ•°é‡å›¾æ ‡
                add_notify(f"âœ…ã€Š{task['taskname']}ã€‹ æ·»åŠ è¿½æ›´:")
                if file_count > 0:
                    add_notify(f"/{task['savepath']}")
                    
                    # æ‰“å°æ–‡ä»¶åˆ—è¡¨
                    for idx, (display_name, _) in enumerate(display_files):
                        prefix = "â”œâ”€â”€ " if idx < len(display_files) - 1 else "â””â”€â”€ "
                        add_notify(f"{prefix}{display_name}")
                else:
                    add_notify(f"/{task['savepath']} (ç©ºç›®å½•)")
                add_notify("")
            
            # ç°åœ¨æ‰“å°é‡å‘½åæ—¥å¿—
            if rename_logs:
                # å¯¹é‡å‘½åæ—¥å¿—è¿›è¡Œæ’åºï¼Œç¡®ä¿æŒ‰ç…§æ–°æ–‡ä»¶åçš„é¡ºåºæ˜¾ç¤º
                sorted_rename_logs = []
                for log in rename_logs:
                    # æå–æ–°æ–‡ä»¶åï¼ˆæ ¼å¼ï¼šé‡å‘½å: æ—§å â†’ æ–°åï¼‰
                    match = re.search(r'â†’\s+(\d+\.\w+)', log)
                    if match:
                        new_name = match.group(1)
                        # æå–åºå·
                        seq_match = re.match(r'(\d+)', new_name)
                        seq_num = int(seq_match.group(1)) if seq_match else 999
                        sorted_rename_logs.append((seq_num, log))
                    else:
                        # æœªæ‰¾åˆ°åºå·çš„æ—¥å¿—æ”¾åœ¨æœ€å
                        sorted_rename_logs.append((999, log))
                
                # æŒ‰åºå·æ’åº
                sorted_rename_logs.sort(key=lambda x: x[0])
                
                # æ‰“å°æ’åºåçš„æ—¥å¿—
                for _, log in sorted_rename_logs:
                    print(log)
            else:
                # åŸå§‹é€»è¾‘ï¼šç›´æ¥æ‰“å°æ‰€æœ‰æ—¥å¿—
                for log in rename_logs:
                    print(log)
            
            # è¡¥å……ä»»åŠ¡çš„æ’ä»¶é…ç½®
            def merge_dicts(a, b):
                result = a.copy()
                for key, value in b.items():
                    if (
                        key in result
                        and isinstance(result[key], dict)
                        and isinstance(value, dict)
                    ):
                        result[key] = merge_dicts(result[key], value)
                    elif key not in result:
                        result[key] = value
                return result

            task["addition"] = merge_dicts(
                task.get("addition", {}), task_plugins_config
            )
            
            # ä¸ºä»»åŠ¡æ·»åŠ å‰§é›†æ¨¡å¼é…ç½®
            if task.get("use_episode_naming") and task.get("episode_naming"):
                task["config_data"] = {
                    "episode_patterns": CONFIG_DATA.get("episode_patterns", [])
                }
            # è°ƒç”¨æ’ä»¶
            if is_new_tree or is_rename:
                print()
                print(f"ğŸ§© è°ƒç”¨æ’ä»¶")
                for plugin_name, plugin in plugins.items():
                    if plugin.is_active and (is_new_tree or is_rename):
                        task = (
                            plugin.run(task, account=account, tree=is_new_tree) or task
                        )
            elif is_new_tree is False:  # æ˜ç¡®æ²¡æœ‰æ–°æ–‡ä»¶
                print(f"ä»»åŠ¡å®Œæˆï¼šæ²¡æœ‰æ–°çš„æ–‡ä»¶éœ€è¦è½¬å­˜")
                print()
    print()


def main():
    global CONFIG_DATA
    start_time = datetime.now()
    print(f"===============ç¨‹åºå¼€å§‹===============")
    print(f"â° æ‰§è¡Œæ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    # è¯»å–å¯åŠ¨å‚æ•°
    config_path = sys.argv[1] if len(sys.argv) > 1 else "quark_config.json"
    # ä»ç¯å¢ƒå˜é‡ä¸­è·å– TASKLIST
    tasklist_from_env = []
    if tasklist_json := os.environ.get("TASKLIST"):
        try:
            tasklist_from_env = json.loads(tasklist_json)
        except Exception as e:
            print(f"ä»ç¯å¢ƒå˜é‡è§£æä»»åŠ¡åˆ—è¡¨å¤±è´¥ {e}")
    # æ£€æŸ¥æœ¬åœ°æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨å°±ä¸‹è½½
    if not os.path.exists(config_path):
        if os.environ.get("QUARK_COOKIE"):
            print(
                f"âš™ï¸ è¯»å–åˆ° QUARK_COOKIE ç¯å¢ƒå˜é‡ï¼Œä»…ç­¾åˆ°é¢†ç©ºé—´ã€‚å¦‚éœ€æ‰§è¡Œè½¬å­˜ï¼Œè¯·åˆ é™¤è¯¥ç¯å¢ƒå˜é‡åé…ç½® {config_path} æ–‡ä»¶"
            )
            cookie_val = os.environ.get("QUARK_COOKIE")
            cookie_form_file = False
        else:
            print(f"âš™ï¸ é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨âŒï¼Œæ­£è¿œç¨‹ä»ä¸‹è½½é…ç½®æ¨¡ç‰ˆ")
            config_url = f"{GH_PROXY}https://raw.githubusercontent.com/Cp0204/quark_auto_save/main/quark_config.json"
            if Config.download_file(config_url, config_path):
                print("âš™ï¸ é…ç½®æ¨¡ç‰ˆä¸‹è½½æˆåŠŸâœ…ï¼Œè¯·åˆ°ç¨‹åºç›®å½•ä¸­æ‰‹åŠ¨é…ç½®")
            return
    else:
        print(f"âš™ï¸ æ­£ä» {config_path} æ–‡ä»¶ä¸­è¯»å–é…ç½®")
        CONFIG_DATA = Config.read_json(config_path)
        Config.breaking_change_update(CONFIG_DATA)
        cookie_val = CONFIG_DATA.get("cookie")
        if not CONFIG_DATA.get("magic_regex"):
            CONFIG_DATA["magic_regex"] = MAGIC_REGEX
        cookie_form_file = True
    # è·å–cookie
    cookies = Config.get_cookies(cookie_val)
    if not cookies:
        print("âŒ cookie æœªé…ç½®")
        return
    accounts = [Quark(cookie, index) for index, cookie in enumerate(cookies)]
    # ç­¾åˆ°
    print(f"===============ç­¾åˆ°ä»»åŠ¡===============")
    if tasklist_from_env:
        verify_account(accounts[0])
    else:
        for account in accounts:
            verify_account(account)
            do_sign(account)
    print()
    # è½¬å­˜
    if accounts[0].is_active and cookie_form_file:
        print(f"===============è½¬å­˜ä»»åŠ¡===============")
        # ä»»åŠ¡åˆ—è¡¨
        if tasklist_from_env:
            do_save(accounts[0], tasklist_from_env)
        else:
            do_save(accounts[0], CONFIG_DATA.get("tasklist", []))
        print()
    # é€šçŸ¥
    if NOTIFYS:
        notify_body = "\n".join(NOTIFYS)
        print(f"===============æ¨é€é€šçŸ¥===============")
        send_ql_notify("ã€å¤¸å…‹è‡ªåŠ¨è¿½æ›´ã€‘", notify_body)
        print()
    if cookie_form_file:
        # æ›´æ–°é…ç½®
        Config.write_json(config_path, CONFIG_DATA)

    print(f"===============ç¨‹åºç»“æŸ===============")
    duration = datetime.now() - start_time
    print(f"ğŸ˜ƒ è¿è¡Œæ—¶é•¿: {round(duration.total_seconds(), 2)}s")
    print()


if __name__ == "__main__":
    main()
